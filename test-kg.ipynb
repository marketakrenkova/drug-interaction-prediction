{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating my KG on OGB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from kg_model import KG_model\n",
    "\n",
    "from ogb.linkproppred import Evaluator, PygLinkPropPredDataset\n",
    "\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline, pipeline_from_config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([   0,    0,    0,  ..., 4266, 4266, 4266]),\n",
       "             col=tensor([   4,    6,    7,  ..., 3953, 3972, 4014]),\n",
       "             size=(4267, 4267), nnz=2135822, density=11.73%)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "data.adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge': tensor([[4039, 2424],\n",
       "         [4039,  225],\n",
       "         [4039, 3901],\n",
       "         ...,\n",
       "         [ 647,  708],\n",
       "         [ 708,  338],\n",
       "         [ 835, 3554]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "train_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101882, 2])\n",
      "torch.Size([133489, 2])\n"
     ]
    }
   ],
   "source": [
    "print(valid_edge['edge_neg'].shape)\n",
    "print(valid_edge['edge'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "        data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "        create_inverse_triples=True,\n",
    "        entity_to_id=None,\n",
    "        relation_to_id=None,\n",
    "        compact_id=False \n",
    "    )\n",
    "\n",
    "    print(tf_data.mapped_triples)\n",
    "\n",
    "    return tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,  667],\n",
      "        [   0,    0, 1182],\n",
      "        [   0,    0, 1280],\n",
      "        ...,\n",
      "        [4266,    0, 4250],\n",
      "        [4266,    0, 4252],\n",
      "        [4266,    0, 4260]])\n",
      "tensor([[   0,    0,  729],\n",
      "        [   1,    0,  681],\n",
      "        [   1,    0,  768],\n",
      "        ...,\n",
      "        [3812,    0, 3722],\n",
      "        [3812,    0, 3758],\n",
      "        [3812,    0, 3802]])\n",
      "tensor([[   0,    0,    3],\n",
      "        [   0,    0,  185],\n",
      "        [   0,    0,  187],\n",
      "        ...,\n",
      "        [1611,    0, 1562],\n",
      "        [1611,    0, 1573],\n",
      "        [1611,    0, 1601]])\n"
     ]
    }
   ],
   "source": [
    "# add relation type - interacts with\n",
    "\n",
    "train = train_edge['edge']\n",
    "train = torch.tensor([[x[0], 0, x[1]] for x in train])\n",
    "train_df = pd.DataFrame(train, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "valid = valid_edge['edge']\n",
    "valid = torch.tensor([[x[0], 0, x[1]] for x in valid])\n",
    "valid_df = pd.DataFrame(valid, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "valid_neg = valid_edge['edge_neg']\n",
    "valid_neg = torch.tensor([[x[0], 0, x[1]] for x in valid_neg])\n",
    "\n",
    "test = test_edge['edge']\n",
    "test = torch.tensor([[x[0], 0, x[1]] for x in test])\n",
    "test_df = pd.DataFrame(test, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "test_neg = test_edge['edge_neg']\n",
    "test_neg = torch.tensor([[x[0], 0, x[1]] for x in test_neg])\n",
    "\n",
    "train_tf = convert_to_triples_factory(train_df)\n",
    "valid_tf = convert_to_triples_factory(valid_df)\n",
    "test_tf = convert_to_triples_factory(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset split to txt files\n",
    "\n",
    "dir_data_my_split = 'dataset/ogbl_ddi-my_split/'\n",
    "\n",
    "train_df.to_csv(dir_data_my_split + 'train.txt', sep='\\t', header=False, index=False)\n",
    "valid_df.to_csv(dir_data_my_split + 'valid.txt', sep='\\t', header=False, index=False)\n",
    "test_df.to_csv(dir_data_my_split + 'test.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train my KG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kg = KG_model('TransE', train_tf, valid_tf, test_tf, 'ogb')\n",
    "model_kg.set_params(20, 'Adam', RankBasedEvaluator, 'gpu')\n",
    "print('Training...')\n",
    "model_kg.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'metadata': dict(\n",
    "        title='TransE model - best config'\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        training = train_tf,\n",
    "        validation = valid_tf,\n",
    "        testing = test_tf,\n",
    "        model='TransE',\n",
    "        model_kwargs=dict(\n",
    "               embedding_dim=150,\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.001),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1.3),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=32),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=9),\n",
    "        evaluator='rankbased',\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=32),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 1166338746.\n",
      "INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "Training epochs on cuda:0:   0%|                     | 0/100 [00:00<?, ?epoch/s]INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 12/66745 [00:00<09:17, 119.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 60/66745 [00:00<03:21, 330.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 113/66745 [00:00<02:39, 418.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 166/66745 [00:00<02:24, 461.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 219/66745 [00:00<02:17, 483.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 276/66745 [00:00<02:09, 511.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 335/66745 [00:00<02:03, 536.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 395/66745 [00:00<01:59, 554.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 455/66745 [00:00<01:57, 566.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 515/66745 [00:01<01:55, 573.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 575/66745 [00:01<01:54, 579.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 635/66745 [00:01<01:53, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 695/66745 [00:01<01:52, 585.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 755/66745 [00:01<01:52, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 815/66745 [00:01<01:51, 588.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 875/66745 [00:01<01:51, 590.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 935/66745 [00:01<01:51, 590.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 995/66745 [00:01<01:51, 591.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1055/66745 [00:01<01:51, 591.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1115/66745 [00:02<01:50, 593.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1177/66745 [00:02<01:49, 598.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1237/66745 [00:02<01:49, 597.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1297/66745 [00:02<01:49, 596.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1357/66745 [00:02<01:49, 594.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1417/66745 [00:02<01:49, 594.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1477/66745 [00:02<01:49, 594.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1537/66745 [00:02<01:51, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1596/66745 [00:02<01:52, 580.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1655/66745 [00:02<01:52, 577.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1713/66745 [00:03<01:54, 569.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1773/66745 [00:03<01:52, 576.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1833/66745 [00:03<01:51, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1893/66745 [00:03<01:50, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1953/66745 [00:03<01:50, 588.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2013/66745 [00:03<01:49, 590.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2073/66745 [00:03<01:49, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2133/66745 [00:03<01:49, 590.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2193/66745 [00:03<01:49, 590.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2253/66745 [00:03<01:49, 591.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2313/66745 [00:04<01:48, 591.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2373/66745 [00:04<01:48, 591.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2433/66745 [00:04<01:48, 592.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2493/66745 [00:04<01:48, 590.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2555/66745 [00:04<01:47, 596.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2615/66745 [00:04<01:48, 591.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2675/66745 [00:04<01:48, 591.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2735/66745 [00:04<01:48, 590.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2795/66745 [00:04<01:51, 575.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2853/66745 [00:04<01:53, 562.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2910/66745 [00:05<01:55, 553.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2966/66745 [00:05<01:56, 547.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3021/66745 [00:05<01:57, 543.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3076/66745 [00:05<01:58, 537.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3130/66745 [00:05<01:58, 535.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3184/66745 [00:05<01:58, 534.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3238/66745 [00:05<01:59, 532.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3294/66745 [00:05<01:57, 540.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3354/66745 [00:05<01:54, 555.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3414/66745 [00:06<01:51, 565.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3474/66745 [00:06<01:50, 573.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3534/66745 [00:06<01:49, 578.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3594/66745 [00:06<01:48, 582.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3653/66745 [00:06<01:49, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3712/66745 [00:06<01:49, 577.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3771/66745 [00:06<01:48, 580.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3830/66745 [00:06<01:48, 582.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3889/66745 [00:06<01:47, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3948/66745 [00:06<01:49, 573.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4007/66745 [00:07<01:48, 576.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4067/66745 [00:07<01:47, 580.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4127/66745 [00:07<01:47, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4187/66745 [00:07<01:46, 586.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4246/66745 [00:07<01:47, 580.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4305/66745 [00:07<01:47, 580.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4364/66745 [00:07<01:47, 582.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4423/66745 [00:07<01:46, 583.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4482/66745 [00:07<01:46, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4541/66745 [00:07<01:48, 572.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4601/66745 [00:08<01:47, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4661/66745 [00:08<01:46, 581.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4721/66745 [00:08<01:46, 584.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4781/66745 [00:08<01:45, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4840/66745 [00:08<01:46, 579.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4899/66745 [00:08<01:46, 580.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4958/66745 [00:08<01:47, 574.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5018/66745 [00:08<01:46, 581.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5079/66745 [00:08<01:44, 587.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5139/66745 [00:08<01:44, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5199/66745 [00:09<01:44, 590.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5259/66745 [00:09<01:43, 591.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5319/66745 [00:09<01:43, 592.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5379/66745 [00:09<01:43, 592.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5439/66745 [00:09<01:43, 592.21batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   8%|▍     | 5499/66745 [00:09<01:43, 592.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5559/66745 [00:09<01:43, 593.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5619/66745 [00:09<01:43, 592.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5679/66745 [00:09<01:43, 592.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5739/66745 [00:09<01:43, 592.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5799/66745 [00:10<01:42, 592.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5859/66745 [00:10<01:42, 592.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5919/66745 [00:10<01:42, 592.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5979/66745 [00:10<01:46, 571.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6037/66745 [00:10<01:49, 556.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6093/66745 [00:10<01:51, 545.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6153/66745 [00:10<01:48, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6212/66745 [00:10<01:46, 568.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6271/66745 [00:10<01:45, 573.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6330/66745 [00:11<01:44, 577.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6390/66745 [00:11<01:43, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6450/66745 [00:11<01:43, 584.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6510/66745 [00:11<01:42, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6570/66745 [00:11<01:42, 587.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6629/66745 [00:11<01:42, 587.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6688/66745 [00:11<01:42, 587.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6748/66745 [00:11<01:41, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6807/66745 [00:11<01:41, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6867/66745 [00:11<01:41, 589.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6926/66745 [00:12<01:41, 589.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6985/66745 [00:12<01:41, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7045/66745 [00:12<01:41, 589.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7105/66745 [00:12<01:41, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7165/66745 [00:12<01:41, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7224/66745 [00:12<01:42, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7285/66745 [00:12<01:40, 590.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7345/66745 [00:12<01:40, 591.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7405/66745 [00:12<01:41, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7465/66745 [00:12<01:41, 586.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7526/66745 [00:13<01:40, 590.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7586/66745 [00:13<01:39, 591.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7646/66745 [00:13<01:40, 589.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7706/66745 [00:13<01:40, 588.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7765/66745 [00:13<01:40, 587.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7824/66745 [00:13<01:40, 586.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7883/66745 [00:13<01:40, 587.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7942/66745 [00:13<01:40, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8001/66745 [00:13<01:41, 580.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8061/66745 [00:13<01:40, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8120/66745 [00:14<01:40, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8179/66745 [00:14<01:39, 586.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8238/66745 [00:14<01:39, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8297/66745 [00:14<01:39, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8356/66745 [00:14<01:39, 587.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8415/66745 [00:14<01:39, 587.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8474/66745 [00:14<01:39, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8535/66745 [00:14<01:38, 590.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8595/66745 [00:14<01:42, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8652/66745 [00:14<01:43, 561.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8712/66745 [00:15<01:41, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8770/66745 [00:15<01:42, 563.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8827/66745 [00:15<01:44, 555.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8883/66745 [00:15<01:45, 548.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8938/66745 [00:15<01:46, 541.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8993/66745 [00:15<01:47, 535.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9047/66745 [00:15<01:48, 533.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9101/66745 [00:15<01:48, 531.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9156/66745 [00:15<01:47, 534.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9214/66745 [00:16<01:45, 547.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9273/66745 [00:16<01:42, 559.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9332/66745 [00:16<01:41, 567.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9391/66745 [00:16<01:39, 573.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9450/66745 [00:16<01:39, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9509/66745 [00:16<01:38, 579.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9567/66745 [00:16<01:41, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9626/66745 [00:16<01:40, 570.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9684/66745 [00:16<01:41, 559.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9743/66745 [00:16<01:40, 568.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9802/66745 [00:17<01:39, 574.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9862/66745 [00:17<01:38, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9922/66745 [00:17<01:37, 583.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9981/66745 [00:17<01:37, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10041/66745 [00:17<01:37, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10101/66745 [00:17<01:36, 586.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10160/66745 [00:17<01:37, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10220/66745 [00:17<01:36, 585.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10279/66745 [00:17<01:36, 584.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10339/66745 [00:17<01:36, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10398/66745 [00:18<01:36, 586.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10457/66745 [00:18<01:35, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10516/66745 [00:18<01:35, 587.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10575/66745 [00:18<01:35, 586.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10634/66745 [00:18<01:35, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10693/66745 [00:18<01:35, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10755/66745 [00:18<01:34, 595.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10816/66745 [00:18<01:33, 599.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10876/66745 [00:18<01:36, 581.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10936/66745 [00:18<01:35, 585.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10995/66745 [00:19<01:35, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11054/66745 [00:19<01:35, 583.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11113/66745 [00:19<01:35, 584.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11172/66745 [00:19<01:37, 571.45batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  17%|▊    | 11230/66745 [00:19<01:38, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11292/66745 [00:19<01:35, 577.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11350/66745 [00:19<01:36, 574.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11409/66745 [00:19<01:35, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11469/66745 [00:19<01:35, 581.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11528/66745 [00:20<01:35, 580.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11587/66745 [00:20<01:34, 581.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11647/66745 [00:20<01:34, 584.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11707/66745 [00:20<01:33, 587.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11766/66745 [00:20<01:33, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11827/66745 [00:20<01:32, 593.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11887/66745 [00:20<01:32, 595.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11947/66745 [00:20<01:32, 595.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12007/66745 [00:20<01:31, 595.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12067/66745 [00:20<01:32, 590.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12127/66745 [00:21<01:32, 592.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12188/66745 [00:21<01:31, 595.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12249/66745 [00:21<01:31, 597.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12310/66745 [00:21<01:30, 600.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12371/66745 [00:21<01:30, 602.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12432/66745 [00:21<01:32, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12491/66745 [00:21<01:32, 586.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12551/66745 [00:21<01:31, 589.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12611/66745 [00:21<01:31, 591.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12671/66745 [00:21<01:31, 592.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12731/66745 [00:22<01:31, 589.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12791/66745 [00:22<01:31, 591.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12851/66745 [00:22<01:30, 593.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12911/66745 [00:22<01:30, 594.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12971/66745 [00:22<01:30, 595.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13031/66745 [00:22<01:30, 595.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13091/66745 [00:22<01:30, 591.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13151/66745 [00:22<01:30, 593.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13211/66745 [00:22<01:31, 586.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13270/66745 [00:22<01:32, 579.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13329/66745 [00:23<01:32, 575.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13387/66745 [00:23<01:34, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13444/66745 [00:23<01:34, 564.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13505/66745 [00:23<01:32, 577.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13563/66745 [00:23<01:32, 573.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13621/66745 [00:23<01:34, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13678/66745 [00:23<01:36, 551.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13735/66745 [00:23<01:35, 554.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13792/66745 [00:23<01:34, 558.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13848/66745 [00:23<01:35, 556.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13904/66745 [00:24<01:36, 547.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13962/66745 [00:24<01:34, 555.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14021/66745 [00:24<01:33, 565.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14080/66745 [00:24<01:32, 572.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14139/66745 [00:24<01:31, 577.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14199/66745 [00:24<01:30, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14258/66745 [00:24<01:29, 583.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14317/66745 [00:24<01:30, 579.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14379/66745 [00:24<01:28, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14439/66745 [00:25<01:28, 589.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14498/66745 [00:25<01:31, 573.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14556/66745 [00:25<01:32, 563.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14614/66745 [00:25<01:31, 567.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14675/66745 [00:25<01:30, 578.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14736/66745 [00:25<01:28, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14797/66745 [00:25<01:27, 590.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14857/66745 [00:25<01:27, 592.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14917/66745 [00:25<01:28, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14976/66745 [00:25<01:28, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15035/66745 [00:26<01:30, 570.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15093/66745 [00:26<01:32, 561.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15150/66745 [00:26<01:32, 557.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15206/66745 [00:26<01:33, 553.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15262/66745 [00:26<01:33, 547.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15318/66745 [00:26<01:33, 551.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15377/66745 [00:26<01:31, 560.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15434/66745 [00:26<01:31, 558.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15493/66745 [00:26<01:30, 566.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15552/66745 [00:26<01:29, 573.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15611/66745 [00:27<01:28, 577.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15670/66745 [00:27<01:27, 581.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15729/66745 [00:27<01:27, 583.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15788/66745 [00:27<01:27, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15846/66745 [00:27<01:28, 572.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15906/66745 [00:27<01:27, 577.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15966/66745 [00:27<01:27, 582.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16025/66745 [00:27<01:27, 581.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16084/66745 [00:27<01:28, 571.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16143/66745 [00:27<01:28, 574.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16201/66745 [00:28<01:28, 572.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16259/66745 [00:28<01:28, 573.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16319/66745 [00:28<01:27, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16379/66745 [00:28<01:26, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16438/66745 [00:28<01:28, 567.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16495/66745 [00:28<01:30, 558.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16551/66745 [00:28<01:30, 553.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16609/66745 [00:28<01:29, 559.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16668/66745 [00:28<01:28, 567.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16727/66745 [00:29<01:27, 571.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16786/66745 [00:29<01:26, 576.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16845/66745 [00:29<01:26, 579.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16904/66745 [00:29<01:25, 582.40batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  25%|█▎   | 16963/66745 [00:29<01:25, 584.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17022/66745 [00:29<01:24, 585.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17081/66745 [00:29<01:24, 586.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17140/66745 [00:29<01:24, 587.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17199/66745 [00:29<01:25, 579.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17259/66745 [00:29<01:24, 583.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17319/66745 [00:30<01:24, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17379/66745 [00:30<01:23, 588.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17439/66745 [00:30<01:23, 591.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17499/66745 [00:30<01:22, 593.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17559/66745 [00:30<01:23, 592.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17619/66745 [00:30<01:23, 590.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17679/66745 [00:30<01:23, 590.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17739/66745 [00:30<01:23, 589.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17798/66745 [00:30<01:23, 585.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17857/66745 [00:30<01:24, 575.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17916/66745 [00:31<01:24, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17975/66745 [00:31<01:23, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18035/66745 [00:31<01:23, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18095/66745 [00:31<01:22, 586.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18155/66745 [00:31<01:22, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18215/66745 [00:31<01:22, 589.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18275/66745 [00:31<01:22, 589.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18335/66745 [00:31<01:21, 590.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18395/66745 [00:31<01:22, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18454/66745 [00:31<01:23, 579.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18512/66745 [00:32<01:24, 571.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18570/66745 [00:32<01:24, 572.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18628/66745 [00:32<01:25, 564.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18688/66745 [00:32<01:23, 572.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18748/66745 [00:32<01:23, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18808/66745 [00:32<01:22, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18868/66745 [00:32<01:21, 584.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18927/66745 [00:32<01:21, 586.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18986/66745 [00:32<01:21, 583.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19045/66745 [00:32<01:23, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19103/66745 [00:33<01:24, 564.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19160/66745 [00:33<01:26, 553.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19216/66745 [00:33<01:26, 547.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19271/66745 [00:33<01:27, 543.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19326/66745 [00:33<01:27, 541.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19381/66745 [00:33<01:27, 539.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19438/66745 [00:33<01:26, 546.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19493/66745 [00:33<01:28, 534.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19547/66745 [00:33<01:29, 530.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19601/66745 [00:34<01:30, 523.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19654/66745 [00:34<01:30, 517.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19713/66745 [00:34<01:27, 537.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19772/66745 [00:34<01:25, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19832/66745 [00:34<01:23, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19892/66745 [00:34<01:21, 571.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19952/66745 [00:34<01:21, 577.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 20012/66745 [00:34<01:20, 581.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20071/66745 [00:34<01:19, 583.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20130/66745 [00:34<01:19, 585.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20189/66745 [00:35<01:19, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20248/66745 [00:35<01:19, 587.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20307/66745 [00:35<01:19, 587.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20366/66745 [00:35<01:21, 571.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20424/66745 [00:35<01:21, 568.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20484/66745 [00:35<01:20, 575.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20544/66745 [00:35<01:19, 579.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20604/66745 [00:35<01:19, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20665/66745 [00:35<01:18, 590.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20726/66745 [00:35<01:17, 594.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20786/66745 [00:36<01:17, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20846/66745 [00:36<01:18, 588.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20905/66745 [00:36<01:18, 584.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20965/66745 [00:36<01:17, 587.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21025/66745 [00:36<01:17, 590.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21085/66745 [00:36<01:17, 585.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21145/66745 [00:36<01:17, 588.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21204/66745 [00:36<01:17, 587.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21263/66745 [00:36<01:17, 584.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21322/66745 [00:36<01:18, 579.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21380/66745 [00:37<01:18, 577.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21438/66745 [00:37<01:18, 578.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21497/66745 [00:37<01:17, 580.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21556/66745 [00:37<01:17, 581.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21616/66745 [00:37<01:17, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21676/66745 [00:37<01:16, 587.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21736/66745 [00:37<01:16, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21796/66745 [00:37<01:16, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21856/66745 [00:37<01:16, 589.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21915/66745 [00:38<01:16, 586.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21974/66745 [00:38<01:16, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22033/66745 [00:38<01:16, 584.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22092/66745 [00:38<01:16, 583.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22152/66745 [00:38<01:15, 587.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22211/66745 [00:38<01:17, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22271/66745 [00:38<01:16, 582.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22331/66745 [00:38<01:15, 586.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22391/66745 [00:38<01:15, 588.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22450/66745 [00:38<01:16, 579.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22509/66745 [00:39<01:17, 571.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22569/66745 [00:39<01:16, 577.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22629/66745 [00:39<01:15, 581.29batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  34%|█▋   | 22689/66745 [00:39<01:15, 585.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22750/66745 [00:39<01:14, 591.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22811/66745 [00:39<01:13, 596.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22871/66745 [00:39<01:14, 590.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22931/66745 [00:39<01:17, 566.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22991/66745 [00:39<01:16, 574.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23049/66745 [00:39<01:17, 560.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23106/66745 [00:40<01:18, 558.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23164/66745 [00:40<01:17, 563.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23222/66745 [00:40<01:16, 567.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23281/66745 [00:40<01:15, 573.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23342/66745 [00:40<01:14, 584.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23401/66745 [00:40<01:15, 572.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23459/66745 [00:40<01:17, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23517/66745 [00:40<01:16, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23577/66745 [00:40<01:15, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23637/66745 [00:40<01:14, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23695/66745 [00:41<01:14, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23755/66745 [00:41<01:14, 579.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23815/66745 [00:41<01:13, 583.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23875/66745 [00:41<01:13, 585.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23935/66745 [00:41<01:12, 587.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23995/66745 [00:41<01:12, 589.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24055/66745 [00:41<01:12, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24115/66745 [00:41<01:12, 587.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24174/66745 [00:41<01:12, 583.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24233/66745 [00:42<01:13, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24291/66745 [00:42<01:14, 571.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24349/66745 [00:42<01:14, 570.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24407/66745 [00:42<01:14, 569.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24464/66745 [00:42<01:14, 568.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24521/66745 [00:42<01:14, 564.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24579/66745 [00:42<01:14, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24636/66745 [00:42<01:15, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24692/66745 [00:42<01:16, 549.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24747/66745 [00:42<01:17, 543.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24804/66745 [00:43<01:16, 549.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24860/66745 [00:43<01:16, 549.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24918/66745 [00:43<01:15, 557.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24974/66745 [00:43<01:15, 553.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25030/66745 [00:43<01:15, 554.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25092/66745 [00:43<01:12, 571.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25150/66745 [00:43<01:12, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25210/66745 [00:43<01:11, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25268/66745 [00:43<01:12, 570.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25326/66745 [00:43<01:12, 570.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25384/66745 [00:44<01:12, 571.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25442/66745 [00:44<01:12, 566.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25499/66745 [00:44<01:12, 567.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25560/66745 [00:44<01:11, 578.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25618/66745 [00:44<01:11, 575.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25676/66745 [00:44<01:11, 576.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25736/66745 [00:44<01:10, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25796/66745 [00:44<01:10, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25857/66745 [00:44<01:09, 589.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25916/66745 [00:44<01:09, 589.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25976/66745 [00:45<01:09, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26036/66745 [00:45<01:11, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26097/66745 [00:45<01:09, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26156/66745 [00:45<01:10, 572.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26214/66745 [00:45<01:11, 563.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26271/66745 [00:45<01:12, 561.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26331/66745 [00:45<01:10, 570.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26389/66745 [00:45<01:10, 570.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26447/66745 [00:45<01:10, 569.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26506/66745 [00:46<01:10, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26564/66745 [00:46<01:10, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26622/66745 [00:46<01:10, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26682/66745 [00:46<01:09, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26740/66745 [00:46<01:10, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26801/66745 [00:46<01:08, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26862/66745 [00:46<01:07, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26921/66745 [00:46<01:08, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26980/66745 [00:46<01:08, 582.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27039/66745 [00:46<01:09, 567.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27096/66745 [00:47<01:11, 556.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27155/66745 [00:47<01:10, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27212/66745 [00:47<01:09, 564.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27271/66745 [00:47<01:08, 572.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27331/66745 [00:47<01:08, 579.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27391/66745 [00:47<01:07, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27451/66745 [00:47<01:06, 587.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27511/66745 [00:47<01:06, 590.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27571/66745 [00:47<01:06, 592.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27631/66745 [00:47<01:06, 587.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27690/66745 [00:48<01:06, 585.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27749/66745 [00:48<01:06, 583.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27808/66745 [00:48<01:07, 574.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27868/66745 [00:48<01:06, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27928/66745 [00:48<01:06, 585.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27988/66745 [00:48<01:05, 588.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28047/66745 [00:48<01:06, 583.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28107/66745 [00:48<01:05, 585.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28166/66745 [00:48<01:06, 581.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28225/66745 [00:48<01:07, 573.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28283/66745 [00:49<01:07, 571.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28343/66745 [00:49<01:06, 577.94batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  43%|██▏  | 28403/66745 [00:49<01:05, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28462/66745 [00:49<01:05, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28521/66745 [00:49<01:05, 583.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28580/66745 [00:49<01:07, 565.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28637/66745 [00:49<01:07, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28694/66745 [00:49<01:08, 554.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28750/66745 [00:49<01:09, 544.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28805/66745 [00:50<01:09, 545.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28864/66745 [00:50<01:08, 555.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28924/66745 [00:50<01:06, 567.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28981/66745 [00:50<01:06, 565.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29038/66745 [00:50<01:08, 550.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29096/66745 [00:50<01:07, 556.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29154/66745 [00:50<01:06, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29215/66745 [00:50<01:05, 575.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29273/66745 [00:50<01:05, 574.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29331/66745 [00:50<01:05, 574.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29390/66745 [00:51<01:04, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29448/66745 [00:51<01:04, 575.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29506/66745 [00:51<01:04, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29564/66745 [00:51<01:05, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29626/66745 [00:51<01:03, 583.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29685/66745 [00:51<01:03, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29744/66745 [00:51<01:04, 571.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29802/66745 [00:51<01:05, 566.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29859/66745 [00:51<01:06, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29916/66745 [00:51<01:06, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29972/66745 [00:52<01:06, 554.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 30034/66745 [00:52<01:04, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30092/66745 [00:52<01:04, 567.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30149/66745 [00:52<01:04, 566.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30207/66745 [00:52<01:04, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30264/66745 [00:52<01:04, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30325/66745 [00:52<01:02, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30383/66745 [00:52<01:03, 574.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30441/66745 [00:52<01:03, 574.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30499/66745 [00:52<01:04, 563.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30556/66745 [00:53<01:05, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30612/66745 [00:53<01:05, 554.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30672/66745 [00:53<01:03, 566.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30732/66745 [00:53<01:02, 574.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30790/66745 [00:53<01:03, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30847/66745 [00:53<01:04, 559.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30904/66745 [00:53<01:04, 558.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30960/66745 [00:53<01:04, 556.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 31016/66745 [00:53<01:04, 556.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31073/66745 [00:54<01:03, 559.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31132/66745 [00:54<01:02, 566.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31193/66745 [00:54<01:01, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31253/66745 [00:54<01:00, 584.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31313/66745 [00:54<01:00, 587.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31373/66745 [00:54<00:59, 590.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31434/66745 [00:54<00:59, 596.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31495/66745 [00:54<00:58, 599.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31556/66745 [00:54<00:58, 602.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31617/66745 [00:54<00:58, 603.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31678/66745 [00:55<00:57, 605.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31739/66745 [00:55<00:57, 606.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31800/66745 [00:55<00:57, 607.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31862/66745 [00:55<00:57, 608.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31923/66745 [00:55<00:57, 609.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31984/66745 [00:55<00:58, 589.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32044/66745 [00:55<00:58, 590.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32104/66745 [00:55<00:58, 590.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32164/66745 [00:55<00:58, 591.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32224/66745 [00:55<00:58, 591.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32284/66745 [00:56<00:59, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32342/66745 [00:56<01:01, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32399/66745 [00:56<01:02, 553.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32457/66745 [00:56<01:01, 559.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32517/66745 [00:56<01:00, 569.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32575/66745 [00:56<01:01, 557.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32631/66745 [00:56<01:01, 552.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32690/66745 [00:56<01:00, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32747/66745 [00:56<01:01, 548.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32802/66745 [00:56<01:02, 545.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32861/66745 [00:57<01:00, 557.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32921/66745 [00:57<00:59, 568.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32981/66745 [00:57<00:58, 575.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33039/66745 [00:57<00:59, 567.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33099/66745 [00:57<00:58, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33157/66745 [00:57<00:59, 564.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33214/66745 [00:57<00:59, 560.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33271/66745 [00:57<01:00, 554.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33328/66745 [00:57<01:00, 556.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33384/66745 [00:58<01:01, 546.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33439/66745 [00:58<01:01, 542.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33495/66745 [00:58<01:00, 546.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33555/66745 [00:58<00:59, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33615/66745 [00:58<00:58, 568.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33675/66745 [00:58<00:57, 575.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33734/66745 [00:58<00:56, 579.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33793/66745 [00:58<00:56, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33853/66745 [00:58<00:56, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33912/66745 [00:58<00:56, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33971/66745 [00:59<00:59, 552.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34027/66745 [00:59<00:59, 550.79batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  51%|██▌  | 34083/66745 [00:59<00:59, 549.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34144/66745 [00:59<00:57, 565.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34203/66745 [00:59<00:56, 572.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34264/66745 [00:59<00:55, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34323/66745 [00:59<00:56, 573.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34381/66745 [00:59<00:56, 570.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34440/66745 [00:59<00:56, 573.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34498/66745 [00:59<00:56, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34557/66745 [01:00<00:55, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34615/66745 [01:00<00:56, 571.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34673/66745 [01:00<00:56, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34732/66745 [01:00<00:55, 572.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34791/66745 [01:00<00:55, 575.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34849/66745 [01:00<00:55, 573.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34908/66745 [01:00<00:55, 575.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34967/66745 [01:00<00:55, 577.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 35026/66745 [01:00<00:54, 578.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35085/66745 [01:00<00:54, 579.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35144/66745 [01:01<00:54, 581.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35203/66745 [01:01<00:54, 581.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35262/66745 [01:01<00:54, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35321/66745 [01:01<00:54, 578.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35380/66745 [01:01<00:54, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35439/66745 [01:01<00:53, 581.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35498/66745 [01:01<00:53, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35557/66745 [01:01<00:53, 581.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35616/66745 [01:01<00:54, 576.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35674/66745 [01:02<00:54, 575.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35733/66745 [01:02<00:53, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35792/66745 [01:02<00:53, 578.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35850/66745 [01:02<00:53, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35909/66745 [01:02<00:53, 575.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35968/66745 [01:02<00:53, 577.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36027/66745 [01:02<00:53, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36085/66745 [01:02<00:53, 576.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36143/66745 [01:02<00:53, 574.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36202/66745 [01:02<00:52, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36262/66745 [01:03<00:52, 581.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36321/66745 [01:03<00:52, 583.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36380/66745 [01:03<00:51, 585.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36439/66745 [01:03<00:51, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36499/66745 [01:03<00:51, 587.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36559/66745 [01:03<00:51, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36618/66745 [01:03<00:51, 587.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36678/66745 [01:03<00:50, 590.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36739/66745 [01:03<00:50, 593.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36799/66745 [01:03<00:50, 594.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36859/66745 [01:04<00:50, 592.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36919/66745 [01:04<00:50, 591.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36979/66745 [01:04<00:50, 590.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37039/66745 [01:04<00:50, 590.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37099/66745 [01:04<00:50, 590.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37159/66745 [01:04<00:50, 590.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37219/66745 [01:04<00:50, 590.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37279/66745 [01:04<00:49, 590.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37339/66745 [01:04<00:50, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37398/66745 [01:04<00:50, 585.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37457/66745 [01:05<00:49, 586.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37517/66745 [01:05<00:49, 587.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37576/66745 [01:05<00:49, 587.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37635/66745 [01:05<00:49, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37694/66745 [01:05<00:49, 585.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37753/66745 [01:05<00:49, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37813/66745 [01:05<00:49, 584.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37873/66745 [01:05<00:49, 585.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37932/66745 [01:05<00:49, 587.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37991/66745 [01:05<00:48, 587.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38050/66745 [01:06<00:48, 588.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38109/66745 [01:06<00:48, 584.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38169/66745 [01:06<00:48, 586.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38229/66745 [01:06<00:48, 587.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38288/66745 [01:06<00:48, 584.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38347/66745 [01:06<00:49, 577.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38406/66745 [01:06<00:48, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38466/66745 [01:06<00:48, 584.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38525/66745 [01:06<00:48, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38585/66745 [01:06<00:48, 582.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38644/66745 [01:07<00:49, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38702/66745 [01:07<00:49, 568.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38761/66745 [01:07<00:48, 574.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38820/66745 [01:07<00:48, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38880/66745 [01:07<00:47, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38939/66745 [01:07<00:47, 584.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38998/66745 [01:07<00:47, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39057/66745 [01:07<00:47, 580.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39116/66745 [01:07<00:49, 560.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39175/66745 [01:08<00:48, 568.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39234/66745 [01:08<00:47, 574.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39293/66745 [01:08<00:47, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39353/66745 [01:08<00:47, 581.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39412/66745 [01:08<00:46, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39471/66745 [01:08<00:46, 585.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39530/66745 [01:08<00:46, 586.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39589/66745 [01:08<00:46, 586.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39648/66745 [01:08<00:46, 587.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39707/66745 [01:08<00:46, 586.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39766/66745 [01:09<00:46, 585.71batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  60%|██▉  | 39826/66745 [01:09<00:45, 587.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39886/66745 [01:09<00:45, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39946/66745 [01:09<00:45, 589.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40005/66745 [01:09<00:46, 571.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40063/66745 [01:09<00:46, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40122/66745 [01:09<00:46, 574.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40181/66745 [01:09<00:45, 578.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40240/66745 [01:09<00:45, 580.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40299/66745 [01:09<00:45, 582.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40358/66745 [01:10<00:45, 584.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40417/66745 [01:10<00:44, 585.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40476/66745 [01:10<00:44, 586.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40535/66745 [01:10<00:44, 587.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40594/66745 [01:10<00:44, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40653/66745 [01:10<00:44, 587.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40712/66745 [01:10<00:44, 588.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40771/66745 [01:10<00:44, 588.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40830/66745 [01:10<00:44, 588.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40889/66745 [01:10<00:43, 587.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40948/66745 [01:11<00:43, 588.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41007/66745 [01:11<00:43, 588.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41066/66745 [01:11<00:43, 587.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41125/66745 [01:11<00:43, 586.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41184/66745 [01:11<00:43, 587.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41244/66745 [01:11<00:43, 588.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41304/66745 [01:11<00:43, 589.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41364/66745 [01:11<00:43, 589.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41423/66745 [01:11<00:43, 585.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41483/66745 [01:11<00:43, 587.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41543/66745 [01:12<00:42, 588.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41603/66745 [01:12<00:42, 590.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41663/66745 [01:12<00:42, 591.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41723/66745 [01:12<00:42, 589.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41783/66745 [01:12<00:42, 592.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41845/66745 [01:12<00:41, 599.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41906/66745 [01:12<00:41, 602.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41967/66745 [01:12<00:41, 601.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42028/66745 [01:12<00:41, 599.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42088/66745 [01:12<00:41, 596.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42148/66745 [01:13<00:41, 588.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42208/66745 [01:13<00:41, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42268/66745 [01:13<00:41, 590.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42328/66745 [01:13<00:41, 590.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42388/66745 [01:13<00:41, 591.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42448/66745 [01:13<00:41, 591.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42508/66745 [01:13<00:40, 592.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42568/66745 [01:13<00:40, 592.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42629/66745 [01:13<00:40, 595.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42689/66745 [01:13<00:40, 596.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42751/66745 [01:14<00:39, 601.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42813/66745 [01:14<00:39, 604.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42874/66745 [01:14<00:39, 604.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42935/66745 [01:14<00:39, 600.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42996/66745 [01:14<00:39, 597.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43056/66745 [01:14<00:39, 595.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43116/66745 [01:14<00:39, 594.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43176/66745 [01:14<00:39, 593.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43236/66745 [01:14<00:39, 592.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43296/66745 [01:15<00:39, 591.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43356/66745 [01:15<00:39, 591.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43416/66745 [01:15<00:39, 591.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43476/66745 [01:15<00:40, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43534/66745 [01:15<00:42, 552.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43590/66745 [01:15<00:42, 550.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43646/66745 [01:15<00:42, 549.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43701/66745 [01:15<00:42, 548.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43756/66745 [01:15<00:42, 547.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43811/66745 [01:15<00:42, 545.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43866/66745 [01:16<00:41, 546.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43921/66745 [01:16<00:41, 546.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43976/66745 [01:16<00:41, 546.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44031/66745 [01:16<00:41, 546.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44086/66745 [01:16<00:41, 546.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44141/66745 [01:16<00:41, 546.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44196/66745 [01:16<00:41, 547.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44256/66745 [01:16<00:40, 560.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44316/66745 [01:16<00:39, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44373/66745 [01:16<00:39, 568.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44431/66745 [01:17<00:39, 570.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44490/66745 [01:17<00:38, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44548/66745 [01:17<00:38, 575.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44606/66745 [01:17<00:38, 574.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44664/66745 [01:17<00:38, 572.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44722/66745 [01:17<00:38, 574.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44780/66745 [01:17<00:38, 569.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44837/66745 [01:17<00:38, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44896/66745 [01:17<00:38, 570.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44954/66745 [01:17<00:38, 571.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45012/66745 [01:18<00:37, 572.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45070/66745 [01:18<00:37, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45129/66745 [01:18<00:37, 576.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45187/66745 [01:18<00:37, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45245/66745 [01:18<00:37, 571.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45303/66745 [01:18<00:37, 572.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45361/66745 [01:18<00:37, 571.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45421/66745 [01:18<00:36, 579.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45480/66745 [01:18<00:36, 582.59batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  68%|███▍ | 45539/66745 [01:18<00:36, 576.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45597/66745 [01:19<00:37, 567.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45654/66745 [01:19<00:37, 560.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45716/66745 [01:19<00:36, 575.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45774/66745 [01:19<00:37, 564.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45831/66745 [01:19<00:37, 559.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45887/66745 [01:19<00:37, 559.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45944/66745 [01:19<00:37, 559.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46001/66745 [01:19<00:36, 561.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46058/66745 [01:19<00:36, 559.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46115/66745 [01:20<00:36, 562.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46176/66745 [01:20<00:35, 575.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46234/66745 [01:20<00:35, 570.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46293/66745 [01:20<00:35, 574.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46351/66745 [01:20<00:35, 567.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46408/66745 [01:20<00:36, 563.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46467/66745 [01:20<00:35, 570.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46528/66745 [01:20<00:34, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46589/66745 [01:20<00:34, 587.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46649/66745 [01:20<00:34, 588.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46708/66745 [01:21<00:34, 584.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46767/66745 [01:21<00:34, 575.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46825/66745 [01:21<00:35, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46882/66745 [01:21<00:35, 562.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46943/66745 [01:21<00:34, 574.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47001/66745 [01:21<00:35, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47058/66745 [01:21<00:34, 564.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47117/66745 [01:21<00:34, 570.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47176/66745 [01:21<00:33, 575.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47235/66745 [01:21<00:33, 579.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47294/66745 [01:22<00:33, 580.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47353/66745 [01:22<00:33, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47412/66745 [01:22<00:33, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47471/66745 [01:22<00:32, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47530/66745 [01:22<00:32, 584.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47589/66745 [01:22<00:32, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47648/66745 [01:22<00:32, 585.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47707/66745 [01:22<00:32, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47766/66745 [01:22<00:32, 585.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47825/66745 [01:22<00:32, 585.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47884/66745 [01:23<00:32, 586.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47943/66745 [01:23<00:32, 586.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48002/66745 [01:23<00:31, 586.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48062/66745 [01:23<00:31, 589.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48121/66745 [01:23<00:32, 581.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48180/66745 [01:23<00:32, 570.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48238/66745 [01:23<00:32, 562.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48297/66745 [01:23<00:32, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48354/66745 [01:23<00:32, 567.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48412/66745 [01:23<00:32, 569.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48472/66745 [01:24<00:31, 576.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48532/66745 [01:24<00:31, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48592/66745 [01:24<00:31, 584.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48652/66745 [01:24<00:30, 586.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48712/66745 [01:24<00:30, 588.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48772/66745 [01:24<00:30, 589.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48832/66745 [01:24<00:30, 590.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48892/66745 [01:24<00:30, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48952/66745 [01:24<00:30, 591.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 49012/66745 [01:24<00:29, 593.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49072/66745 [01:25<00:29, 594.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49132/66745 [01:25<00:30, 576.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49190/66745 [01:25<00:30, 574.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49248/66745 [01:25<00:30, 573.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49306/66745 [01:25<00:30, 566.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49365/66745 [01:25<00:30, 572.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49424/66745 [01:25<00:30, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49482/66745 [01:25<00:30, 569.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49540/66745 [01:25<00:30, 570.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49599/66745 [01:26<00:29, 576.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49660/66745 [01:26<00:29, 584.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49721/66745 [01:26<00:28, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49781/66745 [01:26<00:28, 587.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49841/66745 [01:26<00:28, 589.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49900/66745 [01:26<00:28, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49959/66745 [01:26<00:28, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50018/66745 [01:26<00:28, 578.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50076/66745 [01:26<00:28, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50134/66745 [01:26<00:29, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50192/66745 [01:27<00:29, 567.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50249/66745 [01:27<00:29, 567.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50306/66745 [01:27<00:29, 565.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50363/66745 [01:27<00:29, 559.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50422/66745 [01:27<00:28, 566.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50480/66745 [01:27<00:28, 568.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50537/66745 [01:27<00:28, 565.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50595/66745 [01:27<00:28, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50652/66745 [01:27<00:28, 563.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50709/66745 [01:27<00:28, 556.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50766/66745 [01:28<00:28, 560.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50823/66745 [01:28<00:28, 559.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50879/66745 [01:28<00:28, 553.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50935/66745 [01:28<00:28, 550.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50994/66745 [01:28<00:28, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51053/66745 [01:28<00:27, 567.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51112/66745 [01:28<00:27, 572.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51171/66745 [01:28<00:27, 574.99batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  77%|███▊ | 51229/66745 [01:28<00:27, 565.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51286/66745 [01:28<00:27, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51345/66745 [01:29<00:27, 568.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51402/66745 [01:29<00:27, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51462/66745 [01:29<00:26, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51520/66745 [01:29<00:26, 569.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51577/66745 [01:29<00:26, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51636/66745 [01:29<00:26, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51695/66745 [01:29<00:26, 575.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51754/66745 [01:29<00:25, 577.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51813/66745 [01:29<00:25, 577.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51872/66745 [01:30<00:25, 580.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51931/66745 [01:30<00:26, 567.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51990/66745 [01:30<00:25, 571.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52050/66745 [01:30<00:25, 578.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52110/66745 [01:30<00:25, 581.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52169/66745 [01:30<00:25, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52227/66745 [01:30<00:25, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52284/66745 [01:30<00:25, 558.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52341/66745 [01:30<00:25, 559.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52398/66745 [01:30<00:25, 558.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52454/66745 [01:31<00:25, 558.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52510/66745 [01:31<00:25, 550.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52567/66745 [01:31<00:25, 555.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52626/66745 [01:31<00:25, 564.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52685/66745 [01:31<00:24, 569.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52744/66745 [01:31<00:24, 574.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52803/66745 [01:31<00:24, 577.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52862/66745 [01:31<00:23, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52921/66745 [01:31<00:23, 580.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52980/66745 [01:31<00:23, 581.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53039/66745 [01:32<00:23, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53098/66745 [01:32<00:24, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53157/66745 [01:32<00:23, 570.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53215/66745 [01:32<00:24, 561.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53272/66745 [01:32<00:23, 562.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53331/66745 [01:32<00:23, 568.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53390/66745 [01:32<00:23, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53449/66745 [01:32<00:23, 576.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53508/66745 [01:32<00:22, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53567/66745 [01:32<00:22, 580.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53626/66745 [01:33<00:22, 581.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53685/66745 [01:33<00:22, 582.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53744/66745 [01:33<00:22, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53803/66745 [01:33<00:22, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53862/66745 [01:33<00:22, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53921/66745 [01:33<00:22, 577.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53979/66745 [01:33<00:22, 576.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54037/66745 [01:33<00:22, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54096/66745 [01:33<00:21, 576.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54154/66745 [01:34<00:22, 570.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54212/66745 [01:34<00:21, 572.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54273/66745 [01:34<00:21, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54333/66745 [01:34<00:21, 585.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54393/66745 [01:34<00:21, 588.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54452/66745 [01:34<00:21, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54511/66745 [01:34<00:20, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54571/66745 [01:34<00:20, 587.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54631/66745 [01:34<00:20, 590.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54691/66745 [01:34<00:20, 589.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54752/66745 [01:35<00:20, 593.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54812/66745 [01:35<00:20, 595.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54872/66745 [01:35<00:20, 582.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54932/66745 [01:35<00:20, 586.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54991/66745 [01:35<00:20, 576.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55049/66745 [01:35<00:20, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55109/66745 [01:35<00:20, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55167/66745 [01:35<00:20, 571.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55225/66745 [01:35<00:20, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55286/66745 [01:35<00:19, 574.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55346/66745 [01:36<00:19, 580.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55405/66745 [01:36<00:19, 581.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55464/66745 [01:36<00:19, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55523/66745 [01:36<00:19, 568.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55580/66745 [01:36<00:20, 556.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55637/66745 [01:36<00:19, 559.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55697/66745 [01:36<00:19, 571.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55759/66745 [01:36<00:18, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55820/66745 [01:36<00:18, 589.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55879/66745 [01:36<00:18, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55938/66745 [01:37<00:18, 586.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55998/66745 [01:37<00:18, 588.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56059/66745 [01:37<00:17, 593.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56119/66745 [01:37<00:18, 587.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56179/66745 [01:37<00:17, 590.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56240/66745 [01:37<00:17, 594.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56300/66745 [01:37<00:17, 584.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56359/66745 [01:37<00:17, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56418/66745 [01:37<00:17, 581.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56480/66745 [01:37<00:17, 590.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56542/66745 [01:38<00:17, 596.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56602/66745 [01:38<00:17, 586.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56661/66745 [01:38<00:17, 576.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56722/66745 [01:38<00:17, 583.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56781/66745 [01:38<00:17, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56841/66745 [01:38<00:16, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56900/66745 [01:38<00:16, 587.63batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  85%|████▎| 56960/66745 [01:38<00:16, 588.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57020/66745 [01:38<00:16, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57079/66745 [01:39<00:16, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57139/66745 [01:39<00:16, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57199/66745 [01:39<00:16, 590.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57259/66745 [01:39<00:16, 589.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57318/66745 [01:39<00:16, 583.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57377/66745 [01:39<00:16, 577.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57436/66745 [01:39<00:16, 579.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57496/66745 [01:39<00:15, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57556/66745 [01:39<00:15, 586.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57615/66745 [01:39<00:15, 582.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57674/66745 [01:40<00:15, 570.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57732/66745 [01:40<00:16, 556.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57791/66745 [01:40<00:15, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57850/66745 [01:40<00:15, 569.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57909/66745 [01:40<00:15, 573.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57968/66745 [01:40<00:15, 576.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58027/66745 [01:40<00:15, 578.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58086/66745 [01:40<00:14, 580.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58145/66745 [01:40<00:14, 581.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58204/66745 [01:40<00:14, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58263/66745 [01:41<00:14, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58322/66745 [01:41<00:14, 582.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58381/66745 [01:41<00:14, 582.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58440/66745 [01:41<00:14, 582.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58500/66745 [01:41<00:14, 585.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58562/66745 [01:41<00:13, 594.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58622/66745 [01:41<00:13, 594.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58682/66745 [01:41<00:13, 593.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58742/66745 [01:41<00:13, 594.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58802/66745 [01:41<00:13, 592.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58862/66745 [01:42<00:13, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58922/66745 [01:42<00:13, 591.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58982/66745 [01:42<00:13, 592.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59042/66745 [01:42<00:13, 591.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59102/66745 [01:42<00:12, 592.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59164/66745 [01:42<00:12, 599.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59224/66745 [01:42<00:12, 598.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59284/66745 [01:42<00:12, 593.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59344/66745 [01:42<00:12, 579.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59403/66745 [01:42<00:12, 580.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59462/66745 [01:43<00:12, 563.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59519/66745 [01:43<00:13, 552.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59579/66745 [01:43<00:12, 563.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59636/66745 [01:43<00:12, 561.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59693/66745 [01:43<00:12, 551.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59753/66745 [01:43<00:12, 564.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59810/66745 [01:43<00:12, 561.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59867/66745 [01:43<00:12, 556.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59927/66745 [01:43<00:12, 567.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59989/66745 [01:44<00:11, 580.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60048/66745 [01:44<00:11, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60107/66745 [01:44<00:11, 562.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60164/66745 [01:44<00:11, 553.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60220/66745 [01:44<00:11, 547.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60275/66745 [01:44<00:11, 543.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60330/66745 [01:44<00:11, 538.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60384/66745 [01:44<00:11, 535.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60438/66745 [01:44<00:11, 535.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60492/66745 [01:44<00:11, 535.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60550/66745 [01:45<00:11, 546.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60610/66745 [01:45<00:10, 561.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60670/66745 [01:45<00:10, 572.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60730/66745 [01:45<00:10, 580.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60792/66745 [01:45<00:10, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60852/66745 [01:45<00:10, 589.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60912/66745 [01:45<00:09, 589.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60972/66745 [01:45<00:09, 590.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61032/66745 [01:45<00:09, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61090/66745 [01:45<00:09, 575.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61149/66745 [01:46<00:09, 577.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61207/66745 [01:46<00:09, 574.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61266/66745 [01:46<00:09, 579.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61328/66745 [01:46<00:09, 588.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61387/66745 [01:46<00:09, 586.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61446/66745 [01:46<00:09, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61505/66745 [01:46<00:09, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61564/66745 [01:46<00:09, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61624/66745 [01:46<00:08, 581.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61683/66745 [01:47<00:08, 583.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61742/66745 [01:47<00:08, 585.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61801/66745 [01:47<00:08, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61860/66745 [01:47<00:08, 587.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61920/66745 [01:47<00:08, 588.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61980/66745 [01:47<00:08, 589.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62039/66745 [01:47<00:07, 589.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62098/66745 [01:47<00:07, 589.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62157/66745 [01:47<00:07, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62216/66745 [01:47<00:07, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62275/66745 [01:48<00:07, 580.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62334/66745 [01:48<00:07, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62392/66745 [01:48<00:07, 572.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62450/66745 [01:48<00:07, 566.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62507/66745 [01:48<00:07, 563.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62566/66745 [01:48<00:07, 570.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62624/66745 [01:48<00:07, 569.84batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  94%|████▋| 62682/66745 [01:48<00:07, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62739/66745 [01:48<00:07, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62796/66745 [01:48<00:07, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62853/66745 [01:49<00:06, 557.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62913/66745 [01:49<00:06, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62975/66745 [01:49<00:06, 581.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63034/66745 [01:49<00:06, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63093/66745 [01:49<00:06, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63152/66745 [01:49<00:06, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63211/66745 [01:49<00:06, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63270/66745 [01:49<00:05, 582.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63329/66745 [01:49<00:05, 582.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63388/66745 [01:49<00:05, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63449/66745 [01:50<00:05, 588.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63508/66745 [01:50<00:05, 588.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63567/66745 [01:50<00:05, 585.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63627/66745 [01:50<00:05, 586.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63687/66745 [01:50<00:05, 587.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63746/66745 [01:50<00:05, 578.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63805/66745 [01:50<00:05, 579.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63864/66745 [01:50<00:04, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63923/66745 [01:50<00:04, 581.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63982/66745 [01:50<00:04, 584.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64041/66745 [01:51<00:04, 573.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64100/66745 [01:51<00:04, 577.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64159/66745 [01:51<00:04, 580.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64218/66745 [01:51<00:04, 582.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64277/66745 [01:51<00:04, 582.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64336/66745 [01:51<00:04, 580.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64395/66745 [01:51<00:04, 574.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64453/66745 [01:51<00:04, 566.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64510/66745 [01:51<00:03, 563.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64567/66745 [01:52<00:03, 553.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64626/66745 [01:52<00:03, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64685/66745 [01:52<00:03, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64744/66745 [01:52<00:03, 572.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64803/66745 [01:52<00:03, 575.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64862/66745 [01:52<00:03, 577.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64921/66745 [01:52<00:03, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64980/66745 [01:52<00:03, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65039/66745 [01:52<00:02, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65098/66745 [01:52<00:02, 582.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65157/66745 [01:53<00:02, 582.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65216/66745 [01:53<00:02, 582.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65275/66745 [01:53<00:02, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65334/66745 [01:53<00:02, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65393/66745 [01:53<00:02, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65452/66745 [01:53<00:02, 583.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65511/66745 [01:53<00:02, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65570/66745 [01:53<00:02, 584.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65629/66745 [01:53<00:01, 584.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65688/66745 [01:53<00:01, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65747/66745 [01:54<00:01, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65806/66745 [01:54<00:01, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65865/66745 [01:54<00:01, 583.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65924/66745 [01:54<00:01, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65983/66745 [01:54<00:01, 583.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66042/66745 [01:54<00:01, 583.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66101/66745 [01:54<00:01, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66160/66745 [01:54<00:01, 584.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66219/66745 [01:54<00:00, 584.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66278/66745 [01:54<00:00, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66337/66745 [01:55<00:00, 569.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66396/66745 [01:55<00:00, 573.34batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66455/66745 [01:55<00:00, 576.37batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66514/66745 [01:55<00:00, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66573/66745 [01:55<00:00, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66631/66745 [01:55<00:00, 577.41batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66689/66745 [01:55<00:00, 562.27batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   1%| | 1/100 [01:55<3:11:20, 115.96s/epoch, loss=0.4\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 15/66745 [00:00<07:27, 148.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 69/66745 [00:00<02:57, 376.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 126/66745 [00:00<02:24, 461.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 185/66745 [00:00<02:10, 511.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 240/66745 [00:00<02:07, 522.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 295/66745 [00:00<02:05, 530.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 355/66745 [00:00<02:00, 551.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 414/66745 [00:00<01:57, 562.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 471/66745 [00:00<01:57, 564.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 529/66745 [00:01<01:56, 567.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 589/66745 [00:01<01:55, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 649/66745 [00:01<01:53, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 709/66745 [00:01<01:52, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 768/66745 [00:01<01:52, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 827/66745 [00:01<01:54, 573.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 885/66745 [00:01<01:57, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 942/66745 [00:01<01:57, 558.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|      | 1001/66745 [00:01<01:56, 565.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1058/66745 [00:01<01:57, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1114/66745 [00:02<01:58, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1170/66745 [00:02<01:58, 555.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1226/66745 [00:02<01:59, 548.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1285/66745 [00:02<01:57, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1344/66745 [00:02<01:55, 566.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1403/66745 [00:02<01:54, 571.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1462/66745 [00:02<01:53, 575.29batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   2%|▏     | 1521/66745 [00:02<01:52, 577.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1579/66745 [00:02<01:53, 574.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1637/66745 [00:02<01:53, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1695/66745 [00:03<01:54, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1754/66745 [00:03<01:53, 574.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1814/66745 [00:03<01:52, 579.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1872/66745 [00:03<01:52, 578.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1930/66745 [00:03<01:53, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1990/66745 [00:03<01:51, 578.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2049/66745 [00:03<01:51, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2108/66745 [00:03<01:52, 573.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2166/66745 [00:03<01:54, 566.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2223/66745 [00:03<01:55, 558.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2279/66745 [00:04<01:56, 555.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2336/66745 [00:04<01:55, 558.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2392/66745 [00:04<01:56, 553.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2448/66745 [00:04<01:57, 546.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2504/66745 [00:04<01:56, 549.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2564/66745 [00:04<01:54, 562.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2621/66745 [00:04<01:55, 554.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2679/66745 [00:04<01:54, 561.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2736/66745 [00:04<01:54, 557.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2793/66745 [00:05<01:54, 559.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2850/66745 [00:05<01:54, 559.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2909/66745 [00:05<01:52, 566.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2967/66745 [00:05<01:52, 567.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3024/66745 [00:05<01:53, 561.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3081/66745 [00:05<01:54, 555.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3137/66745 [00:05<01:54, 556.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3195/66745 [00:05<01:53, 561.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3254/66745 [00:05<01:51, 570.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3313/66745 [00:05<01:50, 575.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3371/66745 [00:06<01:50, 574.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3429/66745 [00:06<01:52, 565.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3486/66745 [00:06<01:54, 552.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3543/66745 [00:06<01:53, 555.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3602/66745 [00:06<01:52, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3661/66745 [00:06<01:50, 569.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3720/66745 [00:06<01:49, 573.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3779/66745 [00:06<01:49, 577.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3838/66745 [00:06<01:48, 578.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3897/66745 [00:06<01:48, 579.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3955/66745 [00:07<01:50, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4012/66745 [00:07<01:51, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4071/66745 [00:07<01:50, 566.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4128/66745 [00:07<01:51, 561.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4187/66745 [00:07<01:50, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4246/66745 [00:07<01:49, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4304/66745 [00:07<01:49, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4364/66745 [00:07<01:48, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4424/66745 [00:07<01:47, 580.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4483/66745 [00:07<01:48, 571.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4542/66745 [00:08<01:47, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4600/66745 [00:08<01:48, 574.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4658/66745 [00:08<01:48, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4716/66745 [00:08<01:49, 566.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4774/66745 [00:08<01:48, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4832/66745 [00:08<01:48, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4890/66745 [00:08<01:47, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4948/66745 [00:08<01:47, 575.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5006/66745 [00:08<01:50, 560.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5063/66745 [00:09<01:51, 552.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5119/66745 [00:09<01:52, 547.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5176/66745 [00:09<01:51, 551.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5232/66745 [00:09<01:51, 551.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5292/66745 [00:09<01:48, 563.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5349/66745 [00:09<01:48, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5407/66745 [00:09<01:47, 568.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5466/66745 [00:09<01:47, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5524/66745 [00:09<01:46, 573.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5583/66745 [00:09<01:46, 576.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5641/66745 [00:10<01:48, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5698/66745 [00:10<01:48, 564.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5755/66745 [00:10<01:49, 555.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5815/66745 [00:10<01:47, 566.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5872/66745 [00:10<01:47, 564.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5929/66745 [00:10<01:49, 556.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5986/66745 [00:10<01:48, 558.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6046/66745 [00:10<01:46, 567.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6103/66745 [00:10<01:48, 556.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6159/66745 [00:10<01:49, 552.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6215/66745 [00:11<01:49, 551.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6271/66745 [00:11<01:51, 543.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6329/66745 [00:11<01:48, 554.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6388/66745 [00:11<01:47, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6447/66745 [00:11<01:45, 569.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6506/66745 [00:11<01:44, 573.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6564/66745 [00:11<01:45, 570.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6622/66745 [00:11<01:46, 563.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6681/66745 [00:11<01:45, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6742/66745 [00:11<01:43, 579.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6800/66745 [00:12<01:44, 572.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6858/66745 [00:12<01:47, 556.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6914/66745 [00:12<01:49, 546.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6969/66745 [00:12<01:51, 537.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7027/66745 [00:12<01:48, 549.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7085/66745 [00:12<01:46, 558.32batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  11%|▋     | 7143/66745 [00:12<01:45, 564.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7201/66745 [00:12<01:44, 569.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7259/66745 [00:12<01:44, 571.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7317/66745 [00:13<01:44, 569.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7375/66745 [00:13<01:46, 559.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7432/66745 [00:13<01:46, 555.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7489/66745 [00:13<01:46, 558.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7546/66745 [00:13<01:45, 559.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7606/66745 [00:13<01:43, 570.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7665/66745 [00:13<01:42, 575.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7724/66745 [00:13<01:42, 578.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7782/66745 [00:13<01:41, 578.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7841/66745 [00:13<01:41, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7899/66745 [00:14<01:41, 577.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7957/66745 [00:14<01:43, 567.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8014/66745 [00:14<01:43, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8071/66745 [00:14<01:44, 560.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8128/66745 [00:14<01:45, 557.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8184/66745 [00:14<01:45, 554.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8240/66745 [00:14<01:45, 554.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8298/66745 [00:14<01:44, 560.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8355/66745 [00:14<01:44, 559.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8413/66745 [00:14<01:43, 563.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8470/66745 [00:15<01:43, 564.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8527/66745 [00:15<01:44, 558.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8585/66745 [00:15<01:43, 562.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8643/66745 [00:15<01:42, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8700/66745 [00:15<01:42, 565.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8760/66745 [00:15<01:40, 574.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8820/66745 [00:15<01:39, 581.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8879/66745 [00:15<01:39, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8937/66745 [00:15<01:40, 576.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8997/66745 [00:15<01:39, 580.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9057/66745 [00:16<01:38, 585.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9117/66745 [00:16<01:38, 587.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9176/66745 [00:16<01:38, 583.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9235/66745 [00:16<01:39, 578.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9293/66745 [00:16<01:39, 575.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9354/66745 [00:16<01:38, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9414/66745 [00:16<01:37, 586.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9473/66745 [00:16<01:38, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9532/66745 [00:16<01:38, 578.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9590/66745 [00:16<01:38, 577.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9648/66745 [00:17<01:40, 570.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9706/66745 [00:17<01:41, 559.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9764/66745 [00:17<01:40, 564.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9821/66745 [00:17<01:41, 558.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9879/66745 [00:17<01:40, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9937/66745 [00:17<01:39, 568.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9994/66745 [00:17<01:42, 554.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10052/66745 [00:17<01:40, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10111/66745 [00:17<01:39, 568.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10170/66745 [00:18<01:38, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10229/66745 [00:18<01:38, 575.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10288/66745 [00:18<01:37, 577.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10346/66745 [00:18<01:38, 575.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10404/66745 [00:18<01:40, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10461/66745 [00:18<01:41, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10517/66745 [00:18<01:42, 546.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10574/66745 [00:18<01:41, 552.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10630/66745 [00:18<01:42, 545.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10690/66745 [00:18<01:40, 559.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10750/66745 [00:19<01:38, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10808/66745 [00:19<01:39, 560.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10866/66745 [00:19<01:39, 563.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10923/66745 [00:19<01:40, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10981/66745 [00:19<01:39, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11038/66745 [00:19<01:41, 550.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11094/66745 [00:19<01:41, 550.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11152/66745 [00:19<01:39, 555.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11210/66745 [00:19<01:38, 561.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11269/66745 [00:19<01:37, 568.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11326/66745 [00:20<01:38, 560.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11386/66745 [00:20<01:37, 569.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11443/66745 [00:20<01:37, 565.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11501/66745 [00:20<01:37, 567.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11558/66745 [00:20<01:38, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11615/66745 [00:20<01:40, 550.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11671/66745 [00:20<01:40, 547.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11730/66745 [00:20<01:38, 560.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11787/66745 [00:20<01:39, 553.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11845/66745 [00:21<01:38, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11904/66745 [00:21<01:36, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11961/66745 [00:21<01:38, 555.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12017/66745 [00:21<01:40, 546.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12072/66745 [00:21<01:40, 544.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12127/66745 [00:21<01:41, 540.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12185/66745 [00:21<01:39, 550.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12243/66745 [00:21<01:37, 558.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12303/66745 [00:21<01:35, 570.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12363/66745 [00:21<01:34, 577.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12421/66745 [00:22<01:34, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12479/66745 [00:22<01:35, 570.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12537/66745 [00:22<01:36, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12594/66745 [00:22<01:36, 561.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12653/66745 [00:22<01:35, 567.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12711/66745 [00:22<01:34, 570.22batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  19%|▉    | 12769/66745 [00:22<01:35, 567.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12828/66745 [00:22<01:33, 574.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12887/66745 [00:22<01:33, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12945/66745 [00:22<01:33, 574.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 13004/66745 [00:23<01:33, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13063/66745 [00:23<01:32, 579.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13121/66745 [00:23<01:35, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13181/66745 [00:23<01:33, 572.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13239/66745 [00:23<01:35, 558.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13298/66745 [00:23<01:34, 564.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13356/66745 [00:23<01:34, 565.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13416/66745 [00:23<01:33, 573.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13475/66745 [00:23<01:32, 578.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13533/66745 [00:23<01:33, 566.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13590/66745 [00:24<01:34, 565.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13647/66745 [00:24<01:33, 565.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13704/66745 [00:24<01:34, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13761/66745 [00:24<01:35, 553.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13817/66745 [00:24<01:37, 544.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13877/66745 [00:24<01:34, 558.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13934/66745 [00:24<01:34, 561.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13994/66745 [00:24<01:32, 569.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14052/66745 [00:24<01:33, 565.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14112/66745 [00:25<01:31, 574.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14173/66745 [00:25<01:30, 582.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14232/66745 [00:25<01:30, 579.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14292/66745 [00:25<01:29, 583.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14351/66745 [00:25<01:29, 583.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14410/66745 [00:25<01:29, 583.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14469/66745 [00:25<01:29, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14528/66745 [00:25<01:29, 580.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14587/66745 [00:25<01:31, 572.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14645/66745 [00:25<01:31, 571.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14704/66745 [00:26<01:30, 576.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14763/66745 [00:26<01:29, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14822/66745 [00:26<01:29, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14881/66745 [00:26<01:31, 566.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14939/66745 [00:26<01:31, 569.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14998/66745 [00:26<01:30, 574.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15057/66745 [00:26<01:29, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15115/66745 [00:26<01:31, 565.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15172/66745 [00:26<01:32, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15228/66745 [00:26<01:32, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15288/66745 [00:27<01:30, 566.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15345/66745 [00:27<01:31, 564.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15402/66745 [00:27<01:32, 553.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15458/66745 [00:27<01:32, 553.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15514/66745 [00:27<01:33, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15569/66745 [00:27<01:34, 543.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15624/66745 [00:27<01:33, 544.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15683/66745 [00:27<01:31, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15742/66745 [00:27<01:30, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15801/66745 [00:28<01:29, 570.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15860/66745 [00:28<01:28, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15919/66745 [00:28<01:28, 576.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15978/66745 [00:28<01:27, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16037/66745 [00:28<01:27, 580.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16096/66745 [00:28<01:27, 579.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16154/66745 [00:28<01:27, 577.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16212/66745 [00:28<01:28, 571.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16270/66745 [00:28<01:28, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16329/66745 [00:28<01:28, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16388/66745 [00:29<01:27, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16447/66745 [00:29<01:27, 577.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16506/66745 [00:29<01:26, 578.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16565/66745 [00:29<01:26, 579.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16624/66745 [00:29<01:26, 581.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16683/66745 [00:29<01:25, 582.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16742/66745 [00:29<01:25, 583.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16801/66745 [00:29<01:25, 583.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16860/66745 [00:29<01:25, 583.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16920/66745 [00:29<01:24, 586.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16979/66745 [00:30<01:24, 585.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17038/66745 [00:30<01:27, 566.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17095/66745 [00:30<01:28, 561.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17156/66745 [00:30<01:26, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17215/66745 [00:30<01:25, 578.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17275/66745 [00:30<01:25, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17334/66745 [00:30<01:24, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17393/66745 [00:30<01:27, 565.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17450/66745 [00:30<01:29, 553.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17506/66745 [00:30<01:29, 553.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17565/66745 [00:31<01:27, 562.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17622/66745 [00:31<01:27, 560.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17679/66745 [00:31<01:27, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17736/66745 [00:31<01:27, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17793/66745 [00:31<01:27, 560.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17851/66745 [00:31<01:26, 564.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17908/66745 [00:31<01:27, 555.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17964/66745 [00:31<01:27, 555.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18020/66745 [00:31<01:27, 553.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18079/66745 [00:31<01:26, 562.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18138/66745 [00:32<01:25, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18197/66745 [00:32<01:24, 575.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18256/66745 [00:32<01:23, 579.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18315/66745 [00:32<01:23, 581.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18374/66745 [00:32<01:23, 582.64batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  28%|█▍   | 18433/66745 [00:32<01:22, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18492/66745 [00:32<01:22, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18551/66745 [00:32<01:22, 586.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18610/66745 [00:32<01:22, 586.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18669/66745 [00:33<01:23, 574.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18727/66745 [00:33<01:24, 567.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18784/66745 [00:33<01:25, 562.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18843/66745 [00:33<01:24, 568.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18901/66745 [00:33<01:23, 571.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18959/66745 [00:33<01:23, 572.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 19017/66745 [00:33<01:24, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19076/66745 [00:33<01:23, 570.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19136/66745 [00:33<01:22, 578.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19196/66745 [00:33<01:21, 582.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19256/66745 [00:34<01:21, 586.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19315/66745 [00:34<01:22, 575.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19373/66745 [00:34<01:23, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19433/66745 [00:34<01:22, 574.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19491/66745 [00:34<01:23, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19548/66745 [00:34<01:24, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19605/66745 [00:34<01:26, 546.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19664/66745 [00:34<01:24, 557.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19721/66745 [00:34<01:23, 559.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19781/66745 [00:34<01:22, 571.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19840/66745 [00:35<01:21, 577.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19898/66745 [00:35<01:21, 572.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19956/66745 [00:35<01:23, 559.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 20013/66745 [00:35<01:23, 558.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20070/66745 [00:35<01:23, 561.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20130/66745 [00:35<01:21, 570.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20190/66745 [00:35<01:20, 577.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20249/66745 [00:35<01:19, 581.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20308/66745 [00:35<01:21, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20367/66745 [00:35<01:20, 573.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20425/66745 [00:36<01:21, 568.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20484/66745 [00:36<01:20, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20543/66745 [00:36<01:19, 578.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20602/66745 [00:36<01:19, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20661/66745 [00:36<01:19, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20719/66745 [00:36<01:22, 560.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20776/66745 [00:36<01:22, 557.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20832/66745 [00:36<01:22, 553.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20888/66745 [00:36<01:23, 548.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20944/66745 [00:37<01:23, 549.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 21000/66745 [00:37<01:22, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21056/66745 [00:37<01:23, 549.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21116/66745 [00:37<01:21, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21173/66745 [00:37<01:21, 556.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21231/66745 [00:37<01:21, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21288/66745 [00:37<01:21, 560.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21345/66745 [00:37<01:22, 552.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21402/66745 [00:37<01:21, 556.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21461/66745 [00:37<01:19, 566.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21519/66745 [00:38<01:19, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21577/66745 [00:38<01:19, 571.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21635/66745 [00:38<01:19, 570.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21693/66745 [00:38<01:18, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21751/66745 [00:38<01:18, 573.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21809/66745 [00:38<01:18, 575.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21867/66745 [00:38<01:18, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21926/66745 [00:38<01:17, 579.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21985/66745 [00:38<01:17, 580.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22044/66745 [00:38<01:18, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22102/66745 [00:39<01:18, 570.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22160/66745 [00:39<01:18, 566.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22220/66745 [00:39<01:17, 573.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22279/66745 [00:39<01:16, 577.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22337/66745 [00:39<01:17, 573.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22395/66745 [00:39<01:17, 570.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22453/66745 [00:39<01:18, 561.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22510/66745 [00:39<01:18, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22569/66745 [00:39<01:17, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22627/66745 [00:39<01:18, 561.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22684/66745 [00:40<01:18, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22741/66745 [00:40<01:19, 552.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22799/66745 [00:40<01:18, 558.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22855/66745 [00:40<01:18, 556.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22913/66745 [00:40<01:17, 562.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22971/66745 [00:40<01:17, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23028/66745 [00:40<01:18, 554.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23086/66745 [00:40<01:17, 562.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23143/66745 [00:40<01:18, 555.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23199/66745 [00:41<01:19, 547.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23254/66745 [00:41<01:19, 547.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23309/66745 [00:41<01:19, 545.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23367/66745 [00:41<01:18, 552.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23426/66745 [00:41<01:17, 562.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23484/66745 [00:41<01:16, 567.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23541/66745 [00:41<01:16, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23598/66745 [00:41<01:16, 565.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23657/66745 [00:41<01:15, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23716/66745 [00:41<01:14, 575.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23777/66745 [00:42<01:13, 583.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23838/66745 [00:42<01:12, 588.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23898/66745 [00:42<01:12, 591.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23958/66745 [00:42<01:13, 584.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24017/66745 [00:42<01:13, 578.34batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  36%|█▊   | 24075/66745 [00:42<01:13, 577.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24133/66745 [00:42<01:14, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24191/66745 [00:42<01:15, 564.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24248/66745 [00:42<01:15, 562.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24305/66745 [00:42<01:16, 554.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24361/66745 [00:43<01:17, 547.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24421/66745 [00:43<01:15, 559.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24478/66745 [00:43<01:16, 556.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24536/66745 [00:43<01:15, 561.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24594/66745 [00:43<01:14, 565.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24652/66745 [00:43<01:14, 567.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24709/66745 [00:43<01:14, 565.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24766/66745 [00:43<01:14, 566.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24825/66745 [00:43<01:13, 571.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24883/66745 [00:43<01:13, 571.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24942/66745 [00:44<01:12, 576.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 25001/66745 [00:44<01:11, 580.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25060/66745 [00:44<01:13, 569.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25117/66745 [00:44<01:13, 567.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25174/66745 [00:44<01:13, 563.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25231/66745 [00:44<01:14, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25288/66745 [00:44<01:14, 555.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25344/66745 [00:44<01:14, 554.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25401/66745 [00:44<01:14, 557.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25458/66745 [00:44<01:13, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25515/66745 [00:45<01:13, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25572/66745 [00:45<01:13, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25629/66745 [00:45<01:13, 556.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25685/66745 [00:45<01:13, 555.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25744/66745 [00:45<01:12, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25802/66745 [00:45<01:12, 565.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25859/66745 [00:45<01:12, 566.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25918/66745 [00:45<01:11, 570.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25977/66745 [00:45<01:10, 575.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26035/66745 [00:46<01:10, 574.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26094/66745 [00:46<01:10, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26153/66745 [00:46<01:10, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26211/66745 [00:46<01:10, 572.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26269/66745 [00:46<01:12, 561.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26327/66745 [00:46<01:11, 564.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26386/66745 [00:46<01:10, 570.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26445/66745 [00:46<01:10, 574.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26503/66745 [00:46<01:10, 570.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26563/66745 [00:46<01:09, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26621/66745 [00:47<01:09, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26679/66745 [00:47<01:09, 573.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26737/66745 [00:47<01:11, 561.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26794/66745 [00:47<01:11, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26850/66745 [00:47<01:12, 550.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26909/66745 [00:47<01:11, 559.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26968/66745 [00:47<01:10, 565.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 27027/66745 [00:47<01:09, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27086/66745 [00:47<01:09, 574.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27145/66745 [00:47<01:08, 576.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27204/66745 [00:48<01:08, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27263/66745 [00:48<01:08, 579.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27322/66745 [00:48<01:07, 580.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27381/66745 [00:48<01:07, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27440/66745 [00:48<01:07, 580.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27499/66745 [00:48<01:08, 573.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27557/66745 [00:48<01:10, 558.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27616/66745 [00:48<01:09, 566.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27675/66745 [00:48<01:08, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27734/66745 [00:48<01:07, 577.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27792/66745 [00:49<01:08, 564.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27849/66745 [00:49<01:08, 565.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27906/66745 [00:49<01:08, 566.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27966/66745 [00:49<01:07, 573.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28026/66745 [00:49<01:06, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28086/66745 [00:49<01:06, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28145/66745 [00:49<01:06, 583.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28204/66745 [00:49<01:06, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28263/66745 [00:49<01:06, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28322/66745 [00:50<01:05, 582.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28381/66745 [00:50<01:05, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28440/66745 [00:50<01:05, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28499/66745 [00:50<01:05, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28560/66745 [00:50<01:04, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28619/66745 [00:50<01:05, 578.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28678/66745 [00:50<01:05, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28737/66745 [00:50<01:05, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28796/66745 [00:50<01:06, 566.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28854/66745 [00:50<01:06, 567.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28912/66745 [00:51<01:06, 569.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28973/66745 [00:51<01:05, 578.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 29032/66745 [00:51<01:04, 581.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29091/66745 [00:51<01:04, 579.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29150/66745 [00:51<01:04, 579.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29209/66745 [00:51<01:04, 581.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29268/66745 [00:51<01:04, 583.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29327/66745 [00:51<01:03, 585.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29386/66745 [00:51<01:03, 586.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29445/66745 [00:51<01:03, 586.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29504/66745 [00:52<01:03, 584.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29564/66745 [00:52<01:03, 586.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29624/66745 [00:52<01:03, 588.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29683/66745 [00:52<01:03, 586.14batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  45%|██▏  | 29742/66745 [00:52<01:03, 580.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29801/66745 [00:52<01:03, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29860/66745 [00:52<01:03, 583.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29919/66745 [00:52<01:03, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29978/66745 [00:52<01:02, 585.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30037/66745 [00:52<01:02, 585.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30096/66745 [00:53<01:02, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30155/66745 [00:53<01:03, 574.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30213/66745 [00:53<01:04, 565.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30270/66745 [00:53<01:04, 562.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30329/66745 [00:53<01:03, 569.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30388/66745 [00:53<01:03, 574.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30447/66745 [00:53<01:02, 578.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30506/66745 [00:53<01:02, 581.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30565/66745 [00:53<01:02, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30624/66745 [00:53<01:03, 570.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30682/66745 [00:54<01:03, 570.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30740/66745 [00:54<01:03, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30797/66745 [00:54<01:03, 562.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30854/66745 [00:54<01:05, 548.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30912/66745 [00:54<01:04, 556.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30972/66745 [00:54<01:03, 566.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 31029/66745 [00:54<01:03, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31086/66745 [00:54<01:03, 562.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31143/66745 [00:54<01:04, 548.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31199/66745 [00:55<01:04, 549.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31256/66745 [00:55<01:04, 554.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31315/66745 [00:55<01:02, 564.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31374/66745 [00:55<01:02, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31432/66745 [00:55<01:02, 566.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31489/66745 [00:55<01:02, 566.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31546/66745 [00:55<01:02, 563.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31603/66745 [00:55<01:03, 553.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31659/66745 [00:55<01:04, 546.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31716/66745 [00:55<01:03, 552.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31777/66745 [00:56<01:01, 568.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31834/66745 [00:56<01:01, 565.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31893/66745 [00:56<01:01, 571.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31951/66745 [00:56<01:01, 567.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32008/66745 [00:56<01:01, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32067/66745 [00:56<01:00, 570.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32125/66745 [00:56<01:01, 566.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32182/66745 [00:56<01:02, 557.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32240/66745 [00:56<01:01, 561.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32299/66745 [00:56<01:00, 569.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32358/66745 [00:57<00:59, 574.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32416/66745 [00:57<01:00, 566.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32475/66745 [00:57<00:59, 572.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32533/66745 [00:57<01:00, 563.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32590/66745 [00:57<01:00, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32648/66745 [00:57<01:00, 565.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32706/66745 [00:57<00:59, 569.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32766/66745 [00:57<00:58, 576.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32826/66745 [00:57<00:58, 581.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32885/66745 [00:57<00:59, 566.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32942/66745 [00:58<01:00, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32999/66745 [00:58<01:00, 560.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33056/66745 [00:58<01:00, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33115/66745 [00:58<00:59, 568.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33175/66745 [00:58<00:58, 575.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33235/66745 [00:58<00:57, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33294/66745 [00:58<00:58, 571.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33352/66745 [00:58<00:59, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33408/66745 [00:58<01:00, 547.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33466/66745 [00:59<00:59, 556.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33523/66745 [00:59<00:59, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33580/66745 [00:59<00:59, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33639/66745 [00:59<00:58, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33698/66745 [00:59<00:57, 573.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33756/66745 [00:59<00:57, 574.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33814/66745 [00:59<00:57, 575.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33873/66745 [00:59<00:56, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33931/66745 [00:59<00:57, 571.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33989/66745 [00:59<00:57, 573.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34047/66745 [01:00<00:58, 560.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34105/66745 [01:00<00:57, 565.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34164/66745 [01:00<00:56, 571.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34225/66745 [01:00<00:55, 581.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34284/66745 [01:00<00:55, 581.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34343/66745 [01:00<00:55, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34402/66745 [01:00<00:55, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34461/66745 [01:00<00:56, 571.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34519/66745 [01:00<00:56, 570.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34577/66745 [01:00<00:57, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34633/66745 [01:01<00:57, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34692/66745 [01:01<00:56, 563.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34751/66745 [01:01<00:56, 568.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34808/66745 [01:01<00:56, 562.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34865/66745 [01:01<00:56, 560.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34922/66745 [01:01<00:57, 554.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34978/66745 [01:01<00:57, 556.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 35038/66745 [01:01<00:55, 566.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35095/66745 [01:01<00:56, 558.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35152/66745 [01:01<00:56, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35211/66745 [01:02<00:55, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35270/66745 [01:02<00:54, 573.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35329/66745 [01:02<00:54, 576.29batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  53%|██▋  | 35388/66745 [01:02<00:54, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35447/66745 [01:02<00:53, 579.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35506/66745 [01:02<00:53, 580.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35565/66745 [01:02<00:53, 581.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35625/66745 [01:02<00:53, 584.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35684/66745 [01:02<00:53, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35743/66745 [01:03<00:53, 584.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35802/66745 [01:03<00:53, 581.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35861/66745 [01:03<00:53, 580.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35920/66745 [01:03<00:53, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35979/66745 [01:03<00:54, 565.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36036/66745 [01:03<00:55, 557.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36092/66745 [01:03<00:55, 554.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36150/66745 [01:03<00:54, 559.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36208/66745 [01:03<00:54, 564.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36269/66745 [01:03<00:52, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36329/66745 [01:04<00:52, 580.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36388/66745 [01:04<00:52, 578.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36446/66745 [01:04<00:52, 574.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36504/66745 [01:04<00:53, 569.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36561/66745 [01:04<00:54, 556.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36617/66745 [01:04<00:54, 551.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36673/66745 [01:04<00:54, 553.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36729/66745 [01:04<00:54, 551.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36790/66745 [01:04<00:52, 566.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36848/66745 [01:04<00:52, 569.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36906/66745 [01:05<00:52, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36966/66745 [01:05<00:51, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37026/66745 [01:05<00:51, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37085/66745 [01:05<00:50, 584.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37144/66745 [01:05<00:51, 577.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37202/66745 [01:05<00:52, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37259/66745 [01:05<00:52, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37316/66745 [01:05<00:52, 557.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37372/66745 [01:05<00:52, 555.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37429/66745 [01:05<00:52, 558.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37488/66745 [01:06<00:51, 565.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37547/66745 [01:06<00:51, 570.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37605/66745 [01:06<00:52, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37662/66745 [01:06<00:52, 551.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37719/66745 [01:06<00:52, 554.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37777/66745 [01:06<00:51, 559.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37837/66745 [01:06<00:50, 568.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37895/66745 [01:06<00:50, 569.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37954/66745 [01:06<00:50, 574.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38012/66745 [01:07<00:50, 573.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38070/66745 [01:07<00:49, 574.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38128/66745 [01:07<00:49, 574.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38186/66745 [01:07<00:50, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38243/66745 [01:07<00:50, 559.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38299/66745 [01:07<00:50, 558.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38356/66745 [01:07<00:50, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38414/66745 [01:07<00:50, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38471/66745 [01:07<00:50, 564.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38528/66745 [01:07<00:50, 554.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38584/66745 [01:08<00:50, 555.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38642/66745 [01:08<00:50, 560.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38699/66745 [01:08<00:49, 561.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38756/66745 [01:08<00:49, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38813/66745 [01:08<00:49, 562.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38872/66745 [01:08<00:48, 568.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38931/66745 [01:08<00:48, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38990/66745 [01:08<00:48, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39050/66745 [01:08<00:47, 580.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39109/66745 [01:08<00:47, 583.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39168/66745 [01:09<00:47, 583.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39227/66745 [01:09<00:47, 574.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39285/66745 [01:09<00:48, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39342/66745 [01:09<00:49, 553.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39398/66745 [01:09<00:49, 550.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39454/66745 [01:09<00:49, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39513/66745 [01:09<00:48, 561.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39572/66745 [01:09<00:47, 567.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39631/66745 [01:09<00:47, 572.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39689/66745 [01:09<00:47, 566.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39746/66745 [01:10<00:48, 556.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39802/66745 [01:10<00:48, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39861/66745 [01:10<00:47, 564.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39919/66745 [01:10<00:47, 567.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39976/66745 [01:10<00:47, 564.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40033/66745 [01:10<00:47, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40090/66745 [01:10<00:48, 551.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40146/66745 [01:10<00:48, 550.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40207/66745 [01:10<00:46, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40264/66745 [01:11<00:47, 561.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40321/66745 [01:11<00:47, 552.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40380/66745 [01:11<00:46, 562.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40438/66745 [01:11<00:46, 567.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40496/66745 [01:11<00:45, 570.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40554/66745 [01:11<00:45, 572.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40612/66745 [01:11<00:45, 574.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40670/66745 [01:11<00:45, 575.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40728/66745 [01:11<00:45, 576.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40786/66745 [01:11<00:46, 563.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40843/66745 [01:12<00:47, 549.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40899/66745 [01:12<00:47, 548.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40954/66745 [01:12<00:47, 544.65batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  61%|███  | 41010/66745 [01:12<00:46, 547.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41065/66745 [01:12<00:47, 544.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41120/66745 [01:12<00:47, 543.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41178/66745 [01:12<00:46, 553.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41236/66745 [01:12<00:45, 560.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41293/66745 [01:12<00:46, 548.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41348/66745 [01:12<00:46, 543.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41405/66745 [01:13<00:46, 549.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41460/66745 [01:13<00:46, 545.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41515/66745 [01:13<00:46, 543.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41570/66745 [01:13<00:46, 542.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41627/66745 [01:13<00:45, 548.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41686/66745 [01:13<00:44, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41745/66745 [01:13<00:44, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41804/66745 [01:13<00:43, 572.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41863/66745 [01:13<00:43, 575.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41922/66745 [01:13<00:42, 577.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41983/66745 [01:14<00:42, 585.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42042/66745 [01:14<00:42, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42102/66745 [01:14<00:41, 589.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42163/66745 [01:14<00:41, 594.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42223/66745 [01:14<00:41, 588.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42282/66745 [01:14<00:41, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42341/66745 [01:14<00:41, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42400/66745 [01:14<00:41, 583.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42459/66745 [01:14<00:41, 584.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42518/66745 [01:14<00:41, 585.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42577/66745 [01:15<00:41, 585.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42636/66745 [01:15<00:41, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42695/66745 [01:15<00:41, 574.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42753/66745 [01:15<00:42, 567.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42812/66745 [01:15<00:41, 572.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42870/66745 [01:15<00:41, 571.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42929/66745 [01:15<00:41, 575.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42988/66745 [01:15<00:41, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43047/66745 [01:15<00:40, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43107/66745 [01:16<00:40, 585.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43166/66745 [01:16<00:40, 581.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43225/66745 [01:16<00:40, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43284/66745 [01:16<00:40, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43343/66745 [01:16<00:40, 584.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43402/66745 [01:16<00:40, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43462/66745 [01:16<00:39, 587.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43523/66745 [01:16<00:39, 591.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43584/66745 [01:16<00:38, 594.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43646/66745 [01:16<00:38, 599.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43707/66745 [01:17<00:38, 600.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43768/66745 [01:17<00:38, 596.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43828/66745 [01:17<00:38, 595.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43889/66745 [01:17<00:38, 596.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43951/66745 [01:17<00:37, 601.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44013/66745 [01:17<00:37, 605.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44075/66745 [01:17<00:37, 607.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44136/66745 [01:17<00:37, 597.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44196/66745 [01:17<00:38, 589.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44255/66745 [01:17<00:38, 587.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44314/66745 [01:18<00:38, 583.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44373/66745 [01:18<00:38, 583.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44432/66745 [01:18<00:38, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44491/66745 [01:18<00:37, 586.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44550/66745 [01:18<00:37, 585.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44609/66745 [01:18<00:37, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44668/66745 [01:18<00:37, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44727/66745 [01:18<00:37, 582.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44786/66745 [01:18<00:37, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44845/66745 [01:18<00:37, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44904/66745 [01:19<00:37, 584.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44963/66745 [01:19<00:37, 581.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45022/66745 [01:19<00:37, 577.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45080/66745 [01:19<00:38, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45139/66745 [01:19<00:37, 573.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45198/66745 [01:19<00:37, 577.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45257/66745 [01:19<00:37, 579.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45315/66745 [01:19<00:37, 577.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45374/66745 [01:19<00:36, 580.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45434/66745 [01:19<00:36, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45494/66745 [01:20<00:36, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45554/66745 [01:20<00:35, 590.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45614/66745 [01:20<00:35, 590.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45674/66745 [01:20<00:35, 586.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45734/66745 [01:20<00:35, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45794/66745 [01:20<00:35, 589.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45854/66745 [01:20<00:35, 590.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45914/66745 [01:20<00:35, 591.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45974/66745 [01:20<00:35, 592.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46034/66745 [01:20<00:34, 591.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46094/66745 [01:21<00:34, 592.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46154/66745 [01:21<00:34, 593.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46214/66745 [01:21<00:34, 593.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46274/66745 [01:21<00:34, 592.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46334/66745 [01:21<00:34, 592.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46394/66745 [01:21<00:34, 592.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46454/66745 [01:21<00:34, 592.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46514/66745 [01:21<00:34, 593.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46574/66745 [01:21<00:34, 593.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46634/66745 [01:21<00:33, 593.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46694/66745 [01:22<00:33, 593.89batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  70%|███▌ | 46754/66745 [01:22<00:33, 589.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46814/66745 [01:22<00:33, 590.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46874/66745 [01:22<00:33, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46934/66745 [01:22<00:33, 589.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46994/66745 [01:22<00:33, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47054/66745 [01:22<00:33, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47114/66745 [01:22<00:34, 576.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47172/66745 [01:22<00:34, 564.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47229/66745 [01:23<00:34, 562.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47287/66745 [01:23<00:34, 565.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47344/66745 [01:23<00:34, 554.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47400/66745 [01:23<00:35, 548.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47455/66745 [01:23<00:35, 542.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47510/66745 [01:23<00:35, 543.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47572/66745 [01:23<00:33, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47634/66745 [01:23<00:33, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47695/66745 [01:23<00:32, 587.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47754/66745 [01:23<00:32, 576.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47814/66745 [01:24<00:32, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47874/66745 [01:24<00:32, 586.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47934/66745 [01:24<00:31, 588.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47993/66745 [01:24<00:32, 585.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48052/66745 [01:24<00:32, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48112/66745 [01:24<00:31, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48172/66745 [01:24<00:31, 588.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48234/66745 [01:24<00:31, 596.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48296/66745 [01:24<00:30, 601.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48357/66745 [01:24<00:30, 600.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48418/66745 [01:25<00:30, 592.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48478/66745 [01:25<00:30, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48538/66745 [01:25<00:31, 586.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48599/66745 [01:25<00:30, 592.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48659/66745 [01:25<00:31, 580.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48719/66745 [01:25<00:30, 584.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48778/66745 [01:25<00:30, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48838/66745 [01:25<00:30, 586.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48897/66745 [01:25<00:30, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48956/66745 [01:25<00:30, 586.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 49015/66745 [01:26<00:30, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49074/66745 [01:26<00:30, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49133/66745 [01:26<00:29, 587.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49192/66745 [01:26<00:29, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49251/66745 [01:26<00:30, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49310/66745 [01:26<00:30, 579.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49370/66745 [01:26<00:29, 583.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49430/66745 [01:26<00:29, 586.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49490/66745 [01:26<00:29, 588.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49550/66745 [01:27<00:29, 589.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49609/66745 [01:27<00:29, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49669/66745 [01:27<00:29, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49728/66745 [01:27<00:29, 586.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49787/66745 [01:27<00:28, 587.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49846/66745 [01:27<00:29, 579.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49905/66745 [01:27<00:29, 573.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49965/66745 [01:27<00:28, 579.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50024/66745 [01:27<00:28, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50083/66745 [01:27<00:28, 579.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50141/66745 [01:28<00:29, 566.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50198/66745 [01:28<00:29, 565.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50258/66745 [01:28<00:28, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50318/66745 [01:28<00:28, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50378/66745 [01:28<00:28, 584.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50437/66745 [01:28<00:28, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50497/66745 [01:28<00:27, 584.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50557/66745 [01:28<00:27, 587.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50617/66745 [01:28<00:27, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50677/66745 [01:28<00:27, 590.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50737/66745 [01:29<00:27, 590.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50797/66745 [01:29<00:27, 590.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50857/66745 [01:29<00:26, 589.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50916/66745 [01:29<00:27, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50976/66745 [01:29<00:27, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51036/66745 [01:29<00:26, 586.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51096/66745 [01:29<00:26, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51156/66745 [01:29<00:26, 590.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51216/66745 [01:29<00:26, 591.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51276/66745 [01:29<00:26, 594.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51336/66745 [01:30<00:26, 582.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51396/66745 [01:30<00:26, 586.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51456/66745 [01:30<00:25, 590.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51516/66745 [01:30<00:25, 591.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51576/66745 [01:30<00:25, 588.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51636/66745 [01:30<00:25, 590.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51696/66745 [01:30<00:25, 591.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51756/66745 [01:30<00:25, 592.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51816/66745 [01:30<00:25, 591.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51876/66745 [01:30<00:25, 591.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51936/66745 [01:31<00:25, 591.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51996/66745 [01:31<00:24, 590.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52056/66745 [01:31<00:24, 590.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52116/66745 [01:31<00:24, 589.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52176/66745 [01:31<00:24, 590.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52236/66745 [01:31<00:24, 590.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52296/66745 [01:31<00:24, 591.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52356/66745 [01:31<00:24, 591.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52416/66745 [01:31<00:24, 591.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52476/66745 [01:32<00:24, 590.42batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  79%|███▉ | 52536/66745 [01:32<00:24, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52595/66745 [01:32<00:24, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52654/66745 [01:32<00:23, 588.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52714/66745 [01:32<00:23, 590.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52774/66745 [01:32<00:23, 591.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52834/66745 [01:32<00:23, 591.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52894/66745 [01:32<00:23, 592.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52954/66745 [01:32<00:23, 592.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53014/66745 [01:32<00:23, 592.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53074/66745 [01:33<00:23, 592.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53134/66745 [01:33<00:23, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53194/66745 [01:33<00:22, 589.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53253/66745 [01:33<00:23, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53313/66745 [01:33<00:23, 583.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53373/66745 [01:33<00:22, 586.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53432/66745 [01:33<00:22, 579.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53490/66745 [01:33<00:22, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53551/66745 [01:33<00:22, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53611/66745 [01:33<00:22, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53671/66745 [01:34<00:22, 589.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53730/66745 [01:34<00:22, 586.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53789/66745 [01:34<00:22, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53848/66745 [01:34<00:22, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53908/66745 [01:34<00:21, 586.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53968/66745 [01:34<00:21, 589.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54028/66745 [01:34<00:21, 591.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54088/66745 [01:34<00:21, 586.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54148/66745 [01:34<00:21, 588.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54208/66745 [01:34<00:21, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54268/66745 [01:35<00:21, 591.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54328/66745 [01:35<00:20, 591.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54388/66745 [01:35<00:20, 591.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54448/66745 [01:35<00:20, 591.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54508/66745 [01:35<00:20, 592.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54568/66745 [01:35<00:20, 592.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54628/66745 [01:35<00:20, 592.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54688/66745 [01:35<00:20, 581.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54748/66745 [01:35<00:20, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54808/66745 [01:35<00:20, 587.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54868/66745 [01:36<00:20, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54927/66745 [01:36<00:20, 589.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54987/66745 [01:36<00:19, 589.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55046/66745 [01:36<00:19, 589.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55105/66745 [01:36<00:19, 589.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55164/66745 [01:36<00:19, 589.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55223/66745 [01:36<00:19, 588.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55282/66745 [01:36<00:19, 584.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55342/66745 [01:36<00:19, 587.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55402/66745 [01:36<00:19, 588.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55463/66745 [01:37<00:18, 594.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55523/66745 [01:37<00:19, 576.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55581/66745 [01:37<00:19, 577.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55639/66745 [01:37<00:19, 572.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55697/66745 [01:37<00:19, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55754/66745 [01:37<00:19, 551.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55812/66745 [01:37<00:19, 559.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55869/66745 [01:37<00:19, 549.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55926/66745 [01:37<00:19, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55984/66745 [01:38<00:19, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56041/66745 [01:38<00:19, 561.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56100/66745 [01:38<00:18, 569.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56159/66745 [01:38<00:18, 574.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56217/66745 [01:38<00:18, 560.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56276/66745 [01:38<00:18, 566.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56333/66745 [01:38<00:18, 565.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56393/66745 [01:38<00:18, 574.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56451/66745 [01:38<00:18, 568.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56508/66745 [01:38<00:18, 563.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56566/66745 [01:39<00:17, 568.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56624/66745 [01:39<00:17, 568.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56681/66745 [01:39<00:17, 566.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56740/66745 [01:39<00:17, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56799/66745 [01:39<00:17, 574.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56857/66745 [01:39<00:17, 562.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56914/66745 [01:39<00:17, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56973/66745 [01:39<00:17, 570.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57031/66745 [01:39<00:17, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57089/66745 [01:39<00:16, 568.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57149/66745 [01:40<00:16, 576.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57208/66745 [01:40<00:16, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57268/66745 [01:40<00:16, 583.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57327/66745 [01:40<00:16, 580.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57386/66745 [01:40<00:16, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57445/66745 [01:40<00:15, 582.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57504/66745 [01:40<00:15, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57563/66745 [01:40<00:15, 579.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57621/66745 [01:40<00:15, 573.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57680/66745 [01:40<00:15, 576.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57739/66745 [01:41<00:15, 579.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57797/66745 [01:41<00:15, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57856/66745 [01:41<00:15, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57917/66745 [01:41<00:15, 584.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57977/66745 [01:41<00:14, 587.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58036/66745 [01:41<00:15, 574.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58094/66745 [01:41<00:15, 574.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58153/66745 [01:41<00:14, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58211/66745 [01:41<00:14, 569.30batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  87%|████▎| 58271/66745 [01:41<00:14, 575.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58331/66745 [01:42<00:14, 580.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58390/66745 [01:42<00:14, 580.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58449/66745 [01:42<00:14, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58509/66745 [01:42<00:14, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58569/66745 [01:42<00:13, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58629/66745 [01:42<00:13, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58689/66745 [01:42<00:13, 588.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58749/66745 [01:42<00:13, 589.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58808/66745 [01:42<00:13, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58867/66745 [01:43<00:13, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58926/66745 [01:43<00:13, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58985/66745 [01:43<00:13, 582.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59044/66745 [01:43<00:13, 584.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59104/66745 [01:43<00:13, 587.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59164/66745 [01:43<00:12, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59224/66745 [01:43<00:12, 590.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59284/66745 [01:43<00:12, 577.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59344/66745 [01:43<00:12, 582.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59403/66745 [01:43<00:12, 568.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59460/66745 [01:44<00:12, 561.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59517/66745 [01:44<00:12, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59574/66745 [01:44<00:12, 556.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59630/66745 [01:44<00:12, 551.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59686/66745 [01:44<00:12, 552.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59742/66745 [01:44<00:12, 550.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59798/66745 [01:44<00:12, 544.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59853/66745 [01:44<00:12, 541.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59908/66745 [01:44<00:12, 534.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59962/66745 [01:44<00:12, 529.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60016/66745 [01:45<00:12, 530.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60073/66745 [01:45<00:12, 540.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60128/66745 [01:45<00:12, 540.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60187/66745 [01:45<00:11, 553.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60245/66745 [01:45<00:11, 561.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60303/66745 [01:45<00:11, 564.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60361/66745 [01:45<00:11, 566.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60418/66745 [01:45<00:11, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60475/66745 [01:45<00:11, 562.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60535/66745 [01:45<00:10, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60594/66745 [01:46<00:10, 575.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60652/66745 [01:46<00:10, 571.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60710/66745 [01:46<00:10, 571.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60768/66745 [01:46<00:10, 568.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60825/66745 [01:46<00:10, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60883/66745 [01:46<00:10, 569.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60940/66745 [01:46<00:10, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60999/66745 [01:46<00:10, 571.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61057/66745 [01:46<00:10, 559.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61113/66745 [01:47<00:10, 550.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61171/66745 [01:47<00:10, 556.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61230/66745 [01:47<00:09, 563.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61287/66745 [01:47<00:09, 558.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61343/66745 [01:47<00:09, 552.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61399/66745 [01:47<00:09, 546.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61454/66745 [01:47<00:09, 546.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61512/66745 [01:47<00:09, 555.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61570/66745 [01:47<00:09, 560.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61627/66745 [01:47<00:09, 560.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61684/66745 [01:48<00:09, 560.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61742/66745 [01:48<00:08, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61802/66745 [01:48<00:08, 572.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61861/66745 [01:48<00:08, 576.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61921/66745 [01:48<00:08, 580.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61980/66745 [01:48<00:08, 582.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62039/66745 [01:48<00:08, 581.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62098/66745 [01:48<00:08, 571.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62157/66745 [01:48<00:07, 576.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62217/66745 [01:48<00:07, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62276/66745 [01:49<00:07, 582.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62335/66745 [01:49<00:07, 580.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62394/66745 [01:49<00:07, 574.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62452/66745 [01:49<00:07, 573.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62510/66745 [01:49<00:07, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62570/66745 [01:49<00:07, 574.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62630/66745 [01:49<00:07, 579.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62690/66745 [01:49<00:06, 583.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62750/66745 [01:49<00:06, 586.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62809/66745 [01:49<00:06, 587.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62868/66745 [01:50<00:06, 584.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62927/66745 [01:50<00:06, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62986/66745 [01:50<00:06, 580.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63046/66745 [01:50<00:06, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63105/66745 [01:50<00:06, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63165/66745 [01:50<00:06, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63224/66745 [01:50<00:06, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63284/66745 [01:50<00:05, 585.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63344/66745 [01:50<00:05, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63403/66745 [01:51<00:05, 586.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63462/66745 [01:51<00:05, 587.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63521/66745 [01:51<00:05, 585.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63580/66745 [01:51<00:05, 569.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63638/66745 [01:51<00:05, 563.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63697/66745 [01:51<00:05, 570.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63756/66745 [01:51<00:05, 574.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63814/66745 [01:51<00:05, 573.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63874/66745 [01:51<00:04, 578.59batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  96%|████▊| 63932/66745 [01:51<00:04, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63990/66745 [01:52<00:04, 573.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64048/66745 [01:52<00:04, 571.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64107/66745 [01:52<00:04, 575.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64168/66745 [01:52<00:04, 582.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64227/66745 [01:52<00:04, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64286/66745 [01:52<00:04, 578.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64344/66745 [01:52<00:04, 569.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64402/66745 [01:52<00:04, 566.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64459/66745 [01:52<00:04, 563.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64516/66745 [01:52<00:03, 561.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64573/66745 [01:53<00:03, 550.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64630/66745 [01:53<00:03, 553.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64686/66745 [01:53<00:03, 548.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64742/66745 [01:53<00:03, 550.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64798/66745 [01:53<00:03, 551.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64854/66745 [01:53<00:03, 542.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64911/66745 [01:53<00:03, 548.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64970/66745 [01:53<00:03, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65030/66745 [01:53<00:03, 567.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65087/66745 [01:53<00:02, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65144/66745 [01:54<00:02, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65200/66745 [01:54<00:02, 554.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65258/66745 [01:54<00:02, 561.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65316/66745 [01:54<00:02, 565.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65373/66745 [01:54<00:02, 564.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65433/66745 [01:54<00:02, 574.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65491/66745 [01:54<00:02, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65550/66745 [01:54<00:02, 568.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65607/66745 [01:54<00:02, 566.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65667/66745 [01:55<00:01, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65725/66745 [01:55<00:01, 561.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65782/66745 [01:55<00:01, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65839/66745 [01:55<00:01, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65896/66745 [01:55<00:01, 557.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65952/66745 [01:55<00:01, 549.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66009/66745 [01:55<00:01, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66067/66745 [01:55<00:01, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66126/66745 [01:55<00:01, 569.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66185/66745 [01:55<00:00, 574.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66243/66745 [01:56<00:00, 573.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66301/66745 [01:56<00:00, 562.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66358/66745 [01:56<00:00, 562.36batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66415/66745 [01:56<00:00, 557.97batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66471/66745 [01:56<00:00, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66527/66745 [01:56<00:00, 547.40batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66583/66745 [01:56<00:00, 549.47batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66644/66745 [01:56<00:00, 566.87batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66705/66745 [01:56<00:00, 579.15batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   2%| | 2/100 [03:53<3:10:29, 116.63s/epoch, loss=0.3\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 13/66745 [00:00<08:43, 127.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 68/66745 [00:00<03:00, 370.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 126/66745 [00:00<02:23, 463.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 188/66745 [00:00<02:07, 521.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 243/66745 [00:00<02:05, 528.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 296/66745 [00:00<02:06, 525.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 349/66745 [00:00<02:06, 525.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 406/66745 [00:00<02:03, 538.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 460/66745 [00:00<02:03, 538.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 517/66745 [00:01<02:01, 546.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 574/66745 [00:01<01:59, 553.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 630/66745 [00:01<02:01, 546.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 685/66745 [00:01<02:02, 538.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 741/66745 [00:01<02:01, 544.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 796/66745 [00:01<02:01, 543.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 855/66745 [00:01<01:58, 556.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 914/66745 [00:01<01:56, 564.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 973/66745 [00:01<01:55, 570.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1032/66745 [00:01<01:54, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1090/66745 [00:02<01:54, 572.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1148/66745 [00:02<01:58, 555.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1206/66745 [00:02<01:56, 561.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1265/66745 [00:02<01:54, 569.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1326/66745 [00:02<01:52, 580.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1387/66745 [00:02<01:51, 587.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1446/66745 [00:02<01:52, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1505/66745 [00:02<01:53, 572.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1563/66745 [00:02<01:56, 561.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1620/66745 [00:02<01:56, 557.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1677/66745 [00:03<01:56, 559.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1733/66745 [00:03<01:57, 555.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1789/66745 [00:03<01:57, 552.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1846/66745 [00:03<01:56, 555.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1902/66745 [00:03<01:57, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1961/66745 [00:03<01:55, 561.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2019/66745 [00:03<01:54, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2076/66745 [00:03<01:54, 565.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2133/66745 [00:03<01:55, 558.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2189/66745 [00:03<01:58, 546.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2244/66745 [00:04<01:59, 538.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2298/66745 [00:04<02:00, 532.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2352/66745 [00:04<02:02, 526.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2405/66745 [00:04<02:02, 524.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2458/66745 [00:04<02:02, 522.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2511/66745 [00:04<02:03, 521.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2565/66745 [00:04<02:02, 525.33batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   4%|▏     | 2618/66745 [00:04<02:02, 523.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2671/66745 [00:04<02:02, 522.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2724/66745 [00:05<02:02, 521.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2777/66745 [00:05<02:02, 521.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2830/66745 [00:05<02:03, 517.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2883/66745 [00:05<02:03, 519.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2937/66745 [00:05<02:01, 524.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2991/66745 [00:05<02:00, 528.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3047/66745 [00:05<01:58, 537.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3106/66745 [00:05<01:55, 551.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3165/66745 [00:05<01:52, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3224/66745 [00:05<01:51, 569.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3283/66745 [00:06<01:50, 575.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3341/66745 [00:06<01:50, 574.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3402/66745 [00:06<01:48, 583.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3463/66745 [00:06<01:47, 590.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3524/66745 [00:06<01:46, 593.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3584/66745 [00:06<01:46, 594.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3644/66745 [00:06<01:46, 594.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3704/66745 [00:06<01:45, 596.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3764/66745 [00:06<01:45, 596.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3824/66745 [00:06<01:45, 597.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3884/66745 [00:07<01:45, 597.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3944/66745 [00:07<01:45, 596.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4004/66745 [00:07<01:45, 595.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4064/66745 [00:07<01:45, 593.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4124/66745 [00:07<01:45, 592.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4184/66745 [00:07<01:45, 592.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4244/66745 [00:07<01:45, 592.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4304/66745 [00:07<01:45, 592.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4364/66745 [00:07<01:46, 588.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4424/66745 [00:07<01:45, 590.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4484/66745 [00:08<01:45, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4544/66745 [00:08<01:45, 591.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4604/66745 [00:08<01:45, 591.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4664/66745 [00:08<01:44, 592.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4724/66745 [00:08<01:45, 590.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4784/66745 [00:08<01:45, 589.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4843/66745 [00:08<01:45, 584.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4902/66745 [00:08<01:46, 580.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4961/66745 [00:08<01:45, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5020/66745 [00:08<01:45, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5080/66745 [00:09<01:45, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5139/66745 [00:09<01:45, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5198/66745 [00:09<01:46, 579.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5257/66745 [00:09<01:45, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5319/66745 [00:09<01:43, 591.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5381/66745 [00:09<01:42, 598.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5443/66745 [00:09<01:41, 603.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5504/66745 [00:09<01:41, 605.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5566/66745 [00:09<01:40, 606.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5627/66745 [00:09<01:41, 602.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5688/66745 [00:10<01:41, 599.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5748/66745 [00:10<01:42, 596.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5808/66745 [00:10<01:43, 591.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5868/66745 [00:10<01:43, 589.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5929/66745 [00:10<01:42, 593.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5990/66745 [00:10<01:41, 597.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6050/66745 [00:10<01:42, 593.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6110/66745 [00:10<01:41, 595.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6170/66745 [00:10<01:41, 596.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6230/66745 [00:11<01:41, 597.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6290/66745 [00:11<01:41, 597.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6350/66745 [00:11<01:42, 588.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6409/66745 [00:11<01:42, 588.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6468/66745 [00:11<01:42, 585.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6527/66745 [00:11<01:42, 585.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6586/66745 [00:11<01:42, 585.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6647/66745 [00:11<01:41, 591.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6707/66745 [00:11<01:41, 593.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6767/66745 [00:11<01:40, 595.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6827/66745 [00:12<01:41, 592.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6887/66745 [00:12<01:41, 592.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6947/66745 [00:12<01:41, 588.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 7006/66745 [00:12<01:41, 588.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7065/66745 [00:12<01:42, 584.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7126/66745 [00:12<01:41, 589.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7186/66745 [00:12<01:40, 592.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7247/66745 [00:12<01:40, 594.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7307/66745 [00:12<01:39, 595.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7368/66745 [00:12<01:39, 598.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7428/66745 [00:13<01:39, 595.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7488/66745 [00:13<01:39, 596.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7548/66745 [00:13<01:39, 597.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7608/66745 [00:13<01:42, 578.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7666/66745 [00:13<01:44, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7723/66745 [00:13<01:46, 555.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7779/66745 [00:13<01:47, 550.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7835/66745 [00:13<01:47, 547.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7890/66745 [00:13<01:48, 544.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7945/66745 [00:13<01:48, 540.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8000/66745 [00:14<01:49, 537.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8054/66745 [00:14<01:49, 535.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8108/66745 [00:14<01:50, 531.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8162/66745 [00:14<01:50, 528.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8216/66745 [00:14<01:50, 529.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8270/66745 [00:14<01:49, 532.45batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  12%|▋     | 8324/66745 [00:14<01:49, 534.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8378/66745 [00:14<01:49, 533.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8432/66745 [00:14<01:49, 534.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8486/66745 [00:14<01:48, 535.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8541/66745 [00:15<01:47, 539.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8599/66745 [00:15<01:45, 550.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8658/66745 [00:15<01:43, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8717/66745 [00:15<01:42, 568.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8776/66745 [00:15<01:41, 573.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8835/66745 [00:15<01:40, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8895/66745 [00:15<01:39, 581.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8954/66745 [00:15<01:39, 583.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9013/66745 [00:15<01:38, 584.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9072/66745 [00:15<01:38, 585.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9131/66745 [00:16<01:38, 585.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9190/66745 [00:16<01:38, 586.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9249/66745 [00:16<01:38, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9308/66745 [00:16<01:38, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9367/66745 [00:16<01:37, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9427/66745 [00:16<01:37, 587.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9487/66745 [00:16<01:37, 588.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9546/66745 [00:16<01:37, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9606/66745 [00:16<01:36, 590.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9666/66745 [00:17<01:36, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9726/66745 [00:17<01:36, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9786/66745 [00:17<01:36, 591.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9846/66745 [00:17<01:36, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9906/66745 [00:17<01:36, 590.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9966/66745 [00:17<01:36, 590.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10026/66745 [00:17<01:36, 590.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10086/66745 [00:17<01:36, 586.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10146/66745 [00:17<01:36, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10206/66745 [00:17<01:36, 588.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10266/66745 [00:18<01:35, 590.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10326/66745 [00:18<01:35, 591.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10386/66745 [00:18<01:35, 591.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10446/66745 [00:18<01:35, 591.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10506/66745 [00:18<01:35, 586.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10566/66745 [00:18<01:35, 588.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10626/66745 [00:18<01:35, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10687/66745 [00:18<01:34, 594.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10747/66745 [00:18<01:34, 594.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10807/66745 [00:18<01:34, 593.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10867/66745 [00:19<01:34, 593.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10927/66745 [00:19<01:34, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10987/66745 [00:19<01:34, 591.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11047/66745 [00:19<01:34, 591.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11107/66745 [00:19<01:34, 587.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11166/66745 [00:19<01:35, 579.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11224/66745 [00:19<01:35, 579.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11282/66745 [00:19<01:37, 570.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11342/66745 [00:19<01:35, 577.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11402/66745 [00:19<01:34, 583.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11461/66745 [00:20<01:34, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11521/66745 [00:20<01:34, 587.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11581/66745 [00:20<01:33, 589.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11640/66745 [00:20<01:33, 586.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11700/66745 [00:20<01:33, 588.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11759/66745 [00:20<01:33, 585.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11820/66745 [00:20<01:32, 591.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11881/66745 [00:20<01:31, 597.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11941/66745 [00:20<01:33, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12001/66745 [00:20<01:32, 590.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12061/66745 [00:21<01:32, 589.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12121/66745 [00:21<01:32, 591.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12181/66745 [00:21<01:32, 589.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12240/66745 [00:21<01:32, 589.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12300/66745 [00:21<01:32, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12359/66745 [00:21<01:32, 588.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12418/66745 [00:21<01:32, 587.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12477/66745 [00:21<01:32, 588.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12536/66745 [00:21<01:32, 588.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12595/66745 [00:21<01:32, 587.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12655/66745 [00:22<01:31, 588.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12714/66745 [00:22<01:31, 588.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12773/66745 [00:22<01:31, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12832/66745 [00:22<01:31, 588.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12891/66745 [00:22<01:31, 587.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12950/66745 [00:22<01:31, 587.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 13009/66745 [00:22<01:32, 582.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13068/66745 [00:22<01:31, 583.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13127/66745 [00:22<01:31, 584.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13186/66745 [00:22<01:32, 581.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13245/66745 [00:23<01:31, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13304/66745 [00:23<01:31, 584.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13364/66745 [00:23<01:30, 586.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13423/66745 [00:23<01:30, 587.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13482/66745 [00:23<01:30, 587.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13541/66745 [00:23<01:30, 587.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13600/66745 [00:23<01:30, 587.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13659/66745 [00:23<01:30, 587.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13718/66745 [00:23<01:30, 587.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13777/66745 [00:23<01:30, 587.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13837/66745 [00:24<01:29, 588.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13896/66745 [00:24<01:29, 589.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13955/66745 [00:24<01:29, 589.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14014/66745 [00:24<01:30, 584.27batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  21%|█    | 14073/66745 [00:24<01:29, 585.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14132/66745 [00:24<01:29, 586.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14191/66745 [00:24<01:30, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14250/66745 [00:24<01:29, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14309/66745 [00:24<01:29, 585.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14369/66745 [00:25<01:29, 588.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14430/66745 [00:25<01:27, 594.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14492/66745 [00:25<01:27, 599.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14552/66745 [00:25<01:29, 585.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14611/66745 [00:25<01:29, 585.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14670/66745 [00:25<01:28, 586.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14729/66745 [00:25<01:28, 584.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14788/66745 [00:25<01:28, 585.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14847/66745 [00:25<01:28, 585.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14906/66745 [00:25<01:28, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14965/66745 [00:26<01:28, 587.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15024/66745 [00:26<01:28, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15083/66745 [00:26<01:27, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15142/66745 [00:26<01:27, 587.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15201/66745 [00:26<01:27, 588.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15261/66745 [00:26<01:27, 588.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15320/66745 [00:26<01:27, 588.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15379/66745 [00:26<01:27, 588.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15438/66745 [00:26<01:28, 582.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15498/66745 [00:26<01:27, 586.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15558/66745 [00:27<01:26, 589.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15617/66745 [00:27<01:29, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15675/66745 [00:27<01:29, 569.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15733/66745 [00:27<01:29, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15794/66745 [00:27<01:27, 580.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15854/66745 [00:27<01:26, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15913/66745 [00:27<01:28, 574.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15971/66745 [00:27<01:28, 576.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16032/66745 [00:27<01:26, 583.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16093/66745 [00:27<01:25, 591.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16154/66745 [00:28<01:25, 594.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16214/66745 [00:28<01:24, 595.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16275/66745 [00:28<01:24, 599.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16336/66745 [00:28<01:24, 599.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16397/66745 [00:28<01:23, 600.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16458/66745 [00:28<01:24, 597.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16518/66745 [00:28<01:24, 595.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16578/66745 [00:28<01:24, 592.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16638/66745 [00:28<01:25, 587.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16698/66745 [00:28<01:25, 588.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16757/66745 [00:29<01:24, 588.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16816/66745 [00:29<01:24, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16875/66745 [00:29<01:24, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16934/66745 [00:29<01:24, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16993/66745 [00:29<01:24, 588.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17052/66745 [00:29<01:24, 588.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17111/66745 [00:29<01:25, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17170/66745 [00:29<01:25, 578.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17230/66745 [00:29<01:24, 582.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17289/66745 [00:29<01:24, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17348/66745 [00:30<01:24, 585.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17407/66745 [00:30<01:24, 586.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17466/66745 [00:30<01:23, 587.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17525/66745 [00:30<01:23, 587.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17584/66745 [00:30<01:23, 587.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17643/66745 [00:30<01:23, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17702/66745 [00:30<01:24, 580.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17761/66745 [00:30<01:24, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17820/66745 [00:30<01:24, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17880/66745 [00:30<01:23, 585.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17940/66745 [00:31<01:22, 589.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17999/66745 [00:31<01:23, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18061/66745 [00:31<01:22, 591.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18121/66745 [00:31<01:22, 587.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18181/66745 [00:31<01:22, 587.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18240/66745 [00:31<01:22, 588.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18299/66745 [00:31<01:23, 581.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18358/66745 [00:31<01:23, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18418/66745 [00:31<01:22, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18479/66745 [00:32<01:21, 590.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18540/66745 [00:32<01:21, 593.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18602/66745 [00:32<01:20, 599.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18664/66745 [00:32<01:19, 603.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18725/66745 [00:32<01:19, 602.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18786/66745 [00:32<01:20, 598.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18846/66745 [00:32<01:20, 596.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18906/66745 [00:32<01:21, 586.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18965/66745 [00:32<01:22, 582.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19026/66745 [00:32<01:21, 588.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19087/66745 [00:33<01:20, 592.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19147/66745 [00:33<01:20, 590.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19207/66745 [00:33<01:21, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19266/66745 [00:33<01:22, 573.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19324/66745 [00:33<01:23, 568.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19381/66745 [00:33<01:23, 568.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19438/66745 [00:33<01:23, 567.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19500/66745 [00:33<01:21, 580.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19559/66745 [00:33<01:22, 568.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19617/66745 [00:33<01:22, 569.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19674/66745 [00:34<01:23, 564.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19731/66745 [00:34<01:23, 559.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19792/66745 [00:34<01:21, 573.96batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  30%|█▍   | 19850/66745 [00:34<01:22, 570.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19908/66745 [00:34<01:22, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19965/66745 [00:34<01:22, 563.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20025/66745 [00:34<01:21, 573.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20083/66745 [00:34<01:21, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20141/66745 [00:34<01:21, 574.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20199/66745 [00:34<01:22, 566.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20258/66745 [00:35<01:21, 572.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20318/66745 [00:35<01:20, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20380/66745 [00:35<01:18, 590.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20441/66745 [00:35<01:17, 594.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20501/66745 [00:35<01:17, 592.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20561/66745 [00:35<01:18, 591.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20621/66745 [00:35<01:18, 589.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20680/66745 [00:35<01:19, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20740/66745 [00:35<01:18, 587.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20800/66745 [00:36<01:17, 589.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20860/66745 [00:36<01:17, 591.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20920/66745 [00:36<01:17, 591.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20980/66745 [00:36<01:17, 593.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21040/66745 [00:36<01:17, 593.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21102/66745 [00:36<01:16, 599.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21162/66745 [00:36<01:16, 597.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21222/66745 [00:36<01:16, 597.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21282/66745 [00:36<01:17, 590.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21342/66745 [00:36<01:18, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21401/66745 [00:37<01:18, 576.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21460/66745 [00:37<01:18, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21520/66745 [00:37<01:17, 585.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21582/66745 [00:37<01:16, 593.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21642/66745 [00:37<01:16, 593.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21704/66745 [00:37<01:15, 599.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21766/66745 [00:37<01:14, 604.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21828/66745 [00:37<01:13, 607.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21889/66745 [00:37<01:15, 593.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21949/66745 [00:37<01:15, 594.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22009/66745 [00:38<01:15, 592.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22069/66745 [00:38<01:15, 591.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22129/66745 [00:38<01:15, 590.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22189/66745 [00:38<01:15, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22249/66745 [00:38<01:15, 590.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22309/66745 [00:38<01:14, 592.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22369/66745 [00:38<01:15, 590.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22429/66745 [00:38<01:14, 592.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22489/66745 [00:38<01:15, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22548/66745 [00:38<01:15, 586.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22609/66745 [00:39<01:14, 593.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22669/66745 [00:39<01:14, 594.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22731/66745 [00:39<01:13, 599.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22791/66745 [00:39<01:13, 598.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22851/66745 [00:39<01:13, 596.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22912/66745 [00:39<01:13, 598.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22973/66745 [00:39<01:12, 600.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23034/66745 [00:39<01:12, 598.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23094/66745 [00:39<01:14, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23153/66745 [00:39<01:14, 583.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23212/66745 [00:40<01:15, 579.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23270/66745 [00:40<01:15, 574.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23330/66745 [00:40<01:14, 579.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23388/66745 [00:40<01:18, 555.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23450/66745 [00:40<01:15, 571.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23511/66745 [00:40<01:14, 581.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23571/66745 [00:40<01:13, 585.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23631/66745 [00:40<01:13, 589.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23691/66745 [00:40<01:13, 583.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23750/66745 [00:41<01:14, 579.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23810/66745 [00:41<01:13, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23870/66745 [00:41<01:12, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23929/66745 [00:41<01:12, 588.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23988/66745 [00:41<01:13, 583.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24047/66745 [00:41<01:12, 585.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24106/66745 [00:41<01:12, 586.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24165/66745 [00:41<01:12, 587.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24225/66745 [00:41<01:12, 588.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24284/66745 [00:41<01:12, 588.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24343/66745 [00:42<01:13, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24403/66745 [00:42<01:12, 585.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24462/66745 [00:42<01:12, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24521/66745 [00:42<01:12, 586.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24580/66745 [00:42<01:12, 583.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24639/66745 [00:42<01:12, 578.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24701/66745 [00:42<01:11, 588.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24760/66745 [00:42<01:11, 586.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24822/66745 [00:42<01:10, 595.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24882/66745 [00:42<01:10, 594.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24942/66745 [00:43<01:10, 592.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 25002/66745 [00:43<01:10, 591.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25062/66745 [00:43<01:10, 590.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25122/66745 [00:43<01:10, 589.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25181/66745 [00:43<01:10, 589.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25241/66745 [00:43<01:10, 591.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25301/66745 [00:43<01:10, 589.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25362/66745 [00:43<01:09, 594.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25422/66745 [00:43<01:10, 585.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25481/66745 [00:43<01:12, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25539/66745 [00:44<01:12, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25597/66745 [00:44<01:13, 561.91batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  38%|█▉   | 25656/66745 [00:44<01:12, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25716/66745 [00:44<01:11, 575.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25776/66745 [00:44<01:10, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25836/66745 [00:44<01:10, 583.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25896/66745 [00:44<01:09, 585.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25956/66745 [00:44<01:09, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26016/66745 [00:44<01:09, 589.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26075/66745 [00:44<01:09, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26134/66745 [00:45<01:09, 588.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26193/66745 [00:45<01:08, 587.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26252/66745 [00:45<01:08, 587.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26311/66745 [00:45<01:08, 588.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26370/66745 [00:45<01:08, 588.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26429/66745 [00:45<01:08, 588.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26488/66745 [00:45<01:08, 588.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26547/66745 [00:45<01:08, 588.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26606/66745 [00:45<01:08, 588.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26665/66745 [00:45<01:08, 588.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26724/66745 [00:46<01:08, 587.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26783/66745 [00:46<01:08, 581.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26842/66745 [00:46<01:08, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26902/66745 [00:46<01:07, 586.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26961/66745 [00:46<01:07, 587.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 27021/66745 [00:46<01:07, 588.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27082/66745 [00:46<01:06, 594.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27142/66745 [00:46<01:07, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27202/66745 [00:46<01:07, 590.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27263/66745 [00:46<01:06, 595.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27323/66745 [00:47<01:07, 585.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27384/66745 [00:47<01:06, 592.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27445/66745 [00:47<01:06, 595.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27506/66745 [00:47<01:05, 599.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27567/66745 [00:47<01:05, 599.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27628/66745 [00:47<01:05, 600.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27689/66745 [00:47<01:05, 597.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27749/66745 [00:47<01:05, 594.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27809/66745 [00:47<01:05, 592.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27869/66745 [00:48<01:05, 591.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27929/66745 [00:48<01:06, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27989/66745 [00:48<01:05, 587.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28048/66745 [00:48<01:05, 588.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28109/66745 [00:48<01:05, 592.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28169/66745 [00:48<01:06, 576.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28229/66745 [00:48<01:06, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28289/66745 [00:48<01:05, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28349/66745 [00:48<01:05, 586.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28409/66745 [00:48<01:05, 587.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28468/66745 [00:49<01:05, 588.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28527/66745 [00:49<01:06, 576.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28586/66745 [00:49<01:05, 579.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28645/66745 [00:49<01:05, 581.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28704/66745 [00:49<01:05, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28763/66745 [00:49<01:04, 585.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28822/66745 [00:49<01:04, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28881/66745 [00:49<01:04, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28940/66745 [00:49<01:04, 587.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28999/66745 [00:49<01:04, 588.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29059/66745 [00:50<01:04, 588.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29118/66745 [00:50<01:03, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29177/66745 [00:50<01:03, 587.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29236/66745 [00:50<01:03, 588.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29295/66745 [00:50<01:03, 588.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29354/66745 [00:50<01:03, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29413/66745 [00:50<01:03, 588.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29472/66745 [00:50<01:03, 588.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29531/66745 [00:50<01:03, 588.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29591/66745 [00:50<01:02, 590.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29651/66745 [00:51<01:02, 590.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29711/66745 [00:51<01:02, 589.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29770/66745 [00:51<01:02, 589.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29829/66745 [00:51<01:03, 582.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29890/66745 [00:51<01:02, 588.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29949/66745 [00:51<01:02, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 30009/66745 [00:51<01:02, 589.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30069/66745 [00:51<01:02, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30129/66745 [00:51<01:01, 591.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30189/66745 [00:51<01:01, 591.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30249/66745 [00:52<01:01, 590.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30309/66745 [00:52<01:02, 585.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30368/66745 [00:52<01:03, 570.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30429/66745 [00:52<01:02, 579.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30488/66745 [00:52<01:02, 577.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30547/66745 [00:52<01:02, 580.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30606/66745 [00:52<01:02, 582.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30665/66745 [00:52<01:01, 584.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30724/66745 [00:52<01:01, 585.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30783/66745 [00:52<01:01, 586.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30842/66745 [00:53<01:01, 587.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30901/66745 [00:53<01:02, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30959/66745 [00:53<01:02, 576.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 31017/66745 [00:53<01:03, 566.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31077/66745 [00:53<01:01, 575.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31136/66745 [00:53<01:01, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31194/66745 [00:53<01:01, 578.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31252/66745 [00:53<01:01, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31310/66745 [00:53<01:01, 572.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31368/66745 [00:54<01:01, 570.60batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  47%|██▎  | 31426/66745 [00:54<01:02, 569.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31483/66745 [00:54<01:02, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31540/66745 [00:54<01:03, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31596/66745 [00:54<01:03, 551.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31656/66745 [00:54<01:02, 562.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31715/66745 [00:54<01:01, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31773/66745 [00:54<01:01, 571.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31832/66745 [00:54<01:00, 575.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31891/66745 [00:54<01:00, 579.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31951/66745 [00:55<00:59, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32010/66745 [00:55<00:59, 584.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32069/66745 [00:55<00:59, 585.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32128/66745 [00:55<00:59, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32188/66745 [00:55<00:58, 589.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32247/66745 [00:55<00:58, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32307/66745 [00:55<00:58, 588.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32368/66745 [00:55<00:57, 594.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32428/66745 [00:55<00:57, 592.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32488/66745 [00:55<00:57, 591.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32548/66745 [00:56<00:57, 590.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32608/66745 [00:56<00:57, 590.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32668/66745 [00:56<00:57, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32728/66745 [00:56<00:58, 584.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32788/66745 [00:56<00:57, 587.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32848/66745 [00:56<00:57, 589.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32907/66745 [00:56<00:57, 589.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32966/66745 [00:56<00:57, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 33025/66745 [00:56<00:57, 589.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33084/66745 [00:56<00:57, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33143/66745 [00:57<00:57, 589.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33202/66745 [00:57<00:56, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33262/66745 [00:57<00:56, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33321/66745 [00:57<00:57, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33380/66745 [00:57<00:57, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33440/66745 [00:57<00:56, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33499/66745 [00:57<00:56, 587.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33558/66745 [00:57<00:56, 587.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33617/66745 [00:57<00:56, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33676/66745 [00:57<00:56, 587.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33736/66745 [00:58<00:55, 589.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33796/66745 [00:58<00:55, 590.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33856/66745 [00:58<00:55, 590.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33916/66745 [00:58<00:55, 590.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33976/66745 [00:58<00:55, 590.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34036/66745 [00:58<00:55, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34096/66745 [00:58<00:55, 590.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34156/66745 [00:58<00:55, 590.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34216/66745 [00:58<00:55, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34276/66745 [00:58<00:55, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34336/66745 [00:59<00:54, 589.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34395/66745 [00:59<00:54, 589.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34454/66745 [00:59<00:54, 589.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34514/66745 [00:59<00:54, 590.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34574/66745 [00:59<00:54, 590.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34634/66745 [00:59<00:54, 590.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34694/66745 [00:59<00:54, 589.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34753/66745 [00:59<00:54, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34812/66745 [00:59<00:54, 589.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34871/66745 [00:59<00:54, 589.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34931/66745 [01:00<00:53, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34991/66745 [01:00<00:53, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35050/66745 [01:00<00:53, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35109/66745 [01:00<00:53, 588.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35168/66745 [01:00<00:54, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35227/66745 [01:00<00:53, 585.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35286/66745 [01:00<00:53, 586.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35345/66745 [01:00<00:53, 587.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35405/66745 [01:00<00:53, 589.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35464/66745 [01:00<00:53, 587.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35524/66745 [01:01<00:53, 588.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35584/66745 [01:01<00:52, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35644/66745 [01:01<00:52, 592.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35704/66745 [01:01<00:52, 594.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35764/66745 [01:01<00:52, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35825/66745 [01:01<00:52, 592.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35885/66745 [01:01<00:51, 593.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35945/66745 [01:01<00:52, 591.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36005/66745 [01:01<00:52, 589.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36064/66745 [01:02<00:52, 589.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36123/66745 [01:02<00:51, 589.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36182/66745 [01:02<00:51, 588.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36241/66745 [01:02<00:51, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36300/66745 [01:02<00:52, 578.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36359/66745 [01:02<00:52, 581.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36418/66745 [01:02<00:52, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36478/66745 [01:02<00:51, 582.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36538/66745 [01:02<00:51, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36598/66745 [01:02<00:51, 586.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36657/66745 [01:03<00:51, 587.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36717/66745 [01:03<00:51, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36776/66745 [01:03<00:50, 588.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36835/66745 [01:03<00:51, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36894/66745 [01:03<00:50, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36953/66745 [01:03<00:51, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37012/66745 [01:03<00:51, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37071/66745 [01:03<00:51, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37131/66745 [01:03<00:50, 581.95batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  56%|██▊  | 37190/66745 [01:03<00:50, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37249/66745 [01:04<00:50, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37309/66745 [01:04<00:50, 584.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37368/66745 [01:04<00:50, 585.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37428/66745 [01:04<00:49, 587.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37488/66745 [01:04<00:49, 587.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37547/66745 [01:04<00:50, 580.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37606/66745 [01:04<00:50, 580.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37665/66745 [01:04<00:50, 580.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37724/66745 [01:04<00:49, 581.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37783/66745 [01:04<00:49, 581.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37842/66745 [01:05<00:49, 581.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37901/66745 [01:05<00:49, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37960/66745 [01:05<00:49, 582.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38019/66745 [01:05<00:49, 582.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38078/66745 [01:05<00:49, 582.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38137/66745 [01:05<00:49, 581.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38196/66745 [01:05<00:49, 581.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38255/66745 [01:05<00:48, 582.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38314/66745 [01:05<00:48, 582.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38373/66745 [01:05<00:48, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38432/66745 [01:06<00:48, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38491/66745 [01:06<00:48, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38550/66745 [01:06<00:48, 583.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38609/66745 [01:06<00:48, 583.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38668/66745 [01:06<00:48, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38727/66745 [01:06<00:48, 583.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38786/66745 [01:06<00:48, 578.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38845/66745 [01:06<00:48, 579.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38904/66745 [01:06<00:47, 581.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38963/66745 [01:06<00:47, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 39022/66745 [01:07<00:47, 582.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39081/66745 [01:07<00:47, 582.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39140/66745 [01:07<00:47, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39199/66745 [01:07<00:47, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39258/66745 [01:07<00:47, 579.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39317/66745 [01:07<00:47, 580.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39376/66745 [01:07<00:47, 574.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39434/66745 [01:07<00:47, 569.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39493/66745 [01:07<00:47, 573.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39554/66745 [01:08<00:46, 581.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39615/66745 [01:08<00:46, 589.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39676/66745 [01:08<00:45, 594.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39737/66745 [01:08<00:45, 598.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39797/66745 [01:08<00:46, 585.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39856/66745 [01:08<00:46, 577.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39914/66745 [01:08<00:47, 568.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39972/66745 [01:08<00:46, 571.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40030/66745 [01:08<00:46, 572.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40088/66745 [01:08<00:46, 574.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40146/66745 [01:09<00:46, 575.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40204/66745 [01:09<00:46, 576.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40262/66745 [01:09<00:45, 577.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40320/66745 [01:09<00:45, 577.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40378/66745 [01:09<00:45, 577.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40436/66745 [01:09<00:45, 575.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40494/66745 [01:09<00:46, 559.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40551/66745 [01:09<00:47, 556.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40607/66745 [01:09<00:47, 554.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40663/66745 [01:09<00:47, 548.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40724/66745 [01:10<00:45, 565.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40786/66745 [01:10<00:44, 578.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40846/66745 [01:10<00:44, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40905/66745 [01:10<00:44, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40964/66745 [01:10<00:44, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41023/66745 [01:10<00:44, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41082/66745 [01:10<00:44, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41140/66745 [01:10<00:44, 579.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41199/66745 [01:10<00:43, 580.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41258/66745 [01:10<00:43, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41317/66745 [01:11<00:43, 582.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41376/66745 [01:11<00:43, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41435/66745 [01:11<00:43, 582.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41494/66745 [01:11<00:43, 583.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41553/66745 [01:11<00:43, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41612/66745 [01:11<00:43, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41670/66745 [01:11<00:43, 579.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41728/66745 [01:11<00:43, 578.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41787/66745 [01:11<00:43, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41846/66745 [01:11<00:42, 581.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41906/66745 [01:12<00:42, 584.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41965/66745 [01:12<00:42, 585.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42025/66745 [01:12<00:42, 587.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42084/66745 [01:12<00:42, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42145/66745 [01:12<00:41, 592.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42205/66745 [01:12<00:41, 593.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42266/66745 [01:12<00:41, 596.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42326/66745 [01:12<00:42, 578.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42385/66745 [01:12<00:42, 579.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42444/66745 [01:12<00:41, 581.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42503/66745 [01:13<00:41, 582.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42562/66745 [01:13<00:41, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42621/66745 [01:13<00:41, 584.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42680/66745 [01:13<00:41, 584.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42739/66745 [01:13<00:41, 583.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42798/66745 [01:13<00:41, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42857/66745 [01:13<00:41, 576.83batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  64%|███▏ | 42915/66745 [01:13<00:42, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42973/66745 [01:13<00:42, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43032/66745 [01:14<00:41, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43091/66745 [01:14<00:41, 572.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43150/66745 [01:14<00:40, 575.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43209/66745 [01:14<00:40, 578.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43268/66745 [01:14<00:40, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43327/66745 [01:14<00:40, 581.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43386/66745 [01:14<00:40, 581.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43445/66745 [01:14<00:40, 577.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43503/66745 [01:14<00:40, 574.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43561/66745 [01:14<00:41, 564.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43618/66745 [01:15<00:41, 561.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43675/66745 [01:15<00:41, 553.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43736/66745 [01:15<00:40, 569.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43795/66745 [01:15<00:39, 574.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43853/66745 [01:15<00:40, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43912/66745 [01:15<00:39, 575.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43971/66745 [01:15<00:39, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44031/66745 [01:15<00:38, 584.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44090/66745 [01:15<00:39, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44148/66745 [01:15<00:39, 570.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44206/66745 [01:16<00:39, 569.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44265/66745 [01:16<00:39, 575.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44323/66745 [01:16<00:39, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44380/66745 [01:16<00:39, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44437/66745 [01:16<00:39, 563.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44494/66745 [01:16<00:39, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44552/66745 [01:16<00:39, 564.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44610/66745 [01:16<00:38, 569.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44667/66745 [01:16<00:39, 564.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44727/66745 [01:16<00:38, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44788/66745 [01:17<00:37, 582.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44849/66745 [01:17<00:37, 590.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44910/66745 [01:17<00:36, 595.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44971/66745 [01:17<00:36, 598.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45031/66745 [01:17<00:36, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45091/66745 [01:17<00:36, 590.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45151/66745 [01:17<00:36, 589.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45210/66745 [01:17<00:36, 587.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45269/66745 [01:17<00:36, 583.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45328/66745 [01:18<00:36, 582.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45387/66745 [01:18<00:36, 579.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45445/66745 [01:18<00:36, 578.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45503/66745 [01:18<00:36, 578.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45562/66745 [01:18<00:36, 579.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45623/66745 [01:18<00:35, 588.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45682/66745 [01:18<00:35, 588.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45742/66745 [01:18<00:35, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45801/66745 [01:18<00:35, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45860/66745 [01:18<00:36, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45919/66745 [01:19<00:36, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45980/66745 [01:19<00:35, 586.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46039/66745 [01:19<00:35, 585.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46098/66745 [01:19<00:35, 576.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46157/66745 [01:19<00:35, 577.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46217/66745 [01:19<00:35, 582.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46277/66745 [01:19<00:34, 586.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46336/66745 [01:19<00:34, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46396/66745 [01:19<00:34, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46455/66745 [01:19<00:34, 586.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46514/66745 [01:20<00:34, 583.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46574/66745 [01:20<00:34, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46634/66745 [01:20<00:34, 588.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46694/66745 [01:20<00:34, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46754/66745 [01:20<00:33, 590.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46814/66745 [01:20<00:33, 590.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46874/66745 [01:20<00:33, 591.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46934/66745 [01:20<00:33, 591.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46994/66745 [01:20<00:33, 591.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47054/66745 [01:20<00:33, 579.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47113/66745 [01:21<00:33, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47172/66745 [01:21<00:33, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47231/66745 [01:21<00:33, 579.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47289/66745 [01:21<00:33, 577.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47347/66745 [01:21<00:33, 576.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47405/66745 [01:21<00:33, 576.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47463/66745 [01:21<00:33, 576.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47521/66745 [01:21<00:33, 576.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47579/66745 [01:21<00:33, 576.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47637/66745 [01:21<00:34, 554.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47695/66745 [01:22<00:33, 560.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47753/66745 [01:22<00:33, 565.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47811/66745 [01:22<00:33, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47869/66745 [01:22<00:33, 571.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47927/66745 [01:22<00:32, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47985/66745 [01:22<00:32, 574.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48043/66745 [01:22<00:32, 572.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48102/66745 [01:22<00:32, 575.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48161/66745 [01:22<00:32, 577.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48219/66745 [01:22<00:32, 571.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48278/66745 [01:23<00:32, 575.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48336/66745 [01:23<00:32, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48393/66745 [01:23<00:32, 563.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48450/66745 [01:23<00:32, 557.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48509/66745 [01:23<00:32, 565.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48569/66745 [01:23<00:31, 575.25batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  73%|███▋ | 48628/66745 [01:23<00:31, 577.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48687/66745 [01:23<00:31, 578.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48746/66745 [01:23<00:31, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48805/66745 [01:24<00:31, 572.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48863/66745 [01:24<00:31, 568.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48920/66745 [01:24<00:31, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48978/66745 [01:24<00:31, 569.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 49036/66745 [01:24<00:30, 571.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49094/66745 [01:24<00:30, 574.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49152/66745 [01:24<00:30, 575.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49210/66745 [01:24<00:30, 575.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49268/66745 [01:24<00:30, 575.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49326/66745 [01:24<00:30, 575.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49384/66745 [01:25<00:30, 575.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49442/66745 [01:25<00:30, 573.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49500/66745 [01:25<00:30, 572.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49558/66745 [01:25<00:30, 557.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49614/66745 [01:25<00:31, 548.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49669/66745 [01:25<00:31, 539.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49728/66745 [01:25<00:30, 551.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49784/66745 [01:25<00:31, 546.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49839/66745 [01:25<00:30, 546.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49898/66745 [01:25<00:30, 559.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49954/66745 [01:26<00:30, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50012/66745 [01:26<00:29, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50071/66745 [01:26<00:29, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50130/66745 [01:26<00:29, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50189/66745 [01:26<00:28, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50248/66745 [01:26<00:28, 578.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50307/66745 [01:26<00:28, 580.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50366/66745 [01:26<00:28, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50424/66745 [01:26<00:28, 577.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50485/66745 [01:26<00:27, 586.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50546/66745 [01:27<00:27, 592.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50606/66745 [01:27<00:27, 581.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50665/66745 [01:27<00:27, 579.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50725/66745 [01:27<00:27, 582.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50784/66745 [01:27<00:27, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50843/66745 [01:27<00:27, 576.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50904/66745 [01:27<00:27, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50964/66745 [01:27<00:26, 585.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51024/66745 [01:27<00:26, 587.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51084/66745 [01:28<00:26, 588.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51144/66745 [01:28<00:26, 589.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51203/66745 [01:28<00:26, 575.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51261/66745 [01:28<00:27, 572.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51320/66745 [01:28<00:26, 576.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51378/66745 [01:28<00:26, 574.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51439/66745 [01:28<00:26, 582.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51498/66745 [01:28<00:26, 583.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51557/66745 [01:28<00:26, 583.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51617/66745 [01:28<00:25, 586.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51677/66745 [01:29<00:25, 589.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51738/66745 [01:29<00:25, 593.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51798/66745 [01:29<00:25, 576.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51856/66745 [01:29<00:26, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51913/66745 [01:29<00:26, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51974/66745 [01:29<00:25, 576.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52035/66745 [01:29<00:25, 586.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52096/66745 [01:29<00:24, 592.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52156/66745 [01:29<00:24, 589.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52215/66745 [01:29<00:24, 588.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52274/66745 [01:30<00:24, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52333/66745 [01:30<00:25, 570.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52391/66745 [01:30<00:25, 570.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52449/66745 [01:30<00:24, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52508/66745 [01:30<00:24, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52566/66745 [01:30<00:24, 572.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52624/66745 [01:30<00:25, 564.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52683/66745 [01:30<00:24, 570.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52743/66745 [01:30<00:24, 577.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52801/66745 [01:30<00:24, 575.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52859/66745 [01:31<00:24, 570.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52917/66745 [01:31<00:24, 572.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52975/66745 [01:31<00:24, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53033/66745 [01:31<00:23, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53091/66745 [01:31<00:23, 574.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53149/66745 [01:31<00:23, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53207/66745 [01:31<00:23, 576.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53265/66745 [01:31<00:23, 576.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53323/66745 [01:31<00:23, 575.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53382/66745 [01:31<00:23, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53440/66745 [01:32<00:23, 577.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53498/66745 [01:32<00:22, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53556/66745 [01:32<00:23, 572.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53614/66745 [01:32<00:23, 556.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53673/66745 [01:32<00:23, 563.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53732/66745 [01:32<00:22, 568.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53790/66745 [01:32<00:22, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53849/66745 [01:32<00:22, 573.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53907/66745 [01:32<00:22, 567.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53968/66745 [01:33<00:22, 579.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54028/66745 [01:33<00:21, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54089/66745 [01:33<00:21, 589.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54149/66745 [01:33<00:21, 581.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54208/66745 [01:33<00:21, 572.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54266/66745 [01:33<00:22, 566.38batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  81%|████ | 54323/66745 [01:33<00:22, 556.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54379/66745 [01:33<00:22, 551.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54435/66745 [01:33<00:22, 546.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54490/66745 [01:33<00:22, 541.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54545/66745 [01:34<00:22, 537.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54599/66745 [01:34<00:22, 535.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54653/66745 [01:34<00:22, 531.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54707/66745 [01:34<00:22, 525.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54764/66745 [01:34<00:22, 535.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54823/66745 [01:34<00:21, 549.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54882/66745 [01:34<00:21, 560.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54941/66745 [01:34<00:20, 567.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55000/66745 [01:34<00:20, 573.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55058/66745 [01:34<00:20, 568.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55115/66745 [01:35<00:20, 563.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55172/66745 [01:35<00:20, 559.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55228/66745 [01:35<00:20, 555.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55284/66745 [01:35<00:21, 541.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55339/66745 [01:35<00:21, 541.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55398/66745 [01:35<00:20, 554.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55455/66745 [01:35<00:20, 558.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55511/66745 [01:35<00:20, 553.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55567/66745 [01:35<00:20, 552.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55623/66745 [01:36<00:20, 551.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55680/66745 [01:36<00:19, 554.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55741/66745 [01:36<00:19, 569.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55800/66745 [01:36<00:19, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55858/66745 [01:36<00:19, 567.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55917/66745 [01:36<00:18, 573.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55978/66745 [01:36<00:18, 582.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56037/66745 [01:36<00:18, 582.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56096/66745 [01:36<00:18, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56157/66745 [01:36<00:17, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56216/66745 [01:37<00:17, 588.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56275/66745 [01:37<00:17, 587.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56334/66745 [01:37<00:17, 586.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56393/66745 [01:37<00:17, 585.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56452/66745 [01:37<00:17, 572.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56510/66745 [01:37<00:18, 567.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56567/66745 [01:37<00:18, 563.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56626/66745 [01:37<00:17, 569.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56685/66745 [01:37<00:17, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56744/66745 [01:37<00:17, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56803/66745 [01:38<00:17, 577.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56862/66745 [01:38<00:17, 578.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56920/66745 [01:38<00:17, 577.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56978/66745 [01:38<00:16, 575.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57036/66745 [01:38<00:16, 571.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57094/66745 [01:38<00:17, 566.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57151/66745 [01:38<00:17, 560.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57208/66745 [01:38<00:17, 556.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57267/66745 [01:38<00:16, 564.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57324/66745 [01:38<00:16, 555.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57381/66745 [01:39<00:16, 559.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57437/66745 [01:39<00:16, 558.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57496/66745 [01:39<00:16, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57555/66745 [01:39<00:16, 571.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57614/66745 [01:39<00:15, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57672/66745 [01:39<00:15, 567.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57731/66745 [01:39<00:15, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57790/66745 [01:39<00:15, 578.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57848/66745 [01:39<00:15, 570.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57906/66745 [01:39<00:15, 568.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57963/66745 [01:40<00:15, 568.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58022/66745 [01:40<00:15, 571.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58081/66745 [01:40<00:15, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58140/66745 [01:40<00:14, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58199/66745 [01:40<00:14, 581.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58258/66745 [01:40<00:14, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58317/66745 [01:40<00:14, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58376/66745 [01:40<00:14, 580.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58435/66745 [01:40<00:14, 581.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58494/66745 [01:40<00:14, 583.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58553/66745 [01:41<00:14, 584.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58612/66745 [01:41<00:13, 585.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58671/66745 [01:41<00:13, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58730/66745 [01:41<00:13, 583.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58789/66745 [01:41<00:13, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58848/66745 [01:41<00:13, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58906/66745 [01:41<00:13, 566.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58965/66745 [01:41<00:13, 570.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59024/66745 [01:41<00:13, 573.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59082/66745 [01:42<00:13, 570.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59143/66745 [01:42<00:13, 581.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59203/66745 [01:42<00:12, 584.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59262/66745 [01:42<00:12, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59321/66745 [01:42<00:12, 575.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59379/66745 [01:42<00:13, 561.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59436/66745 [01:42<00:13, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59492/66745 [01:42<00:13, 549.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59548/66745 [01:42<00:13, 547.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59606/66745 [01:42<00:12, 556.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59665/66745 [01:43<00:12, 563.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59724/66745 [01:43<00:12, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59783/66745 [01:43<00:12, 573.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59842/66745 [01:43<00:11, 575.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59900/66745 [01:43<00:11, 575.02batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  90%|████▍| 59959/66745 [01:43<00:11, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60017/66745 [01:43<00:11, 567.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60074/66745 [01:43<00:11, 563.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60131/66745 [01:43<00:11, 557.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60190/66745 [01:43<00:11, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60248/66745 [01:44<00:11, 569.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60307/66745 [01:44<00:11, 573.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60366/66745 [01:44<00:11, 577.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60425/66745 [01:44<00:10, 579.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60484/66745 [01:44<00:10, 581.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60543/66745 [01:44<00:10, 582.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60602/66745 [01:44<00:10, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60660/66745 [01:44<00:10, 571.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60718/66745 [01:44<00:10, 564.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60775/66745 [01:44<00:10, 560.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60832/66745 [01:45<00:10, 556.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60888/66745 [01:45<00:10, 553.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60945/66745 [01:45<00:10, 555.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61002/66745 [01:45<00:10, 557.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61061/66745 [01:45<00:10, 564.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61118/66745 [01:45<00:10, 560.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61175/66745 [01:45<00:10, 551.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61236/66745 [01:45<00:09, 566.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61293/66745 [01:45<00:09, 564.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61352/66745 [01:46<00:09, 569.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61409/66745 [01:46<00:09, 554.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61465/66745 [01:46<00:09, 547.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61522/66745 [01:46<00:09, 551.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61583/66745 [01:46<00:09, 567.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61640/66745 [01:46<00:09, 564.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61699/66745 [01:46<00:08, 569.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61757/66745 [01:46<00:08, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61817/66745 [01:46<00:08, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61878/66745 [01:46<00:08, 579.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61937/66745 [01:47<00:08, 580.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61996/66745 [01:47<00:08, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62055/66745 [01:47<00:08, 573.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62113/66745 [01:47<00:08, 571.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62172/66745 [01:47<00:07, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62230/66745 [01:47<00:07, 574.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62288/66745 [01:47<00:07, 575.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62347/66745 [01:47<00:07, 577.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62405/66745 [01:47<00:07, 565.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62462/66745 [01:47<00:07, 559.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62519/66745 [01:48<00:07, 562.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62576/66745 [01:48<00:07, 557.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62632/66745 [01:48<00:07, 550.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62688/66745 [01:48<00:07, 547.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62744/66745 [01:48<00:07, 550.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62801/66745 [01:48<00:07, 553.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62859/66745 [01:48<00:06, 560.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62916/66745 [01:48<00:06, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62972/66745 [01:48<00:06, 553.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63029/66745 [01:49<00:06, 558.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63089/66745 [01:49<00:06, 570.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63148/66745 [01:49<00:06, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63206/66745 [01:49<00:06, 566.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63265/66745 [01:49<00:06, 570.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63323/66745 [01:49<00:05, 570.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63381/66745 [01:49<00:05, 561.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63438/66745 [01:49<00:05, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63494/66745 [01:49<00:05, 555.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63551/66745 [01:49<00:05, 557.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63607/66745 [01:50<00:05, 554.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63666/66745 [01:50<00:05, 564.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63725/66745 [01:50<00:05, 571.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63785/66745 [01:50<00:05, 577.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63847/66745 [01:50<00:04, 587.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63907/66745 [01:50<00:04, 589.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63967/66745 [01:50<00:04, 590.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64027/66745 [01:50<00:04, 591.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64087/66745 [01:50<00:04, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64145/66745 [01:50<00:04, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64204/66745 [01:51<00:04, 568.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64263/66745 [01:51<00:04, 572.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64322/66745 [01:51<00:04, 576.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64381/66745 [01:51<00:04, 580.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64440/66745 [01:51<00:03, 581.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64499/66745 [01:51<00:03, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64558/66745 [01:51<00:03, 583.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64617/66745 [01:51<00:03, 583.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64676/66745 [01:51<00:03, 582.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64735/66745 [01:51<00:03, 566.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64792/66745 [01:52<00:03, 554.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64848/66745 [01:52<00:03, 546.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64903/66745 [01:52<00:03, 542.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64958/66745 [01:52<00:03, 539.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65012/66745 [01:52<00:03, 537.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65066/66745 [01:52<00:03, 536.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65122/66745 [01:52<00:02, 542.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65181/66745 [01:52<00:02, 556.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65238/66745 [01:52<00:02, 559.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65294/66745 [01:53<00:02, 559.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65351/66745 [01:53<00:02, 562.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65409/66745 [01:53<00:02, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65466/66745 [01:53<00:02, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65523/66745 [01:53<00:02, 560.99batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  98%|████▉| 65580/66745 [01:53<00:02, 551.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65636/66745 [01:53<00:02, 548.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65695/66745 [01:53<00:01, 558.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65754/66745 [01:53<00:01, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65811/66745 [01:53<00:01, 565.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65868/66745 [01:54<00:01, 556.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65927/66745 [01:54<00:01, 563.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65984/66745 [01:54<00:01, 564.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66041/66745 [01:54<00:01, 565.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66102/66745 [01:54<00:01, 576.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66161/66745 [01:54<00:01, 579.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66220/66745 [01:54<00:00, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66279/66745 [01:54<00:00, 579.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66338/66745 [01:54<00:00, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66399/66745 [01:54<00:00, 588.58batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66458/66745 [01:55<00:00, 566.95batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66515/66745 [01:55<00:00, 555.52batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66571/66745 [01:55<00:00, 549.08batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66627/66745 [01:55<00:00, 544.47batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66685/66745 [01:55<00:00, 553.92batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████| 66745/66745 [01:55<00:00, 434.97batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   3%| | 3/100 [05:48<3:07:54, 116.23s/epoch, loss=0.3\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 16/66745 [00:00<06:57, 159.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 70/66745 [00:00<02:54, 381.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 122/66745 [00:00<02:29, 444.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 179/66745 [00:00<02:15, 491.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 235/66745 [00:00<02:09, 513.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 292/66745 [00:00<02:04, 532.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 347/66745 [00:00<02:03, 537.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 408/66745 [00:00<01:58, 558.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 468/66745 [00:00<01:56, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 528/66745 [00:01<01:54, 577.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 590/66745 [00:01<01:52, 588.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 650/66745 [00:01<01:51, 591.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 710/66745 [00:01<01:53, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 769/66745 [00:01<01:53, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 830/66745 [00:01<01:52, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 889/66745 [00:01<01:52, 585.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 948/66745 [00:01<01:52, 586.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1007/66745 [00:01<01:51, 587.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1066/66745 [00:01<01:51, 588.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1125/66745 [00:02<01:51, 588.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1184/66745 [00:02<01:51, 588.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1244/66745 [00:02<01:51, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1304/66745 [00:02<01:52, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1365/66745 [00:02<01:50, 589.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1426/66745 [00:02<01:49, 595.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1488/66745 [00:02<01:48, 600.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1549/66745 [00:02<01:49, 598.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1610/66745 [00:02<01:48, 599.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1672/66745 [00:02<01:47, 602.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1734/66745 [00:03<01:47, 605.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1795/66745 [00:03<01:47, 605.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1856/66745 [00:03<01:50, 589.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1916/66745 [00:03<01:52, 578.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1975/66745 [00:03<01:51, 581.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2035/66745 [00:03<01:50, 583.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2094/66745 [00:03<01:52, 572.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2152/66745 [00:03<01:53, 567.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2209/66745 [00:03<01:53, 567.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2267/66745 [00:03<01:53, 569.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2326/66745 [00:04<01:51, 575.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2384/66745 [00:04<01:51, 575.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2442/66745 [00:04<01:54, 563.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2499/66745 [00:04<01:55, 557.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2559/66745 [00:04<01:53, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2621/66745 [00:04<01:50, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2681/66745 [00:04<01:49, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2740/66745 [00:04<01:49, 584.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2799/66745 [00:04<01:49, 585.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2859/66745 [00:04<01:48, 587.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2918/66745 [00:05<01:48, 587.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2977/66745 [00:05<01:48, 587.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3036/66745 [00:05<01:48, 587.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3095/66745 [00:05<01:50, 577.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3155/66745 [00:05<01:49, 582.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3215/66745 [00:05<01:48, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3276/66745 [00:05<01:47, 592.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3338/66745 [00:05<01:46, 597.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3399/66745 [00:05<01:45, 598.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3460/66745 [00:06<01:45, 600.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3521/66745 [00:06<01:47, 588.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3580/66745 [00:06<01:47, 585.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3639/66745 [00:06<01:50, 573.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3697/66745 [00:06<01:52, 560.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3754/66745 [00:06<01:52, 559.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3813/66745 [00:06<01:50, 567.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3870/66745 [00:06<01:51, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3928/66745 [00:06<01:50, 568.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3985/66745 [00:06<01:50, 568.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4042/66745 [00:07<01:50, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4099/66745 [00:07<01:50, 565.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4156/66745 [00:07<01:50, 566.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4215/66745 [00:07<01:49, 571.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4273/66745 [00:07<01:50, 567.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4330/66745 [00:07<01:50, 564.89batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   7%|▍     | 4388/66745 [00:07<01:50, 566.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4447/66745 [00:07<01:48, 573.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4505/66745 [00:07<01:48, 574.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4563/66745 [00:07<01:48, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4625/66745 [00:08<01:46, 584.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4687/66745 [00:08<01:44, 592.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4747/66745 [00:08<01:45, 587.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4806/66745 [00:08<01:45, 587.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4865/66745 [00:08<01:46, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4924/66745 [00:08<01:46, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4986/66745 [00:08<01:44, 590.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5047/66745 [00:08<01:43, 595.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5107/66745 [00:08<01:44, 587.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5166/66745 [00:08<01:44, 587.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5225/66745 [00:09<01:45, 585.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5284/66745 [00:09<01:45, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5343/66745 [00:09<01:44, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5402/66745 [00:09<01:44, 586.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5461/66745 [00:09<01:44, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5520/66745 [00:09<01:45, 579.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5580/66745 [00:09<01:44, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5640/66745 [00:09<01:43, 588.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5699/66745 [00:09<01:43, 587.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5758/66745 [00:09<01:44, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5817/66745 [00:10<01:44, 582.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5876/66745 [00:10<01:46, 569.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5936/66745 [00:10<01:45, 575.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5995/66745 [00:10<01:44, 579.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6054/66745 [00:10<01:45, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6112/66745 [00:10<01:46, 568.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6172/66745 [00:10<01:45, 576.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6231/66745 [00:10<01:44, 580.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6290/66745 [00:10<01:43, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6349/66745 [00:11<01:43, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6408/66745 [00:11<01:43, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6467/66745 [00:11<01:42, 586.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6526/66745 [00:11<01:42, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6585/66745 [00:11<01:43, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6644/66745 [00:11<01:42, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6703/66745 [00:11<01:44, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6763/66745 [00:11<01:42, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6822/66745 [00:11<01:42, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6881/66745 [00:11<01:42, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6940/66745 [00:12<01:42, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6999/66745 [00:12<01:42, 582.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7058/66745 [00:12<01:42, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7117/66745 [00:12<01:44, 569.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7175/66745 [00:12<01:46, 557.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7231/66745 [00:12<01:48, 548.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7290/66745 [00:12<01:46, 558.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7351/66745 [00:12<01:43, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7409/66745 [00:12<01:43, 574.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7469/66745 [00:12<01:42, 579.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7528/66745 [00:13<01:41, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7587/66745 [00:13<01:41, 583.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7646/66745 [00:13<01:41, 584.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7705/66745 [00:13<01:40, 584.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7764/66745 [00:13<01:40, 585.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7823/66745 [00:13<01:40, 586.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7882/66745 [00:13<01:41, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7942/66745 [00:13<01:40, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8002/66745 [00:13<01:40, 586.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8062/66745 [00:13<01:39, 588.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8122/66745 [00:14<01:39, 590.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8182/66745 [00:14<01:38, 591.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8242/66745 [00:14<01:39, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8302/66745 [00:14<01:39, 588.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8361/66745 [00:14<01:39, 588.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8420/66745 [00:14<01:39, 588.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8479/66745 [00:14<01:40, 576.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8538/66745 [00:14<01:40, 578.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8597/66745 [00:14<01:40, 581.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8657/66745 [00:14<01:39, 584.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8716/66745 [00:15<01:39, 585.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8776/66745 [00:15<01:38, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8836/66745 [00:15<01:37, 591.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8896/66745 [00:15<01:38, 587.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8956/66745 [00:15<01:37, 589.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9018/66745 [00:15<01:36, 596.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9078/66745 [00:15<01:38, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9137/66745 [00:15<01:40, 571.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9195/66745 [00:15<01:41, 564.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9253/66745 [00:16<01:41, 568.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9312/66745 [00:16<01:40, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9372/66745 [00:16<01:39, 577.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9430/66745 [00:16<01:39, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9489/66745 [00:16<01:38, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9548/66745 [00:16<01:38, 583.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9607/66745 [00:16<01:38, 580.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9666/66745 [00:16<01:39, 573.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9726/66745 [00:16<01:38, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9786/66745 [00:16<01:37, 583.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9846/66745 [00:17<01:36, 586.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9906/66745 [00:17<01:36, 588.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9966/66745 [00:17<01:36, 589.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10025/66745 [00:17<01:38, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10083/66745 [00:17<01:39, 571.04batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  15%|▊    | 10143/66745 [00:17<01:37, 578.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10204/66745 [00:17<01:36, 586.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10263/66745 [00:17<01:37, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10323/66745 [00:17<01:36, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10382/66745 [00:17<01:36, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10441/66745 [00:18<01:38, 573.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10499/66745 [00:18<01:38, 572.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10559/66745 [00:18<01:37, 578.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10619/66745 [00:18<01:36, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10679/66745 [00:18<01:35, 586.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10739/66745 [00:18<01:35, 588.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10799/66745 [00:18<01:34, 589.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10858/66745 [00:18<01:39, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10917/66745 [00:18<01:38, 569.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10976/66745 [00:18<01:36, 575.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11035/66745 [00:19<01:36, 579.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11094/66745 [00:19<01:35, 581.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11153/66745 [00:19<01:35, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11212/66745 [00:19<01:35, 581.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11271/66745 [00:19<01:35, 583.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11330/66745 [00:19<01:34, 583.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11389/66745 [00:19<01:34, 584.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11448/66745 [00:19<01:35, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11507/66745 [00:19<01:35, 579.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11568/66745 [00:19<01:33, 588.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11628/66745 [00:20<01:33, 589.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11687/66745 [00:20<01:33, 589.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11746/66745 [00:20<01:33, 589.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11805/66745 [00:20<01:33, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11864/66745 [00:20<01:33, 588.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11923/66745 [00:20<01:33, 588.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11982/66745 [00:20<01:33, 588.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12041/66745 [00:20<01:33, 587.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12100/66745 [00:20<01:34, 579.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12159/66745 [00:21<01:34, 580.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12218/66745 [00:21<01:33, 581.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12277/66745 [00:21<01:33, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12336/66745 [00:21<01:32, 585.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12395/66745 [00:21<01:32, 586.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12454/66745 [00:21<01:32, 587.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12513/66745 [00:21<01:32, 587.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12573/66745 [00:21<01:31, 588.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12632/66745 [00:21<01:31, 588.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12691/66745 [00:21<01:33, 579.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12751/66745 [00:22<01:32, 584.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12811/66745 [00:22<01:31, 588.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12873/66745 [00:22<01:30, 596.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12935/66745 [00:22<01:29, 600.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12996/66745 [00:22<01:29, 598.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13056/66745 [00:22<01:29, 597.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13116/66745 [00:22<01:29, 596.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13176/66745 [00:22<01:29, 596.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13236/66745 [00:22<01:29, 595.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13296/66745 [00:22<01:31, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13356/66745 [00:23<01:30, 586.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13416/66745 [00:23<01:30, 589.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13476/66745 [00:23<01:30, 590.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13536/66745 [00:23<01:30, 587.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13596/66745 [00:23<01:30, 589.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13655/66745 [00:23<01:30, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13715/66745 [00:23<01:29, 589.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13775/66745 [00:23<01:29, 590.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13835/66745 [00:23<01:29, 591.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13895/66745 [00:23<01:30, 582.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13954/66745 [00:24<01:30, 580.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14013/66745 [00:24<01:30, 580.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14072/66745 [00:24<01:30, 582.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14131/66745 [00:24<01:30, 583.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14191/66745 [00:24<01:29, 585.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14250/66745 [00:24<01:31, 574.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14309/66745 [00:24<01:30, 576.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14367/66745 [00:24<01:30, 576.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14427/66745 [00:24<01:29, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14486/66745 [00:24<01:30, 574.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14546/66745 [00:25<01:30, 579.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14605/66745 [00:25<01:29, 582.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14664/66745 [00:25<01:29, 583.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14723/66745 [00:25<01:28, 584.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14782/66745 [00:25<01:28, 585.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14841/66745 [00:25<01:28, 586.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14900/66745 [00:25<01:30, 574.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14958/66745 [00:25<01:31, 567.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 15016/66745 [00:25<01:30, 571.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15075/66745 [00:25<01:29, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15133/66745 [00:26<01:29, 574.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15192/66745 [00:26<01:29, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15251/66745 [00:26<01:28, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15311/66745 [00:26<01:27, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15370/66745 [00:26<01:27, 586.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15430/66745 [00:26<01:27, 587.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15489/66745 [00:26<01:27, 588.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15549/66745 [00:26<01:26, 588.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15609/66745 [00:26<01:26, 590.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15669/66745 [00:27<01:27, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15729/66745 [00:27<01:27, 584.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15789/66745 [00:27<01:26, 587.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15849/66745 [00:27<01:26, 589.41batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  24%|█▏   | 15909/66745 [00:27<01:26, 590.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15969/66745 [00:27<01:26, 589.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16028/66745 [00:27<01:28, 574.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16086/66745 [00:27<01:28, 571.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16145/66745 [00:27<01:27, 575.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16204/66745 [00:27<01:27, 578.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16262/66745 [00:28<01:27, 574.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16320/66745 [00:28<01:28, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16379/66745 [00:28<01:27, 573.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16438/66745 [00:28<01:27, 575.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16496/66745 [00:28<01:28, 564.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16555/66745 [00:28<01:28, 569.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16614/66745 [00:28<01:27, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16673/66745 [00:28<01:26, 575.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16731/66745 [00:28<01:26, 575.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16789/66745 [00:28<01:26, 575.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16847/66745 [00:29<01:27, 571.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16905/66745 [00:29<01:26, 572.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16964/66745 [00:29<01:26, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17023/66745 [00:29<01:26, 577.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17083/66745 [00:29<01:25, 581.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17143/66745 [00:29<01:24, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17203/66745 [00:29<01:24, 587.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17263/66745 [00:29<01:23, 589.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17322/66745 [00:29<01:25, 577.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17381/66745 [00:29<01:25, 579.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17440/66745 [00:30<01:24, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17499/66745 [00:30<01:25, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17558/66745 [00:30<01:24, 579.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17617/66745 [00:30<01:25, 571.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17675/66745 [00:30<01:28, 557.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17731/66745 [00:30<01:28, 552.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17789/66745 [00:30<01:27, 560.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17847/66745 [00:30<01:26, 565.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17905/66745 [00:30<01:25, 569.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17964/66745 [00:30<01:24, 574.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18022/66745 [00:31<01:25, 570.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18082/66745 [00:31<01:24, 577.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18142/66745 [00:31<01:23, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18202/66745 [00:31<01:22, 585.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18262/66745 [00:31<01:22, 586.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18321/66745 [00:31<01:23, 578.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18379/66745 [00:31<01:24, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18440/66745 [00:31<01:23, 580.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18500/66745 [00:31<01:22, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18560/66745 [00:32<01:21, 587.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18619/66745 [00:32<01:22, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18679/66745 [00:32<01:21, 590.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18739/66745 [00:32<01:21, 589.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18798/66745 [00:32<01:21, 587.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18857/66745 [00:32<01:22, 582.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18916/66745 [00:32<01:21, 583.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18975/66745 [00:32<01:21, 584.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19034/66745 [00:32<01:21, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19093/66745 [00:32<01:21, 586.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19154/66745 [00:33<01:20, 592.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19215/66745 [00:33<01:19, 596.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19275/66745 [00:33<01:21, 580.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19334/66745 [00:33<01:22, 571.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19392/66745 [00:33<01:22, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19452/66745 [00:33<01:21, 579.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19514/66745 [00:33<01:20, 588.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19576/66745 [00:33<01:19, 595.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19636/66745 [00:33<01:19, 594.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19696/66745 [00:33<01:19, 590.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19756/66745 [00:34<01:20, 586.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19815/66745 [00:34<01:20, 580.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19874/66745 [00:34<01:20, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19933/66745 [00:34<01:21, 574.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19992/66745 [00:34<01:21, 576.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20051/66745 [00:34<01:20, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20109/66745 [00:34<01:20, 578.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20169/66745 [00:34<01:19, 584.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20228/66745 [00:34<01:19, 585.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20287/66745 [00:34<01:19, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20346/66745 [00:35<01:18, 587.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20405/66745 [00:35<01:19, 583.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20464/66745 [00:35<01:19, 584.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20523/66745 [00:35<01:18, 585.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20583/66745 [00:35<01:18, 587.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20643/66745 [00:35<01:18, 588.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20703/66745 [00:35<01:18, 589.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20763/66745 [00:35<01:17, 589.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20823/66745 [00:35<01:17, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20883/66745 [00:35<01:17, 590.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20943/66745 [00:36<01:17, 590.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 21003/66745 [00:36<01:17, 586.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21062/66745 [00:36<01:17, 585.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21121/66745 [00:36<01:19, 571.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21180/66745 [00:36<01:19, 575.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21240/66745 [00:36<01:18, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21299/66745 [00:36<01:17, 582.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21358/66745 [00:36<01:17, 584.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21417/66745 [00:36<01:17, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21476/66745 [00:37<01:17, 581.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21535/66745 [00:37<01:17, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21594/66745 [00:37<01:17, 585.28batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  32%|█▌   | 21653/66745 [00:37<01:17, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21712/66745 [00:37<01:16, 585.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21771/66745 [00:37<01:16, 586.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21830/66745 [00:37<01:16, 587.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21889/66745 [00:37<01:16, 587.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21948/66745 [00:37<01:16, 585.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22008/66745 [00:37<01:15, 588.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22068/66745 [00:38<01:15, 590.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22128/66745 [00:38<01:15, 592.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22188/66745 [00:38<01:15, 593.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22248/66745 [00:38<01:15, 592.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22308/66745 [00:38<01:15, 591.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22368/66745 [00:38<01:15, 589.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22428/66745 [00:38<01:14, 591.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22488/66745 [00:38<01:14, 592.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22548/66745 [00:38<01:15, 588.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22608/66745 [00:38<01:14, 590.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22668/66745 [00:39<01:15, 584.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22727/66745 [00:39<01:16, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22785/66745 [00:39<01:17, 566.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22842/66745 [00:39<01:19, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22900/66745 [00:39<01:18, 560.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22958/66745 [00:39<01:17, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 23017/66745 [00:39<01:16, 570.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23075/66745 [00:39<01:16, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23133/66745 [00:39<01:15, 574.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23194/66745 [00:39<01:14, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23253/66745 [00:40<01:14, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23312/66745 [00:40<01:14, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23371/66745 [00:40<01:16, 570.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23429/66745 [00:40<01:17, 555.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23488/66745 [00:40<01:16, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23545/66745 [00:40<01:16, 565.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23604/66745 [00:40<01:15, 570.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23663/66745 [00:40<01:15, 573.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23722/66745 [00:40<01:14, 575.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23780/66745 [00:40<01:14, 576.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23839/66745 [00:41<01:13, 579.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23898/66745 [00:41<01:13, 581.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23957/66745 [00:41<01:15, 568.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24014/66745 [00:41<01:15, 568.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24071/66745 [00:41<01:16, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24128/66745 [00:41<01:16, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24186/66745 [00:41<01:15, 563.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24244/66745 [00:41<01:14, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24301/66745 [00:41<01:15, 565.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24358/66745 [00:42<01:15, 563.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24416/66745 [00:42<01:14, 567.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24476/66745 [00:42<01:13, 576.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24537/66745 [00:42<01:12, 584.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24596/66745 [00:42<01:13, 576.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24654/66745 [00:42<01:14, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24711/66745 [00:42<01:14, 565.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24768/66745 [00:42<01:15, 557.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24825/66745 [00:42<01:14, 559.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24881/66745 [00:42<01:15, 552.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24937/66745 [00:43<01:16, 547.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24992/66745 [00:43<01:16, 545.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25047/66745 [00:43<01:16, 543.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25102/66745 [00:43<01:17, 540.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25157/66745 [00:43<01:16, 540.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25215/66745 [00:43<01:15, 550.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25276/66745 [00:43<01:13, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25335/66745 [00:43<01:12, 573.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25394/66745 [00:43<01:11, 578.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25453/66745 [00:43<01:11, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25512/66745 [00:44<01:10, 582.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25571/66745 [00:44<01:10, 584.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25630/66745 [00:44<01:10, 585.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25689/66745 [00:44<01:10, 586.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25748/66745 [00:44<01:10, 578.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25807/66745 [00:44<01:10, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25866/66745 [00:44<01:10, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25925/66745 [00:44<01:09, 583.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25984/66745 [00:44<01:10, 578.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26042/66745 [00:44<01:11, 569.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26100/66745 [00:45<01:11, 570.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26159/66745 [00:45<01:10, 574.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26217/66745 [00:45<01:11, 569.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26275/66745 [00:45<01:10, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26333/66745 [00:45<01:10, 569.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26392/66745 [00:45<01:10, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26451/66745 [00:45<01:09, 577.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26510/66745 [00:45<01:09, 580.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26569/66745 [00:45<01:08, 583.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26628/66745 [00:45<01:08, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26687/66745 [00:46<01:08, 585.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26746/66745 [00:46<01:08, 587.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26805/66745 [00:46<01:07, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26864/66745 [00:46<01:09, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26922/66745 [00:46<01:09, 571.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26981/66745 [00:46<01:09, 574.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27040/66745 [00:46<01:08, 578.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27099/66745 [00:46<01:08, 580.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27158/66745 [00:46<01:07, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27217/66745 [00:46<01:07, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27276/66745 [00:47<01:07, 585.40batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  41%|██   | 27335/66745 [00:47<01:07, 586.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27394/66745 [00:47<01:07, 586.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27453/66745 [00:47<01:06, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27512/66745 [00:47<01:06, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27571/66745 [00:47<01:06, 586.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27630/66745 [00:47<01:07, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27689/66745 [00:47<01:06, 583.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27748/66745 [00:47<01:06, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27807/66745 [00:47<01:06, 585.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27866/66745 [00:48<01:06, 585.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27925/66745 [00:48<01:06, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27984/66745 [00:48<01:06, 586.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28043/66745 [00:48<01:06, 586.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28102/66745 [00:48<01:05, 585.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28161/66745 [00:48<01:05, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28220/66745 [00:48<01:05, 585.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28279/66745 [00:48<01:05, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28338/66745 [00:48<01:05, 586.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28397/66745 [00:49<01:05, 587.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28456/66745 [00:49<01:05, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28516/66745 [00:49<01:04, 588.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28576/66745 [00:49<01:04, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28637/66745 [00:49<01:04, 594.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28697/66745 [00:49<01:04, 592.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28757/66745 [00:49<01:04, 590.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28817/66745 [00:49<01:04, 589.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28876/66745 [00:49<01:04, 588.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28935/66745 [00:49<01:04, 588.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28994/66745 [00:50<01:04, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29053/66745 [00:50<01:04, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29112/66745 [00:50<01:04, 582.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29171/66745 [00:50<01:04, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29230/66745 [00:50<01:04, 584.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29289/66745 [00:50<01:04, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29348/66745 [00:50<01:03, 584.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29407/66745 [00:50<01:03, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29466/66745 [00:50<01:03, 585.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29525/66745 [00:50<01:03, 586.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29584/66745 [00:51<01:03, 586.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29643/66745 [00:51<01:03, 584.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29703/66745 [00:51<01:03, 587.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29763/66745 [00:51<01:02, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29823/66745 [00:51<01:02, 590.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29883/66745 [00:51<01:02, 591.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29943/66745 [00:51<01:03, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 30002/66745 [00:51<01:03, 582.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30061/66745 [00:51<01:02, 582.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30120/66745 [00:51<01:02, 582.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30179/66745 [00:52<01:02, 582.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30238/66745 [00:52<01:02, 583.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30297/66745 [00:52<01:02, 582.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30356/66745 [00:52<01:02, 581.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30415/66745 [00:52<01:04, 563.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30472/66745 [00:52<01:04, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30528/66745 [00:52<01:05, 552.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30584/66745 [00:52<01:05, 548.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30640/66745 [00:52<01:05, 549.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30701/66745 [00:52<01:03, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30760/66745 [00:53<01:02, 572.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30820/66745 [00:53<01:02, 578.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30879/66745 [00:53<01:01, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30939/66745 [00:53<01:01, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30998/66745 [00:53<01:01, 585.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31057/66745 [00:53<01:02, 572.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31115/66745 [00:53<01:03, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31172/66745 [00:53<01:03, 560.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31231/66745 [00:53<01:02, 568.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31291/66745 [00:54<01:01, 574.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31351/66745 [00:54<01:01, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31410/66745 [00:54<01:00, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31470/66745 [00:54<01:00, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31530/66745 [00:54<01:00, 586.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31590/66745 [00:54<00:59, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31650/66745 [00:54<00:59, 588.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31711/66745 [00:54<00:58, 594.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31771/66745 [00:54<00:58, 594.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31831/66745 [00:54<00:59, 589.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31891/66745 [00:55<00:59, 586.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31950/66745 [00:55<00:59, 585.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32009/66745 [00:55<00:59, 583.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32068/66745 [00:55<00:59, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32127/66745 [00:55<00:59, 581.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32186/66745 [00:55<00:59, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32245/66745 [00:55<00:59, 581.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32304/66745 [00:55<00:59, 581.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32363/66745 [00:55<00:59, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32422/66745 [00:55<00:59, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32481/66745 [00:56<00:58, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32540/66745 [00:56<00:59, 576.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32598/66745 [00:56<00:59, 577.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32657/66745 [00:56<00:58, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32716/66745 [00:56<00:58, 579.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32775/66745 [00:56<00:58, 581.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32834/66745 [00:56<00:58, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32893/66745 [00:56<00:58, 580.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32952/66745 [00:56<00:58, 579.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 33010/66745 [00:56<00:58, 579.63batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|██▍  | 33069/66745 [00:57<00:58, 579.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33128/66745 [00:57<00:57, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33187/66745 [00:57<00:58, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33245/66745 [00:57<00:58, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33304/66745 [00:57<00:57, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33363/66745 [00:57<00:57, 578.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33421/66745 [00:57<00:57, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33479/66745 [00:57<00:57, 576.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33537/66745 [00:57<00:57, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33596/66745 [00:57<00:57, 575.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33655/66745 [00:58<00:57, 576.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33714/66745 [00:58<00:57, 578.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33772/66745 [00:58<00:57, 574.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33830/66745 [00:58<00:57, 575.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33889/66745 [00:58<00:56, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33947/66745 [00:58<00:57, 573.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34005/66745 [00:58<00:56, 575.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34064/66745 [00:58<00:56, 576.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34122/66745 [00:58<00:56, 576.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34181/66745 [00:58<00:56, 578.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34240/66745 [00:59<00:56, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34298/66745 [00:59<00:56, 578.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34357/66745 [00:59<00:55, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34416/66745 [00:59<00:55, 578.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34475/66745 [00:59<00:55, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34534/66745 [00:59<00:55, 583.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34593/66745 [00:59<00:54, 584.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34652/66745 [00:59<00:54, 585.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34711/66745 [00:59<00:55, 581.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34770/66745 [00:59<00:54, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34829/66745 [01:00<00:54, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34889/66745 [01:00<00:54, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34948/66745 [01:00<00:54, 586.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 35007/66745 [01:00<00:54, 587.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35067/66745 [01:00<00:53, 589.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35129/66745 [01:00<00:53, 595.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35189/66745 [01:00<00:53, 594.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35249/66745 [01:00<00:52, 594.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35309/66745 [01:00<00:53, 590.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35369/66745 [01:01<00:54, 573.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35429/66745 [01:01<00:54, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35490/66745 [01:01<00:53, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35551/66745 [01:01<00:52, 591.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35611/66745 [01:01<00:52, 592.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35671/66745 [01:01<00:52, 592.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35731/66745 [01:01<00:52, 592.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35791/66745 [01:01<00:52, 592.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35851/66745 [01:01<00:52, 593.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35911/66745 [01:01<00:51, 592.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35971/66745 [01:02<00:51, 593.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36031/66745 [01:02<00:51, 593.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36091/66745 [01:02<00:51, 593.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36151/66745 [01:02<00:51, 593.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36211/66745 [01:02<00:51, 593.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36271/66745 [01:02<00:51, 593.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36331/66745 [01:02<00:51, 592.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36391/66745 [01:02<00:51, 591.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36451/66745 [01:02<00:51, 590.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36511/66745 [01:02<00:51, 588.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36570/66745 [01:03<00:51, 588.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36629/66745 [01:03<00:51, 588.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36688/66745 [01:03<00:51, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36747/66745 [01:03<00:51, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36806/66745 [01:03<00:50, 587.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36865/66745 [01:03<00:50, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36924/66745 [01:03<00:50, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36983/66745 [01:03<00:50, 586.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37042/66745 [01:03<00:50, 586.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37101/66745 [01:03<00:50, 586.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37160/66745 [01:04<00:50, 582.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37219/66745 [01:04<00:50, 584.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37278/66745 [01:04<00:50, 585.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37337/66745 [01:04<00:50, 586.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37396/66745 [01:04<00:50, 586.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37455/66745 [01:04<00:49, 586.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37514/66745 [01:04<00:49, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37573/66745 [01:04<00:50, 581.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37632/66745 [01:04<00:49, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37691/66745 [01:04<00:49, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37750/66745 [01:05<00:49, 583.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37809/66745 [01:05<00:49, 584.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37868/66745 [01:05<00:50, 571.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37926/66745 [01:05<00:51, 564.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37984/66745 [01:05<00:50, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38042/66745 [01:05<00:50, 571.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38100/66745 [01:05<00:49, 573.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38158/66745 [01:05<00:49, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38216/66745 [01:05<00:49, 576.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38274/66745 [01:05<00:49, 576.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38333/66745 [01:06<00:49, 577.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38392/66745 [01:06<00:48, 578.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38451/66745 [01:06<00:48, 579.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38510/66745 [01:06<00:48, 580.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38569/66745 [01:06<00:48, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38628/66745 [01:06<00:48, 580.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38687/66745 [01:06<00:48, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38746/66745 [01:06<00:48, 579.00batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  58%|██▉  | 38804/66745 [01:06<00:48, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38862/66745 [01:06<00:48, 578.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38920/66745 [01:07<00:48, 578.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38978/66745 [01:07<00:48, 578.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 39037/66745 [01:07<00:47, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39095/66745 [01:07<00:47, 578.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39153/66745 [01:07<00:47, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39211/66745 [01:07<00:47, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39269/66745 [01:07<00:47, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39327/66745 [01:07<00:47, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39385/66745 [01:07<00:47, 578.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39443/66745 [01:07<00:47, 573.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39502/66745 [01:08<00:47, 576.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39560/66745 [01:08<00:47, 577.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39619/66745 [01:08<00:46, 578.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39678/66745 [01:08<00:46, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39736/66745 [01:08<00:46, 578.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39794/66745 [01:08<00:46, 575.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39853/66745 [01:08<00:46, 577.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39912/66745 [01:08<00:46, 579.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39970/66745 [01:08<00:47, 564.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40027/66745 [01:09<00:47, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40085/66745 [01:09<00:47, 565.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40143/66745 [01:09<00:46, 569.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40203/66745 [01:09<00:45, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40263/66745 [01:09<00:45, 581.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40322/66745 [01:09<00:45, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40382/66745 [01:09<00:45, 585.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40443/66745 [01:09<00:44, 590.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40503/66745 [01:09<00:44, 588.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40562/66745 [01:09<00:44, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40621/66745 [01:10<00:45, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40681/66745 [01:10<00:44, 582.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40740/66745 [01:10<00:44, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40800/66745 [01:10<00:44, 586.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40860/66745 [01:10<00:43, 588.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40920/66745 [01:10<00:43, 589.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40982/66745 [01:10<00:43, 596.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41043/66745 [01:10<00:43, 597.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41105/66745 [01:10<00:42, 601.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41166/66745 [01:10<00:43, 590.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41226/66745 [01:11<00:43, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41285/66745 [01:11<00:43, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41345/66745 [01:11<00:43, 586.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41404/66745 [01:11<00:43, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41464/66745 [01:11<00:42, 588.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41524/66745 [01:11<00:42, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41584/66745 [01:11<00:42, 591.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41644/66745 [01:11<00:42, 588.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41704/66745 [01:11<00:42, 590.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41764/66745 [01:11<00:42, 583.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41823/66745 [01:12<00:43, 578.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41881/66745 [01:12<00:43, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41941/66745 [01:12<00:42, 584.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42000/66745 [01:12<00:42, 585.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42059/66745 [01:12<00:43, 569.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42117/66745 [01:12<00:43, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42176/66745 [01:12<00:43, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42235/66745 [01:12<00:42, 573.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42293/66745 [01:12<00:42, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42351/66745 [01:12<00:43, 559.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42408/66745 [01:13<00:43, 553.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42468/66745 [01:13<00:42, 565.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42527/66745 [01:13<00:42, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42588/66745 [01:13<00:41, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42647/66745 [01:13<00:41, 584.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42706/66745 [01:13<00:41, 582.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42765/66745 [01:13<00:41, 578.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42824/66745 [01:13<00:41, 579.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42882/66745 [01:13<00:42, 567.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42942/66745 [01:14<00:41, 573.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43000/66745 [01:14<00:41, 571.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43059/66745 [01:14<00:41, 576.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43117/66745 [01:14<00:41, 573.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43175/66745 [01:14<00:41, 564.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43232/66745 [01:14<00:42, 556.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43288/66745 [01:14<00:42, 551.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43346/66745 [01:14<00:41, 558.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43402/66745 [01:14<00:42, 552.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43458/66745 [01:14<00:42, 553.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43514/66745 [01:15<00:42, 546.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43569/66745 [01:15<00:42, 539.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43624/66745 [01:15<00:43, 534.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43678/66745 [01:15<00:43, 531.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43734/66745 [01:15<00:42, 537.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43792/66745 [01:15<00:41, 549.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43850/66745 [01:15<00:41, 557.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43909/66745 [01:15<00:40, 564.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43968/66745 [01:15<00:39, 570.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44026/66745 [01:15<00:40, 564.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44083/66745 [01:16<00:40, 562.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44143/66745 [01:16<00:39, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44201/66745 [01:16<00:40, 561.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44258/66745 [01:16<00:40, 558.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44316/66745 [01:16<00:39, 564.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44376/66745 [01:16<00:38, 574.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44436/66745 [01:16<00:38, 580.55batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  67%|███▎ | 44495/66745 [01:16<00:38, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44554/66745 [01:16<00:38, 579.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44615/66745 [01:16<00:37, 586.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44674/66745 [01:17<00:37, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44733/66745 [01:17<00:37, 579.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44792/66745 [01:17<00:38, 571.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44850/66745 [01:17<00:38, 566.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44907/66745 [01:17<00:38, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44966/66745 [01:17<00:38, 571.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45026/66745 [01:17<00:37, 578.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45085/66745 [01:17<00:37, 579.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45143/66745 [01:17<00:38, 565.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45200/66745 [01:18<00:38, 561.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45257/66745 [01:18<00:39, 547.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45314/66745 [01:18<00:38, 551.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45370/66745 [01:18<00:38, 553.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45427/66745 [01:18<00:38, 557.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45483/66745 [01:18<00:38, 548.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45540/66745 [01:18<00:38, 554.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45599/66745 [01:18<00:37, 564.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45658/66745 [01:18<00:36, 570.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45717/66745 [01:18<00:36, 575.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45776/66745 [01:19<00:36, 577.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45834/66745 [01:19<00:36, 573.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45892/66745 [01:19<00:36, 566.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45951/66745 [01:19<00:36, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46010/66745 [01:19<00:35, 576.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46069/66745 [01:19<00:35, 579.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46128/66745 [01:19<00:35, 581.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46187/66745 [01:19<00:35, 582.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46246/66745 [01:19<00:35, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46305/66745 [01:19<00:34, 584.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46364/66745 [01:20<00:34, 584.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46423/66745 [01:20<00:35, 577.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46481/66745 [01:20<00:35, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46540/66745 [01:20<00:35, 576.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46598/66745 [01:20<00:35, 573.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46658/66745 [01:20<00:34, 579.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46716/66745 [01:20<00:35, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46773/66745 [01:20<00:35, 559.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46831/66745 [01:20<00:35, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46889/66745 [01:20<00:35, 567.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46947/66745 [01:21<00:34, 568.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47004/66745 [01:21<00:34, 565.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47062/66745 [01:21<00:34, 567.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47121/66745 [01:21<00:34, 572.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47179/66745 [01:21<00:34, 568.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47236/66745 [01:21<00:34, 568.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47293/66745 [01:21<00:34, 566.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47350/66745 [01:21<00:34, 567.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47407/66745 [01:21<00:34, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47464/66745 [01:22<00:34, 563.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47522/66745 [01:22<00:33, 568.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47579/66745 [01:22<00:33, 566.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47640/66745 [01:22<00:33, 578.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47701/66745 [01:22<00:32, 585.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47760/66745 [01:22<00:32, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47819/66745 [01:22<00:33, 571.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47877/66745 [01:22<00:33, 568.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47936/66745 [01:22<00:32, 573.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47994/66745 [01:22<00:32, 575.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48052/66745 [01:23<00:32, 574.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48110/66745 [01:23<00:32, 572.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48168/66745 [01:23<00:32, 570.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48227/66745 [01:23<00:32, 575.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48285/66745 [01:23<00:33, 557.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48343/66745 [01:23<00:32, 562.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48400/66745 [01:23<00:32, 559.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48456/66745 [01:23<00:32, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48512/66745 [01:23<00:32, 556.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48569/66745 [01:23<00:32, 559.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48627/66745 [01:24<00:32, 565.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48684/66745 [01:24<00:32, 557.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48741/66745 [01:24<00:32, 558.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48800/66745 [01:24<00:31, 566.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48858/66745 [01:24<00:31, 568.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48915/66745 [01:24<00:31, 559.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48973/66745 [01:24<00:31, 565.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 49033/66745 [01:24<00:30, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49091/66745 [01:24<00:31, 568.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49150/66745 [01:24<00:30, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49208/66745 [01:25<00:31, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49265/66745 [01:25<00:31, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49321/66745 [01:25<00:32, 543.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49380/66745 [01:25<00:31, 554.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49436/66745 [01:25<00:31, 549.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49492/66745 [01:25<00:31, 550.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49550/66745 [01:25<00:30, 558.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49608/66745 [01:25<00:30, 563.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49667/66745 [01:25<00:29, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49726/66745 [01:26<00:29, 574.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49785/66745 [01:26<00:29, 577.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49843/66745 [01:26<00:29, 565.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49900/66745 [01:26<00:30, 553.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49956/66745 [01:26<00:30, 544.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50015/66745 [01:26<00:30, 556.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50074/66745 [01:26<00:29, 566.01batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  75%|███▊ | 50133/66745 [01:26<00:28, 572.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50192/66745 [01:26<00:28, 577.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50251/66745 [01:26<00:28, 581.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50311/66745 [01:27<00:28, 585.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50371/66745 [01:27<00:27, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50430/66745 [01:27<00:28, 579.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50489/66745 [01:27<00:28, 574.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50547/66745 [01:27<00:28, 566.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50605/66745 [01:27<00:28, 568.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50663/66745 [01:27<00:28, 570.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50721/66745 [01:27<00:28, 570.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50779/66745 [01:27<00:28, 566.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50836/66745 [01:27<00:28, 563.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50894/66745 [01:28<00:27, 568.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50952/66745 [01:28<00:27, 571.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51010/66745 [01:28<00:27, 572.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51068/66745 [01:28<00:27, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51126/66745 [01:28<00:27, 574.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51184/66745 [01:28<00:27, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51243/66745 [01:28<00:26, 577.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51302/66745 [01:28<00:26, 579.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51361/66745 [01:28<00:26, 581.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51420/66745 [01:28<00:26, 582.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51479/66745 [01:29<00:26, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51538/66745 [01:29<00:26, 583.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51597/66745 [01:29<00:25, 583.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51656/66745 [01:29<00:26, 576.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51717/66745 [01:29<00:25, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51778/66745 [01:29<00:25, 591.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51838/66745 [01:29<00:25, 593.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51898/66745 [01:29<00:25, 589.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51957/66745 [01:29<00:25, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52018/66745 [01:29<00:24, 591.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52078/66745 [01:30<00:25, 575.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52136/66745 [01:30<00:25, 565.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52193/66745 [01:30<00:25, 561.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52250/66745 [01:30<00:25, 563.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52311/66745 [01:30<00:25, 575.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52369/66745 [01:30<00:24, 576.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52427/66745 [01:30<00:25, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52486/66745 [01:30<00:24, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52544/66745 [01:30<00:24, 569.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52601/66745 [01:31<00:25, 561.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52658/66745 [01:31<00:25, 562.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52715/66745 [01:31<00:25, 552.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52771/66745 [01:31<00:25, 551.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52827/66745 [01:31<00:25, 551.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52886/66745 [01:31<00:24, 561.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52945/66745 [01:31<00:24, 568.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53004/66745 [01:31<00:23, 573.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53063/66745 [01:31<00:23, 576.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53121/66745 [01:31<00:23, 572.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53179/66745 [01:32<00:23, 566.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53238/66745 [01:32<00:23, 571.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53296/66745 [01:32<00:23, 566.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53355/66745 [01:32<00:23, 570.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53414/66745 [01:32<00:23, 575.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53474/66745 [01:32<00:22, 581.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53533/66745 [01:32<00:22, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53592/66745 [01:32<00:22, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53651/66745 [01:32<00:22, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53711/66745 [01:32<00:22, 584.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53771/66745 [01:33<00:22, 587.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53832/66745 [01:33<00:21, 593.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53892/66745 [01:33<00:21, 588.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53951/66745 [01:33<00:21, 583.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54010/66745 [01:33<00:22, 578.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54068/66745 [01:33<00:22, 575.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54126/66745 [01:33<00:21, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54184/66745 [01:33<00:21, 573.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54242/66745 [01:33<00:21, 572.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54300/66745 [01:33<00:21, 574.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54358/66745 [01:34<00:21, 574.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54416/66745 [01:34<00:21, 572.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54474/66745 [01:34<00:21, 566.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54531/66745 [01:34<00:21, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54588/66745 [01:34<00:21, 567.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54645/66745 [01:34<00:21, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54702/66745 [01:34<00:21, 565.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54760/66745 [01:34<00:21, 568.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54818/66745 [01:34<00:20, 569.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54876/66745 [01:34<00:20, 571.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54934/66745 [01:35<00:20, 571.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54992/66745 [01:35<00:20, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55050/66745 [01:35<00:20, 564.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55108/66745 [01:35<00:20, 566.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55165/66745 [01:35<00:20, 561.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55222/66745 [01:35<00:20, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55279/66745 [01:35<00:20, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55335/66745 [01:35<00:20, 546.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55390/66745 [01:35<00:21, 535.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55446/66745 [01:36<00:20, 539.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55505/66745 [01:36<00:20, 552.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55564/66745 [01:36<00:19, 561.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55623/66745 [01:36<00:19, 567.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55682/66745 [01:36<00:19, 572.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55741/66745 [01:36<00:19, 575.94batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  84%|████▏| 55800/66745 [01:36<00:18, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55859/66745 [01:36<00:18, 580.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55918/66745 [01:36<00:18, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55977/66745 [01:36<00:18, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56036/66745 [01:37<00:18, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56095/66745 [01:37<00:18, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56154/66745 [01:37<00:18, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56213/66745 [01:37<00:18, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56272/66745 [01:37<00:18, 573.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56330/66745 [01:37<00:18, 569.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56388/66745 [01:37<00:18, 559.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56446/66745 [01:37<00:18, 564.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56506/66745 [01:37<00:17, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56566/66745 [01:37<00:17, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56626/66745 [01:38<00:17, 584.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56687/66745 [01:38<00:17, 589.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56749/66745 [01:38<00:16, 596.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56809/66745 [01:38<00:16, 593.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56869/66745 [01:38<00:16, 588.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56928/66745 [01:38<00:16, 581.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56987/66745 [01:38<00:16, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57046/66745 [01:38<00:16, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57104/66745 [01:38<00:16, 579.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57162/66745 [01:38<00:16, 579.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57220/66745 [01:39<00:16, 579.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57278/66745 [01:39<00:16, 579.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57336/66745 [01:39<00:16, 579.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57394/66745 [01:39<00:16, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57452/66745 [01:39<00:16, 573.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57510/66745 [01:39<00:16, 574.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57568/66745 [01:39<00:16, 562.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57627/66745 [01:39<00:16, 569.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57684/66745 [01:39<00:16, 561.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57741/66745 [01:39<00:16, 558.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57797/66745 [01:40<00:16, 557.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57855/66745 [01:40<00:15, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57912/66745 [01:40<00:15, 561.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57969/66745 [01:40<00:16, 547.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58028/66745 [01:40<00:15, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58087/66745 [01:40<00:15, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58144/66745 [01:40<00:15, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58200/66745 [01:40<00:15, 556.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58261/66745 [01:40<00:14, 570.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58320/66745 [01:41<00:14, 574.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58379/66745 [01:41<00:14, 576.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58438/66745 [01:41<00:14, 580.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58497/66745 [01:41<00:14, 577.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58555/66745 [01:41<00:14, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58612/66745 [01:41<00:14, 569.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58669/66745 [01:41<00:14, 555.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58725/66745 [01:41<00:14, 549.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58780/66745 [01:41<00:14, 546.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58839/66745 [01:41<00:14, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58898/66745 [01:42<00:13, 565.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58957/66745 [01:42<00:13, 571.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59016/66745 [01:42<00:13, 575.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59075/66745 [01:42<00:13, 579.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59134/66745 [01:42<00:13, 570.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59193/66745 [01:42<00:13, 574.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59252/66745 [01:42<00:12, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59311/66745 [01:42<00:12, 581.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59370/66745 [01:42<00:12, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59429/66745 [01:42<00:12, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59488/66745 [01:43<00:12, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59547/66745 [01:43<00:12, 587.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59606/66745 [01:43<00:12, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59665/66745 [01:43<00:12, 577.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59724/66745 [01:43<00:12, 578.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59783/66745 [01:43<00:11, 581.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59842/66745 [01:43<00:11, 584.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59901/66745 [01:43<00:11, 579.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59960/66745 [01:43<00:11, 581.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60019/66745 [01:43<00:11, 582.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60078/66745 [01:44<00:11, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60137/66745 [01:44<00:11, 584.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60196/66745 [01:44<00:11, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60255/66745 [01:44<00:11, 584.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60314/66745 [01:44<00:10, 584.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60373/66745 [01:44<00:10, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60432/66745 [01:44<00:10, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60491/66745 [01:44<00:10, 583.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60550/66745 [01:44<00:10, 565.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60607/66745 [01:44<00:10, 566.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60666/66745 [01:45<00:10, 572.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60725/66745 [01:45<00:10, 576.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60783/66745 [01:45<00:10, 574.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60842/66745 [01:45<00:10, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60901/66745 [01:45<00:10, 581.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60960/66745 [01:45<00:09, 582.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61019/66745 [01:45<00:09, 584.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61079/66745 [01:45<00:09, 586.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61138/66745 [01:45<00:09, 586.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61197/66745 [01:46<00:09, 587.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61256/66745 [01:46<00:09, 582.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61315/66745 [01:46<00:09, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61374/66745 [01:46<00:09, 582.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61433/66745 [01:46<00:09, 568.08batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  92%|████▌| 61490/66745 [01:46<00:09, 562.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61547/66745 [01:46<00:09, 560.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61604/66745 [01:46<00:09, 558.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61660/66745 [01:46<00:09, 557.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61716/66745 [01:46<00:09, 554.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61772/66745 [01:47<00:09, 551.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61828/66745 [01:47<00:08, 549.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61883/66745 [01:47<00:08, 547.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61941/66745 [01:47<00:08, 554.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61997/66745 [01:47<00:08, 547.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62055/66745 [01:47<00:08, 556.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62111/66745 [01:47<00:08, 554.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62169/66745 [01:47<00:08, 560.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62228/66745 [01:47<00:07, 568.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62285/66745 [01:47<00:07, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62342/66745 [01:48<00:07, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62399/66745 [01:48<00:07, 551.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62455/66745 [01:48<00:07, 543.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62513/66745 [01:48<00:07, 553.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62570/66745 [01:48<00:07, 556.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62626/66745 [01:48<00:07, 553.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62685/66745 [01:48<00:07, 562.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62745/66745 [01:48<00:06, 571.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62805/66745 [01:48<00:06, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62865/66745 [01:48<00:06, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62925/66745 [01:49<00:06, 586.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62985/66745 [01:49<00:06, 588.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63045/66745 [01:49<00:06, 590.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63105/66745 [01:49<00:06, 575.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63165/66745 [01:49<00:06, 580.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63224/66745 [01:49<00:06, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63282/66745 [01:49<00:06, 567.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63339/66745 [01:49<00:06, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63397/66745 [01:49<00:05, 565.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63454/66745 [01:50<00:05, 562.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63515/66745 [01:50<00:05, 573.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63573/66745 [01:50<00:05, 574.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63631/66745 [01:50<00:05, 567.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63688/66745 [01:50<00:05, 555.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63744/66745 [01:50<00:05, 547.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63801/66745 [01:50<00:05, 551.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63858/66745 [01:50<00:05, 556.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63917/66745 [01:50<00:05, 563.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63975/66745 [01:50<00:04, 568.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64034/66745 [01:51<00:04, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64093/66745 [01:51<00:04, 574.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64152/66745 [01:51<00:04, 577.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64211/66745 [01:51<00:04, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64269/66745 [01:51<00:04, 575.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64328/66745 [01:51<00:04, 577.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64386/66745 [01:51<00:04, 577.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64444/66745 [01:51<00:03, 575.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64504/66745 [01:51<00:03, 581.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64564/66745 [01:51<00:03, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64623/66745 [01:52<00:03, 584.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64682/66745 [01:52<00:03, 574.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64740/66745 [01:52<00:03, 574.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64800/66745 [01:52<00:03, 579.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64859/66745 [01:52<00:03, 581.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64918/66745 [01:52<00:03, 581.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64977/66745 [01:52<00:03, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65036/66745 [01:52<00:03, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65093/66745 [01:52<00:02, 567.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65150/66745 [01:52<00:02, 567.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65207/66745 [01:53<00:02, 558.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65264/66745 [01:53<00:02, 560.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65321/66745 [01:53<00:02, 555.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65377/66745 [01:53<00:02, 555.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65434/66745 [01:53<00:02, 559.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65491/66745 [01:53<00:02, 553.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65547/66745 [01:53<00:02, 548.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65602/66745 [01:53<00:02, 544.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65657/66745 [01:53<00:02, 541.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65712/66745 [01:54<00:01, 536.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65768/66745 [01:54<00:01, 541.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65826/66745 [01:54<00:01, 549.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65883/66745 [01:54<00:01, 553.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65939/66745 [01:54<00:01, 549.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65996/66745 [01:54<00:01, 552.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66055/66745 [01:54<00:01, 562.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66112/66745 [01:54<00:01, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66170/66745 [01:54<00:01, 566.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66227/66745 [01:54<00:00, 565.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66284/66745 [01:55<00:00, 558.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66340/66745 [01:55<00:00, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66396/66745 [01:55<00:00, 554.28batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66452/66745 [01:55<00:00, 543.45batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66507/66745 [01:55<00:00, 536.22batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66561/66745 [01:55<00:00, 531.24batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66615/66745 [01:55<00:00, 533.50batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66669/66745 [01:55<00:00, 529.37batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66728/66745 [01:55<00:00, 545.28batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   4%| | 4/100 [07:44<3:05:51, 116.17s/epoch, loss=0.3\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 16/66745 [00:00<06:57, 159.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 68/66745 [00:00<03:01, 366.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 125/66745 [00:00<02:26, 456.06batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   0%|       | 182/66745 [00:00<02:13, 497.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 240/66745 [00:00<02:06, 526.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 299/66745 [00:00<02:01, 544.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 357/66745 [00:00<01:59, 554.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 414/66745 [00:00<01:58, 559.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 471/66745 [00:00<01:57, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 529/66745 [00:01<01:57, 564.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 586/66745 [00:01<01:56, 565.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 644/66745 [00:01<01:56, 567.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 701/66745 [00:01<01:56, 567.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 758/66745 [00:01<01:56, 568.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 816/66745 [00:01<01:55, 568.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 873/66745 [00:01<01:55, 568.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 930/66745 [00:01<01:55, 568.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 987/66745 [00:01<01:56, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1044/66745 [00:01<01:56, 564.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1103/66745 [00:02<01:55, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1163/66745 [00:02<01:53, 577.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1222/66745 [00:02<01:53, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1280/66745 [00:02<01:55, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1339/66745 [00:02<01:54, 570.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1397/66745 [00:02<01:53, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1455/66745 [00:02<01:53, 575.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1513/66745 [00:02<01:53, 575.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1571/66745 [00:02<01:53, 576.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1630/66745 [00:02<01:52, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1688/66745 [00:03<01:52, 578.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1746/66745 [00:03<01:52, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1804/66745 [00:03<01:52, 578.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1862/66745 [00:03<01:52, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1920/66745 [00:03<01:53, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1978/66745 [00:03<01:53, 572.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2036/66745 [00:03<01:52, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2094/66745 [00:03<01:53, 570.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2152/66745 [00:03<01:54, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2211/66745 [00:03<01:53, 570.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2269/66745 [00:04<01:52, 573.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2328/66745 [00:04<01:51, 575.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2386/66745 [00:04<01:52, 572.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2444/66745 [00:04<01:52, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2502/66745 [00:04<01:52, 569.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2559/66745 [00:04<01:53, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2616/66745 [00:04<01:53, 565.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2675/66745 [00:04<01:52, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2734/66745 [00:04<01:51, 573.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2793/66745 [00:04<01:50, 576.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2852/66745 [00:05<01:50, 579.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2911/66745 [00:05<01:49, 580.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2970/66745 [00:05<01:50, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3030/66745 [00:05<01:49, 582.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3089/66745 [00:05<01:49, 583.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3148/66745 [00:05<01:48, 584.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3207/66745 [00:05<01:48, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3266/66745 [00:05<01:48, 584.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3325/66745 [00:05<01:48, 584.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3384/66745 [00:05<01:48, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3443/66745 [00:06<01:48, 585.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3502/66745 [00:06<01:47, 585.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3561/66745 [00:06<01:47, 586.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3620/66745 [00:06<01:48, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3679/66745 [00:06<01:48, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3738/66745 [00:06<01:48, 580.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3797/66745 [00:06<01:48, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3856/66745 [00:06<01:48, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3914/66745 [00:06<01:48, 578.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3972/66745 [00:06<01:48, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4030/66745 [00:07<01:48, 579.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4088/66745 [00:07<01:48, 579.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4146/66745 [00:07<01:48, 579.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4204/66745 [00:07<01:47, 579.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4262/66745 [00:07<01:47, 579.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4320/66745 [00:07<01:47, 579.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4378/66745 [00:07<01:47, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4436/66745 [00:07<01:48, 573.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4494/66745 [00:07<01:49, 570.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4553/66745 [00:07<01:48, 575.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4612/66745 [00:08<01:47, 578.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4671/66745 [00:08<01:46, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4730/66745 [00:08<01:46, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4789/66745 [00:08<01:46, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4848/66745 [00:08<01:45, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4908/66745 [00:08<01:45, 586.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4967/66745 [00:08<01:47, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5025/66745 [00:08<01:47, 575.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5083/66745 [00:08<01:47, 575.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5143/66745 [00:09<01:45, 582.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5202/66745 [00:09<01:45, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5261/66745 [00:09<01:45, 581.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5320/66745 [00:09<01:45, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5379/66745 [00:09<01:45, 580.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5438/66745 [00:09<01:48, 564.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5495/66745 [00:09<01:50, 552.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5552/66745 [00:09<01:50, 556.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5611/66745 [00:09<01:48, 565.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5670/66745 [00:09<01:46, 572.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5728/66745 [00:10<01:49, 557.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5784/66745 [00:10<01:49, 554.71batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   9%|▌     | 5843/66745 [00:10<01:47, 564.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5900/66745 [00:10<01:49, 555.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5956/66745 [00:10<01:49, 557.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6017/66745 [00:10<01:46, 570.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6076/66745 [00:10<01:45, 573.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6136/66745 [00:10<01:44, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6195/66745 [00:10<01:46, 570.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6255/66745 [00:10<01:44, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6315/66745 [00:11<01:43, 582.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6374/66745 [00:11<01:43, 583.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6433/66745 [00:11<01:43, 584.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6492/66745 [00:11<01:44, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6550/66745 [00:11<01:44, 577.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6610/66745 [00:11<01:43, 582.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6669/66745 [00:11<01:43, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6729/66745 [00:11<01:42, 585.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6788/66745 [00:11<01:42, 585.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6848/66745 [00:11<01:41, 587.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6908/66745 [00:12<01:41, 589.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6967/66745 [00:12<01:41, 589.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7026/66745 [00:12<01:41, 587.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7085/66745 [00:12<01:44, 572.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7143/66745 [00:12<01:43, 574.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7202/66745 [00:12<01:43, 577.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7260/66745 [00:12<01:44, 570.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7319/66745 [00:12<01:43, 574.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7378/66745 [00:12<01:42, 576.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7437/66745 [00:13<01:42, 578.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7496/66745 [00:13<01:41, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7555/66745 [00:13<01:41, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7614/66745 [00:13<01:42, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7672/66745 [00:13<01:42, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7730/66745 [00:13<01:41, 578.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7788/66745 [00:13<01:42, 573.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7846/66745 [00:13<01:42, 574.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7905/66745 [00:13<01:42, 576.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7963/66745 [00:13<01:42, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8021/66745 [00:14<01:41, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8079/66745 [00:14<01:41, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8138/66745 [00:14<01:41, 578.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8197/66745 [00:14<01:40, 580.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8256/66745 [00:14<01:41, 574.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8314/66745 [00:14<01:43, 565.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8374/66745 [00:14<01:41, 573.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8432/66745 [00:14<01:42, 569.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8489/66745 [00:14<01:44, 555.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8550/66745 [00:14<01:42, 569.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8608/66745 [00:15<01:42, 567.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8665/66745 [00:15<01:44, 558.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8721/66745 [00:15<01:44, 552.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8777/66745 [00:15<01:44, 552.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8836/66745 [00:15<01:43, 561.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8895/66745 [00:15<01:41, 568.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8954/66745 [00:15<01:40, 572.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9013/66745 [00:15<01:40, 576.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9072/66745 [00:15<01:39, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9131/66745 [00:15<01:39, 579.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9190/66745 [00:16<01:39, 580.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9249/66745 [00:16<01:38, 581.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9308/66745 [00:16<01:39, 578.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9367/66745 [00:16<01:38, 581.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9426/66745 [00:16<01:38, 583.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9485/66745 [00:16<01:37, 584.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9544/66745 [00:16<01:37, 585.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9603/66745 [00:16<01:37, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9662/66745 [00:16<01:37, 586.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9721/66745 [00:16<01:40, 567.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9778/66745 [00:17<01:41, 560.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9835/66745 [00:17<01:42, 557.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9895/66745 [00:17<01:40, 567.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9952/66745 [00:17<01:41, 557.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▋    | 10008/66745 [00:17<01:42, 551.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10066/66745 [00:17<01:41, 558.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10125/66745 [00:17<01:39, 567.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10184/66745 [00:17<01:38, 573.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10243/66745 [00:17<01:37, 577.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10302/66745 [00:18<01:37, 579.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10360/66745 [00:18<01:37, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10419/66745 [00:18<01:37, 580.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10480/66745 [00:18<01:35, 586.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10539/66745 [00:18<01:36, 581.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10599/66745 [00:18<01:35, 586.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10659/66745 [00:18<01:35, 589.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10718/66745 [00:18<01:36, 579.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10777/66745 [00:18<01:36, 582.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10836/66745 [00:18<01:36, 579.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10894/66745 [00:19<01:36, 577.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10953/66745 [00:19<01:36, 579.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 11011/66745 [00:19<01:38, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11068/66745 [00:19<01:39, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11125/66745 [00:19<01:39, 560.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11184/66745 [00:19<01:37, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11243/66745 [00:19<01:36, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11302/66745 [00:19<01:36, 576.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11361/66745 [00:19<01:35, 578.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11420/66745 [00:19<01:35, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11479/66745 [00:20<01:36, 572.77batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  17%|▊    | 11537/66745 [00:20<01:38, 560.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11594/66745 [00:20<01:39, 556.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11654/66745 [00:20<01:36, 568.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11711/66745 [00:20<01:37, 564.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11768/66745 [00:20<01:37, 565.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11825/66745 [00:20<01:38, 557.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11882/66745 [00:20<01:37, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11939/66745 [00:20<01:37, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11996/66745 [00:20<01:39, 549.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12052/66745 [00:21<01:40, 544.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12110/66745 [00:21<01:38, 554.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12169/66745 [00:21<01:37, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12227/66745 [00:21<01:36, 567.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12286/66745 [00:21<01:35, 571.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12345/66745 [00:21<01:34, 574.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12403/66745 [00:21<01:34, 574.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12461/66745 [00:21<01:35, 570.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12519/66745 [00:21<01:34, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12580/66745 [00:22<01:32, 582.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12639/66745 [00:22<01:34, 575.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12698/66745 [00:22<01:33, 577.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12757/66745 [00:22<01:33, 578.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12816/66745 [00:22<01:33, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12875/66745 [00:22<01:32, 580.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12934/66745 [00:22<01:32, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12993/66745 [00:22<01:32, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13052/66745 [00:22<01:32, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13111/66745 [00:22<01:32, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13170/66745 [00:23<01:32, 581.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13229/66745 [00:23<01:33, 573.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13288/66745 [00:23<01:32, 578.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13349/66745 [00:23<01:31, 585.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13410/66745 [00:23<01:30, 591.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13471/66745 [00:23<01:29, 595.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13532/66745 [00:23<01:29, 597.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13592/66745 [00:23<01:29, 595.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13652/66745 [00:23<01:29, 591.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13712/66745 [00:23<01:29, 589.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13773/66745 [00:24<01:29, 593.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13833/66745 [00:24<01:29, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13892/66745 [00:24<01:30, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13951/66745 [00:24<01:32, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14011/66745 [00:24<01:31, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14071/66745 [00:24<01:30, 582.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14130/66745 [00:24<01:30, 581.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14189/66745 [00:24<01:30, 580.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14248/66745 [00:24<01:30, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14307/66745 [00:24<01:29, 584.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14366/66745 [00:25<01:29, 584.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14425/66745 [00:25<01:29, 583.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14484/66745 [00:25<01:29, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14543/66745 [00:25<01:29, 584.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14602/66745 [00:25<01:29, 585.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14661/66745 [00:25<01:28, 585.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14720/66745 [00:25<01:29, 583.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14779/66745 [00:25<01:30, 575.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14840/66745 [00:25<01:28, 584.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14900/66745 [00:25<01:28, 586.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14959/66745 [00:26<01:28, 585.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15018/66745 [00:26<01:30, 570.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15076/66745 [00:26<01:31, 565.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15135/66745 [00:26<01:30, 571.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15195/66745 [00:26<01:29, 577.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15255/66745 [00:26<01:28, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15314/66745 [00:26<01:28, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15374/66745 [00:26<01:27, 586.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15434/66745 [00:26<01:27, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15493/66745 [00:26<01:27, 588.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15553/66745 [00:27<01:26, 589.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15612/66745 [00:27<01:26, 588.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15671/66745 [00:27<01:27, 587.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15730/66745 [00:27<01:27, 586.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15789/66745 [00:27<01:28, 575.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15848/66745 [00:27<01:27, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15906/66745 [00:27<01:29, 570.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15965/66745 [00:27<01:28, 573.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16024/66745 [00:27<01:28, 576.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16083/66745 [00:28<01:27, 577.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16142/66745 [00:28<01:27, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16200/66745 [00:28<01:28, 572.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16258/66745 [00:28<01:28, 570.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16316/66745 [00:28<01:28, 570.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16374/66745 [00:28<01:27, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16432/66745 [00:28<01:29, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16489/66745 [00:28<01:29, 559.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16547/66745 [00:28<01:28, 565.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16606/66745 [00:28<01:27, 569.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16665/66745 [00:29<01:27, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16724/66745 [00:29<01:26, 575.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16782/66745 [00:29<01:29, 559.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16839/66745 [00:29<01:30, 550.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16897/66745 [00:29<01:29, 557.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16957/66745 [00:29<01:27, 568.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 17017/66745 [00:29<01:26, 575.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17077/66745 [00:29<01:25, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17136/66745 [00:29<01:25, 580.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17195/66745 [00:29<01:25, 580.48batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  26%|█▎   | 17254/66745 [00:30<01:25, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17313/66745 [00:30<01:25, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17372/66745 [00:30<01:25, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17431/66745 [00:30<01:25, 579.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17490/66745 [00:30<01:25, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17548/66745 [00:30<01:26, 568.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17605/66745 [00:30<01:26, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17662/66745 [00:30<01:26, 568.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17721/66745 [00:30<01:25, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17780/66745 [00:30<01:24, 578.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17839/66745 [00:31<01:24, 580.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17898/66745 [00:31<01:23, 582.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17957/66745 [00:31<01:24, 576.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18015/66745 [00:31<01:24, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18075/66745 [00:31<01:23, 582.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18135/66745 [00:31<01:22, 585.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18195/66745 [00:31<01:22, 589.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18254/66745 [00:31<01:22, 589.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18313/66745 [00:31<01:22, 589.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18372/66745 [00:31<01:22, 589.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18431/66745 [00:32<01:22, 588.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18490/66745 [00:32<01:22, 587.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18549/66745 [00:32<01:23, 579.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18609/66745 [00:32<01:22, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18668/66745 [00:32<01:22, 585.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18728/66745 [00:32<01:21, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18787/66745 [00:32<01:21, 588.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18847/66745 [00:32<01:21, 590.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18907/66745 [00:32<01:20, 592.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18967/66745 [00:33<01:21, 585.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19026/66745 [00:33<01:21, 582.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19085/66745 [00:33<01:23, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19143/66745 [00:33<01:24, 562.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19200/66745 [00:33<01:24, 561.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19259/66745 [00:33<01:23, 567.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19318/66745 [00:33<01:22, 572.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19377/66745 [00:33<01:22, 575.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19436/66745 [00:33<01:21, 577.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19495/66745 [00:33<01:21, 579.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19554/66745 [00:34<01:21, 580.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19613/66745 [00:34<01:20, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19672/66745 [00:34<01:21, 575.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19730/66745 [00:34<01:23, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19787/66745 [00:34<01:23, 564.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19847/66745 [00:34<01:21, 574.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19906/66745 [00:34<01:21, 577.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19965/66745 [00:34<01:20, 580.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20024/66745 [00:34<01:20, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20083/66745 [00:34<01:20, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20142/66745 [00:35<01:19, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20201/66745 [00:35<01:19, 583.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20260/66745 [00:35<01:19, 583.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20319/66745 [00:35<01:20, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20377/66745 [00:35<01:22, 564.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20436/66745 [00:35<01:21, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20498/66745 [00:35<01:19, 582.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20559/66745 [00:35<01:18, 589.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20619/66745 [00:35<01:18, 589.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20679/66745 [00:35<01:18, 589.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20738/66745 [00:36<01:18, 589.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20798/66745 [00:36<01:17, 590.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20858/66745 [00:36<01:17, 591.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20918/66745 [00:36<01:17, 589.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20977/66745 [00:36<01:18, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21036/66745 [00:36<01:18, 580.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21095/66745 [00:36<01:18, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21154/66745 [00:36<01:19, 573.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21212/66745 [00:36<01:19, 571.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21271/66745 [00:36<01:18, 577.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21329/66745 [00:37<01:18, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21387/66745 [00:37<01:19, 571.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21445/66745 [00:37<01:19, 570.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21503/66745 [00:37<01:21, 554.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21561/66745 [00:37<01:20, 558.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21621/66745 [00:37<01:19, 569.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21680/66745 [00:37<01:18, 575.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21739/66745 [00:37<01:17, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21799/66745 [00:37<01:16, 584.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21858/66745 [00:38<01:18, 574.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21917/66745 [00:38<01:17, 577.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21975/66745 [00:38<01:17, 574.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22034/66745 [00:38<01:17, 578.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22093/66745 [00:38<01:17, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22151/66745 [00:38<01:18, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22211/66745 [00:38<01:17, 572.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22271/66745 [00:38<01:16, 577.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22332/66745 [00:38<01:15, 587.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22392/66745 [00:38<01:15, 589.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22452/66745 [00:39<01:15, 588.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22511/66745 [00:39<01:15, 586.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22570/66745 [00:39<01:15, 581.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22629/66745 [00:39<01:15, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22688/66745 [00:39<01:16, 573.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22746/66745 [00:39<01:16, 572.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22806/66745 [00:39<01:15, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22865/66745 [00:39<01:15, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22924/66745 [00:39<01:15, 583.91batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  34%|█▋   | 22984/66745 [00:39<01:14, 585.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23043/66745 [00:40<01:14, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23102/66745 [00:40<01:14, 583.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23161/66745 [00:40<01:15, 580.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23220/66745 [00:40<01:15, 575.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23278/66745 [00:40<01:15, 573.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23336/66745 [00:40<01:16, 569.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23395/66745 [00:40<01:15, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23454/66745 [00:40<01:15, 577.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23513/66745 [00:40<01:14, 579.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23572/66745 [00:40<01:14, 581.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23631/66745 [00:41<01:14, 582.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23690/66745 [00:41<01:13, 584.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23749/66745 [00:41<01:14, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23807/66745 [00:41<01:14, 576.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23865/66745 [00:41<01:15, 567.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23922/66745 [00:41<01:16, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23982/66745 [00:41<01:14, 571.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24040/66745 [00:41<01:15, 567.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24097/66745 [00:41<01:15, 565.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24154/66745 [00:42<01:16, 557.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24210/66745 [00:42<01:17, 551.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24266/66745 [00:42<01:17, 549.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24321/66745 [00:42<01:17, 545.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24377/66745 [00:42<01:17, 548.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24433/66745 [00:42<01:16, 551.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24492/66745 [00:42<01:15, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24551/66745 [00:42<01:14, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24608/66745 [00:42<01:14, 566.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24665/66745 [00:42<01:14, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24725/66745 [00:43<01:13, 574.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24783/66745 [00:43<01:13, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24843/66745 [00:43<01:12, 575.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24902/66745 [00:43<01:12, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24960/66745 [00:43<01:13, 566.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 25018/66745 [00:43<01:13, 568.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25078/66745 [00:43<01:12, 575.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25137/66745 [00:43<01:11, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25196/66745 [00:43<01:11, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25256/66745 [00:43<01:10, 585.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25315/66745 [00:44<01:11, 578.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25373/66745 [00:44<01:12, 573.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25431/66745 [00:44<01:12, 570.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25489/66745 [00:44<01:13, 560.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25546/66745 [00:44<01:14, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25602/66745 [00:44<01:14, 548.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25657/66745 [00:44<01:16, 537.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25711/66745 [00:44<01:16, 537.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25769/66745 [00:44<01:14, 547.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25827/66745 [00:44<01:13, 555.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25884/66745 [00:45<01:13, 557.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25940/66745 [00:45<01:13, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25997/66745 [00:45<01:13, 555.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26054/66745 [00:45<01:12, 558.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26110/66745 [00:45<01:13, 554.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26168/66745 [00:45<01:12, 561.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26225/66745 [00:45<01:14, 547.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26285/66745 [00:45<01:12, 561.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26346/66745 [00:45<01:10, 574.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26405/66745 [00:46<01:09, 578.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26464/66745 [00:46<01:09, 581.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26523/66745 [00:46<01:09, 581.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26583/66745 [00:46<01:08, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26642/66745 [00:46<01:08, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26702/66745 [00:46<01:08, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26761/66745 [00:46<01:08, 587.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26820/66745 [00:46<01:10, 570.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26879/66745 [00:46<01:09, 575.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26939/66745 [00:46<01:08, 580.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26999/66745 [00:47<01:08, 583.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27060/66745 [00:47<01:07, 591.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27121/66745 [00:47<01:06, 596.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27181/66745 [00:47<01:06, 596.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27241/66745 [00:47<01:06, 594.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27301/66745 [00:47<01:06, 593.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27361/66745 [00:47<01:06, 593.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27421/66745 [00:47<01:07, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27480/66745 [00:47<01:07, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27542/66745 [00:47<01:06, 591.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27603/66745 [00:48<01:05, 596.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27663/66745 [00:48<01:06, 590.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27723/66745 [00:48<01:06, 589.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27783/66745 [00:48<01:05, 590.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27843/66745 [00:48<01:05, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27903/66745 [00:48<01:05, 590.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27963/66745 [00:48<01:05, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28023/66745 [00:48<01:07, 573.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28082/66745 [00:48<01:06, 577.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28142/66745 [00:48<01:06, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28203/66745 [00:49<01:05, 587.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28262/66745 [00:49<01:06, 574.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28321/66745 [00:49<01:06, 577.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28382/66745 [00:49<01:05, 584.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28442/66745 [00:49<01:05, 586.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28502/66745 [00:49<01:04, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28562/66745 [00:49<01:04, 589.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28621/66745 [00:49<01:05, 578.22batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  43%|██▏  | 28681/66745 [00:49<01:05, 581.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28741/66745 [00:49<01:04, 586.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28800/66745 [00:50<01:04, 585.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28860/66745 [00:50<01:04, 588.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28919/66745 [00:50<01:04, 587.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28978/66745 [00:50<01:04, 587.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29037/66745 [00:50<01:04, 587.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29096/66745 [00:50<01:04, 587.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29155/66745 [00:50<01:04, 586.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29214/66745 [00:50<01:05, 572.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29273/66745 [00:50<01:04, 577.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29333/66745 [00:51<01:04, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29395/66745 [00:51<01:03, 590.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29455/66745 [00:51<01:05, 571.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29513/66745 [00:51<01:06, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29570/66745 [00:51<01:07, 550.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29629/66745 [00:51<01:06, 560.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29688/66745 [00:51<01:05, 569.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29747/66745 [00:51<01:04, 574.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29805/66745 [00:51<01:04, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29864/66745 [00:51<01:03, 576.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29923/66745 [00:52<01:03, 579.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29982/66745 [00:52<01:03, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30040/66745 [00:52<01:05, 563.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30097/66745 [00:52<01:05, 557.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30156/66745 [00:52<01:04, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30215/66745 [00:52<01:03, 573.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30274/66745 [00:52<01:03, 577.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30333/66745 [00:52<01:02, 580.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30392/66745 [00:52<01:04, 562.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30453/66745 [00:52<01:03, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30514/66745 [00:53<01:02, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30573/66745 [00:53<01:03, 567.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30631/66745 [00:53<01:03, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30689/66745 [00:53<01:03, 566.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30746/66745 [00:53<01:03, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30803/66745 [00:53<01:03, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30860/66745 [00:53<01:03, 564.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30918/66745 [00:53<01:03, 567.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30975/66745 [00:53<01:03, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 31034/66745 [00:53<01:02, 571.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31093/66745 [00:54<01:01, 575.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31152/66745 [00:54<01:01, 578.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31211/66745 [00:54<01:01, 580.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31270/66745 [00:54<01:00, 582.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31329/66745 [00:54<01:00, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31388/66745 [00:54<01:00, 584.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31447/66745 [00:54<01:00, 585.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31506/66745 [00:54<01:00, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31565/66745 [00:54<01:01, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31625/66745 [00:55<01:00, 581.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31685/66745 [00:55<00:59, 584.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31745/66745 [00:55<00:59, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31806/66745 [00:55<00:59, 590.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31866/66745 [00:55<00:58, 593.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31927/66745 [00:55<00:58, 595.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31987/66745 [00:55<00:58, 590.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32047/66745 [00:55<00:58, 589.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32106/66745 [00:55<00:58, 588.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32165/66745 [00:55<00:58, 586.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32224/66745 [00:56<00:58, 586.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32284/66745 [00:56<00:58, 589.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32343/66745 [00:56<00:58, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32402/66745 [00:56<00:58, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32461/66745 [00:56<00:58, 589.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32520/66745 [00:56<00:58, 589.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32580/66745 [00:56<00:57, 589.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32639/66745 [00:56<00:57, 589.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32698/66745 [00:56<00:57, 589.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32757/66745 [00:56<00:59, 573.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32816/66745 [00:57<00:58, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32876/66745 [00:57<00:58, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32935/66745 [00:57<00:57, 583.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32994/66745 [00:57<00:57, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33053/66745 [00:57<00:57, 586.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33113/66745 [00:57<00:57, 587.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33172/66745 [00:57<00:58, 571.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33230/66745 [00:57<00:58, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33287/66745 [00:57<00:59, 562.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33344/66745 [00:57<00:59, 560.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33404/66745 [00:58<00:58, 571.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33465/66745 [00:58<00:57, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33525/66745 [00:58<00:56, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33586/66745 [00:58<00:56, 589.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33645/66745 [00:58<00:56, 588.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33704/66745 [00:58<00:56, 587.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33763/66745 [00:58<00:56, 579.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33824/66745 [00:58<00:56, 587.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33884/66745 [00:58<00:55, 588.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33943/66745 [00:58<00:56, 579.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34002/66745 [00:59<00:56, 580.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34061/66745 [00:59<00:56, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34120/66745 [00:59<00:55, 583.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34179/66745 [00:59<00:55, 583.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34238/66745 [00:59<00:55, 584.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34297/66745 [00:59<00:55, 584.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34356/66745 [00:59<00:55, 585.33batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  52%|██▌  | 34415/66745 [00:59<00:55, 585.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34474/66745 [00:59<00:55, 585.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34533/66745 [00:59<00:55, 579.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34594/66745 [01:00<00:54, 587.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34653/66745 [01:00<00:54, 587.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34712/66745 [01:00<00:54, 587.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34771/66745 [01:00<00:54, 587.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34830/66745 [01:00<00:54, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34889/66745 [01:00<00:54, 587.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34948/66745 [01:00<00:54, 586.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 35007/66745 [01:00<00:54, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35066/66745 [01:00<00:54, 585.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35125/66745 [01:01<00:55, 569.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35183/66745 [01:01<00:56, 560.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35240/66745 [01:01<00:56, 561.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35297/66745 [01:01<00:55, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35354/66745 [01:01<00:56, 557.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35412/66745 [01:01<00:55, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35469/66745 [01:01<00:55, 561.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35528/66745 [01:01<00:54, 569.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35585/66745 [01:01<00:55, 560.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35642/66745 [01:01<00:56, 553.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35701/66745 [01:02<00:55, 563.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35761/66745 [01:02<00:54, 571.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35820/66745 [01:02<00:53, 576.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35880/66745 [01:02<00:53, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35940/66745 [01:02<00:52, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35999/66745 [01:02<00:52, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36059/66745 [01:02<00:52, 586.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36119/66745 [01:02<00:52, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36178/66745 [01:02<00:51, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36237/66745 [01:02<00:51, 588.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36296/66745 [01:03<00:52, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36356/66745 [01:03<00:51, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36416/66745 [01:03<00:51, 587.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36476/66745 [01:03<00:51, 588.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36536/66745 [01:03<00:51, 589.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36596/66745 [01:03<00:51, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36656/66745 [01:03<00:50, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36716/66745 [01:03<00:50, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36776/66745 [01:03<00:50, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36835/66745 [01:03<00:50, 588.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36894/66745 [01:04<00:50, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36954/66745 [01:04<00:50, 589.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37013/66745 [01:04<00:50, 589.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37073/66745 [01:04<00:50, 589.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37133/66745 [01:04<00:50, 590.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37193/66745 [01:04<00:50, 590.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37253/66745 [01:04<00:49, 590.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37313/66745 [01:04<00:49, 590.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37373/66745 [01:04<00:50, 576.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37431/66745 [01:04<00:52, 561.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37488/66745 [01:05<00:52, 556.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37548/66745 [01:05<00:51, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37608/66745 [01:05<00:50, 575.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37668/66745 [01:05<00:49, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37727/66745 [01:05<00:49, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37786/66745 [01:05<00:50, 578.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37845/66745 [01:05<00:49, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37904/66745 [01:05<00:49, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37963/66745 [01:05<00:49, 584.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38022/66745 [01:05<00:49, 585.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38081/66745 [01:06<00:49, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38140/66745 [01:06<00:49, 577.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38199/66745 [01:06<00:49, 580.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38258/66745 [01:06<00:48, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38317/66745 [01:06<00:48, 583.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38376/66745 [01:06<00:48, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38435/66745 [01:06<00:48, 584.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38494/66745 [01:06<00:48, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38553/66745 [01:06<00:48, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38612/66745 [01:07<00:47, 586.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38671/66745 [01:07<00:48, 582.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38730/66745 [01:07<00:48, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38789/66745 [01:07<00:47, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38848/66745 [01:07<00:47, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38907/66745 [01:07<00:47, 584.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38967/66745 [01:07<00:47, 585.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 39026/66745 [01:07<00:47, 583.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39085/66745 [01:07<00:48, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39142/66745 [01:07<00:49, 558.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39202/66745 [01:08<00:48, 569.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39260/66745 [01:08<00:48, 570.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39318/66745 [01:08<00:48, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39377/66745 [01:08<00:47, 574.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39436/66745 [01:08<00:47, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39495/66745 [01:08<00:46, 579.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39554/66745 [01:08<00:46, 580.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39613/66745 [01:08<00:47, 573.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39671/66745 [01:08<00:47, 569.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39728/66745 [01:08<00:47, 568.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39785/66745 [01:09<00:48, 554.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39844/66745 [01:09<00:47, 562.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39903/66745 [01:09<00:47, 568.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39962/66745 [01:09<00:46, 572.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40021/66745 [01:09<00:46, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40080/66745 [01:09<00:46, 578.86batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  60%|███  | 40139/66745 [01:09<00:45, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40198/66745 [01:09<00:45, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40257/66745 [01:09<00:45, 579.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40316/66745 [01:09<00:45, 580.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40375/66745 [01:10<00:45, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40433/66745 [01:10<00:45, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40492/66745 [01:10<00:45, 578.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40551/66745 [01:10<00:45, 579.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40610/66745 [01:10<00:45, 580.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40669/66745 [01:10<00:44, 581.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40728/66745 [01:10<00:44, 582.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40787/66745 [01:10<00:44, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40846/66745 [01:10<00:44, 582.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40905/66745 [01:10<00:44, 582.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40965/66745 [01:11<00:43, 586.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41024/66745 [01:11<00:44, 573.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41082/66745 [01:11<00:45, 561.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41139/66745 [01:11<00:46, 551.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41195/66745 [01:11<00:46, 545.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41250/66745 [01:11<00:47, 540.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41305/66745 [01:11<00:47, 537.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41359/66745 [01:11<00:47, 533.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41413/66745 [01:11<00:47, 532.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41467/66745 [01:12<00:47, 530.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41521/66745 [01:12<00:47, 527.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41577/66745 [01:12<00:47, 534.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41635/66745 [01:12<00:45, 546.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41692/66745 [01:12<00:45, 553.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41752/66745 [01:12<00:44, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41812/66745 [01:12<00:43, 572.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41872/66745 [01:12<00:42, 578.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41932/66745 [01:12<00:42, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41991/66745 [01:12<00:42, 583.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42050/66745 [01:13<00:42, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42109/66745 [01:13<00:43, 567.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42167/66745 [01:13<00:43, 568.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42227/66745 [01:13<00:42, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42287/66745 [01:13<00:42, 580.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42346/66745 [01:13<00:42, 579.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42406/66745 [01:13<00:41, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42466/66745 [01:13<00:41, 586.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42526/66745 [01:13<00:41, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42586/66745 [01:13<00:40, 589.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42646/66745 [01:14<00:40, 592.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42706/66745 [01:14<00:41, 584.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42765/66745 [01:14<00:41, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42825/66745 [01:14<00:40, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42885/66745 [01:14<00:40, 586.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42945/66745 [01:14<00:40, 588.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43005/66745 [01:14<00:40, 589.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43065/66745 [01:14<00:40, 590.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43125/66745 [01:14<00:39, 591.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43185/66745 [01:14<00:40, 586.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43245/66745 [01:15<00:39, 587.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43304/66745 [01:15<00:40, 583.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43363/66745 [01:15<00:40, 573.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43421/66745 [01:15<00:40, 571.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43479/66745 [01:15<00:40, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43536/66745 [01:15<00:41, 564.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43595/66745 [01:15<00:40, 572.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43654/66745 [01:15<00:40, 574.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43712/66745 [01:15<00:40, 572.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43771/66745 [01:16<00:39, 574.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43829/66745 [01:16<00:39, 576.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43887/66745 [01:16<00:40, 568.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43945/66745 [01:16<00:39, 571.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44006/66745 [01:16<00:39, 581.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44065/66745 [01:16<00:38, 583.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44124/66745 [01:16<00:38, 584.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44183/66745 [01:16<00:38, 586.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44242/66745 [01:16<00:38, 586.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44301/66745 [01:16<00:38, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44360/66745 [01:17<00:38, 587.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44419/66745 [01:17<00:38, 586.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44478/66745 [01:17<00:39, 565.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44536/66745 [01:17<00:39, 569.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44595/66745 [01:17<00:38, 574.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44654/66745 [01:17<00:38, 578.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44713/66745 [01:17<00:37, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44772/66745 [01:17<00:37, 583.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44831/66745 [01:17<00:37, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44890/66745 [01:17<00:37, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44949/66745 [01:18<00:37, 583.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45008/66745 [01:18<00:37, 582.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45067/66745 [01:18<00:37, 576.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45125/66745 [01:18<00:38, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45185/66745 [01:18<00:37, 572.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45244/66745 [01:18<00:37, 575.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45302/66745 [01:18<00:37, 576.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45360/66745 [01:18<00:37, 576.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45418/66745 [01:18<00:37, 570.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45476/66745 [01:18<00:37, 569.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45535/66745 [01:19<00:36, 575.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45593/66745 [01:19<00:36, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45651/66745 [01:19<00:37, 555.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45707/66745 [01:19<00:38, 546.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45762/66745 [01:19<00:38, 541.83batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  69%|███▍ | 45817/66745 [01:19<00:38, 537.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45871/66745 [01:19<00:39, 534.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45925/66745 [01:19<00:39, 532.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45980/66745 [01:19<00:38, 535.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46039/66745 [01:20<00:37, 549.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46095/66745 [01:20<00:37, 550.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46152/66745 [01:20<00:37, 554.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46208/66745 [01:20<00:37, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46264/66745 [01:20<00:37, 551.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46323/66745 [01:20<00:36, 561.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46380/66745 [01:20<00:36, 561.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46438/66745 [01:20<00:35, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46495/66745 [01:20<00:36, 556.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46554/66745 [01:20<00:35, 564.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46611/66745 [01:21<00:35, 562.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46668/66745 [01:21<00:35, 559.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46724/66745 [01:21<00:36, 555.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46780/66745 [01:21<00:36, 552.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46839/66745 [01:21<00:35, 561.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46900/66745 [01:21<00:34, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46958/66745 [01:21<00:34, 568.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47016/66745 [01:21<00:34, 570.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47075/66745 [01:21<00:34, 575.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47135/66745 [01:21<00:33, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47194/66745 [01:22<00:33, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47253/66745 [01:22<00:33, 583.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47312/66745 [01:22<00:33, 579.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47370/66745 [01:22<00:34, 561.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47427/66745 [01:22<00:35, 549.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47483/66745 [01:22<00:35, 541.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47541/66745 [01:22<00:34, 552.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47600/66745 [01:22<00:34, 562.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47659/66745 [01:22<00:33, 570.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47718/66745 [01:22<00:33, 575.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47777/66745 [01:23<00:32, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47836/66745 [01:23<00:32, 581.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47895/66745 [01:23<00:32, 583.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47954/66745 [01:23<00:32, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48012/66745 [01:23<00:32, 574.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48071/66745 [01:23<00:32, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48131/66745 [01:23<00:31, 582.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48190/66745 [01:23<00:31, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48250/66745 [01:23<00:31, 586.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48310/66745 [01:23<00:31, 587.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48369/66745 [01:24<00:31, 588.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48429/66745 [01:24<00:31, 588.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48489/66745 [01:24<00:30, 589.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48548/66745 [01:24<00:31, 583.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48607/66745 [01:24<00:31, 578.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48666/66745 [01:24<00:31, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48725/66745 [01:24<00:30, 583.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48784/66745 [01:24<00:30, 584.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48844/66745 [01:24<00:30, 588.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48904/66745 [01:25<00:30, 589.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48964/66745 [01:25<00:30, 590.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 49024/66745 [01:25<00:30, 589.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49083/66745 [01:25<00:29, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49142/66745 [01:25<00:30, 585.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49201/66745 [01:25<00:29, 586.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49261/66745 [01:25<00:29, 587.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49321/66745 [01:25<00:29, 589.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49381/66745 [01:25<00:29, 589.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49441/66745 [01:25<00:29, 589.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49501/66745 [01:26<00:29, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49561/66745 [01:26<00:29, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49621/66745 [01:26<00:29, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49682/66745 [01:26<00:28, 594.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49742/66745 [01:26<00:28, 589.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49801/66745 [01:26<00:28, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49861/66745 [01:26<00:28, 589.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49921/66745 [01:26<00:28, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49981/66745 [01:26<00:28, 590.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50041/66745 [01:26<00:28, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50101/66745 [01:27<00:28, 590.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50161/66745 [01:27<00:28, 590.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50221/66745 [01:27<00:28, 589.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50280/66745 [01:27<00:27, 588.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50339/66745 [01:27<00:28, 585.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50398/66745 [01:27<00:27, 586.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50459/66745 [01:27<00:27, 592.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50520/66745 [01:27<00:27, 597.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50580/66745 [01:27<00:27, 597.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50641/66745 [01:27<00:26, 600.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50702/66745 [01:28<00:26, 603.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50763/66745 [01:28<00:26, 605.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50824/66745 [01:28<00:26, 592.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50884/66745 [01:28<00:27, 587.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50943/66745 [01:28<00:27, 572.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51001/66745 [01:28<00:27, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51059/66745 [01:28<00:27, 568.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51116/66745 [01:28<00:27, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51173/66745 [01:28<00:27, 566.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51230/66745 [01:28<00:27, 565.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51287/66745 [01:29<00:27, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51344/66745 [01:29<00:27, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51404/66745 [01:29<00:27, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51463/66745 [01:29<00:26, 572.46batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  77%|███▊ | 51521/66745 [01:29<00:26, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51580/66745 [01:29<00:26, 574.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51639/66745 [01:29<00:26, 577.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51698/66745 [01:29<00:25, 580.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51757/66745 [01:29<00:25, 582.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51818/66745 [01:29<00:25, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51878/66745 [01:30<00:25, 590.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51939/66745 [01:30<00:24, 596.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51999/66745 [01:30<00:24, 596.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52060/66745 [01:30<00:24, 597.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52121/66745 [01:30<00:24, 599.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52181/66745 [01:30<00:25, 581.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52240/66745 [01:30<00:25, 578.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52302/66745 [01:30<00:24, 588.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52362/66745 [01:30<00:24, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52422/66745 [01:31<00:24, 590.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52482/66745 [01:31<00:24, 589.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52541/66745 [01:31<00:24, 587.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52600/66745 [01:31<00:24, 586.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52659/66745 [01:31<00:24, 585.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52718/66745 [01:31<00:23, 584.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52777/66745 [01:31<00:24, 580.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52836/66745 [01:31<00:23, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52895/66745 [01:31<00:23, 583.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52955/66745 [01:31<00:23, 585.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53015/66745 [01:32<00:23, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53075/66745 [01:32<00:23, 588.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53135/66745 [01:32<00:23, 589.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53195/66745 [01:32<00:22, 590.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53255/66745 [01:32<00:23, 583.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53314/66745 [01:32<00:22, 584.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53375/66745 [01:32<00:22, 590.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53435/66745 [01:32<00:22, 590.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53495/66745 [01:32<00:22, 590.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53555/66745 [01:32<00:22, 590.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53615/66745 [01:33<00:22, 590.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53675/66745 [01:33<00:22, 587.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53735/66745 [01:33<00:22, 588.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53794/66745 [01:33<00:22, 588.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53853/66745 [01:33<00:22, 579.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53912/66745 [01:33<00:22, 580.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53971/66745 [01:33<00:21, 581.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54030/66745 [01:33<00:21, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54090/66745 [01:33<00:21, 586.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54150/66745 [01:33<00:21, 588.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54210/66745 [01:34<00:21, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54270/66745 [01:34<00:21, 590.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54330/66745 [01:34<00:21, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54390/66745 [01:34<00:20, 591.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54450/66745 [01:34<00:21, 578.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54508/66745 [01:34<00:21, 576.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54568/66745 [01:34<00:20, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54629/66745 [01:34<00:20, 586.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54688/66745 [01:34<00:20, 586.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54747/66745 [01:34<00:20, 586.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54806/66745 [01:35<00:20, 586.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54865/66745 [01:35<00:20, 585.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54924/66745 [01:35<00:20, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54983/66745 [01:35<00:20, 585.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55042/66745 [01:35<00:20, 578.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55100/66745 [01:35<00:20, 571.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55160/66745 [01:35<00:20, 577.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55220/66745 [01:35<00:19, 581.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55280/66745 [01:35<00:19, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55340/66745 [01:35<00:19, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55399/66745 [01:36<00:19, 586.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55458/66745 [01:36<00:19, 586.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55517/66745 [01:36<00:19, 585.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55576/66745 [01:36<00:19, 585.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55635/66745 [01:36<00:19, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55695/66745 [01:36<00:18, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55754/66745 [01:36<00:19, 577.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55812/66745 [01:36<00:19, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55870/66745 [01:36<00:19, 572.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55928/66745 [01:37<00:19, 563.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55987/66745 [01:37<00:18, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56048/66745 [01:37<00:18, 578.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56106/66745 [01:37<00:18, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56164/66745 [01:37<00:18, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56220/66745 [01:37<00:18, 556.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56279/66745 [01:37<00:18, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56337/66745 [01:37<00:18, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56397/66745 [01:37<00:18, 574.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56457/66745 [01:37<00:17, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56517/66745 [01:38<00:17, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56577/66745 [01:38<00:17, 587.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56636/66745 [01:38<00:17, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56695/66745 [01:38<00:17, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56754/66745 [01:38<00:17, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56813/66745 [01:38<00:16, 584.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56872/66745 [01:38<00:16, 585.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56931/66745 [01:38<00:16, 585.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56990/66745 [01:38<00:16, 585.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57049/66745 [01:38<00:16, 586.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57108/66745 [01:39<00:16, 584.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57167/66745 [01:39<00:16, 584.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57226/66745 [01:39<00:16, 585.04batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  86%|████▎| 57285/66745 [01:39<00:16, 584.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57344/66745 [01:39<00:16, 584.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57403/66745 [01:39<00:16, 576.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57461/66745 [01:39<00:16, 576.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57522/66745 [01:39<00:15, 586.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57581/66745 [01:39<00:15, 585.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57640/66745 [01:39<00:15, 584.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57699/66745 [01:40<00:15, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57758/66745 [01:40<00:15, 575.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57817/66745 [01:40<00:15, 579.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57876/66745 [01:40<00:15, 582.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57936/66745 [01:40<00:15, 585.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57995/66745 [01:40<00:14, 584.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58054/66745 [01:40<00:14, 584.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58113/66745 [01:40<00:14, 584.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58172/66745 [01:40<00:14, 584.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58231/66745 [01:40<00:14, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58290/66745 [01:41<00:14, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58349/66745 [01:41<00:14, 584.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58408/66745 [01:41<00:14, 584.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58467/66745 [01:41<00:14, 584.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58526/66745 [01:41<00:14, 584.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58585/66745 [01:41<00:13, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58644/66745 [01:41<00:13, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58703/66745 [01:41<00:13, 583.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58762/66745 [01:41<00:13, 583.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58821/66745 [01:41<00:13, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58880/66745 [01:42<00:13, 581.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58939/66745 [01:42<00:13, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58998/66745 [01:42<00:13, 584.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59057/66745 [01:42<00:13, 585.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59116/66745 [01:42<00:13, 585.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59175/66745 [01:42<00:12, 585.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59234/66745 [01:42<00:12, 586.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59293/66745 [01:42<00:12, 586.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59352/66745 [01:42<00:12, 587.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59411/66745 [01:42<00:12, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59470/66745 [01:43<00:12, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59529/66745 [01:43<00:12, 586.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59588/66745 [01:43<00:12, 587.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59647/66745 [01:43<00:12, 587.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59706/66745 [01:43<00:12, 583.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59765/66745 [01:43<00:12, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59824/66745 [01:43<00:11, 578.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59882/66745 [01:43<00:11, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59941/66745 [01:43<00:11, 579.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60000/66745 [01:44<00:11, 580.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60059/66745 [01:44<00:11, 580.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60118/66745 [01:44<00:11, 580.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60177/66745 [01:44<00:11, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60236/66745 [01:44<00:11, 581.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60295/66745 [01:44<00:11, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60354/66745 [01:44<00:11, 576.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60413/66745 [01:44<00:10, 577.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60471/66745 [01:44<00:10, 573.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60529/66745 [01:44<00:10, 568.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60588/66745 [01:45<00:10, 571.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60647/66745 [01:45<00:10, 574.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60706/66745 [01:45<00:10, 578.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60765/66745 [01:45<00:10, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60824/66745 [01:45<00:10, 583.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60883/66745 [01:45<00:10, 575.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60942/66745 [01:45<00:10, 578.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61003/66745 [01:45<00:09, 586.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61064/66745 [01:45<00:09, 592.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61124/66745 [01:45<00:09, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61183/66745 [01:46<00:09, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61242/66745 [01:46<00:09, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61299/66745 [01:46<00:09, 551.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61359/66745 [01:46<00:09, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61416/66745 [01:46<00:09, 562.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61473/66745 [01:46<00:09, 563.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61530/66745 [01:46<00:09, 556.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61587/66745 [01:46<00:09, 559.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61645/66745 [01:46<00:09, 564.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61703/66745 [01:46<00:08, 566.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61762/66745 [01:47<00:08, 571.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61820/66745 [01:47<00:08, 569.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61878/66745 [01:47<00:08, 570.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61937/66745 [01:47<00:08, 576.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61996/66745 [01:47<00:08, 580.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62055/66745 [01:47<00:08, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62114/66745 [01:47<00:07, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62173/66745 [01:47<00:07, 575.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62231/66745 [01:47<00:07, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62290/66745 [01:47<00:07, 576.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62349/66745 [01:48<00:07, 580.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62408/66745 [01:48<00:07, 582.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62467/66745 [01:48<00:07, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62525/66745 [01:48<00:07, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62584/66745 [01:48<00:07, 579.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62643/66745 [01:48<00:07, 581.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62702/66745 [01:48<00:06, 581.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62761/66745 [01:48<00:06, 581.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62820/66745 [01:48<00:06, 583.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62879/66745 [01:49<00:06, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62938/66745 [01:49<00:06, 582.04batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  94%|████▋| 62997/66745 [01:49<00:06, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63056/66745 [01:49<00:06, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63115/66745 [01:49<00:06, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63174/66745 [01:49<00:06, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63233/66745 [01:49<00:06, 583.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63292/66745 [01:49<00:05, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63351/66745 [01:49<00:05, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63410/66745 [01:49<00:05, 583.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63469/66745 [01:50<00:05, 583.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63528/66745 [01:50<00:05, 584.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63587/66745 [01:50<00:05, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63646/66745 [01:50<00:05, 584.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63705/66745 [01:50<00:05, 584.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63764/66745 [01:50<00:05, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63823/66745 [01:50<00:05, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63882/66745 [01:50<00:04, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63942/66745 [01:50<00:04, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64001/66745 [01:50<00:04, 586.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64060/66745 [01:51<00:04, 587.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64119/66745 [01:51<00:04, 588.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64178/66745 [01:51<00:04, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64237/66745 [01:51<00:04, 588.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64296/66745 [01:51<00:04, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64355/66745 [01:51<00:04, 571.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64413/66745 [01:51<00:04, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64470/66745 [01:51<00:04, 562.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64527/66745 [01:51<00:03, 559.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64587/66745 [01:51<00:03, 568.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64646/66745 [01:52<00:03, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64706/66745 [01:52<00:03, 579.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64765/66745 [01:52<00:03, 582.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64825/66745 [01:52<00:03, 585.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64885/66745 [01:52<00:03, 587.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64945/66745 [01:52<00:03, 588.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65005/66745 [01:52<00:02, 588.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65064/66745 [01:52<00:02, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65123/66745 [01:52<00:02, 578.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65182/66745 [01:52<00:02, 581.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65241/66745 [01:53<00:02, 582.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65300/66745 [01:53<00:02, 583.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65359/66745 [01:53<00:02, 583.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65418/66745 [01:53<00:02, 584.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65477/66745 [01:53<00:02, 585.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65536/66745 [01:53<00:02, 584.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65595/66745 [01:53<00:01, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65654/66745 [01:53<00:01, 584.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65713/66745 [01:53<00:01, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65772/66745 [01:53<00:01, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65831/66745 [01:54<00:01, 579.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65890/66745 [01:54<00:01, 580.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65949/66745 [01:54<00:01, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66008/66745 [01:54<00:01, 583.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66067/66745 [01:54<00:01, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66126/66745 [01:54<00:01, 584.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66185/66745 [01:54<00:00, 584.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66244/66745 [01:54<00:00, 584.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66303/66745 [01:54<00:00, 569.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66363/66745 [01:54<00:00, 576.44batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66421/66745 [01:55<00:00, 571.41batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66479/66745 [01:55<00:00, 569.54batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66537/66745 [01:55<00:00, 571.45batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66595/66745 [01:55<00:00, 565.55batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66652/66745 [01:55<00:00, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66708/66745 [01:55<00:00, 548.93batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   5%| | 5/100 [09:40<3:03:45, 116.06s/epoch, loss=0.3\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 18/66745 [00:00<06:15, 177.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 71/66745 [00:00<02:55, 380.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 128/66745 [00:00<02:23, 463.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 187/66745 [00:00<02:10, 510.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 247/66745 [00:00<02:03, 539.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 303/66745 [00:00<02:01, 544.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 360/66745 [00:00<02:00, 550.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 417/66745 [00:00<01:59, 554.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 474/66745 [00:00<01:58, 557.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 530/66745 [00:01<01:58, 557.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 587/66745 [00:01<01:58, 560.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 645/66745 [00:01<01:57, 563.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 703/66745 [00:01<01:56, 565.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 760/66745 [00:01<01:57, 563.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 817/66745 [00:01<01:56, 565.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 874/66745 [00:01<01:56, 565.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 931/66745 [00:01<01:57, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 988/66745 [00:01<01:56, 563.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1045/66745 [00:01<01:56, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1102/66745 [00:02<01:59, 548.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1158/66745 [00:02<01:59, 551.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1214/66745 [00:02<02:00, 543.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1272/66745 [00:02<01:58, 553.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1331/66745 [00:02<01:56, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1390/66745 [00:02<01:54, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1448/66745 [00:02<01:54, 571.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1506/66745 [00:02<01:53, 572.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1564/66745 [00:02<01:55, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1621/66745 [00:02<01:55, 563.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1678/66745 [00:03<01:55, 562.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1735/66745 [00:03<01:55, 564.32batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   3%|▏     | 1795/66745 [00:03<01:53, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1853/66745 [00:03<01:54, 567.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1910/66745 [00:03<01:54, 568.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1967/66745 [00:03<01:54, 566.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2026/66745 [00:03<01:53, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2084/66745 [00:03<01:52, 573.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2142/66745 [00:03<01:52, 573.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2201/66745 [00:03<01:51, 576.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2260/66745 [00:04<01:51, 578.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2318/66745 [00:04<01:52, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2376/66745 [00:04<01:54, 564.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2434/66745 [00:04<01:53, 568.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2492/66745 [00:04<01:52, 569.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2550/66745 [00:04<01:52, 571.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2608/66745 [00:04<01:52, 572.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2667/66745 [00:04<01:51, 576.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2725/66745 [00:04<01:51, 573.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2783/66745 [00:04<01:52, 569.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2840/66745 [00:05<01:52, 568.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2897/66745 [00:05<01:52, 566.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2956/66745 [00:05<01:51, 572.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3015/66745 [00:05<01:50, 576.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3074/66745 [00:05<01:50, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3133/66745 [00:05<01:49, 580.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3192/66745 [00:05<01:49, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3251/66745 [00:05<01:49, 582.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3310/66745 [00:05<01:48, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3369/66745 [00:06<01:50, 575.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3427/66745 [00:06<01:51, 568.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3484/66745 [00:06<01:52, 560.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3543/66745 [00:06<01:51, 567.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3602/66745 [00:06<01:50, 573.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3661/66745 [00:06<01:49, 578.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3720/66745 [00:06<01:48, 581.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3779/66745 [00:06<01:49, 575.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3837/66745 [00:06<01:50, 568.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3894/66745 [00:06<01:50, 567.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3951/66745 [00:07<01:52, 556.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4007/66745 [00:07<01:54, 546.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4063/66745 [00:07<01:53, 549.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4122/66745 [00:07<01:51, 559.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4179/66745 [00:07<01:52, 556.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4235/66745 [00:07<01:54, 545.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4292/66745 [00:07<01:53, 550.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4352/66745 [00:07<01:50, 563.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4409/66745 [00:07<01:52, 554.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4465/66745 [00:07<01:58, 527.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4519/66745 [00:08<02:01, 511.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4573/66745 [00:08<02:00, 517.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4630/66745 [00:08<01:57, 530.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4685/66745 [00:08<01:55, 535.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4744/66745 [00:08<01:52, 549.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4800/66745 [00:08<01:53, 545.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4855/66745 [00:08<01:54, 539.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4914/66745 [00:08<01:51, 552.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4971/66745 [00:08<01:50, 556.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5030/66745 [00:09<01:49, 564.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5087/66745 [00:09<01:49, 564.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5144/66745 [00:09<01:49, 564.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5201/66745 [00:09<01:51, 552.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5257/66745 [00:09<01:51, 550.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5314/66745 [00:09<01:50, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5371/66745 [00:09<01:50, 557.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5427/66745 [00:09<01:50, 557.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5483/66745 [00:09<01:50, 554.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5540/66745 [00:09<01:50, 556.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5597/66745 [00:10<01:49, 557.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5655/66745 [00:10<01:48, 562.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5714/66745 [00:10<01:47, 569.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5771/66745 [00:10<01:47, 567.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5828/66745 [00:10<01:47, 567.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5885/66745 [00:10<01:47, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5942/66745 [00:10<01:49, 556.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5998/66745 [00:10<01:51, 546.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6053/66745 [00:10<01:51, 544.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6110/66745 [00:10<01:50, 549.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6165/66745 [00:11<01:51, 541.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6221/66745 [00:11<01:51, 544.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6279/66745 [00:11<01:49, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6335/66745 [00:11<01:49, 553.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6391/66745 [00:11<01:48, 554.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6452/66745 [00:11<01:45, 569.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6512/66745 [00:11<01:44, 576.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6572/66745 [00:11<01:43, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6631/66745 [00:11<01:43, 578.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6691/66745 [00:11<01:42, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6752/66745 [00:12<01:41, 588.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6811/66745 [00:12<01:43, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6870/66745 [00:12<01:43, 578.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6928/66745 [00:12<01:45, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6985/66745 [00:12<01:47, 556.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7041/66745 [00:12<01:47, 553.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7099/66745 [00:12<01:46, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7156/66745 [00:12<01:45, 562.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7213/66745 [00:12<01:46, 558.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7274/66745 [00:12<01:44, 570.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7333/66745 [00:13<01:43, 575.94batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  11%|▋     | 7391/66745 [00:13<01:44, 569.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7448/66745 [00:13<01:44, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7507/66745 [00:13<01:43, 571.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7566/66745 [00:13<01:42, 575.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7625/66745 [00:13<01:42, 579.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7684/66745 [00:13<01:41, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7743/66745 [00:13<01:41, 582.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7802/66745 [00:13<01:41, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7861/66745 [00:14<01:41, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7920/66745 [00:14<01:41, 581.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7979/66745 [00:14<01:40, 582.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8038/66745 [00:14<01:42, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8096/66745 [00:14<01:42, 569.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8153/66745 [00:14<01:42, 569.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8210/66745 [00:14<01:42, 568.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8267/66745 [00:14<01:42, 568.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8324/66745 [00:14<01:42, 568.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8381/66745 [00:14<01:42, 568.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8438/66745 [00:15<01:42, 568.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8495/66745 [00:15<01:43, 562.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8552/66745 [00:15<01:46, 547.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8610/66745 [00:15<01:44, 555.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8668/66745 [00:15<01:43, 562.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8725/66745 [00:15<01:42, 563.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8783/66745 [00:15<01:42, 566.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8841/66745 [00:15<01:41, 569.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8900/66745 [00:15<01:40, 575.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8959/66745 [00:15<01:39, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9018/66745 [00:16<01:39, 581.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9079/66745 [00:16<01:37, 588.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9138/66745 [00:16<01:37, 589.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9197/66745 [00:16<01:40, 572.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9257/66745 [00:16<01:39, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9319/66745 [00:16<01:37, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9379/66745 [00:16<01:37, 589.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9441/66745 [00:16<01:36, 596.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9502/66745 [00:16<01:35, 597.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9563/66745 [00:16<01:35, 599.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9623/66745 [00:17<01:35, 599.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9683/66745 [00:17<01:35, 597.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9745/66745 [00:17<01:34, 601.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9806/66745 [00:17<01:35, 596.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9866/66745 [00:17<01:35, 592.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9926/66745 [00:17<01:36, 590.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9986/66745 [00:17<01:36, 589.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10045/66745 [00:17<01:36, 588.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10104/66745 [00:17<01:36, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10163/66745 [00:17<01:37, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10223/66745 [00:18<01:36, 584.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10283/66745 [00:18<01:36, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10342/66745 [00:18<01:36, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10401/66745 [00:18<01:36, 581.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10460/66745 [00:18<01:36, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10519/66745 [00:18<01:36, 583.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10578/66745 [00:18<01:36, 584.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10637/66745 [00:18<01:35, 584.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10696/66745 [00:18<01:35, 584.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10755/66745 [00:18<01:35, 585.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10814/66745 [00:19<01:36, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10872/66745 [00:19<01:36, 576.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10930/66745 [00:19<01:37, 574.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10989/66745 [00:19<01:36, 577.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11048/66745 [00:19<01:35, 581.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11108/66745 [00:19<01:35, 583.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11167/66745 [00:19<01:35, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11226/66745 [00:19<01:34, 584.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11285/66745 [00:19<01:34, 585.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11344/66745 [00:20<01:34, 586.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11403/66745 [00:20<01:34, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11462/66745 [00:20<01:34, 587.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11521/66745 [00:20<01:34, 582.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11580/66745 [00:20<01:38, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11636/66745 [00:20<01:40, 548.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11691/66745 [00:20<01:41, 541.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11750/66745 [00:20<01:39, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11809/66745 [00:20<01:37, 563.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11868/66745 [00:20<01:36, 570.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11927/66745 [00:21<01:35, 575.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11986/66745 [00:21<01:34, 578.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12045/66745 [00:21<01:34, 581.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12104/66745 [00:21<01:34, 578.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12162/66745 [00:21<01:34, 575.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12221/66745 [00:21<01:34, 579.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12280/66745 [00:21<01:33, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12339/66745 [00:21<01:33, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12398/66745 [00:21<01:33, 584.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12457/66745 [00:21<01:32, 584.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12516/66745 [00:22<01:32, 584.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12575/66745 [00:22<01:32, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12634/66745 [00:22<01:32, 585.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12693/66745 [00:22<01:32, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12752/66745 [00:22<01:33, 578.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12812/66745 [00:22<01:32, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12874/66745 [00:22<01:31, 590.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12935/66745 [00:22<01:30, 594.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12996/66745 [00:22<01:30, 596.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13056/66745 [00:22<01:30, 593.45batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  20%|▉    | 13116/66745 [00:23<01:31, 587.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13175/66745 [00:23<01:31, 586.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13235/66745 [00:23<01:31, 587.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13295/66745 [00:23<01:30, 588.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13354/66745 [00:23<01:31, 581.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13414/66745 [00:23<01:31, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13475/66745 [00:23<01:30, 588.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13535/66745 [00:23<01:30, 590.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13595/66745 [00:23<01:29, 590.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13656/66745 [00:23<01:29, 593.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13716/66745 [00:24<01:29, 591.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13776/66745 [00:24<01:29, 589.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13835/66745 [00:24<01:29, 588.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13894/66745 [00:24<01:30, 586.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13953/66745 [00:24<01:31, 578.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14014/66745 [00:24<01:29, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14073/66745 [00:24<01:30, 581.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14132/66745 [00:24<01:30, 583.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14191/66745 [00:24<01:29, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14250/66745 [00:25<01:29, 585.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14309/66745 [00:25<01:30, 580.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14368/66745 [00:25<01:29, 582.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14427/66745 [00:25<01:29, 583.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14486/66745 [00:25<01:29, 584.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14545/66745 [00:25<01:30, 577.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14606/66745 [00:25<01:29, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14666/66745 [00:25<01:28, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14725/66745 [00:25<01:28, 588.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14786/66745 [00:25<01:27, 591.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14846/66745 [00:26<01:27, 593.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14906/66745 [00:26<01:27, 590.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14967/66745 [00:26<01:27, 594.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15028/66745 [00:26<01:26, 597.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15088/66745 [00:26<01:27, 592.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15148/66745 [00:26<01:28, 584.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15209/66745 [00:26<01:27, 589.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15269/66745 [00:26<01:26, 592.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15331/66745 [00:26<01:25, 598.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15393/66745 [00:26<01:25, 602.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15455/66745 [00:27<01:24, 604.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15517/66745 [00:27<01:24, 606.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15579/66745 [00:27<01:24, 607.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15640/66745 [00:27<01:24, 603.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15701/66745 [00:27<01:25, 599.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15761/66745 [00:27<01:27, 582.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15820/66745 [00:27<01:28, 578.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15879/66745 [00:27<01:27, 581.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15938/66745 [00:27<01:27, 583.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15997/66745 [00:27<01:26, 584.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16056/66745 [00:28<01:26, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16115/66745 [00:28<01:26, 585.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16174/66745 [00:28<01:26, 585.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16233/66745 [00:28<01:26, 580.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16293/66745 [00:28<01:26, 585.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16352/66745 [00:28<01:26, 584.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16413/66745 [00:28<01:25, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16473/66745 [00:28<01:24, 592.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16533/66745 [00:28<01:24, 594.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16593/66745 [00:28<01:24, 594.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16653/66745 [00:29<01:26, 579.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16712/66745 [00:29<01:27, 571.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16771/66745 [00:29<01:26, 577.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16831/66745 [00:29<01:25, 582.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16890/66745 [00:29<01:26, 576.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16950/66745 [00:29<01:25, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 17010/66745 [00:29<01:24, 585.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17069/66745 [00:29<01:26, 574.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17127/66745 [00:29<01:26, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17187/66745 [00:30<01:25, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17246/66745 [00:30<01:24, 582.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17305/66745 [00:30<01:25, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17363/66745 [00:30<01:26, 569.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17422/66745 [00:30<01:25, 574.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17480/66745 [00:30<01:26, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17539/66745 [00:30<01:25, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17597/66745 [00:30<01:27, 560.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17656/66745 [00:30<01:26, 567.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17715/66745 [00:30<01:25, 573.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17775/66745 [00:31<01:24, 579.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17834/66745 [00:31<01:26, 563.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17891/66745 [00:31<01:27, 558.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17951/66745 [00:31<01:25, 568.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18010/66745 [00:31<01:24, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18068/66745 [00:31<01:25, 572.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18126/66745 [00:31<01:25, 567.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18184/66745 [00:31<01:25, 570.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18242/66745 [00:31<01:24, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18300/66745 [00:31<01:24, 574.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18358/66745 [00:32<01:26, 558.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18416/66745 [00:32<01:25, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18473/66745 [00:32<01:25, 565.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18532/66745 [00:32<01:24, 571.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18592/66745 [00:32<01:23, 576.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18650/66745 [00:32<01:24, 572.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18708/66745 [00:32<01:25, 562.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18769/66745 [00:32<01:23, 574.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18827/66745 [00:32<01:24, 569.04batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  28%|█▍   | 18884/66745 [00:32<01:24, 564.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18941/66745 [00:33<01:25, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 19000/66745 [00:33<01:24, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19059/66745 [00:33<01:23, 570.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19118/66745 [00:33<01:23, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19177/66745 [00:33<01:22, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19236/66745 [00:33<01:22, 577.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19295/66745 [00:33<01:21, 579.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19354/66745 [00:33<01:21, 579.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19413/66745 [00:33<01:21, 580.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19472/66745 [00:34<01:21, 580.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19531/66745 [00:34<01:21, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19590/66745 [00:34<01:21, 581.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19650/66745 [00:34<01:20, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19709/66745 [00:34<01:20, 583.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19768/66745 [00:34<01:21, 573.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19827/66745 [00:34<01:21, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19885/66745 [00:34<01:21, 572.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19944/66745 [00:34<01:21, 574.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 20002/66745 [00:34<01:21, 574.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20060/66745 [00:35<01:21, 575.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20118/66745 [00:35<01:21, 569.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20176/66745 [00:35<01:21, 570.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20234/66745 [00:35<01:22, 565.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20293/66745 [00:35<01:21, 570.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20353/66745 [00:35<01:20, 577.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20413/66745 [00:35<01:19, 581.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20473/66745 [00:35<01:19, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20532/66745 [00:35<01:19, 583.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20591/66745 [00:35<01:19, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20650/66745 [00:36<01:19, 582.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20709/66745 [00:36<01:18, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20768/66745 [00:36<01:19, 581.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20827/66745 [00:36<01:18, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20886/66745 [00:36<01:18, 581.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20945/66745 [00:36<01:19, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 21003/66745 [00:36<01:19, 572.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21061/66745 [00:36<01:20, 570.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21120/66745 [00:36<01:19, 573.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21179/66745 [00:36<01:19, 576.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21238/66745 [00:37<01:18, 577.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21296/66745 [00:37<01:19, 574.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21354/66745 [00:37<01:18, 575.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21413/66745 [00:37<01:18, 578.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21472/66745 [00:37<01:17, 581.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21531/66745 [00:37<01:17, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21590/66745 [00:37<01:18, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21650/66745 [00:37<01:17, 578.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21708/66745 [00:37<01:18, 570.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21766/66745 [00:37<01:19, 569.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21826/66745 [00:38<01:17, 576.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21885/66745 [00:38<01:17, 577.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21943/66745 [00:38<01:17, 578.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22002/66745 [00:38<01:17, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22061/66745 [00:38<01:16, 580.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22120/66745 [00:38<01:16, 580.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22179/66745 [00:38<01:17, 574.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22238/66745 [00:38<01:17, 577.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22298/66745 [00:38<01:16, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22358/66745 [00:38<01:15, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22417/66745 [00:39<01:15, 585.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22477/66745 [00:39<01:15, 587.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22536/66745 [00:39<01:17, 571.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22595/66745 [00:39<01:16, 574.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22654/66745 [00:39<01:16, 576.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22713/66745 [00:39<01:16, 578.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22771/66745 [00:39<01:16, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22829/66745 [00:39<01:16, 573.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22889/66745 [00:39<01:15, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22948/66745 [00:40<01:15, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 23008/66745 [00:40<01:14, 584.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23068/66745 [00:40<01:14, 586.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23127/66745 [00:40<01:14, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23186/66745 [00:40<01:14, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23246/66745 [00:40<01:13, 588.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23306/66745 [00:40<01:13, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23365/66745 [00:40<01:13, 588.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23424/66745 [00:40<01:13, 588.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23483/66745 [00:40<01:13, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23542/66745 [00:41<01:14, 583.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23601/66745 [00:41<01:13, 585.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23660/66745 [00:41<01:13, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23719/66745 [00:41<01:13, 587.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23778/66745 [00:41<01:13, 587.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23837/66745 [00:41<01:12, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23896/66745 [00:41<01:12, 588.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23955/66745 [00:41<01:13, 583.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24014/66745 [00:41<01:13, 585.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24073/66745 [00:41<01:12, 586.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24133/66745 [00:42<01:12, 587.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24193/66745 [00:42<01:12, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24253/66745 [00:42<01:12, 589.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24312/66745 [00:42<01:12, 588.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24372/66745 [00:42<01:11, 589.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24431/66745 [00:42<01:12, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24491/66745 [00:42<01:12, 585.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24550/66745 [00:42<01:11, 586.37batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  37%|█▊   | 24609/66745 [00:42<01:11, 587.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24668/66745 [00:42<01:12, 583.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24728/66745 [00:43<01:11, 585.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24788/66745 [00:43<01:11, 587.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24848/66745 [00:43<01:11, 588.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24907/66745 [00:43<01:11, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24967/66745 [00:43<01:11, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 25026/66745 [00:43<01:11, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25086/66745 [00:43<01:11, 585.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25145/66745 [00:43<01:10, 586.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25205/66745 [00:43<01:10, 587.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25264/66745 [00:43<01:11, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25324/66745 [00:44<01:10, 586.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25384/66745 [00:44<01:10, 587.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25443/66745 [00:44<01:10, 583.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25502/66745 [00:44<01:11, 580.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25561/66745 [00:44<01:10, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25620/66745 [00:44<01:10, 579.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25679/66745 [00:44<01:10, 582.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25738/66745 [00:44<01:10, 584.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25797/66745 [00:44<01:09, 585.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25856/66745 [00:44<01:09, 586.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25915/66745 [00:45<01:09, 587.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25974/66745 [00:45<01:09, 587.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26033/66745 [00:45<01:09, 588.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26093/66745 [00:45<01:09, 589.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26152/66745 [00:45<01:08, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26211/66745 [00:45<01:08, 589.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26270/66745 [00:45<01:08, 589.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26329/66745 [00:45<01:08, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26388/66745 [00:45<01:08, 588.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26447/66745 [00:45<01:08, 588.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26506/66745 [00:46<01:08, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26565/66745 [00:46<01:08, 589.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26624/66745 [00:46<01:08, 589.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26683/66745 [00:46<01:08, 588.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26742/66745 [00:46<01:08, 584.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26801/66745 [00:46<01:08, 579.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26861/66745 [00:46<01:08, 583.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26920/66745 [00:46<01:09, 573.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26978/66745 [00:46<01:09, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27036/66745 [00:47<01:09, 568.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27096/66745 [00:47<01:08, 575.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27154/66745 [00:47<01:08, 575.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27212/66745 [00:47<01:09, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27270/66745 [00:47<01:09, 569.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27327/66745 [00:47<01:10, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27385/66745 [00:47<01:09, 563.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27445/66745 [00:47<01:08, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27503/66745 [00:47<01:08, 572.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27562/66745 [00:47<01:08, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27621/66745 [00:48<01:07, 577.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27679/66745 [00:48<01:08, 574.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27737/66745 [00:48<01:08, 572.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27796/66745 [00:48<01:07, 576.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27854/66745 [00:48<01:07, 576.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27912/66745 [00:48<01:07, 576.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27973/66745 [00:48<01:06, 586.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28035/66745 [00:48<01:05, 593.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28095/66745 [00:48<01:05, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28155/66745 [00:48<01:05, 589.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28214/66745 [00:49<01:05, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28273/66745 [00:49<01:06, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28332/66745 [00:49<01:06, 576.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28390/66745 [00:49<01:06, 573.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28448/66745 [00:49<01:06, 572.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28507/66745 [00:49<01:06, 575.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28566/66745 [00:49<01:06, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28625/66745 [00:49<01:05, 580.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28684/66745 [00:49<01:05, 580.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28743/66745 [00:49<01:05, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28803/66745 [00:50<01:04, 584.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28865/66745 [00:50<01:03, 592.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28925/66745 [00:50<01:04, 590.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28986/66745 [00:50<01:03, 596.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29046/66745 [00:50<01:03, 595.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29106/66745 [00:50<01:03, 594.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29168/66745 [00:50<01:02, 599.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29230/66745 [00:50<01:02, 602.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29291/66745 [00:50<01:03, 590.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29351/66745 [00:50<01:04, 580.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29410/66745 [00:51<01:04, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29468/66745 [00:51<01:04, 577.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29528/66745 [00:51<01:04, 581.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29587/66745 [00:51<01:04, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29648/66745 [00:51<01:03, 580.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29710/66745 [00:51<01:02, 589.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29771/66745 [00:51<01:02, 593.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29831/66745 [00:51<01:02, 591.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29891/66745 [00:51<01:02, 590.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29951/66745 [00:52<01:02, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 30011/66745 [00:52<01:02, 590.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30071/66745 [00:52<01:01, 591.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30131/66745 [00:52<01:01, 592.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30191/66745 [00:52<01:01, 594.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30252/66745 [00:52<01:00, 599.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30312/66745 [00:52<01:01, 596.83batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  46%|██▎  | 30372/66745 [00:52<01:01, 592.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30433/66745 [00:52<01:00, 595.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30493/66745 [00:52<01:01, 585.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30552/66745 [00:53<01:01, 585.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30612/66745 [00:53<01:01, 588.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30672/66745 [00:53<01:01, 590.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30732/66745 [00:53<01:00, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30794/66745 [00:53<01:00, 597.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30854/66745 [00:53<01:00, 598.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30914/66745 [00:53<01:00, 594.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30974/66745 [00:53<01:00, 591.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 31034/66745 [00:53<01:00, 590.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31094/66745 [00:53<01:01, 583.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31153/66745 [00:54<01:00, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31213/66745 [00:54<01:00, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31273/66745 [00:54<01:00, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31335/66745 [00:54<00:59, 596.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31396/66745 [00:54<00:59, 597.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31456/66745 [00:54<00:59, 589.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31515/66745 [00:54<01:00, 586.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31575/66745 [00:54<00:59, 588.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31635/66745 [00:54<00:59, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31695/66745 [00:54<00:59, 585.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31754/66745 [00:55<00:59, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31813/66745 [00:55<01:00, 579.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31871/66745 [00:55<01:00, 573.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31931/66745 [00:55<01:00, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31989/66745 [00:55<01:00, 575.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32051/66745 [00:55<00:59, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32113/66745 [00:55<00:58, 593.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32173/66745 [00:55<00:58, 588.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32232/66745 [00:55<00:59, 577.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32292/66745 [00:55<00:59, 581.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32352/66745 [00:56<00:58, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32411/66745 [00:56<00:58, 585.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32470/66745 [00:56<00:58, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32530/66745 [00:56<00:58, 586.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32589/66745 [00:56<00:58, 583.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32649/66745 [00:56<00:58, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32708/66745 [00:56<00:57, 586.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32768/66745 [00:56<00:57, 589.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32827/66745 [00:56<00:57, 585.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32887/66745 [00:57<00:57, 588.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32947/66745 [00:57<00:57, 588.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 33007/66745 [00:57<00:57, 590.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33067/66745 [00:57<00:56, 591.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33127/66745 [00:57<00:57, 588.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33186/66745 [00:57<00:57, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33245/66745 [00:57<00:57, 585.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33305/66745 [00:57<00:56, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33365/66745 [00:57<00:56, 590.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33425/66745 [00:57<00:56, 591.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33485/66745 [00:58<00:56, 592.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33545/66745 [00:58<00:56, 592.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33605/66745 [00:58<00:56, 587.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33664/66745 [00:58<00:57, 578.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33722/66745 [00:58<00:57, 570.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33781/66745 [00:58<00:57, 574.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33839/66745 [00:58<00:57, 574.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33897/66745 [00:58<00:57, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33957/66745 [00:58<00:56, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34017/66745 [00:58<00:55, 585.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34077/66745 [00:59<00:55, 587.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34137/66745 [00:59<00:55, 589.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34197/66745 [00:59<00:55, 590.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34257/66745 [00:59<00:54, 592.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34317/66745 [00:59<00:54, 593.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34377/66745 [00:59<00:54, 588.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34437/66745 [00:59<00:54, 589.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34497/66745 [00:59<00:54, 591.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34557/66745 [00:59<00:54, 591.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34617/66745 [00:59<00:54, 592.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34677/66745 [01:00<00:54, 589.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34736/66745 [01:00<00:55, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34797/66745 [01:00<00:54, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34858/66745 [01:00<00:53, 592.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34918/66745 [01:00<00:54, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34977/66745 [01:00<00:54, 587.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 35036/66745 [01:00<00:53, 588.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35095/66745 [01:00<00:53, 587.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35154/66745 [01:00<00:53, 586.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35214/66745 [01:00<00:53, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35274/66745 [01:01<00:54, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35334/66745 [01:01<00:53, 582.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35393/66745 [01:01<00:53, 583.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35452/66745 [01:01<00:53, 581.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35511/66745 [01:01<00:55, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35568/66745 [01:01<00:55, 562.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35625/66745 [01:01<00:55, 555.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35684/66745 [01:01<00:54, 565.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35744/66745 [01:01<00:54, 573.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35804/66745 [01:01<00:53, 578.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35862/66745 [01:02<00:53, 573.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35921/66745 [01:02<00:53, 578.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35981/66745 [01:02<00:52, 582.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36040/66745 [01:02<00:52, 584.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36100/66745 [01:02<00:52, 586.23batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  54%|██▋  | 36159/66745 [01:02<00:52, 583.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36218/66745 [01:02<00:53, 573.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36277/66745 [01:02<00:52, 578.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36336/66745 [01:02<00:52, 579.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36396/66745 [01:03<00:52, 583.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36455/66745 [01:03<00:52, 576.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36514/66745 [01:03<00:52, 580.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36573/66745 [01:03<00:51, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36632/66745 [01:03<00:51, 585.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36691/66745 [01:03<00:51, 583.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36751/66745 [01:03<00:51, 585.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36810/66745 [01:03<00:51, 584.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36869/66745 [01:03<00:50, 586.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36928/66745 [01:03<00:51, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36986/66745 [01:04<00:52, 563.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37043/66745 [01:04<00:53, 551.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37099/66745 [01:04<00:54, 548.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37158/66745 [01:04<00:52, 560.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37218/66745 [01:04<00:51, 569.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37276/66745 [01:04<00:51, 572.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37334/66745 [01:04<00:51, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37392/66745 [01:04<00:51, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37452/66745 [01:04<00:50, 576.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37512/66745 [01:04<00:50, 580.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37571/66745 [01:05<00:50, 580.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37630/66745 [01:05<00:50, 573.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37690/66745 [01:05<00:50, 580.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37750/66745 [01:05<00:49, 584.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37809/66745 [01:05<00:50, 571.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37867/66745 [01:05<00:51, 561.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37924/66745 [01:05<00:51, 559.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37983/66745 [01:05<00:50, 566.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38044/66745 [01:05<00:49, 576.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38102/66745 [01:05<00:50, 571.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38161/66745 [01:06<00:49, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38220/66745 [01:06<00:49, 578.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38279/66745 [01:06<00:48, 581.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38338/66745 [01:06<00:49, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38396/66745 [01:06<00:49, 577.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38455/66745 [01:06<00:48, 580.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38514/66745 [01:06<00:48, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38573/66745 [01:06<00:48, 580.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38632/66745 [01:06<00:48, 576.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38690/66745 [01:07<00:49, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38748/66745 [01:07<00:48, 573.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38807/66745 [01:07<00:48, 577.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38866/66745 [01:07<00:48, 580.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38925/66745 [01:07<00:48, 579.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38985/66745 [01:07<00:47, 583.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 39045/66745 [01:07<00:47, 585.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39104/66745 [01:07<00:47, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39163/66745 [01:07<00:47, 584.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39222/66745 [01:07<00:46, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39282/66745 [01:08<00:46, 587.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39341/66745 [01:08<00:46, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39400/66745 [01:08<00:46, 588.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39459/66745 [01:08<00:46, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39519/66745 [01:08<00:46, 586.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39579/66745 [01:08<00:46, 588.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39638/66745 [01:08<00:46, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39698/66745 [01:08<00:45, 588.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39757/66745 [01:08<00:45, 588.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39817/66745 [01:08<00:45, 589.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39877/66745 [01:09<00:45, 590.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39937/66745 [01:09<00:45, 590.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39997/66745 [01:09<00:45, 584.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40057/66745 [01:09<00:45, 586.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40116/66745 [01:09<00:45, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40176/66745 [01:09<00:45, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40236/66745 [01:09<00:45, 587.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40296/66745 [01:09<00:44, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40356/66745 [01:09<00:44, 589.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40415/66745 [01:09<00:44, 589.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40475/66745 [01:10<00:44, 589.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40535/66745 [01:10<00:44, 589.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40594/66745 [01:10<00:44, 589.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40654/66745 [01:10<00:44, 589.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40714/66745 [01:10<00:44, 589.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40774/66745 [01:10<00:44, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40834/66745 [01:10<00:44, 579.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40892/66745 [01:10<00:45, 566.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40949/66745 [01:10<00:46, 554.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41005/66745 [01:10<00:46, 555.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41067/66745 [01:11<00:44, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41128/66745 [01:11<00:44, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41187/66745 [01:11<00:44, 578.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41246/66745 [01:11<00:43, 580.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41305/66745 [01:11<00:44, 576.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41364/66745 [01:11<00:43, 578.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41423/66745 [01:11<00:43, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41482/66745 [01:11<00:43, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41541/66745 [01:11<00:43, 582.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41600/66745 [01:11<00:43, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41659/66745 [01:12<00:43, 583.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41718/66745 [01:12<00:42, 583.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41777/66745 [01:12<00:43, 576.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41839/66745 [01:12<00:42, 586.37batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  63%|███▏ | 41901/66745 [01:12<00:41, 593.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41962/66745 [01:12<00:41, 597.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42022/66745 [01:12<00:41, 596.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42084/66745 [01:12<00:41, 601.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42145/66745 [01:12<00:41, 595.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42205/66745 [01:13<00:42, 577.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42264/66745 [01:13<00:42, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42323/66745 [01:13<00:42, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42382/66745 [01:13<00:41, 582.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42441/66745 [01:13<00:41, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42501/66745 [01:13<00:41, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42560/66745 [01:13<00:41, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42619/66745 [01:13<00:41, 587.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42678/66745 [01:13<00:40, 587.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42737/66745 [01:13<00:40, 585.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42796/66745 [01:14<00:40, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42855/66745 [01:14<00:40, 586.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42914/66745 [01:14<00:40, 587.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42974/66745 [01:14<00:40, 587.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43034/66745 [01:14<00:40, 590.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43095/66745 [01:14<00:39, 593.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43157/66745 [01:14<00:39, 599.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43217/66745 [01:14<00:39, 598.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43277/66745 [01:14<00:39, 596.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43337/66745 [01:14<00:39, 593.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43397/66745 [01:15<00:39, 592.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43457/66745 [01:15<00:39, 589.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43516/66745 [01:15<00:39, 583.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43576/66745 [01:15<00:39, 587.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43636/66745 [01:15<00:39, 590.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43698/66745 [01:15<00:38, 596.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43760/66745 [01:15<00:38, 601.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43821/66745 [01:15<00:38, 596.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43881/66745 [01:15<00:38, 593.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43941/66745 [01:15<00:38, 590.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44001/66745 [01:16<00:38, 591.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44061/66745 [01:16<00:38, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44121/66745 [01:16<00:38, 584.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44180/66745 [01:16<00:39, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44240/66745 [01:16<00:38, 580.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44299/66745 [01:16<00:38, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44357/66745 [01:16<00:38, 575.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44418/66745 [01:16<00:38, 584.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44477/66745 [01:16<00:38, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44536/66745 [01:16<00:38, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44596/66745 [01:17<00:37, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44655/66745 [01:17<00:37, 587.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44714/66745 [01:17<00:37, 586.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44773/66745 [01:17<00:37, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44832/66745 [01:17<00:37, 585.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44891/66745 [01:17<00:37, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 44950/66745 [01:17<00:37, 585.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███▎ | 45009/66745 [01:17<00:37, 585.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45068/66745 [01:17<00:37, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45127/66745 [01:17<00:36, 586.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45187/66745 [01:18<00:36, 588.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45249/66745 [01:18<00:36, 595.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45309/66745 [01:18<00:36, 588.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45370/66745 [01:18<00:35, 593.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45432/66745 [01:18<00:35, 599.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45492/66745 [01:18<00:35, 598.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45552/66745 [01:18<00:35, 595.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45612/66745 [01:18<00:35, 595.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|███▍ | 45672/66745 [01:18<00:35, 594.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45732/66745 [01:19<00:35, 592.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45792/66745 [01:19<00:35, 592.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45852/66745 [01:19<00:35, 591.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45912/66745 [01:19<00:35, 590.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 45972/66745 [01:19<00:35, 588.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46031/66745 [01:19<00:35, 588.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46090/66745 [01:19<00:35, 587.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46149/66745 [01:19<00:35, 586.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46208/66745 [01:19<00:35, 586.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46267/66745 [01:19<00:35, 584.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46327/66745 [01:20<00:34, 586.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|███▍ | 46386/66745 [01:20<00:34, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46446/66745 [01:20<00:34, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46505/66745 [01:20<00:34, 585.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46564/66745 [01:20<00:34, 584.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46624/66745 [01:20<00:34, 587.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▍ | 46684/66745 [01:20<00:34, 589.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46743/66745 [01:20<00:34, 588.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46803/66745 [01:20<00:33, 589.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46862/66745 [01:20<00:33, 588.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46921/66745 [01:21<00:34, 579.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 46979/66745 [01:21<00:34, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|███▌ | 47039/66745 [01:21<00:33, 583.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47098/66745 [01:21<00:33, 584.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47157/66745 [01:21<00:33, 581.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47217/66745 [01:21<00:33, 585.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47277/66745 [01:21<00:33, 588.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47338/66745 [01:21<00:32, 591.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47398/66745 [01:21<00:32, 592.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47458/66745 [01:21<00:32, 587.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47517/66745 [01:22<00:33, 575.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47575/66745 [01:22<00:33, 575.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|███▌ | 47633/66745 [01:22<00:33, 569.67batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  71%|███▌ | 47690/66745 [01:22<00:33, 567.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47749/66745 [01:22<00:33, 572.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47809/66745 [01:22<00:32, 578.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47869/66745 [01:22<00:32, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47928/66745 [01:22<00:32, 584.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 47988/66745 [01:22<00:31, 587.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48047/66745 [01:22<00:31, 586.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48106/66745 [01:23<00:31, 585.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48165/66745 [01:23<00:32, 576.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48224/66745 [01:23<00:31, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48282/66745 [01:23<00:31, 578.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|███▌ | 48340/66745 [01:23<00:31, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48402/66745 [01:23<00:31, 587.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48463/66745 [01:23<00:30, 594.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48523/66745 [01:23<00:30, 591.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48583/66745 [01:23<00:30, 589.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48642/66745 [01:23<00:30, 587.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48701/66745 [01:24<00:30, 588.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48760/66745 [01:24<00:30, 582.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48819/66745 [01:24<00:30, 582.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48878/66745 [01:24<00:30, 581.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48937/66745 [01:24<00:30, 581.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|███▋ | 48997/66745 [01:24<00:30, 584.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49058/66745 [01:24<00:29, 589.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49118/66745 [01:24<00:29, 590.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49178/66745 [01:24<00:29, 591.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49238/66745 [01:25<00:29, 587.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49298/66745 [01:25<00:29, 588.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49358/66745 [01:25<00:29, 590.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49418/66745 [01:25<00:29, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49478/66745 [01:25<00:29, 588.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49538/66745 [01:25<00:29, 589.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49598/66745 [01:25<00:29, 590.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49658/66745 [01:25<00:28, 592.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|███▋ | 49718/66745 [01:25<00:28, 591.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49778/66745 [01:25<00:28, 591.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49838/66745 [01:26<00:28, 591.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49898/66745 [01:26<00:28, 592.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 49958/66745 [01:26<00:28, 592.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▋ | 50018/66745 [01:26<00:28, 593.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50078/66745 [01:26<00:28, 593.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50138/66745 [01:26<00:27, 593.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50198/66745 [01:26<00:27, 594.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50258/66745 [01:26<00:27, 594.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50318/66745 [01:26<00:27, 594.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|███▊ | 50378/66745 [01:26<00:27, 593.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50438/66745 [01:27<00:27, 593.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50498/66745 [01:27<00:27, 593.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50558/66745 [01:27<00:27, 592.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50618/66745 [01:27<00:27, 594.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50678/66745 [01:27<00:27, 588.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50737/66745 [01:27<00:27, 586.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50796/66745 [01:27<00:27, 580.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50855/66745 [01:27<00:27, 581.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50914/66745 [01:27<00:27, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 50973/66745 [01:27<00:27, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███▊ | 51032/66745 [01:28<00:26, 583.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51091/66745 [01:28<00:26, 582.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51150/66745 [01:28<00:27, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51209/66745 [01:28<00:27, 571.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51268/66745 [01:28<00:26, 575.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51326/66745 [01:28<00:26, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51385/66745 [01:28<00:26, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51443/66745 [01:28<00:26, 577.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51503/66745 [01:28<00:26, 582.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51563/66745 [01:28<00:25, 585.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51623/66745 [01:29<00:25, 587.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███▊ | 51682/66745 [01:29<00:25, 586.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51741/66745 [01:29<00:25, 584.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51801/66745 [01:29<00:25, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51861/66745 [01:29<00:25, 588.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51920/66745 [01:29<00:25, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 51979/66745 [01:29<00:25, 585.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52038/66745 [01:29<00:25, 584.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52097/66745 [01:29<00:25, 584.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52156/66745 [01:29<00:24, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52215/66745 [01:30<00:24, 584.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52274/66745 [01:30<00:24, 584.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52333/66745 [01:30<00:25, 569.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███▉ | 52391/66745 [01:30<00:25, 569.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52449/66745 [01:30<00:25, 570.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52507/66745 [01:30<00:24, 571.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52565/66745 [01:30<00:24, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52623/66745 [01:30<00:24, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52681/66745 [01:30<00:24, 568.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52738/66745 [01:31<00:24, 562.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52795/66745 [01:31<00:24, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52851/66745 [01:31<00:25, 552.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52907/66745 [01:31<00:25, 552.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 52963/66745 [01:31<00:25, 548.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███▉ | 53018/66745 [01:31<00:25, 546.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53073/66745 [01:31<00:25, 544.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53130/66745 [01:31<00:24, 551.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53189/66745 [01:31<00:24, 561.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53248/66745 [01:31<00:23, 568.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53307/66745 [01:32<00:23, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███▉ | 53367/66745 [01:32<00:23, 579.97batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  80%|████ | 53428/66745 [01:32<00:22, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53487/66745 [01:32<00:22, 581.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53546/66745 [01:32<00:23, 570.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53604/66745 [01:32<00:23, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53662/66745 [01:32<00:23, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████ | 53720/66745 [01:32<00:22, 569.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53778/66745 [01:32<00:22, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53836/66745 [01:32<00:22, 562.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53893/66745 [01:33<00:23, 550.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 53949/66745 [01:33<00:23, 545.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54004/66745 [01:33<00:23, 542.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54059/66745 [01:33<00:23, 543.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54114/66745 [01:33<00:23, 526.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54167/66745 [01:33<00:23, 525.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54220/66745 [01:33<00:23, 526.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54275/66745 [01:33<00:23, 531.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54330/66745 [01:33<00:23, 535.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████ | 54384/66745 [01:33<00:23, 535.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54438/66745 [01:34<00:23, 530.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54492/66745 [01:34<00:23, 532.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54551/66745 [01:34<00:22, 547.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54610/66745 [01:34<00:21, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54669/66745 [01:34<00:21, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54728/66745 [01:34<00:21, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54786/66745 [01:34<00:20, 573.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54845/66745 [01:34<00:20, 576.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54904/66745 [01:34<00:20, 577.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 54963/66745 [01:35<00:20, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████ | 55022/66745 [01:35<00:20, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55081/66745 [01:35<00:20, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55140/66745 [01:35<00:19, 581.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55199/66745 [01:35<00:19, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55258/66745 [01:35<00:19, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55317/66745 [01:35<00:19, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55376/66745 [01:35<00:19, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55435/66745 [01:35<00:19, 581.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55494/66745 [01:35<00:19, 581.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55553/66745 [01:36<00:19, 581.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55612/66745 [01:36<00:19, 581.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55671/66745 [01:36<00:19, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████▏| 55730/66745 [01:36<00:19, 576.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55789/66745 [01:36<00:18, 578.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55848/66745 [01:36<00:18, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55907/66745 [01:36<00:18, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 55966/66745 [01:36<00:18, 580.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56025/66745 [01:36<00:18, 581.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56084/66745 [01:36<00:18, 582.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56143/66745 [01:37<00:18, 584.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56202/66745 [01:37<00:18, 579.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56261/66745 [01:37<00:18, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56320/66745 [01:37<00:17, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|████▏| 56379/66745 [01:37<00:17, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56439/66745 [01:37<00:17, 588.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56499/66745 [01:37<00:17, 591.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56559/66745 [01:37<00:17, 590.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56619/66745 [01:37<00:17, 582.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▏| 56678/66745 [01:37<00:17, 570.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56736/66745 [01:38<00:17, 569.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56795/66745 [01:38<00:17, 573.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56854/66745 [01:38<00:17, 576.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56913/66745 [01:38<00:16, 578.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 56972/66745 [01:38<00:16, 579.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|████▎| 57031/66745 [01:38<00:16, 580.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57090/66745 [01:38<00:16, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57149/66745 [01:38<00:16, 581.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57208/66745 [01:38<00:16, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57267/66745 [01:38<00:16, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57326/66745 [01:39<00:16, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57384/66745 [01:39<00:16, 575.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57444/66745 [01:39<00:16, 581.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57505/66745 [01:39<00:15, 588.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57565/66745 [01:39<00:15, 590.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57625/66745 [01:39<00:15, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|████▎| 57685/66745 [01:39<00:15, 591.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57745/66745 [01:39<00:15, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57804/66745 [01:39<00:15, 586.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57863/66745 [01:39<00:15, 585.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57922/66745 [01:40<00:15, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 57981/66745 [01:40<00:15, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58039/66745 [01:40<00:15, 570.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58098/66745 [01:40<00:15, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58156/66745 [01:40<00:15, 567.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58215/66745 [01:40<00:14, 573.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58274/66745 [01:40<00:14, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58333/66745 [01:40<00:14, 580.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|████▎| 58392/66745 [01:40<00:14, 582.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58451/66745 [01:41<00:14, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58510/66745 [01:41<00:14, 582.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58569/66745 [01:41<00:14, 579.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58627/66745 [01:41<00:14, 577.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58688/66745 [01:41<00:13, 585.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58747/66745 [01:41<00:13, 586.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58806/66745 [01:41<00:13, 587.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58865/66745 [01:41<00:13, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58924/66745 [01:41<00:13, 584.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 58983/66745 [01:41<00:13, 582.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|████▍| 59042/66745 [01:42<00:13, 581.97batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  89%|████▍| 59101/66745 [01:42<00:13, 583.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59160/66745 [01:42<00:12, 583.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59219/66745 [01:42<00:13, 576.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59277/66745 [01:42<00:13, 569.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59336/66745 [01:42<00:12, 575.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59396/66745 [01:42<00:12, 579.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59455/66745 [01:42<00:12, 582.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59514/66745 [01:42<00:12, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59573/66745 [01:42<00:12, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59633/66745 [01:43<00:12, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|████▍| 59693/66745 [01:43<00:12, 586.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59752/66745 [01:43<00:11, 587.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59812/66745 [01:43<00:11, 588.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59872/66745 [01:43<00:11, 591.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59932/66745 [01:43<00:11, 591.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 59992/66745 [01:43<00:11, 593.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▍| 60052/66745 [01:43<00:11, 589.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60111/66745 [01:43<00:11, 586.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60170/66745 [01:43<00:11, 585.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60229/66745 [01:44<00:11, 585.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60288/66745 [01:44<00:11, 584.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████▌| 60347/66745 [01:44<00:10, 583.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60406/66745 [01:44<00:10, 583.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60465/66745 [01:44<00:10, 583.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60524/66745 [01:44<00:10, 583.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60583/66745 [01:44<00:10, 583.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60642/66745 [01:44<00:10, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60701/66745 [01:44<00:10, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60760/66745 [01:44<00:10, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60820/66745 [01:45<00:10, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60879/66745 [01:45<00:10, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60938/66745 [01:45<00:09, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 60997/66745 [01:45<00:10, 573.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|████▌| 61055/66745 [01:45<00:10, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61114/66745 [01:45<00:09, 572.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61172/66745 [01:45<00:09, 571.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61231/66745 [01:45<00:09, 574.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61290/66745 [01:45<00:09, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61349/66745 [01:45<00:09, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61408/66745 [01:46<00:09, 580.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61467/66745 [01:46<00:09, 578.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61526/66745 [01:46<00:09, 579.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61585/66745 [01:46<00:08, 580.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61644/66745 [01:46<00:08, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|████▌| 61703/66745 [01:46<00:08, 583.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61762/66745 [01:46<00:08, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61821/66745 [01:46<00:08, 578.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61881/66745 [01:46<00:08, 582.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61940/66745 [01:47<00:08, 567.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 61999/66745 [01:47<00:08, 573.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62058/66745 [01:47<00:08, 576.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62117/66745 [01:47<00:07, 578.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62176/66745 [01:47<00:07, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62235/66745 [01:47<00:07, 581.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62294/66745 [01:47<00:07, 582.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████▋| 62353/66745 [01:47<00:07, 583.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62412/66745 [01:47<00:07, 584.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62471/66745 [01:47<00:07, 584.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62530/66745 [01:48<00:07, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62589/66745 [01:48<00:07, 578.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62648/66745 [01:48<00:07, 580.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62707/66745 [01:48<00:06, 581.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62766/66745 [01:48<00:06, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62825/66745 [01:48<00:06, 581.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62884/66745 [01:48<00:06, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 62943/66745 [01:48<00:06, 578.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63002/66745 [01:48<00:06, 580.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████▋| 63061/66745 [01:48<00:06, 580.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63120/66745 [01:49<00:06, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63179/66745 [01:49<00:06, 582.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63238/66745 [01:49<00:06, 583.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63297/66745 [01:49<00:05, 583.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▋| 63356/66745 [01:49<00:05, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63415/66745 [01:49<00:05, 584.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63474/66745 [01:49<00:05, 584.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63533/66745 [01:49<00:05, 584.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63592/66745 [01:49<00:05, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63651/66745 [01:49<00:05, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████▊| 63710/66745 [01:50<00:05, 583.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63769/66745 [01:50<00:05, 583.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63828/66745 [01:50<00:04, 583.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63887/66745 [01:50<00:04, 585.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 63947/66745 [01:50<00:04, 588.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64008/66745 [01:50<00:04, 594.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64069/66745 [01:50<00:04, 599.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64129/66745 [01:50<00:04, 594.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64189/66745 [01:50<00:04, 591.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64249/66745 [01:50<00:04, 588.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64308/66745 [01:51<00:04, 586.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████▊| 64367/66745 [01:51<00:04, 586.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64426/66745 [01:51<00:03, 586.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64485/66745 [01:51<00:03, 585.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64544/66745 [01:51<00:03, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64603/66745 [01:51<00:03, 584.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64662/66745 [01:51<00:03, 582.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64721/66745 [01:51<00:03, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64780/66745 [01:51<00:03, 585.90batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  97%|████▊| 64839/66745 [01:51<00:03, 586.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64899/66745 [01:52<00:03, 587.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 64959/66745 [01:52<00:03, 589.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████▊| 65019/66745 [01:52<00:02, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65078/66745 [01:52<00:02, 589.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65137/66745 [01:52<00:02, 589.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65196/66745 [01:52<00:02, 589.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65255/66745 [01:52<00:02, 589.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65315/66745 [01:52<00:02, 590.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65375/66745 [01:52<00:02, 589.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65434/66745 [01:52<00:02, 583.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65493/66745 [01:53<00:02, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65552/66745 [01:53<00:02, 581.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65611/66745 [01:53<00:01, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65669/66745 [01:53<00:01, 576.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|████▉| 65728/66745 [01:53<00:01, 580.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65787/66745 [01:53<00:01, 583.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65846/66745 [01:53<00:01, 585.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65905/66745 [01:53<00:01, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 65964/66745 [01:53<00:01, 587.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66023/66745 [01:53<00:01, 587.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66082/66745 [01:54<00:01, 587.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66141/66745 [01:54<00:01, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66200/66745 [01:54<00:00, 587.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66259/66745 [01:54<00:00, 587.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66318/66745 [01:54<00:00, 587.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|████▉| 66377/66745 [01:54<00:00, 588.02batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66436/66745 [01:54<00:00, 588.44batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66495/66745 [01:54<00:00, 588.50batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66554/66745 [01:54<00:00, 588.53batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66613/66745 [01:54<00:00, 588.52batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66672/66745 [01:55<00:00, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████▉| 66731/66745 [01:55<00:00, 588.20batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   6%| | 6/100 [11:36<3:01:28, 115.83s/epoch, loss=0.3\u001b[A\n",
      "Training batches on cuda:0:   0%|                  | 0/66745 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 17/66745 [00:00<06:34, 169.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 71/66745 [00:00<02:54, 383.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 128/66745 [00:00<02:22, 467.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 188/66745 [00:00<02:08, 516.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 248/66745 [00:00<02:02, 543.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|       | 307/66745 [00:00<01:58, 558.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 366/66745 [00:00<01:56, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 426/66745 [00:00<01:55, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 486/66745 [00:00<01:54, 579.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 545/66745 [00:01<01:53, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 604/66745 [00:01<01:56, 567.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 661/66745 [00:01<01:57, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 720/66745 [00:01<01:55, 569.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 779/66745 [00:01<01:54, 574.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 837/66745 [00:01<01:54, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 895/66745 [00:01<01:56, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|       | 954/66745 [00:01<01:55, 569.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1014/66745 [00:01<01:53, 577.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1072/66745 [00:01<01:55, 568.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1132/66745 [00:02<01:53, 577.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1190/66745 [00:02<01:53, 575.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1248/66745 [00:02<01:54, 570.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1306/66745 [00:02<01:54, 572.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|      | 1365/66745 [00:02<01:53, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1425/66745 [00:02<01:52, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1484/66745 [00:02<01:51, 583.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1543/66745 [00:02<01:51, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1602/66745 [00:02<01:51, 583.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏     | 1661/66745 [00:02<01:51, 583.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1720/66745 [00:03<01:53, 572.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1779/66745 [00:03<01:52, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1837/66745 [00:03<01:54, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1896/66745 [00:03<01:53, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 1955/66745 [00:03<01:52, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2014/66745 [00:03<01:51, 578.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2072/66745 [00:03<01:51, 577.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2130/66745 [00:03<01:54, 564.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2187/66745 [00:03<01:55, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2243/66745 [00:03<01:55, 557.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏     | 2300/66745 [00:04<01:55, 559.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2358/66745 [00:04<01:54, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2416/66745 [00:04<01:53, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2473/66745 [00:04<01:55, 555.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2529/66745 [00:04<01:56, 549.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2585/66745 [00:04<01:59, 538.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2639/66745 [00:04<02:01, 526.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2699/66745 [00:04<01:57, 545.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▏     | 2758/66745 [00:04<01:54, 557.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2816/66745 [00:05<01:53, 564.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2873/66745 [00:05<01:53, 561.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2931/66745 [00:05<01:53, 564.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎     | 2989/66745 [00:05<01:52, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3047/66745 [00:05<01:51, 571.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3105/66745 [00:05<01:51, 569.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3164/66745 [00:05<01:50, 572.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3222/66745 [00:05<01:51, 568.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3279/66745 [00:05<01:51, 568.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3338/66745 [00:05<01:50, 573.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3397/66745 [00:06<01:49, 577.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3455/66745 [00:06<01:50, 573.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3513/66745 [00:06<01:51, 567.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎     | 3570/66745 [00:06<01:52, 563.94batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   5%|▎     | 3627/66745 [00:06<01:51, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3686/66745 [00:06<01:50, 570.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3745/66745 [00:06<01:49, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3803/66745 [00:06<01:51, 566.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3860/66745 [00:06<01:52, 558.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3916/66745 [00:06<01:53, 551.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 3974/66745 [00:07<01:52, 559.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4034/66745 [00:07<01:50, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4092/66745 [00:07<01:49, 570.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▎     | 4150/66745 [00:07<01:49, 571.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4208/66745 [00:07<01:49, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4267/66745 [00:07<01:48, 574.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍     | 4326/66745 [00:07<01:48, 577.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4384/66745 [00:07<01:47, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4443/66745 [00:07<01:47, 579.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4502/66745 [00:07<01:47, 580.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4561/66745 [00:08<01:46, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4620/66745 [00:08<01:48, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4678/66745 [00:08<01:48, 570.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4737/66745 [00:08<01:47, 575.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4795/66745 [00:08<01:49, 563.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4852/66745 [00:08<01:49, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4909/66745 [00:08<01:50, 560.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▍     | 4966/66745 [00:08<01:51, 554.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5022/66745 [00:08<01:52, 547.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5079/66745 [00:09<01:51, 552.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5136/66745 [00:09<01:50, 557.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5194/66745 [00:09<01:49, 563.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5251/66745 [00:09<01:50, 555.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5307/66745 [00:09<01:52, 548.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5364/66745 [00:09<01:50, 554.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5423/66745 [00:09<01:48, 563.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5482/66745 [00:09<01:47, 568.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▍     | 5539/66745 [00:09<01:48, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5596/66745 [00:09<01:48, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌     | 5653/66745 [00:10<01:48, 565.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5710/66745 [00:10<01:49, 559.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5767/66745 [00:10<01:50, 553.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5823/66745 [00:10<01:51, 548.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5880/66745 [00:10<01:49, 554.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5939/66745 [00:10<01:47, 564.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 5998/66745 [00:10<01:46, 571.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6057/66745 [00:10<01:45, 576.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6115/66745 [00:10<01:46, 570.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6173/66745 [00:10<01:46, 568.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6232/66745 [00:11<01:45, 572.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▌     | 6291/66745 [00:11<01:44, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6350/66745 [00:11<01:44, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6409/66745 [00:11<01:44, 579.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6468/66745 [00:11<01:43, 580.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6527/66745 [00:11<01:43, 580.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6586/66745 [00:11<01:43, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6645/66745 [00:11<01:43, 580.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6704/66745 [00:11<01:43, 580.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6763/66745 [00:11<01:44, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6821/66745 [00:12<01:46, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6878/66745 [00:12<01:47, 558.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▌     | 6937/66745 [00:12<01:45, 567.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▋     | 6996/66745 [00:12<01:44, 573.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7054/66745 [00:12<01:46, 561.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7111/66745 [00:12<01:46, 557.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7170/66745 [00:12<01:45, 566.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7229/66745 [00:12<01:43, 573.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7288/66745 [00:12<01:42, 577.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7347/66745 [00:12<01:42, 580.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7406/66745 [00:13<01:41, 582.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7465/66745 [00:13<01:42, 578.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7523/66745 [00:13<01:42, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7582/66745 [00:13<01:42, 579.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▋     | 7642/66745 [00:13<01:41, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7702/66745 [00:13<01:40, 585.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7762/66745 [00:13<01:40, 586.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7821/66745 [00:13<01:40, 586.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7880/66745 [00:13<01:40, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7939/66745 [00:14<01:42, 576.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 7997/66745 [00:14<01:44, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8054/66745 [00:14<01:45, 556.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8110/66745 [00:14<01:45, 555.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8169/66745 [00:14<01:43, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8228/66745 [00:14<01:42, 569.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▋     | 8287/66745 [00:14<01:41, 573.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8346/66745 [00:14<01:41, 577.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8405/66745 [00:14<01:40, 579.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8464/66745 [00:14<01:40, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8525/66745 [00:15<01:39, 587.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8584/66745 [00:15<01:39, 583.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8643/66745 [00:15<01:39, 584.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8702/66745 [00:15<01:40, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8760/66745 [00:15<01:40, 576.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8818/66745 [00:15<01:40, 576.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8876/66745 [00:15<01:42, 562.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8933/66745 [00:15<01:44, 553.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▊     | 8989/66745 [00:15<01:46, 543.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9044/66745 [00:15<01:46, 543.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9099/66745 [00:16<01:47, 537.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9153/66745 [00:16<01:48, 531.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9213/66745 [00:16<01:44, 549.30batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  14%|▊     | 9273/66745 [00:16<01:42, 562.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9333/66745 [00:16<01:40, 573.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9392/66745 [00:16<01:39, 575.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9452/66745 [00:16<01:38, 580.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9511/66745 [00:16<01:38, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9571/66745 [00:16<01:37, 585.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▊     | 9630/66745 [00:16<01:37, 582.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊     | 9689/66745 [00:17<01:39, 574.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9748/66745 [00:17<01:38, 577.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9806/66745 [00:17<01:40, 568.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9863/66745 [00:17<01:41, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9922/66745 [00:17<01:40, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▉     | 9981/66745 [00:17<01:39, 572.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10040/66745 [00:17<01:38, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10099/66745 [00:17<01:37, 578.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10158/66745 [00:17<01:37, 579.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10217/66745 [00:18<01:37, 580.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10276/66745 [00:18<01:37, 578.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|▊    | 10334/66745 [00:18<01:39, 568.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10392/66745 [00:18<01:38, 570.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10451/66745 [00:18<01:38, 573.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10509/66745 [00:18<01:38, 568.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10567/66745 [00:18<01:38, 570.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10625/66745 [00:18<01:38, 570.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10685/66745 [00:18<01:37, 577.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10744/66745 [00:18<01:36, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10803/66745 [00:19<01:36, 579.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10862/66745 [00:19<01:36, 580.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10921/66745 [00:19<01:36, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|▊    | 10980/66745 [00:19<01:35, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11039/66745 [00:19<01:35, 581.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11098/66745 [00:19<01:35, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11157/66745 [00:19<01:35, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11216/66745 [00:19<01:35, 582.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11275/66745 [00:19<01:35, 582.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11334/66745 [00:19<01:35, 582.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11393/66745 [00:20<01:35, 581.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11452/66745 [00:20<01:34, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11511/66745 [00:20<01:34, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11570/66745 [00:20<01:34, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|▊    | 11629/66745 [00:20<01:34, 583.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11688/66745 [00:20<01:34, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11747/66745 [00:20<01:34, 582.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11806/66745 [00:20<01:34, 582.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11865/66745 [00:20<01:34, 583.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11924/66745 [00:20<01:33, 583.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 11983/66745 [00:21<01:34, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12042/66745 [00:21<01:34, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12100/66745 [00:21<01:35, 572.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12158/66745 [00:21<01:35, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12216/66745 [00:21<01:35, 571.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12275/66745 [00:21<01:34, 574.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|▉    | 12333/66745 [00:21<01:34, 573.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12392/66745 [00:21<01:34, 575.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12450/66745 [00:21<01:34, 571.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12508/66745 [00:21<01:36, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12565/66745 [00:22<01:37, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12621/66745 [00:22<01:38, 550.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12677/66745 [00:22<01:38, 549.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12733/66745 [00:22<01:38, 548.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12792/66745 [00:22<01:36, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12852/66745 [00:22<01:34, 569.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12910/66745 [00:22<01:34, 567.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|▉    | 12967/66745 [00:22<01:36, 559.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13026/66745 [00:22<01:34, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13085/66745 [00:23<01:33, 572.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13144/66745 [00:23<01:33, 575.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13202/66745 [00:23<01:33, 570.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13261/66745 [00:23<01:33, 573.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|▉    | 13319/66745 [00:23<01:32, 574.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13377/66745 [00:23<01:34, 564.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13436/66745 [00:23<01:33, 569.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13494/66745 [00:23<01:33, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13553/66745 [00:23<01:33, 571.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13611/66745 [00:23<01:32, 572.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█    | 13670/66745 [00:24<01:32, 575.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13728/66745 [00:24<01:32, 574.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13786/66745 [00:24<01:33, 564.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13843/66745 [00:24<01:33, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13900/66745 [00:24<01:33, 562.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 13961/66745 [00:24<01:31, 574.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14021/66745 [00:24<01:31, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14080/66745 [00:24<01:30, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14139/66745 [00:24<01:30, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14198/66745 [00:24<01:30, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14257/66745 [00:25<01:30, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█    | 14316/66745 [00:25<01:31, 571.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14374/66745 [00:25<01:32, 569.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14431/66745 [00:25<01:33, 561.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14488/66745 [00:25<01:33, 557.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14547/66745 [00:25<01:32, 565.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14606/66745 [00:25<01:31, 570.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14665/66745 [00:25<01:30, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14724/66745 [00:25<01:30, 577.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14782/66745 [00:25<01:30, 577.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14841/66745 [00:26<01:29, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 14899/66745 [00:26<01:29, 577.92batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  22%|█    | 14957/66745 [00:26<01:30, 574.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█    | 15015/66745 [00:26<01:31, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15072/66745 [00:26<01:32, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15129/66745 [00:26<01:32, 560.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15186/66745 [00:26<01:31, 562.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15243/66745 [00:26<01:31, 563.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15304/66745 [00:26<01:29, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15363/66745 [00:26<01:28, 578.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15422/66745 [00:27<01:28, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15481/66745 [00:27<01:27, 582.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15540/66745 [00:27<01:27, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15600/66745 [00:27<01:26, 588.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▏   | 15659/66745 [00:27<01:27, 587.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15720/66745 [00:27<01:26, 592.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15780/66745 [00:27<01:26, 591.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15840/66745 [00:27<01:26, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15900/66745 [00:27<01:26, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 15960/66745 [00:28<01:27, 577.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16018/66745 [00:28<01:29, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16075/66745 [00:28<01:30, 562.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16132/66745 [00:28<01:31, 554.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16188/66745 [00:28<01:32, 546.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16247/66745 [00:28<01:30, 557.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▏   | 16306/66745 [00:28<01:29, 565.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16365/66745 [00:28<01:28, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16424/66745 [00:28<01:27, 574.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16483/66745 [00:28<01:27, 577.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16542/66745 [00:29<01:26, 579.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16601/66745 [00:29<01:26, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▏   | 16660/66745 [00:29<01:26, 581.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16719/66745 [00:29<01:25, 583.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16778/66745 [00:29<01:28, 565.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16835/66745 [00:29<01:30, 553.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16891/66745 [00:29<01:30, 553.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 16948/66745 [00:29<01:29, 557.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▎   | 17009/66745 [00:29<01:26, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17068/66745 [00:29<01:26, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17126/66745 [00:30<01:26, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17185/66745 [00:30<01:26, 575.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17244/66745 [00:30<01:25, 577.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17303/66745 [00:30<01:25, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17361/66745 [00:30<01:26, 571.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17419/66745 [00:30<01:27, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17476/66745 [00:30<01:27, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17535/66745 [00:30<01:26, 571.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17594/66745 [00:30<01:25, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▎   | 17652/66745 [00:30<01:25, 572.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17711/66745 [00:31<01:25, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17770/66745 [00:31<01:24, 577.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17829/66745 [00:31<01:24, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17888/66745 [00:31<01:24, 579.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 17946/66745 [00:31<01:24, 574.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18006/66745 [00:31<01:23, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18067/66745 [00:31<01:22, 587.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18126/66745 [00:31<01:23, 581.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18185/66745 [00:31<01:24, 576.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18243/66745 [00:32<01:25, 566.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▎   | 18300/66745 [00:32<01:25, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18358/66745 [00:32<01:24, 570.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18416/66745 [00:32<01:25, 564.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18473/66745 [00:32<01:26, 559.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18532/66745 [00:32<01:25, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18589/66745 [00:32<01:25, 566.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18647/66745 [00:32<01:24, 568.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18706/66745 [00:32<01:23, 573.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18764/66745 [00:32<01:23, 573.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18823/66745 [00:33<01:22, 577.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18881/66745 [00:33<01:23, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18939/66745 [00:33<01:26, 552.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▍   | 18995/66745 [00:33<01:26, 552.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19054/66745 [00:33<01:24, 561.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19113/66745 [00:33<01:23, 567.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19172/66745 [00:33<01:23, 571.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19231/66745 [00:33<01:22, 574.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19290/66745 [00:33<01:22, 576.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19348/66745 [00:33<01:22, 576.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19407/66745 [00:34<01:21, 577.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19465/66745 [00:34<01:23, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19522/66745 [00:34<01:23, 564.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19579/66745 [00:34<01:23, 562.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█▍   | 19636/66745 [00:34<01:24, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19695/66745 [00:34<01:22, 567.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19752/66745 [00:34<01:23, 560.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19813/66745 [00:34<01:21, 573.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19871/66745 [00:34<01:22, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19928/66745 [00:34<01:23, 563.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▍   | 19987/66745 [00:35<01:22, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20045/66745 [00:35<01:21, 570.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20104/66745 [00:35<01:21, 574.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20162/66745 [00:35<01:21, 572.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20221/66745 [00:35<01:20, 577.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20279/66745 [00:35<01:20, 577.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█▌   | 20337/66745 [00:35<01:21, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20397/66745 [00:35<01:20, 577.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20456/66745 [00:35<01:19, 580.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20515/66745 [00:35<01:19, 580.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20574/66745 [00:36<01:20, 574.08batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  31%|█▌   | 20632/66745 [00:36<01:21, 567.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20689/66745 [00:36<01:22, 556.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20747/66745 [00:36<01:21, 561.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20806/66745 [00:36<01:20, 568.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20865/66745 [00:36<01:20, 572.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20923/66745 [00:36<01:20, 570.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█▌   | 20981/66745 [00:36<01:21, 563.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21041/66745 [00:36<01:19, 571.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21102/66745 [00:37<01:18, 581.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21163/66745 [00:37<01:17, 588.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21222/66745 [00:37<01:18, 583.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21281/66745 [00:37<01:18, 576.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21340/66745 [00:37<01:18, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21401/66745 [00:37<01:17, 586.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21462/66745 [00:37<01:16, 591.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21522/66745 [00:37<01:18, 573.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21580/66745 [00:37<01:19, 569.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█▌   | 21638/66745 [00:37<01:19, 569.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21696/66745 [00:38<01:19, 569.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21753/66745 [00:38<01:20, 559.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21811/66745 [00:38<01:19, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21868/66745 [00:38<01:19, 561.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21925/66745 [00:38<01:19, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 21983/66745 [00:38<01:19, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22041/66745 [00:38<01:18, 568.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22102/66745 [00:38<01:17, 578.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22161/66745 [00:38<01:16, 579.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22220/66745 [00:38<01:16, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22279/66745 [00:39<01:16, 582.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|█▋   | 22338/66745 [00:39<01:16, 583.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22397/66745 [00:39<01:15, 584.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22456/66745 [00:39<01:15, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22515/66745 [00:39<01:15, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22574/66745 [00:39<01:15, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22633/66745 [00:39<01:16, 580.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22692/66745 [00:39<01:16, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22750/66745 [00:39<01:16, 578.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22808/66745 [00:39<01:15, 578.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22866/66745 [00:40<01:15, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22924/66745 [00:40<01:15, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|█▋   | 22983/66745 [00:40<01:15, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23042/66745 [00:40<01:15, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23101/66745 [00:40<01:14, 582.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23160/66745 [00:40<01:15, 580.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23219/66745 [00:40<01:14, 582.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23278/66745 [00:40<01:14, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▋   | 23337/66745 [00:40<01:14, 583.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23396/66745 [00:40<01:14, 583.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23455/66745 [00:41<01:14, 584.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23514/66745 [00:41<01:15, 574.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23572/66745 [00:41<01:15, 572.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23630/66745 [00:41<01:17, 558.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|█▊   | 23686/66745 [00:41<01:17, 557.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23742/66745 [00:41<01:17, 553.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23798/66745 [00:41<01:18, 549.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23855/66745 [00:41<01:17, 554.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23914/66745 [00:41<01:16, 563.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 23971/66745 [00:42<01:17, 552.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24030/66745 [00:42<01:16, 561.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24087/66745 [00:42<01:15, 563.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24146/66745 [00:42<01:14, 571.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24204/66745 [00:42<01:15, 565.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24261/66745 [00:42<01:15, 565.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|█▊   | 24319/66745 [00:42<01:14, 568.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24378/66745 [00:42<01:14, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24436/66745 [00:42<01:15, 562.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24493/66745 [00:42<01:15, 562.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24550/66745 [00:43<01:15, 556.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24606/66745 [00:43<01:16, 548.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24664/66745 [00:43<01:15, 555.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24725/66745 [00:43<01:13, 571.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24783/66745 [00:43<01:13, 570.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24841/66745 [00:43<01:13, 571.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24900/66745 [00:43<01:12, 574.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 24959/66745 [00:43<01:12, 577.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|█▊   | 25018/66745 [00:43<01:12, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25077/66745 [00:43<01:11, 580.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25136/66745 [00:44<01:13, 566.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25193/66745 [00:44<01:13, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25252/66745 [00:44<01:12, 570.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25310/66745 [00:44<01:13, 567.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25369/66745 [00:44<01:12, 571.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25428/66745 [00:44<01:11, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25487/66745 [00:44<01:11, 576.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25546/66745 [00:44<01:11, 578.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25605/66745 [00:44<01:10, 580.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|█▉   | 25664/66745 [00:44<01:10, 582.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25723/66745 [00:45<01:11, 574.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25781/66745 [00:45<01:11, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25839/66745 [00:45<01:11, 574.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25898/66745 [00:45<01:10, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 25956/66745 [00:45<01:11, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26014/66745 [00:45<01:11, 573.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26072/66745 [00:45<01:11, 571.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26130/66745 [00:45<01:11, 565.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26188/66745 [00:45<01:11, 569.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26247/66745 [00:46<01:10, 573.53batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  39%|█▉   | 26305/66745 [00:46<01:10, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|█▉   | 26363/66745 [00:46<01:10, 574.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26422/66745 [00:46<01:09, 576.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26481/66745 [00:46<01:09, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26539/66745 [00:46<01:09, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26598/66745 [00:46<01:09, 578.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|█▉   | 26656/66745 [00:46<01:09, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26715/66745 [00:46<01:09, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26773/66745 [00:46<01:10, 565.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26830/66745 [00:47<01:10, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26888/66745 [00:47<01:09, 569.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 26945/66745 [00:47<01:10, 564.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██   | 27002/66745 [00:47<01:10, 563.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27059/66745 [00:47<01:11, 557.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27116/66745 [00:47<01:10, 558.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27172/66745 [00:47<01:11, 552.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27229/66745 [00:47<01:11, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27287/66745 [00:47<01:10, 561.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27344/66745 [00:47<01:10, 557.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27400/66745 [00:48<01:10, 557.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27458/66745 [00:48<01:09, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27515/66745 [00:48<01:09, 561.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27572/66745 [00:48<01:09, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27630/66745 [00:48<01:09, 565.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██   | 27687/66745 [00:48<01:10, 550.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27743/66745 [00:48<01:10, 552.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27801/66745 [00:48<01:09, 559.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27858/66745 [00:48<01:10, 550.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27915/66745 [00:48<01:09, 556.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 27974/66745 [00:49<01:08, 564.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28033/66745 [00:49<01:07, 570.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28092/66745 [00:49<01:07, 574.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28151/66745 [00:49<01:06, 577.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28209/66745 [00:49<01:06, 577.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28267/66745 [00:49<01:07, 571.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██   | 28325/66745 [00:49<01:07, 571.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28384/66745 [00:49<01:06, 574.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28442/66745 [00:49<01:06, 572.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28501/66745 [00:49<01:06, 577.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28560/66745 [00:50<01:05, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28619/66745 [00:50<01:06, 575.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28678/66745 [00:50<01:05, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28737/66745 [00:50<01:05, 579.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28796/66745 [00:50<01:05, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28855/66745 [00:50<01:05, 582.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28914/66745 [00:50<01:04, 582.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 28973/66745 [00:50<01:05, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▏  | 29031/66745 [00:50<01:06, 566.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29089/66745 [00:51<01:06, 569.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29149/66745 [00:51<01:05, 576.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29208/66745 [00:51<01:04, 579.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29268/66745 [00:51<01:04, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29327/66745 [00:51<01:05, 569.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29385/66745 [00:51<01:07, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29442/66745 [00:51<01:06, 558.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29498/66745 [00:51<01:07, 555.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29554/66745 [00:51<01:07, 551.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29611/66745 [00:51<01:06, 555.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|██▏  | 29670/66745 [00:52<01:05, 563.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29727/66745 [00:52<01:06, 555.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29784/66745 [00:52<01:06, 557.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29844/66745 [00:52<01:05, 567.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29901/66745 [00:52<01:05, 559.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 29957/66745 [00:52<01:06, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▏  | 30013/66745 [00:52<01:06, 549.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30068/66745 [00:52<01:07, 542.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30124/66745 [00:52<01:06, 547.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30183/66745 [00:52<01:05, 557.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30242/66745 [00:53<01:04, 564.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30301/66745 [00:53<01:03, 569.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██▎  | 30360/66745 [00:53<01:03, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30419/66745 [00:53<01:02, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30478/66745 [00:53<01:02, 578.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30537/66745 [00:53<01:02, 579.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30595/66745 [00:53<01:02, 579.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30653/66745 [00:53<01:03, 570.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30712/66745 [00:53<01:02, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30770/66745 [00:53<01:02, 571.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30828/66745 [00:54<01:03, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30885/66745 [00:54<01:03, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30942/66745 [00:54<01:03, 560.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██▎  | 30999/66745 [00:54<01:04, 554.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31060/66745 [00:54<01:02, 569.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31121/66745 [00:54<01:01, 578.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31180/66745 [00:54<01:01, 579.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31239/66745 [00:54<01:01, 576.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31297/66745 [00:54<01:02, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31356/66745 [00:55<01:02, 569.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31414/66745 [00:55<01:02, 569.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31473/66745 [00:55<01:01, 574.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31531/66745 [00:55<01:02, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31588/66745 [00:55<01:02, 558.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██▎  | 31648/66745 [00:55<01:01, 568.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31705/66745 [00:55<01:03, 555.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31762/66745 [00:55<01:02, 559.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31819/66745 [00:55<01:02, 554.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31875/66745 [00:55<01:02, 554.92batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  48%|██▍  | 31931/66745 [00:56<01:03, 548.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 31990/66745 [00:56<01:02, 558.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32047/66745 [00:56<01:01, 560.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32106/66745 [00:56<01:01, 566.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32167/66745 [00:56<00:59, 578.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32227/66745 [00:56<00:59, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32288/66745 [00:56<00:58, 590.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██▍  | 32348/66745 [00:56<00:58, 588.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32407/66745 [00:56<00:59, 574.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32465/66745 [00:56<01:00, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32525/66745 [00:57<00:59, 572.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32586/66745 [00:57<00:58, 582.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32647/66745 [00:57<00:57, 588.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32706/66745 [00:57<00:59, 575.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32767/66745 [00:57<00:58, 584.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32826/66745 [00:57<00:57, 585.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32885/66745 [00:57<00:59, 568.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32942/66745 [00:57<01:00, 555.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|██▍  | 32998/66745 [00:57<01:01, 550.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33054/66745 [00:58<01:01, 547.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33113/66745 [00:58<01:00, 557.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33172/66745 [00:58<00:59, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33229/66745 [00:58<00:59, 561.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33288/66745 [00:58<00:58, 569.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▍  | 33347/66745 [00:58<00:58, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33406/66745 [00:58<00:57, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33465/66745 [00:58<00:57, 581.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33524/66745 [00:58<00:58, 572.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33584/66745 [00:58<00:57, 578.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33644/66745 [00:59<00:56, 581.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|██▌  | 33703/66745 [00:59<00:58, 567.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33760/66745 [00:59<00:58, 560.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33817/66745 [00:59<00:59, 556.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33873/66745 [00:59<00:58, 557.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33932/66745 [00:59<00:58, 565.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 33993/66745 [00:59<00:56, 577.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34051/66745 [00:59<00:57, 570.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34109/66745 [00:59<00:57, 567.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34169/66745 [00:59<00:56, 576.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34228/66745 [01:00<00:56, 578.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34287/66745 [01:00<00:56, 578.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|██▌  | 34345/66745 [01:00<00:55, 578.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34403/66745 [01:00<00:55, 578.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34461/66745 [01:00<00:57, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34518/66745 [01:00<00:56, 565.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34577/66745 [01:00<00:56, 572.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34636/66745 [01:00<00:55, 576.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34694/66745 [01:00<00:56, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34753/66745 [01:00<00:55, 573.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34811/66745 [01:01<00:55, 571.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34869/66745 [01:01<00:57, 556.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34928/66745 [01:01<00:56, 565.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|██▌  | 34988/66745 [01:01<00:55, 572.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35048/66745 [01:01<00:54, 578.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35108/66745 [01:01<00:54, 582.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35167/66745 [01:01<00:55, 570.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35225/66745 [01:01<00:56, 556.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35281/66745 [01:01<00:57, 547.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35339/66745 [01:02<00:56, 555.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35395/66745 [01:02<00:56, 553.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35451/66745 [01:02<00:57, 546.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35506/66745 [01:02<00:57, 539.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35564/66745 [01:02<00:56, 550.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35622/66745 [01:02<00:55, 558.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|██▋  | 35681/66745 [01:02<00:54, 564.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35739/66745 [01:02<00:54, 569.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35797/66745 [01:02<00:54, 571.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35855/66745 [01:02<00:55, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35912/66745 [01:03<00:54, 561.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 35971/66745 [01:03<00:54, 569.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36030/66745 [01:03<00:53, 575.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36088/66745 [01:03<00:53, 568.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36147/66745 [01:03<00:53, 574.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36206/66745 [01:03<00:52, 578.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36265/66745 [01:03<00:52, 582.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|██▋  | 36324/66745 [01:03<00:52, 584.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36383/66745 [01:03<00:51, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36442/66745 [01:03<00:52, 580.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36501/66745 [01:04<00:52, 578.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36559/66745 [01:04<00:52, 578.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36617/66745 [01:04<00:53, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▋  | 36674/66745 [01:04<00:53, 557.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36730/66745 [01:04<00:53, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36789/66745 [01:04<00:52, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36848/66745 [01:04<00:52, 573.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36907/66745 [01:04<00:51, 576.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 36966/66745 [01:04<00:51, 578.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|██▊  | 37025/66745 [01:04<00:51, 579.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37084/66745 [01:05<00:51, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37143/66745 [01:05<00:50, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37202/66745 [01:05<00:51, 577.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37261/66745 [01:05<00:50, 580.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37321/66745 [01:05<00:50, 583.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37381/66745 [01:05<00:50, 585.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37440/66745 [01:05<00:49, 586.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37499/66745 [01:05<00:51, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37557/66745 [01:05<00:52, 555.54batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  56%|██▊  | 37615/66745 [01:06<00:51, 560.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|██▊  | 37674/66745 [01:06<00:51, 569.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37733/66745 [01:06<00:50, 573.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37792/66745 [01:06<00:50, 576.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37851/66745 [01:06<00:49, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37911/66745 [01:06<00:49, 583.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 37970/66745 [01:06<00:49, 585.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38030/66745 [01:06<00:48, 586.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38089/66745 [01:06<00:48, 587.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38148/66745 [01:06<00:49, 582.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38207/66745 [01:07<00:48, 582.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38266/66745 [01:07<00:48, 582.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|██▊  | 38325/66745 [01:07<00:48, 583.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38384/66745 [01:07<00:48, 583.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38443/66745 [01:07<00:48, 583.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38502/66745 [01:07<00:48, 583.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38561/66745 [01:07<00:48, 583.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38620/66745 [01:07<00:48, 584.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38679/66745 [01:07<00:48, 584.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38738/66745 [01:07<00:49, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38796/66745 [01:08<00:49, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38853/66745 [01:08<00:49, 562.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38910/66745 [01:08<00:50, 554.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 38966/66745 [01:08<00:50, 550.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██▉  | 39022/66745 [01:08<00:50, 551.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39081/66745 [01:08<00:49, 562.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39141/66745 [01:08<00:48, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39201/66745 [01:08<00:47, 576.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39261/66745 [01:08<00:47, 581.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39320/66745 [01:08<00:47, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39378/66745 [01:09<00:48, 569.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39438/66745 [01:09<00:47, 576.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39497/66745 [01:09<00:47, 578.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39556/66745 [01:09<00:46, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39615/66745 [01:09<00:46, 582.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██▉  | 39674/66745 [01:09<00:46, 583.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39733/66745 [01:09<00:46, 584.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39793/66745 [01:09<00:45, 586.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39853/66745 [01:09<00:45, 586.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39912/66745 [01:09<00:46, 575.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 39971/66745 [01:10<00:46, 577.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██▉  | 40029/66745 [01:10<00:46, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40088/66745 [01:10<00:46, 579.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40147/66745 [01:10<00:45, 580.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40207/66745 [01:10<00:45, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40267/66745 [01:10<00:45, 585.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|███  | 40327/66745 [01:10<00:44, 587.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40387/66745 [01:10<00:44, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40447/66745 [01:10<00:44, 589.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40506/66745 [01:11<00:44, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40565/66745 [01:11<00:44, 581.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40624/66745 [01:11<00:44, 581.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40683/66745 [01:11<00:44, 582.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40742/66745 [01:11<00:44, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40801/66745 [01:11<00:44, 583.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40860/66745 [01:11<00:44, 583.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40919/66745 [01:11<00:44, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 40978/66745 [01:11<00:44, 584.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|███  | 41037/66745 [01:11<00:43, 584.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41096/66745 [01:12<00:44, 581.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41155/66745 [01:12<00:44, 581.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41215/66745 [01:12<00:43, 584.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41274/66745 [01:12<00:43, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41334/66745 [01:12<00:43, 586.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41393/66745 [01:12<00:43, 587.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41453/66745 [01:12<00:42, 588.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41513/66745 [01:12<00:42, 589.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41573/66745 [01:12<00:42, 592.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41633/66745 [01:12<00:42, 590.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|███  | 41693/66745 [01:13<00:42, 585.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41752/66745 [01:13<00:43, 576.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41811/66745 [01:13<00:43, 578.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41870/66745 [01:13<00:42, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41929/66745 [01:13<00:42, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 41988/66745 [01:13<00:42, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42047/66745 [01:13<00:42, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42106/66745 [01:13<00:42, 583.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42165/66745 [01:13<00:42, 584.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42224/66745 [01:13<00:41, 584.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42283/66745 [01:14<00:42, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███▏ | 42342/66745 [01:14<00:41, 582.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42401/66745 [01:14<00:41, 582.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42460/66745 [01:14<00:42, 575.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42519/66745 [01:14<00:41, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42578/66745 [01:14<00:41, 580.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42637/66745 [01:14<00:41, 581.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42696/66745 [01:14<00:41, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42755/66745 [01:14<00:41, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42814/66745 [01:14<00:40, 584.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42873/66745 [01:15<00:40, 585.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42932/66745 [01:15<00:41, 569.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 42990/66745 [01:15<00:42, 558.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███▏ | 43046/66745 [01:15<00:43, 549.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43102/66745 [01:15<00:42, 550.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43158/66745 [01:15<00:43, 548.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43214/66745 [01:15<00:42, 551.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▏ | 43272/66745 [01:15<00:41, 559.79batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  65%|███▏ | 43331/66745 [01:15<00:41, 568.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43390/66745 [01:15<00:40, 574.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43448/66745 [01:16<00:41, 567.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43505/66745 [01:16<00:40, 567.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43562/66745 [01:16<00:41, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43620/66745 [01:16<00:40, 567.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███▎ | 43677/66745 [01:16<00:40, 564.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43736/66745 [01:16<00:40, 570.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43795/66745 [01:16<00:39, 574.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43854/66745 [01:16<00:39, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43913/66745 [01:16<00:39, 579.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 43972/66745 [01:17<00:39, 581.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44031/66745 [01:17<00:39, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███▎ | 44090/66745 [01:17<00:39, 578.62batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   6%| | 6/100 [12:53<3:21:56, 128.90s/epoch, loss=0.3\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline_result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:783\u001b[0m, in \u001b[0;36mpipeline_from_config\u001b[0;34m(config, discard_seed, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m     random_seed \u001b[38;5;241m=\u001b[39m pipeline_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    781\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIgnoring random_seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You need to explicitly disable this, if unintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:628\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    625\u001b[0m evaluated_once \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    627\u001b[0m num_training_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# Recall that torch *accumulates* gradients. Before passing in a\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# new instance, you need to zero out the gradients from the old instance\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# Get batch size of current batch (last batch may be incomplete)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:43\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/instances.py:237\u001b[0m, in \u001b[0;36mBaseBatchedSLCWAInstances.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterate over batches.\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m triple_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_triple_ids():\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/instances.py:212\u001b[0m, in \u001b[0;36mBaseBatchedSLCWAInstances.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a batch from the given list of positive triple IDs.\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m positive_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapped_triples[item]\n\u001b[0;32m--> 212\u001b[0m negative_batch, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SLCWABatch(positives\u001b[38;5;241m=\u001b[39mpositive_batch, negatives\u001b[38;5;241m=\u001b[39mnegative_batch, masks\u001b[38;5;241m=\u001b[39mmasks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/sampling/negative_sampler.py:100\u001b[0m, in \u001b[0;36mNegativeSampler.sample\u001b[0;34m(self, positive_batch)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mGenerate negative samples from the positive batch.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m       An optional filter mask. True where negative samples are valid.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# create unfiltered negative batch by corruption\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m negative_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrupt_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilterer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m negative_batch, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/sampling/basic_negative_sampler.py:91\u001b[0m, in \u001b[0;36mBasicNegativeSampler.corrupt_batch\u001b[0;34m(self, positive_batch)\u001b[0m\n\u001b[1;32m     88\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m positive_batch\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# clone positive batch for corruption (.repeat_interleave creates a copy)\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m negative_batch \u001b[38;5;241m=\u001b[39m \u001b[43mpositive_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_negs_per_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Bind the total number of negatives to sample in this batch\u001b[39;00m\n\u001b[1;32m     94\u001b[0m total_num_negatives \u001b[38;5;241m=\u001b[39m negative_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline_result = pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores for given triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute scores for positive and negative triplets \n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "n = train.size(0) // batch_size\n",
    "pos_train_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, train.size(0))\n",
    "    edge = train[start_idx:end_idx]\n",
    "    pos_train_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "n = valid.size(0) // batch_size\n",
    "pos_valid_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, valid.size(0))\n",
    "    edge = valid[start_idx:end_idx]\n",
    "    pos_valid_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "n = valid_neg.size(0) // batch_size\n",
    "neg_valid_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, valid_neg.size(0))\n",
    "    edge = valid_neg[start_idx:end_idx]\n",
    "    neg_valid_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "n = test.size(0) // batch_size\n",
    "pos_test_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, test.size(0))\n",
    "    edge = test[start_idx:end_idx]\n",
    "    pos_test_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "n = test_neg.size(0) // batch_size\n",
    "neg_test_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, test_neg.size(0))\n",
    "    edge = test_neg[start_idx:end_idx]\n",
    "    neg_test_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "neg_test_pred = torch.cat(neg_test_preds, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate my results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Train: 0.01%\n",
      "Valid: 0.01%\n",
      "Test: 0.01%\n",
      "Hits@20\n",
      "Train: 0.02%\n",
      "Valid: 0.02%\n",
      "Test: 0.02%\n",
      "Hits@30\n",
      "Train: 0.03%\n",
      "Valid: 0.03%\n",
      "Test: 0.03%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the coputed scores - hits@K\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbl-ddi')\n",
    "\n",
    "results = {}\n",
    "for K in [10, 20, 30]:\n",
    "    evaluator.K = K\n",
    "    train_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_train_pred,\n",
    "        'y_pred_neg': neg_valid_pred,\n",
    "    })[f'hits@{K}']\n",
    "    valid_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_valid_pred,\n",
    "        'y_pred_neg': neg_valid_pred,\n",
    "    })[f'hits@{K}']\n",
    "    test_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_test_pred,\n",
    "        'y_pred_neg': neg_test_pred,\n",
    "    })[f'hits@{K}']\n",
    "    \n",
    "    results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "    \n",
    "    \n",
    "for hits, result in results.items():\n",
    "    print(hits)\n",
    "#     print(result)\n",
    "    train_hits, valid_hits, test_hits = result\n",
    "    print(f'Train: {100 * train_hits:.2f}%')\n",
    "    print(f'Valid: {100 * valid_hits:.2f}%')\n",
    "    print(f'Test: {100 * test_hits:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leuprolide - decrease_adverse_effects:\n",
      "      head_id head_label     score  in_training\n",
      "1776     1776       2597 -4.225868         True\n",
      "1787     1787       2606 -4.259010         True\n",
      "1549     1549       2392 -4.277555         True\n",
      "3626     3626       4261 -4.303725         True\n",
      "4148     4148        892 -4.309386         True\n",
      "1917     1917       2723 -4.312338        False\n",
      "1929     1929       2734 -4.312355         True\n",
      "1610     1610       2447 -4.334918         True\n",
      "3955     3955        718 -4.335896        False\n",
      "1236     1236        211 -4.366917         True\n"
     ]
    }
   ],
   "source": [
    "model_kg.predict_head('2424', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005993003168800426\n",
      "0.0036557319329682597\n",
      "0.007348920135741521\n"
     ]
    }
   ],
   "source": [
    "print(model_kg.trained_model.get_metric('hits@1'))\n",
    "print(model_kg.trained_model.get_metric('hits@5'))\n",
    "print(model_kg.trained_model.get_metric('hits@10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config\n",
    "\n",
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "#         dataset='Nations',\n",
    "        training = train_tf,\n",
    "        testing = test_tf,\n",
    "        validation = valid_tf,\n",
    "        model='TransE',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=50, high=220, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=20, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-30 09:10:42,742]\u001b[0m A new study created in memory with name: no-name-c005a0f9-7d4f-437f-bc0c-163f72eb63f9\u001b[0m\n",
      "INFO:pykeen.hpo.hpo:Using model: <class 'pykeen.models.unimodal.trans_e.TransE'>\n",
      "INFO:pykeen.hpo.hpo:Using loss: <class 'pykeen.losses.MarginRankingLoss'>\n",
      "INFO:pykeen.hpo.hpo:Using optimizer: <class 'torch.optim.adam.Adam'>\n",
      "INFO:pykeen.hpo.hpo:Using training loop: <class 'pykeen.training.slcwa.SLCWATrainingLoop'>\n",
      "INFO:pykeen.hpo.hpo:Using negative sampler: <class 'pykeen.sampling.basic_negative_sampler.BasicNegativeSampler'>\n",
      "INFO:pykeen.hpo.hpo:Using evaluator: <class 'pykeen.evaluation.rank_based_evaluator.RankBasedEvaluator'>\n",
      "INFO:pykeen.hpo.hpo:Attempting to maximize both.realistic.inverse_harmonic_mean_rank\n",
      "INFO:pykeen.hpo.hpo:Filter validation triples when testing: True\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1922190294.\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: /work/.data/pykeen/checkpoints/best-model-weights-788cfe08-4ab7-44b1-a674-0b8e013ba656.pt\n",
      "INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "Training epochs on cuda:0:   0%|                                               | 0/20 [00:00<?, ?epoch/s]INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 15/16687 [00:00<01:51, 149.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 60/16687 [00:00<00:51, 324.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 114/16687 [00:00<00:39, 419.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 170/16687 [00:00<00:34, 474.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 226/16687 [00:00<00:32, 503.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 283/16687 [00:00<00:31, 525.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 343/16687 [00:00<00:29, 547.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 400/16687 [00:00<00:29, 553.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 459/16687 [00:00<00:28, 562.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 519/16687 [00:01<00:28, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 577/16687 [00:01<00:28, 572.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 635/16687 [00:01<00:27, 573.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 695/16687 [00:01<00:27, 579.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 753/16687 [00:01<00:27, 579.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 813/16687 [00:01<00:27, 583.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 872/16687 [00:01<00:28, 562.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 929/16687 [00:01<00:28, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 986/16687 [00:01<00:28, 557.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1043/16687 [00:01<00:27, 560.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1101/16687 [00:02<00:27, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1159/16687 [00:02<00:27, 567.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1217/16687 [00:02<00:27, 571.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1275/16687 [00:02<00:26, 572.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1333/16687 [00:02<00:26, 572.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1391/16687 [00:02<00:26, 574.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1451/16687 [00:02<00:26, 579.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1509/16687 [00:02<00:26, 578.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1567/16687 [00:02<00:26, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1625/16687 [00:02<00:26, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1683/16687 [00:03<00:26, 576.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1743/16687 [00:03<00:25, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1802/16687 [00:03<00:25, 579.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1862/16687 [00:03<00:25, 583.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1922/16687 [00:03<00:25, 586.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1981/16687 [00:03<00:25, 584.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2040/16687 [00:03<00:25, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2100/16687 [00:03<00:24, 585.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2159/16687 [00:03<00:24, 581.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2218/16687 [00:03<00:25, 575.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2278/16687 [00:04<00:24, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2337/16687 [00:04<00:24, 579.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2395/16687 [00:04<00:24, 575.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2453/16687 [00:04<00:24, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2513/16687 [00:04<00:24, 579.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2573/16687 [00:04<00:24, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2633/16687 [00:04<00:23, 586.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2693/16687 [00:04<00:23, 587.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2752/16687 [00:04<00:23, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2811/16687 [00:04<00:23, 579.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2871/16687 [00:05<00:23, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2930/16687 [00:05<00:23, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2989/16687 [00:05<00:23, 580.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3048/16687 [00:05<00:23, 572.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3106/16687 [00:05<00:24, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3164/16687 [00:05<00:23, 568.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3224/16687 [00:05<00:23, 574.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3282/16687 [00:05<00:23, 576.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3340/16687 [00:05<00:23, 571.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3398/16687 [00:06<00:23, 571.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3456/16687 [00:06<00:23, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3513/16687 [00:06<00:24, 544.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3568/16687 [00:06<00:24, 530.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3622/16687 [00:06<00:25, 519.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3681/16687 [00:06<00:24, 538.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3736/16687 [00:06<00:23, 541.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3793/16687 [00:06<00:23, 547.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3850/16687 [00:06<00:23, 552.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▎                       | 3906/16687 [00:06<00:23, 540.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3963/16687 [00:07<00:23, 548.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4020/16687 [00:07<00:22, 552.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4076/16687 [00:07<00:22, 552.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4134/16687 [00:07<00:22, 558.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4190/16687 [00:07<00:22, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4248/16687 [00:07<00:22, 560.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4306/16687 [00:07<00:21, 564.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4363/16687 [00:07<00:21, 561.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4421/16687 [00:07<00:21, 564.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4478/16687 [00:07<00:21, 558.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4537/16687 [00:08<00:21, 567.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4595/16687 [00:08<00:21, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4653/16687 [00:08<00:21, 572.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4713/16687 [00:08<00:20, 578.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4773/16687 [00:08<00:20, 581.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4833/16687 [00:08<00:20, 584.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4892/16687 [00:08<00:20, 581.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4951/16687 [00:08<00:20, 580.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5010/16687 [00:08<00:20, 575.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5068/16687 [00:08<00:20, 562.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5125/16687 [00:09<00:20, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5183/16687 [00:09<00:20, 568.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5241/16687 [00:09<00:20, 570.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5299/16687 [00:09<00:19, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5359/16687 [00:09<00:19, 578.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5419/16687 [00:09<00:19, 582.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5478/16687 [00:09<00:19, 580.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5538/16687 [00:09<00:19, 583.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5597/16687 [00:09<00:19, 581.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5656/16687 [00:10<00:19, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5714/16687 [00:10<00:19, 571.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5772/16687 [00:10<00:19, 565.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5830/16687 [00:10<00:19, 567.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5888/16687 [00:10<00:18, 569.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5946/16687 [00:10<00:19, 560.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6006/16687 [00:10<00:18, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6066/16687 [00:10<00:18, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6126/16687 [00:10<00:18, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6186/16687 [00:10<00:17, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6245/16687 [00:11<00:18, 575.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6304/16687 [00:11<00:17, 579.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6362/16687 [00:11<00:17, 579.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6420/16687 [00:11<00:17, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6480/16687 [00:11<00:17, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6540/16687 [00:11<00:17, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6600/16687 [00:11<00:17, 586.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6659/16687 [00:11<00:17, 584.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6718/16687 [00:11<00:17, 582.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6777/16687 [00:11<00:17, 581.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6836/16687 [00:12<00:17, 574.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6894/16687 [00:12<00:17, 575.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6952/16687 [00:12<00:17, 572.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7010/16687 [00:12<00:16, 572.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7070/16687 [00:12<00:16, 578.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7130/16687 [00:12<00:16, 581.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7189/16687 [00:12<00:16, 580.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7248/16687 [00:12<00:16, 583.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7307/16687 [00:12<00:16, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7365/16687 [00:12<00:16, 577.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7423/16687 [00:13<00:16, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7481/16687 [00:13<00:16, 571.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7541/16687 [00:13<00:15, 577.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7599/16687 [00:13<00:15, 576.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7659/16687 [00:13<00:15, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7719/16687 [00:13<00:15, 584.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7778/16687 [00:13<00:15, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7837/16687 [00:13<00:15, 581.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7897/16687 [00:13<00:15, 584.41batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  48%|██████████████▊                | 7956/16687 [00:13<00:14, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8015/16687 [00:14<00:15, 570.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8073/16687 [00:14<00:15, 572.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8133/16687 [00:14<00:14, 578.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8191/16687 [00:14<00:14, 573.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8249/16687 [00:14<00:14, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8306/16687 [00:14<00:14, 564.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8365/16687 [00:14<00:14, 571.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8423/16687 [00:14<00:14, 566.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8480/16687 [00:14<00:14, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8537/16687 [00:15<00:14, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8594/16687 [00:15<00:14, 551.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8651/16687 [00:15<00:14, 557.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8709/16687 [00:15<00:14, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8766/16687 [00:15<00:14, 563.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8823/16687 [00:15<00:14, 559.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8879/16687 [00:15<00:13, 559.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8939/16687 [00:15<00:13, 568.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8999/16687 [00:15<00:13, 575.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9059/16687 [00:15<00:13, 580.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9119/16687 [00:16<00:12, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9178/16687 [00:16<00:13, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9236/16687 [00:16<00:12, 574.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9294/16687 [00:16<00:12, 570.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9352/16687 [00:16<00:12, 565.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9409/16687 [00:16<00:12, 561.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9467/16687 [00:16<00:12, 564.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9524/16687 [00:16<00:12, 560.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9582/16687 [00:16<00:12, 563.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9639/16687 [00:16<00:12, 560.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9696/16687 [00:17<00:12, 558.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9752/16687 [00:17<00:12, 548.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9807/16687 [00:17<00:12, 535.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9861/16687 [00:17<00:12, 526.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9914/16687 [00:17<00:12, 522.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9970/16687 [00:17<00:12, 532.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10026/16687 [00:17<00:12, 538.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10083/16687 [00:17<00:12, 547.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10139/16687 [00:17<00:11, 549.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10195/16687 [00:18<00:11, 549.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10251/16687 [00:18<00:11, 550.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10307/16687 [00:18<00:11, 543.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10364/16687 [00:18<00:11, 551.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10421/16687 [00:18<00:11, 555.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10477/16687 [00:18<00:11, 557.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10535/16687 [00:18<00:10, 560.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10592/16687 [00:18<00:10, 558.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10649/16687 [00:18<00:10, 561.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10706/16687 [00:18<00:10, 563.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10763/16687 [00:19<00:10, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10820/16687 [00:19<00:10, 565.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10877/16687 [00:19<00:10, 558.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10935/16687 [00:19<00:10, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10993/16687 [00:19<00:10, 568.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11051/16687 [00:19<00:09, 570.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11111/16687 [00:19<00:09, 577.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11169/16687 [00:19<00:09, 577.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11229/16687 [00:19<00:09, 581.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11289/16687 [00:19<00:09, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11348/16687 [00:20<00:09, 582.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11407/16687 [00:20<00:09, 581.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11466/16687 [00:20<00:09, 574.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11524/16687 [00:20<00:09, 573.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11582/16687 [00:20<00:08, 569.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11639/16687 [00:20<00:08, 565.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11696/16687 [00:20<00:08, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11754/16687 [00:20<00:08, 566.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11811/16687 [00:20<00:08, 566.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11868/16687 [00:20<00:08, 567.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11925/16687 [00:21<00:08, 568.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11982/16687 [00:21<00:08, 562.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12039/16687 [00:21<00:08, 551.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12096/16687 [00:21<00:08, 554.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12153/16687 [00:21<00:08, 558.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12209/16687 [00:21<00:08, 555.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12265/16687 [00:21<00:07, 553.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12321/16687 [00:21<00:07, 552.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12378/16687 [00:21<00:07, 557.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12435/16687 [00:21<00:07, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12491/16687 [00:22<00:07, 557.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12547/16687 [00:22<00:07, 556.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12603/16687 [00:22<00:07, 548.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12658/16687 [00:22<00:07, 548.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12715/16687 [00:22<00:07, 554.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12771/16687 [00:22<00:07, 553.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12828/16687 [00:22<00:06, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12885/16687 [00:22<00:06, 558.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12943/16687 [00:22<00:06, 562.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 13000/16687 [00:22<00:06, 559.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13056/16687 [00:23<00:06, 557.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13112/16687 [00:23<00:06, 556.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13168/16687 [00:23<00:06, 552.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13225/16687 [00:23<00:06, 556.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13282/16687 [00:23<00:06, 558.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13338/16687 [00:23<00:06, 554.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13395/16687 [00:23<00:05, 558.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13451/16687 [00:23<00:05, 558.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13509/16687 [00:23<00:05, 564.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13566/16687 [00:24<00:05, 559.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13622/16687 [00:24<00:05, 552.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13678/16687 [00:24<00:05, 539.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13733/16687 [00:24<00:05, 539.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13789/16687 [00:24<00:05, 544.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13848/16687 [00:24<00:05, 557.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13908/16687 [00:24<00:04, 567.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13968/16687 [00:24<00:04, 575.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14028/16687 [00:24<00:04, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14088/16687 [00:24<00:04, 583.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14148/16687 [00:25<00:04, 585.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14208/16687 [00:25<00:04, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14267/16687 [00:25<00:04, 582.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14326/16687 [00:25<00:04, 572.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14384/16687 [00:25<00:04, 572.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14442/16687 [00:25<00:03, 566.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14499/16687 [00:25<00:03, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14556/16687 [00:25<00:03, 559.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14613/16687 [00:25<00:03, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14669/16687 [00:25<00:03, 557.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14725/16687 [00:26<00:03, 555.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14783/16687 [00:26<00:03, 560.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14840/16687 [00:26<00:03, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14896/16687 [00:26<00:03, 557.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14952/16687 [00:26<00:03, 556.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15008/16687 [00:26<00:03, 544.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15063/16687 [00:26<00:03, 531.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15117/16687 [00:26<00:03, 523.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15170/16687 [00:26<00:02, 517.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15222/16687 [00:26<00:02, 513.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15274/16687 [00:27<00:02, 511.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15326/16687 [00:27<00:02, 509.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15377/16687 [00:27<00:02, 508.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15429/16687 [00:27<00:02, 510.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15488/16687 [00:27<00:02, 533.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15544/16687 [00:27<00:02, 539.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15602/16687 [00:27<00:01, 549.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15660/16687 [00:27<00:01, 556.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15718/16687 [00:27<00:01, 560.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▎ | 15776/16687 [00:28<00:01, 564.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15833/16687 [00:28<00:01, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15891/16687 [00:28<00:01, 569.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15949/16687 [00:28<00:01, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16007/16687 [00:28<00:01, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16064/16687 [00:28<00:01, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16120/16687 [00:28<00:01, 554.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16178/16687 [00:28<00:00, 561.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16236/16687 [00:28<00:00, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16293/16687 [00:28<00:00, 565.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16351/16687 [00:29<00:00, 568.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16409/16687 [00:29<00:00, 571.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16467/16687 [00:29<00:00, 572.36batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16525/16687 [00:29<00:00, 574.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16583/16687 [00:29<00:00, 567.02batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16640/16687 [00:29<00:00, 561.47batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   5%|▌           | 1/20 [00:29<09:26, 29.82s/epoch, loss=0.659, prev_loss=nan]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:33, 177.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 72/16687 [00:00<00:42, 386.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 131/16687 [00:00<00:34, 477.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 191/16687 [00:00<00:31, 523.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▍                               | 251/16687 [00:00<00:29, 548.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 307/16687 [00:00<00:29, 551.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 365/16687 [00:00<00:29, 558.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 423/16687 [00:00<00:28, 564.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 482/16687 [00:00<00:28, 571.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 540/16687 [00:01<00:28, 573.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 598/16687 [00:01<00:28, 574.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 656/16687 [00:01<00:27, 574.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 715/16687 [00:01<00:27, 578.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 773/16687 [00:01<00:27, 571.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 831/16687 [00:01<00:27, 570.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 889/16687 [00:01<00:28, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 947/16687 [00:01<00:27, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                             | 1006/16687 [00:01<00:27, 573.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1066/16687 [00:01<00:26, 578.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1126/16687 [00:02<00:26, 582.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1185/16687 [00:02<00:26, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1244/16687 [00:02<00:26, 582.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1303/16687 [00:02<00:26, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1361/16687 [00:02<00:27, 563.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▋                            | 1418/16687 [00:02<00:27, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1475/16687 [00:02<00:27, 558.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1531/16687 [00:02<00:27, 557.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1587/16687 [00:02<00:27, 556.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1643/16687 [00:02<00:27, 555.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1701/16687 [00:03<00:26, 561.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1758/16687 [00:03<00:26, 563.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1816/16687 [00:03<00:26, 566.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1873/16687 [00:03<00:26, 567.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1930/16687 [00:03<00:25, 567.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1987/16687 [00:03<00:25, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2045/16687 [00:03<00:25, 568.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2102/16687 [00:03<00:26, 558.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2160/16687 [00:03<00:25, 563.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2218/16687 [00:03<00:25, 566.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2276/16687 [00:04<00:25, 568.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2334/16687 [00:04<00:25, 569.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2392/16687 [00:04<00:25, 570.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2450/16687 [00:04<00:25, 566.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2508/16687 [00:04<00:24, 567.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2565/16687 [00:04<00:24, 568.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2622/16687 [00:04<00:24, 568.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2679/16687 [00:04<00:25, 555.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2736/16687 [00:04<00:24, 559.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2793/16687 [00:04<00:24, 558.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2850/16687 [00:05<00:24, 560.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2908/16687 [00:05<00:24, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2966/16687 [00:05<00:24, 567.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3024/16687 [00:05<00:23, 570.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3082/16687 [00:05<00:24, 566.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3140/16687 [00:05<00:23, 568.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3197/16687 [00:05<00:23, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3254/16687 [00:05<00:23, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3311/16687 [00:05<00:23, 557.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3367/16687 [00:06<00:24, 550.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3423/16687 [00:06<00:24, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3479/16687 [00:06<00:24, 549.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3539/16687 [00:06<00:23, 561.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3599/16687 [00:06<00:22, 570.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3657/16687 [00:06<00:22, 572.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3715/16687 [00:06<00:22, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3772/16687 [00:06<00:22, 567.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3829/16687 [00:06<00:22, 567.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3886/16687 [00:06<00:22, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3943/16687 [00:07<00:22, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4000/16687 [00:07<00:22, 565.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4057/16687 [00:07<00:22, 566.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4115/16687 [00:07<00:22, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4172/16687 [00:07<00:22, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4229/16687 [00:07<00:21, 567.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4286/16687 [00:07<00:21, 567.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4344/16687 [00:07<00:21, 569.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4402/16687 [00:07<00:21, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4460/16687 [00:07<00:21, 565.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4517/16687 [00:08<00:21, 562.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4575/16687 [00:08<00:21, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4633/16687 [00:08<00:21, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4691/16687 [00:08<00:21, 568.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4749/16687 [00:08<00:20, 569.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4807/16687 [00:08<00:20, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4865/16687 [00:08<00:21, 555.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████▏                     | 4921/16687 [00:08<00:21, 538.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4975/16687 [00:08<00:21, 532.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5034/16687 [00:08<00:21, 547.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5094/16687 [00:09<00:20, 560.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5152/16687 [00:09<00:20, 565.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5210/16687 [00:09<00:20, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5269/16687 [00:09<00:19, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5327/16687 [00:09<00:19, 574.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5387/16687 [00:09<00:19, 579.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5447/16687 [00:09<00:19, 582.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5506/16687 [00:09<00:19, 579.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5565/16687 [00:09<00:19, 573.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5623/16687 [00:09<00:19, 571.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5681/16687 [00:10<00:19, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5739/16687 [00:10<00:19, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5797/16687 [00:10<00:18, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5856/16687 [00:10<00:18, 576.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5915/16687 [00:10<00:18, 579.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5974/16687 [00:10<00:18, 581.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6033/16687 [00:10<00:18, 580.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6092/16687 [00:10<00:18, 573.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6150/16687 [00:10<00:18, 564.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6207/16687 [00:11<00:18, 560.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6264/16687 [00:11<00:18, 559.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6320/16687 [00:11<00:18, 557.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6376/16687 [00:11<00:18, 557.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6434/16687 [00:11<00:18, 561.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6492/16687 [00:11<00:18, 564.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6549/16687 [00:11<00:18, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6606/16687 [00:11<00:18, 559.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6664/16687 [00:11<00:17, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6721/16687 [00:11<00:17, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6778/16687 [00:12<00:17, 560.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6835/16687 [00:12<00:17, 559.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6893/16687 [00:12<00:17, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6951/16687 [00:12<00:17, 566.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7009/16687 [00:12<00:17, 568.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7067/16687 [00:12<00:16, 570.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7125/16687 [00:12<00:16, 571.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7183/16687 [00:12<00:16, 567.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7241/16687 [00:12<00:16, 568.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7299/16687 [00:12<00:16, 570.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7357/16687 [00:13<00:16, 566.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7414/16687 [00:13<00:16, 563.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7472/16687 [00:13<00:16, 565.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7530/16687 [00:13<00:16, 567.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7587/16687 [00:13<00:16, 567.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7645/16687 [00:13<00:15, 568.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7703/16687 [00:13<00:15, 569.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7760/16687 [00:13<00:15, 568.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7817/16687 [00:13<00:15, 569.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7874/16687 [00:13<00:15, 569.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▋                | 7931/16687 [00:14<00:15, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7989/16687 [00:14<00:15, 570.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8047/16687 [00:14<00:15, 571.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8105/16687 [00:14<00:15, 560.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8162/16687 [00:14<00:15, 550.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8218/16687 [00:14<00:15, 549.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▎               | 8273/16687 [00:14<00:15, 548.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8328/16687 [00:14<00:15, 548.08batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|███████████████▌               | 8383/16687 [00:14<00:15, 540.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8440/16687 [00:14<00:15, 547.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8495/16687 [00:15<00:15, 537.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8550/16687 [00:15<00:15, 540.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8607/16687 [00:15<00:14, 546.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8663/16687 [00:15<00:14, 549.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8721/16687 [00:15<00:14, 557.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8779/16687 [00:15<00:14, 563.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8836/16687 [00:15<00:13, 561.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8893/16687 [00:15<00:13, 560.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8950/16687 [00:15<00:13, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9008/16687 [00:16<00:13, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9065/16687 [00:16<00:13, 560.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9123/16687 [00:16<00:13, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9180/16687 [00:16<00:13, 561.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9238/16687 [00:16<00:13, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9295/16687 [00:16<00:13, 546.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9354/16687 [00:16<00:13, 558.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9411/16687 [00:16<00:12, 561.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9468/16687 [00:16<00:12, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9525/16687 [00:16<00:12, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9582/16687 [00:17<00:12, 556.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9639/16687 [00:17<00:12, 557.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9699/16687 [00:17<00:12, 567.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9756/16687 [00:17<00:12, 567.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9814/16687 [00:17<00:12, 570.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9873/16687 [00:17<00:11, 575.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9931/16687 [00:17<00:11, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9989/16687 [00:17<00:11, 569.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10046/16687 [00:17<00:11, 568.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10104/16687 [00:17<00:11, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10162/16687 [00:18<00:11, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10220/16687 [00:18<00:11, 571.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10278/16687 [00:18<00:11, 567.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10335/16687 [00:18<00:11, 564.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10392/16687 [00:18<00:11, 561.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10449/16687 [00:18<00:11, 560.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10507/16687 [00:18<00:10, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10565/16687 [00:18<00:10, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10622/16687 [00:18<00:10, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10680/16687 [00:18<00:10, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10737/16687 [00:19<00:10, 555.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10793/16687 [00:19<00:10, 556.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10851/16687 [00:19<00:10, 561.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10909/16687 [00:19<00:10, 564.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10966/16687 [00:19<00:10, 561.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11023/16687 [00:19<00:10, 559.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11081/16687 [00:19<00:09, 562.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11138/16687 [00:19<00:09, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11196/16687 [00:19<00:09, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11254/16687 [00:19<00:09, 565.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11311/16687 [00:20<00:09, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11369/16687 [00:20<00:09, 561.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11426/16687 [00:20<00:09, 561.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11483/16687 [00:20<00:09, 558.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11540/16687 [00:20<00:09, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11598/16687 [00:20<00:09, 564.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11655/16687 [00:20<00:09, 549.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11711/16687 [00:20<00:09, 539.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11768/16687 [00:20<00:08, 546.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11828/16687 [00:21<00:08, 560.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11886/16687 [00:21<00:08, 565.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11943/16687 [00:21<00:08, 563.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12000/16687 [00:21<00:08, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12057/16687 [00:21<00:08, 564.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12114/16687 [00:21<00:08, 565.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12171/16687 [00:21<00:07, 566.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12229/16687 [00:21<00:07, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12286/16687 [00:21<00:07, 568.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12343/16687 [00:21<00:07, 568.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12400/16687 [00:22<00:07, 568.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12457/16687 [00:22<00:07, 562.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12514/16687 [00:22<00:07, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12571/16687 [00:22<00:07, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12628/16687 [00:22<00:07, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12686/16687 [00:22<00:07, 568.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12744/16687 [00:22<00:06, 571.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12802/16687 [00:22<00:06, 572.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12860/16687 [00:22<00:06, 573.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12918/16687 [00:22<00:06, 574.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12976/16687 [00:23<00:06, 574.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13034/16687 [00:23<00:06, 567.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13091/16687 [00:23<00:06, 565.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13149/16687 [00:23<00:06, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13206/16687 [00:23<00:06, 568.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13263/16687 [00:23<00:06, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13321/16687 [00:23<00:05, 566.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13379/16687 [00:23<00:05, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13437/16687 [00:23<00:05, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13495/16687 [00:23<00:05, 569.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13553/16687 [00:24<00:05, 571.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13611/16687 [00:24<00:05, 571.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13669/16687 [00:24<00:05, 570.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13727/16687 [00:24<00:05, 566.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13785/16687 [00:24<00:05, 568.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13843/16687 [00:24<00:04, 569.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13901/16687 [00:24<00:04, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13959/16687 [00:24<00:04, 571.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14017/16687 [00:24<00:04, 572.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14075/16687 [00:24<00:04, 572.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14133/16687 [00:25<00:04, 572.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14191/16687 [00:25<00:04, 572.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14249/16687 [00:25<00:04, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14307/16687 [00:25<00:04, 572.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14365/16687 [00:25<00:04, 572.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14423/16687 [00:25<00:03, 572.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14481/16687 [00:25<00:03, 572.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14539/16687 [00:25<00:03, 572.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14597/16687 [00:25<00:03, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14655/16687 [00:25<00:03, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14713/16687 [00:26<00:03, 566.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14770/16687 [00:26<00:03, 565.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14827/16687 [00:26<00:03, 549.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14883/16687 [00:26<00:03, 542.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▊   | 14941/16687 [00:26<00:03, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14999/16687 [00:26<00:03, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15057/16687 [00:26<00:02, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15115/16687 [00:26<00:02, 568.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15173/16687 [00:26<00:02, 571.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15231/16687 [00:27<00:02, 572.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15289/16687 [00:27<00:02, 574.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15347/16687 [00:27<00:02, 575.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15405/16687 [00:27<00:02, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15463/16687 [00:27<00:02, 570.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15521/16687 [00:27<00:02, 572.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15579/16687 [00:27<00:01, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15637/16687 [00:27<00:01, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15695/16687 [00:27<00:01, 572.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15753/16687 [00:27<00:01, 572.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15811/16687 [00:28<00:01, 572.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15869/16687 [00:28<00:01, 571.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▋ | 15928/16687 [00:28<00:01, 575.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15986/16687 [00:28<00:01, 570.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16044/16687 [00:28<00:01, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16101/16687 [00:28<00:01, 556.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16158/16687 [00:28<00:00, 558.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16218/16687 [00:28<00:00, 568.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16277/16687 [00:28<00:00, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16337/16687 [00:28<00:00, 579.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16397/16687 [00:29<00:00, 583.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16457/16687 [00:29<00:00, 586.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16517/16687 [00:29<00:00, 587.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16576/16687 [00:29<00:00, 587.05batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16635/16687 [00:29<00:00, 584.04batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  10%|█          | 2/20 [00:59<08:55, 29.77s/epoch, loss=0.65, prev_loss=0.659]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 19/16687 [00:00<01:28, 188.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 71/16687 [00:00<00:43, 379.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 128/16687 [00:00<00:35, 462.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 185/16687 [00:00<00:32, 503.84batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   1%|▍                               | 243/16687 [00:00<00:31, 530.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 301/16687 [00:00<00:30, 545.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 359/16687 [00:00<00:29, 555.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 417/16687 [00:00<00:28, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 475/16687 [00:00<00:28, 566.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 533/16687 [00:01<00:28, 569.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 591/16687 [00:01<00:28, 572.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 649/16687 [00:01<00:27, 573.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 707/16687 [00:01<00:27, 573.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 765/16687 [00:01<00:27, 574.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 823/16687 [00:01<00:27, 574.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 881/16687 [00:01<00:27, 574.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 939/16687 [00:01<00:27, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 997/16687 [00:01<00:27, 569.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1055/16687 [00:01<00:27, 571.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1113/16687 [00:02<00:27, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1171/16687 [00:02<00:27, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1227/16687 [00:02<00:28, 543.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1282/16687 [00:02<00:28, 538.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1339/16687 [00:02<00:28, 546.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1394/16687 [00:02<00:28, 544.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1449/16687 [00:02<00:28, 533.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1503/16687 [00:02<00:28, 532.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1557/16687 [00:02<00:28, 528.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1610/16687 [00:02<00:28, 526.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1665/16687 [00:03<00:28, 530.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1719/16687 [00:03<00:28, 527.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1772/16687 [00:03<00:28, 528.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1825/16687 [00:03<00:28, 522.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1883/16687 [00:03<00:27, 537.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1937/16687 [00:03<00:27, 532.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1993/16687 [00:03<00:27, 540.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2050/16687 [00:03<00:26, 549.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2105/16687 [00:03<00:26, 547.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2163/16687 [00:03<00:26, 556.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2219/16687 [00:04<00:26, 549.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2277/16687 [00:04<00:25, 555.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2335/16687 [00:04<00:25, 560.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2393/16687 [00:04<00:25, 563.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2451/16687 [00:04<00:25, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2509/16687 [00:04<00:24, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2566/16687 [00:04<00:24, 567.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2623/16687 [00:04<00:25, 548.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2680/16687 [00:04<00:25, 554.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2738/16687 [00:05<00:24, 559.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2796/16687 [00:05<00:24, 563.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2854/16687 [00:05<00:24, 565.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2912/16687 [00:05<00:24, 567.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2971/16687 [00:05<00:23, 573.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3031/16687 [00:05<00:23, 578.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▋                         | 3091/16687 [00:05<00:23, 582.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3150/16687 [00:05<00:24, 557.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3208/16687 [00:05<00:24, 561.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3265/16687 [00:05<00:24, 544.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3323/16687 [00:06<00:24, 552.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3382/16687 [00:06<00:23, 561.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3439/16687 [00:06<00:23, 563.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3496/16687 [00:06<00:23, 565.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3553/16687 [00:06<00:23, 566.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3610/16687 [00:06<00:23, 567.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3667/16687 [00:06<00:23, 560.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3724/16687 [00:06<00:23, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3783/16687 [00:06<00:22, 566.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3842/16687 [00:06<00:22, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3901/16687 [00:07<00:22, 576.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3960/16687 [00:07<00:21, 579.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4019/16687 [00:07<00:21, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4078/16687 [00:07<00:21, 576.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4136/16687 [00:07<00:22, 563.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4195/16687 [00:07<00:21, 571.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4253/16687 [00:07<00:21, 573.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4311/16687 [00:07<00:21, 567.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4369/16687 [00:07<00:21, 571.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4428/16687 [00:07<00:21, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4486/16687 [00:08<00:21, 569.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4544/16687 [00:08<00:21, 568.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4601/16687 [00:08<00:21, 567.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4658/16687 [00:08<00:21, 567.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4715/16687 [00:08<00:21, 567.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4772/16687 [00:08<00:21, 567.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4831/16687 [00:08<00:20, 571.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4889/16687 [00:08<00:21, 559.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4946/16687 [00:08<00:21, 555.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5003/16687 [00:09<00:20, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5062/16687 [00:09<00:20, 567.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5119/16687 [00:09<00:20, 559.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5176/16687 [00:09<00:20, 549.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5232/16687 [00:09<00:21, 542.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5287/16687 [00:09<00:21, 537.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5341/16687 [00:09<00:21, 533.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5395/16687 [00:09<00:21, 529.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5448/16687 [00:09<00:21, 527.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5501/16687 [00:09<00:21, 524.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5554/16687 [00:10<00:21, 517.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5610/16687 [00:10<00:20, 529.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5667/16687 [00:10<00:20, 540.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5722/16687 [00:10<00:20, 541.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5778/16687 [00:10<00:20, 544.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5836/16687 [00:10<00:19, 552.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5892/16687 [00:10<00:19, 554.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5950/16687 [00:10<00:19, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6006/16687 [00:10<00:19, 554.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6062/16687 [00:10<00:19, 539.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6118/16687 [00:11<00:19, 543.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6173/16687 [00:11<00:19, 542.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6229/16687 [00:11<00:19, 546.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6287/16687 [00:11<00:18, 556.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6346/16687 [00:11<00:18, 564.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6403/16687 [00:11<00:18, 563.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6460/16687 [00:11<00:18, 554.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6516/16687 [00:11<00:18, 543.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6571/16687 [00:11<00:18, 544.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6626/16687 [00:11<00:18, 544.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6681/16687 [00:12<00:18, 541.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6739/16687 [00:12<00:18, 550.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6797/16687 [00:12<00:17, 557.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6855/16687 [00:12<00:17, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6913/16687 [00:12<00:17, 566.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6971/16687 [00:12<00:17, 569.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7029/16687 [00:12<00:16, 571.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7087/16687 [00:12<00:16, 571.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7145/16687 [00:12<00:16, 562.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7204/16687 [00:13<00:16, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▍                 | 7262/16687 [00:13<00:16, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7321/16687 [00:13<00:16, 573.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7379/16687 [00:13<00:16, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7437/16687 [00:13<00:16, 567.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7494/16687 [00:13<00:16, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7553/16687 [00:13<00:15, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7611/16687 [00:13<00:15, 573.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7670/16687 [00:13<00:15, 577.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7728/16687 [00:13<00:15, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7786/16687 [00:14<00:15, 570.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7844/16687 [00:14<00:15, 569.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7902/16687 [00:14<00:15, 569.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7960/16687 [00:14<00:15, 569.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8017/16687 [00:14<00:15, 569.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8074/16687 [00:14<00:15, 564.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8131/16687 [00:14<00:15, 566.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8188/16687 [00:14<00:14, 567.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8245/16687 [00:14<00:14, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8302/16687 [00:14<00:14, 567.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8359/16687 [00:15<00:14, 565.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8418/16687 [00:15<00:14, 570.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8476/16687 [00:15<00:14, 573.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8534/16687 [00:15<00:14, 567.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8591/16687 [00:15<00:14, 559.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8649/16687 [00:15<00:14, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8707/16687 [00:15<00:14, 565.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8764/16687 [00:15<00:14, 563.71batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  53%|████████████████▍              | 8821/16687 [00:15<00:13, 563.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8879/16687 [00:15<00:13, 565.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8936/16687 [00:16<00:13, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8993/16687 [00:16<00:13, 566.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9050/16687 [00:16<00:13, 564.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9107/16687 [00:16<00:13, 565.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9164/16687 [00:16<00:13, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9221/16687 [00:16<00:13, 566.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9278/16687 [00:16<00:13, 566.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9335/16687 [00:16<00:13, 553.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9391/16687 [00:16<00:13, 549.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9449/16687 [00:16<00:13, 556.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9507/16687 [00:17<00:12, 562.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9566/16687 [00:17<00:12, 570.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9624/16687 [00:17<00:12, 568.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9681/16687 [00:17<00:12, 568.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9739/16687 [00:17<00:12, 569.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9797/16687 [00:17<00:12, 569.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9855/16687 [00:17<00:11, 570.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9913/16687 [00:17<00:11, 570.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9971/16687 [00:17<00:12, 557.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10027/16687 [00:17<00:11, 556.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10083/16687 [00:18<00:12, 543.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10141/16687 [00:18<00:11, 553.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10200/16687 [00:18<00:11, 563.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10257/16687 [00:18<00:11, 561.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10314/16687 [00:18<00:11, 554.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10370/16687 [00:18<00:11, 549.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10427/16687 [00:18<00:11, 554.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10484/16687 [00:18<00:11, 559.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10540/16687 [00:18<00:11, 556.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10596/16687 [00:19<00:10, 555.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10653/16687 [00:19<00:10, 558.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10709/16687 [00:19<00:10, 556.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▎          | 10766/16687 [00:19<00:10, 559.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10823/16687 [00:19<00:10, 562.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10880/16687 [00:19<00:10, 558.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10936/16687 [00:19<00:10, 556.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10993/16687 [00:19<00:10, 559.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11050/16687 [00:19<00:10, 561.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11107/16687 [00:19<00:10, 555.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11164/16687 [00:20<00:09, 559.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11221/16687 [00:20<00:09, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11278/16687 [00:20<00:09, 561.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11336/16687 [00:20<00:09, 564.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11394/16687 [00:20<00:09, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11452/16687 [00:20<00:09, 569.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11510/16687 [00:20<00:09, 570.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11568/16687 [00:20<00:08, 571.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11626/16687 [00:20<00:08, 572.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11684/16687 [00:20<00:08, 568.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11741/16687 [00:21<00:08, 556.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11799/16687 [00:21<00:08, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11859/16687 [00:21<00:08, 570.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11919/16687 [00:21<00:08, 576.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11977/16687 [00:21<00:08, 571.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12035/16687 [00:21<00:08, 571.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12093/16687 [00:21<00:08, 570.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12151/16687 [00:21<00:07, 571.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12209/16687 [00:21<00:07, 570.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12267/16687 [00:21<00:07, 560.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12324/16687 [00:22<00:07, 545.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12379/16687 [00:22<00:08, 530.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12433/16687 [00:22<00:08, 521.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12486/16687 [00:22<00:08, 514.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12541/16687 [00:22<00:07, 522.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12600/16687 [00:22<00:07, 541.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12659/16687 [00:22<00:07, 555.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12718/16687 [00:22<00:07, 565.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12776/16687 [00:22<00:06, 567.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12835/16687 [00:23<00:06, 571.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12893/16687 [00:23<00:06, 570.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12951/16687 [00:23<00:06, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13009/16687 [00:23<00:06, 556.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13066/16687 [00:23<00:06, 560.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13123/16687 [00:23<00:06, 562.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13180/16687 [00:23<00:06, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13237/16687 [00:23<00:06, 565.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13294/16687 [00:23<00:05, 566.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13352/16687 [00:23<00:05, 567.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13409/16687 [00:24<00:05, 567.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13466/16687 [00:24<00:05, 567.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13524/16687 [00:24<00:05, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13582/16687 [00:24<00:05, 569.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13640/16687 [00:24<00:05, 569.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13698/16687 [00:24<00:05, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13756/16687 [00:24<00:05, 570.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13814/16687 [00:24<00:05, 571.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13872/16687 [00:24<00:04, 568.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13930/16687 [00:24<00:04, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13987/16687 [00:25<00:04, 569.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14045/16687 [00:25<00:04, 571.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14104/16687 [00:25<00:04, 574.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14162/16687 [00:25<00:04, 573.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14220/16687 [00:25<00:04, 573.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14278/16687 [00:25<00:04, 569.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14337/16687 [00:25<00:04, 572.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14397/16687 [00:25<00:03, 578.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14456/16687 [00:25<00:03, 580.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14515/16687 [00:25<00:03, 582.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14574/16687 [00:26<00:03, 577.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14632/16687 [00:26<00:03, 571.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14691/16687 [00:26<00:03, 576.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14749/16687 [00:26<00:03, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14807/16687 [00:26<00:03, 555.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14865/16687 [00:26<00:03, 560.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14922/16687 [00:26<00:03, 556.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14979/16687 [00:26<00:03, 560.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15036/16687 [00:26<00:02, 562.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15093/16687 [00:26<00:02, 564.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15150/16687 [00:27<00:02, 558.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15207/16687 [00:27<00:02, 559.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15265/16687 [00:27<00:02, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15323/16687 [00:27<00:02, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15381/16687 [00:27<00:02, 567.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15439/16687 [00:27<00:02, 569.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15496/16687 [00:27<00:02, 566.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15554/16687 [00:27<00:01, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15612/16687 [00:27<00:01, 568.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15669/16687 [00:28<00:01, 568.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15726/16687 [00:28<00:01, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▎ | 15783/16687 [00:28<00:01, 560.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15841/16687 [00:28<00:01, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15900/16687 [00:28<00:01, 570.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15959/16687 [00:28<00:01, 575.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16017/16687 [00:28<00:01, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16074/16687 [00:28<00:01, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16131/16687 [00:28<00:00, 558.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16188/16687 [00:28<00:00, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16244/16687 [00:29<00:00, 556.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16300/16687 [00:29<00:00, 541.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16356/16687 [00:29<00:00, 545.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16413/16687 [00:29<00:00, 550.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16470/16687 [00:29<00:00, 554.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16527/16687 [00:29<00:00, 557.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16585/16687 [00:29<00:00, 562.56batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16643/16687 [00:29<00:00, 567.34batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  15%|█▋         | 3/20 [01:29<08:27, 29.88s/epoch, loss=0.651, prev_loss=0.65]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 16/16687 [00:00<01:44, 159.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 67/16687 [00:00<00:45, 365.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 122/16687 [00:00<00:36, 449.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 174/16687 [00:00<00:34, 476.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 226/16687 [00:00<00:33, 489.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 281/16687 [00:00<00:32, 507.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 338/16687 [00:00<00:31, 525.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 397/16687 [00:00<00:29, 543.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 454/16687 [00:00<00:29, 550.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 511/16687 [00:01<00:29, 553.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 568/16687 [00:01<00:28, 557.23batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   4%|█▏                              | 625/16687 [00:01<00:28, 559.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 683/16687 [00:01<00:28, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 741/16687 [00:01<00:28, 565.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 799/16687 [00:01<00:27, 567.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 857/16687 [00:01<00:27, 568.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▊                              | 914/16687 [00:01<00:27, 566.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 971/16687 [00:01<00:27, 562.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1030/16687 [00:01<00:27, 569.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1088/16687 [00:02<00:27, 570.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1146/16687 [00:02<00:27, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1203/16687 [00:02<00:29, 531.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1260/16687 [00:02<00:28, 541.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1315/16687 [00:02<00:28, 534.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1372/16687 [00:02<00:28, 543.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1431/16687 [00:02<00:27, 556.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1490/16687 [00:02<00:26, 565.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1547/16687 [00:02<00:27, 553.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1603/16687 [00:02<00:27, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1659/16687 [00:03<00:27, 547.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1717/16687 [00:03<00:26, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1776/16687 [00:03<00:26, 563.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1835/16687 [00:03<00:26, 570.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1894/16687 [00:03<00:25, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1954/16687 [00:03<00:25, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2012/16687 [00:03<00:25, 569.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2070/16687 [00:03<00:25, 568.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2127/16687 [00:03<00:26, 554.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2183/16687 [00:04<00:26, 543.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2241/16687 [00:04<00:26, 551.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2300/16687 [00:04<00:25, 561.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2357/16687 [00:04<00:25, 558.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2413/16687 [00:04<00:25, 557.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2471/16687 [00:04<00:25, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2528/16687 [00:04<00:25, 556.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2585/16687 [00:04<00:25, 558.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2641/16687 [00:04<00:25, 555.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2697/16687 [00:04<00:25, 552.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2753/16687 [00:05<00:25, 549.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2811/16687 [00:05<00:24, 556.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2869/16687 [00:05<00:24, 560.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2926/16687 [00:05<00:24, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2984/16687 [00:05<00:24, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3042/16687 [00:05<00:24, 564.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3100/16687 [00:05<00:23, 567.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3158/16687 [00:05<00:23, 569.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3215/16687 [00:05<00:23, 565.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3272/16687 [00:05<00:23, 561.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3329/16687 [00:06<00:23, 559.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3388/16687 [00:06<00:23, 565.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3447/16687 [00:06<00:23, 571.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3505/16687 [00:06<00:23, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3563/16687 [00:06<00:22, 571.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3621/16687 [00:06<00:22, 570.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3679/16687 [00:06<00:22, 570.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3737/16687 [00:06<00:22, 571.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3795/16687 [00:06<00:22, 570.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3853/16687 [00:06<00:22, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▎                       | 3911/16687 [00:07<00:22, 570.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3969/16687 [00:07<00:22, 570.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4027/16687 [00:07<00:22, 570.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4085/16687 [00:07<00:22, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4142/16687 [00:07<00:22, 564.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4200/16687 [00:07<00:22, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4257/16687 [00:07<00:21, 567.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4315/16687 [00:07<00:21, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4373/16687 [00:07<00:21, 570.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4431/16687 [00:07<00:21, 569.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4489/16687 [00:08<00:21, 569.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4546/16687 [00:08<00:21, 569.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4603/16687 [00:08<00:21, 568.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4660/16687 [00:08<00:21, 568.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4717/16687 [00:08<00:21, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4774/16687 [00:08<00:21, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4831/16687 [00:08<00:20, 566.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4888/16687 [00:08<00:20, 567.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4945/16687 [00:08<00:20, 561.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5002/16687 [00:08<00:20, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5059/16687 [00:09<00:20, 565.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5116/16687 [00:09<00:20, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5173/16687 [00:09<00:20, 562.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5230/16687 [00:09<00:20, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5287/16687 [00:09<00:20, 564.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5344/16687 [00:09<00:20, 560.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5401/16687 [00:09<00:20, 560.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5460/16687 [00:09<00:19, 569.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5518/16687 [00:09<00:19, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5576/16687 [00:10<00:19, 570.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5634/16687 [00:10<00:19, 569.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5691/16687 [00:10<00:19, 559.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5748/16687 [00:10<00:19, 555.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5806/16687 [00:10<00:19, 562.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5863/16687 [00:10<00:19, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5920/16687 [00:10<00:19, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5977/16687 [00:10<00:18, 565.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6034/16687 [00:10<00:18, 566.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6091/16687 [00:10<00:18, 561.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6148/16687 [00:11<00:18, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6205/16687 [00:11<00:18, 564.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6262/16687 [00:11<00:18, 565.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6319/16687 [00:11<00:18, 558.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6378/16687 [00:11<00:18, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6437/16687 [00:11<00:17, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6495/16687 [00:11<00:17, 572.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6553/16687 [00:11<00:17, 570.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6611/16687 [00:11<00:17, 568.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6668/16687 [00:11<00:17, 568.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6725/16687 [00:12<00:17, 564.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6782/16687 [00:12<00:18, 541.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6837/16687 [00:12<00:18, 531.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6893/16687 [00:12<00:18, 537.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6949/16687 [00:12<00:17, 542.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7006/16687 [00:12<00:17, 550.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7063/16687 [00:12<00:17, 555.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7121/16687 [00:12<00:17, 561.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7180/16687 [00:12<00:16, 569.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7239/16687 [00:12<00:16, 573.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7297/16687 [00:13<00:16, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7356/16687 [00:13<00:16, 576.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7414/16687 [00:13<00:16, 576.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7472/16687 [00:13<00:15, 577.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7530/16687 [00:13<00:15, 575.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7588/16687 [00:13<00:15, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7646/16687 [00:13<00:15, 566.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7703/16687 [00:13<00:15, 565.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7760/16687 [00:13<00:15, 565.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7817/16687 [00:13<00:15, 557.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7873/16687 [00:14<00:15, 552.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▋                | 7929/16687 [00:14<00:15, 552.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7986/16687 [00:14<00:15, 556.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8043/16687 [00:14<00:15, 560.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8102/16687 [00:14<00:15, 569.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8161/16687 [00:14<00:14, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8220/16687 [00:14<00:14, 579.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8278/16687 [00:14<00:14, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8336/16687 [00:14<00:14, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8394/16687 [00:14<00:14, 577.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8452/16687 [00:15<00:14, 577.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8510/16687 [00:15<00:14, 571.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8568/16687 [00:15<00:14, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8626/16687 [00:15<00:14, 565.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8683/16687 [00:15<00:14, 566.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8741/16687 [00:15<00:13, 567.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8798/16687 [00:15<00:13, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8855/16687 [00:15<00:13, 563.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8912/16687 [00:15<00:13, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8969/16687 [00:16<00:13, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9025/16687 [00:16<00:13, 557.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9081/16687 [00:16<00:13, 557.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9138/16687 [00:16<00:13, 560.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9195/16687 [00:16<00:13, 559.61batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  55%|█████████████████▏             | 9251/16687 [00:16<00:13, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9309/16687 [00:16<00:13, 564.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9368/16687 [00:16<00:12, 571.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▌             | 9426/16687 [00:16<00:12, 568.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9483/16687 [00:16<00:12, 564.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9542/16687 [00:17<00:12, 570.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9600/16687 [00:17<00:12, 567.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9657/16687 [00:17<00:12, 561.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9715/16687 [00:17<00:12, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9773/16687 [00:17<00:12, 569.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9831/16687 [00:17<00:12, 570.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9889/16687 [00:17<00:11, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9947/16687 [00:17<00:11, 569.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10004/16687 [00:17<00:11, 567.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10061/16687 [00:17<00:11, 566.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10118/16687 [00:18<00:11, 565.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10175/16687 [00:18<00:11, 562.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10232/16687 [00:18<00:11, 561.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10289/16687 [00:18<00:11, 563.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10346/16687 [00:18<00:11, 561.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10404/16687 [00:18<00:11, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10462/16687 [00:18<00:10, 569.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10520/16687 [00:18<00:10, 569.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10577/16687 [00:18<00:10, 569.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10636/16687 [00:18<00:10, 575.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10695/16687 [00:19<00:10, 579.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10753/16687 [00:19<00:10, 576.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10811/16687 [00:19<00:10, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10868/16687 [00:19<00:10, 566.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▋          | 10925/16687 [00:19<00:10, 566.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10982/16687 [00:19<00:10, 566.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11039/16687 [00:19<00:09, 566.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11096/16687 [00:19<00:09, 563.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11153/16687 [00:19<00:09, 564.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11210/16687 [00:19<00:09, 564.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11267/16687 [00:20<00:09, 564.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11324/16687 [00:20<00:09, 560.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11381/16687 [00:20<00:09, 561.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11439/16687 [00:20<00:09, 563.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11496/16687 [00:20<00:09, 561.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11554/16687 [00:20<00:09, 565.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11612/16687 [00:20<00:08, 569.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11670/16687 [00:20<00:08, 571.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11728/16687 [00:20<00:08, 574.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11786/16687 [00:20<00:08, 569.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11843/16687 [00:21<00:08, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11900/16687 [00:21<00:08, 565.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11957/16687 [00:21<00:08, 559.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12014/16687 [00:21<00:08, 562.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12071/16687 [00:21<00:08, 564.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12128/16687 [00:21<00:08, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12186/16687 [00:21<00:07, 566.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12243/16687 [00:21<00:07, 558.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12300/16687 [00:21<00:07, 560.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12357/16687 [00:22<00:07, 561.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12414/16687 [00:22<00:07, 557.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12470/16687 [00:22<00:07, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12527/16687 [00:22<00:07, 557.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12584/16687 [00:22<00:07, 560.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12642/16687 [00:22<00:07, 565.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12700/16687 [00:22<00:07, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12759/16687 [00:22<00:06, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12817/16687 [00:22<00:06, 565.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12874/16687 [00:22<00:06, 563.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12931/16687 [00:23<00:06, 554.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12987/16687 [00:23<00:06, 543.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13042/16687 [00:23<00:06, 537.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13098/16687 [00:23<00:06, 541.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13153/16687 [00:23<00:06, 542.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13209/16687 [00:23<00:06, 547.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13267/16687 [00:23<00:06, 554.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13324/16687 [00:23<00:06, 558.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13381/16687 [00:23<00:05, 560.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13438/16687 [00:23<00:05, 563.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13495/16687 [00:24<00:05, 564.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13552/16687 [00:24<00:05, 560.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13609/16687 [00:24<00:05, 558.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13665/16687 [00:24<00:05, 552.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13722/16687 [00:24<00:05, 557.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13780/16687 [00:24<00:05, 561.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13837/16687 [00:24<00:05, 558.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13895/16687 [00:24<00:04, 562.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13954/16687 [00:24<00:04, 569.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14012/16687 [00:24<00:04, 571.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14070/16687 [00:25<00:04, 572.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14128/16687 [00:25<00:04, 574.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14186/16687 [00:25<00:04, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14244/16687 [00:25<00:04, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14303/16687 [00:25<00:04, 578.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14363/16687 [00:25<00:03, 582.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14422/16687 [00:25<00:03, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14481/16687 [00:25<00:03, 579.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14540/16687 [00:25<00:03, 581.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14599/16687 [00:25<00:03, 583.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14658/16687 [00:26<00:03, 585.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14717/16687 [00:26<00:03, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14776/16687 [00:26<00:03, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14834/16687 [00:26<00:03, 575.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14892/16687 [00:26<00:03, 575.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14950/16687 [00:26<00:03, 568.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15007/16687 [00:26<00:02, 564.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15064/16687 [00:26<00:02, 562.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15121/16687 [00:26<00:02, 558.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15177/16687 [00:26<00:02, 557.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15234/16687 [00:27<00:02, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15291/16687 [00:27<00:02, 559.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15347/16687 [00:27<00:02, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15405/16687 [00:27<00:02, 563.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15465/16687 [00:27<00:02, 571.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15523/16687 [00:27<00:02, 573.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15581/16687 [00:27<00:01, 574.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15639/16687 [00:27<00:01, 575.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15697/16687 [00:27<00:01, 575.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15755/16687 [00:28<00:01, 573.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15813/16687 [00:28<00:01, 572.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15871/16687 [00:28<00:01, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▋ | 15929/16687 [00:28<00:01, 566.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15986/16687 [00:28<00:01, 567.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16043/16687 [00:28<00:01, 563.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16100/16687 [00:28<00:01, 561.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16157/16687 [00:28<00:00, 559.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16214/16687 [00:28<00:00, 562.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16271/16687 [00:28<00:00, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16328/16687 [00:29<00:00, 560.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16385/16687 [00:29<00:00, 558.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16442/16687 [00:29<00:00, 561.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16499/16687 [00:29<00:00, 564.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16556/16687 [00:29<00:00, 561.59batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16613/16687 [00:29<00:00, 563.97batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16670/16687 [00:29<00:00, 565.17batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██        | 4/20 [01:59<07:57, 29.87s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 19/16687 [00:00<01:29, 186.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 67/16687 [00:00<00:46, 357.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 124/16687 [00:00<00:36, 450.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 182/16687 [00:00<00:33, 498.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 237/16687 [00:00<00:31, 516.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 294/16687 [00:00<00:30, 534.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 350/16687 [00:00<00:30, 541.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 406/16687 [00:00<00:29, 544.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 463/16687 [00:00<00:29, 552.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 519/16687 [00:01<00:29, 541.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 574/16687 [00:01<00:29, 541.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 630/16687 [00:01<00:29, 544.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 686/16687 [00:01<00:29, 546.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 741/16687 [00:01<00:29, 543.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 796/16687 [00:01<00:29, 537.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 850/16687 [00:01<00:30, 524.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 908/16687 [00:01<00:29, 538.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 965/16687 [00:01<00:28, 546.63batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   6%|█▉                             | 1023/16687 [00:01<00:28, 554.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|██                             | 1081/16687 [00:02<00:27, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1139/16687 [00:02<00:27, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1196/16687 [00:02<00:27, 562.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1253/16687 [00:02<00:27, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1310/16687 [00:02<00:27, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1369/16687 [00:02<00:27, 565.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1427/16687 [00:02<00:26, 566.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1485/16687 [00:02<00:26, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1543/16687 [00:02<00:26, 571.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1602/16687 [00:02<00:26, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1660/16687 [00:03<00:26, 574.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1719/16687 [00:03<00:25, 578.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1777/16687 [00:03<00:25, 575.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1835/16687 [00:03<00:25, 573.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1893/16687 [00:03<00:25, 571.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1951/16687 [00:03<00:26, 564.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2008/16687 [00:03<00:26, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2064/16687 [00:03<00:26, 556.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2120/16687 [00:03<00:26, 556.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2176/16687 [00:03<00:26, 556.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2232/16687 [00:04<00:25, 556.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2289/16687 [00:04<00:25, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2346/16687 [00:04<00:25, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2404/16687 [00:04<00:25, 562.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2461/16687 [00:04<00:25, 555.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2517/16687 [00:04<00:26, 539.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2572/16687 [00:04<00:26, 531.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2626/16687 [00:04<00:26, 526.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2680/16687 [00:04<00:26, 529.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2736/16687 [00:05<00:26, 536.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2794/16687 [00:05<00:25, 546.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2849/16687 [00:05<00:25, 547.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2905/16687 [00:05<00:25, 550.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2963/16687 [00:05<00:24, 556.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3021/16687 [00:05<00:24, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3078/16687 [00:05<00:24, 559.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3136/16687 [00:05<00:24, 563.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3193/16687 [00:05<00:24, 561.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3250/16687 [00:05<00:23, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3307/16687 [00:06<00:23, 561.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3364/16687 [00:06<00:23, 564.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3423/16687 [00:06<00:23, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3481/16687 [00:06<00:23, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3539/16687 [00:06<00:23, 569.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3596/16687 [00:06<00:23, 565.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3653/16687 [00:06<00:23, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3710/16687 [00:06<00:22, 564.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3767/16687 [00:06<00:23, 560.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3824/16687 [00:06<00:22, 562.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3881/16687 [00:07<00:22, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3938/16687 [00:07<00:22, 564.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3995/16687 [00:07<00:22, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4052/16687 [00:07<00:22, 559.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4111/16687 [00:07<00:22, 566.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4169/16687 [00:07<00:22, 568.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4228/16687 [00:07<00:21, 573.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4287/16687 [00:07<00:21, 576.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4345/16687 [00:07<00:21, 576.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4404/16687 [00:07<00:21, 578.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4463/16687 [00:08<00:21, 580.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4522/16687 [00:08<00:20, 583.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4582/16687 [00:08<00:20, 586.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4641/16687 [00:08<00:20, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4699/16687 [00:08<00:21, 561.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4756/16687 [00:08<00:21, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4814/16687 [00:08<00:20, 566.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4872/16687 [00:08<00:20, 568.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4930/16687 [00:08<00:20, 569.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4988/16687 [00:08<00:20, 570.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5046/16687 [00:09<00:20, 570.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5104/16687 [00:09<00:20, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5162/16687 [00:09<00:20, 568.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5219/16687 [00:09<00:20, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5278/16687 [00:09<00:19, 571.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5336/16687 [00:09<00:20, 557.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5392/16687 [00:09<00:20, 545.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5447/16687 [00:09<00:20, 535.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5501/16687 [00:09<00:21, 528.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5554/16687 [00:10<00:21, 525.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5612/16687 [00:10<00:20, 539.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5671/16687 [00:10<00:19, 552.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5727/16687 [00:10<00:19, 553.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5785/16687 [00:10<00:19, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5843/16687 [00:10<00:19, 562.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5900/16687 [00:10<00:19, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5958/16687 [00:10<00:19, 564.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6015/16687 [00:10<00:19, 548.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6070/16687 [00:10<00:19, 539.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6125/16687 [00:11<00:19, 538.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6182/16687 [00:11<00:19, 546.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6239/16687 [00:11<00:18, 552.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6295/16687 [00:11<00:18, 551.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6351/16687 [00:11<00:18, 552.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6408/16687 [00:11<00:18, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6465/16687 [00:11<00:18, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6522/16687 [00:11<00:18, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6579/16687 [00:11<00:17, 563.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6636/16687 [00:11<00:17, 564.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6693/16687 [00:12<00:17, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6750/16687 [00:12<00:17, 566.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6807/16687 [00:12<00:17, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6864/16687 [00:12<00:17, 562.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6921/16687 [00:12<00:17, 564.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6978/16687 [00:12<00:17, 564.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7035/16687 [00:12<00:17, 560.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7092/16687 [00:12<00:17, 562.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7149/16687 [00:12<00:16, 564.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7206/16687 [00:12<00:16, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▍                 | 7264/16687 [00:13<00:16, 567.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7322/16687 [00:13<00:16, 569.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7380/16687 [00:13<00:16, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7438/16687 [00:13<00:16, 570.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7496/16687 [00:13<00:16, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7553/16687 [00:13<00:16, 566.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7610/16687 [00:13<00:16, 564.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7667/16687 [00:13<00:16, 559.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7726/16687 [00:13<00:15, 566.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7785/16687 [00:13<00:15, 571.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7844/16687 [00:14<00:15, 576.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7903/16687 [00:14<00:15, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7961/16687 [00:14<00:15, 577.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8019/16687 [00:14<00:15, 559.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8077/16687 [00:14<00:15, 562.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8134/16687 [00:14<00:15, 564.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8192/16687 [00:14<00:14, 567.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8250/16687 [00:14<00:14, 568.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8308/16687 [00:14<00:14, 569.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8365/16687 [00:15<00:14, 569.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8423/16687 [00:15<00:14, 570.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8481/16687 [00:15<00:14, 566.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8538/16687 [00:15<00:14, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8595/16687 [00:15<00:14, 561.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8653/16687 [00:15<00:14, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8711/16687 [00:15<00:14, 566.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8768/16687 [00:15<00:14, 564.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8826/16687 [00:15<00:13, 567.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8884/16687 [00:15<00:13, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8941/16687 [00:16<00:13, 565.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8999/16687 [00:16<00:13, 567.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9057/16687 [00:16<00:13, 568.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9114/16687 [00:16<00:13, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9171/16687 [00:16<00:13, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9229/16687 [00:16<00:13, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9286/16687 [00:16<00:13, 567.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9344/16687 [00:16<00:12, 568.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9402/16687 [00:16<00:12, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9460/16687 [00:16<00:12, 570.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9518/16687 [00:17<00:13, 550.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9576/16687 [00:17<00:12, 558.13batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  58%|█████████████████▉             | 9634/16687 [00:17<00:12, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9692/16687 [00:17<00:12, 565.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9750/16687 [00:17<00:12, 566.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9808/16687 [00:17<00:12, 568.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9865/16687 [00:17<00:12, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9923/16687 [00:17<00:11, 566.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9981/16687 [00:17<00:11, 569.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10038/16687 [00:17<00:11, 554.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10094/16687 [00:18<00:11, 556.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10150/16687 [00:18<00:11, 548.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10208/16687 [00:18<00:11, 555.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10264/16687 [00:18<00:11, 550.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10320/16687 [00:18<00:11, 553.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10376/16687 [00:18<00:11, 546.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10435/16687 [00:18<00:11, 559.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10493/16687 [00:18<00:10, 565.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10552/16687 [00:18<00:10, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10612/16687 [00:18<00:10, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10670/16687 [00:19<00:10, 567.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10727/16687 [00:19<00:10, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10785/16687 [00:19<00:10, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10843/16687 [00:19<00:10, 567.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10900/16687 [00:19<00:10, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10958/16687 [00:19<00:10, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11015/16687 [00:19<00:10, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11073/16687 [00:19<00:09, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11132/16687 [00:19<00:09, 570.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11190/16687 [00:20<00:09, 557.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11246/16687 [00:20<00:09, 556.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11304/16687 [00:20<00:09, 560.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11362/16687 [00:20<00:09, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11419/16687 [00:20<00:09, 565.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11479/16687 [00:20<00:09, 572.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11537/16687 [00:20<00:08, 574.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11597/16687 [00:20<00:08, 579.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11657/16687 [00:20<00:08, 583.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11717/16687 [00:20<00:08, 585.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11776/16687 [00:21<00:08, 580.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11835/16687 [00:21<00:08, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11893/16687 [00:21<00:08, 567.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11950/16687 [00:21<00:08, 568.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12007/16687 [00:21<00:08, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12064/16687 [00:21<00:08, 561.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12121/16687 [00:21<00:08, 555.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12178/16687 [00:21<00:08, 558.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12234/16687 [00:21<00:07, 559.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12291/16687 [00:21<00:07, 562.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12348/16687 [00:22<00:07, 560.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12405/16687 [00:22<00:07, 555.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12461/16687 [00:22<00:07, 551.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12517/16687 [00:22<00:07, 553.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12575/16687 [00:22<00:07, 559.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12634/16687 [00:22<00:07, 567.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12693/16687 [00:22<00:06, 572.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12751/16687 [00:22<00:06, 573.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12809/16687 [00:22<00:06, 566.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12866/16687 [00:22<00:06, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12924/16687 [00:23<00:06, 566.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12982/16687 [00:23<00:06, 568.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13039/16687 [00:23<00:06, 566.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13097/16687 [00:23<00:06, 568.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13154/16687 [00:23<00:06, 568.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13211/16687 [00:23<00:06, 568.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13268/16687 [00:23<00:06, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13326/16687 [00:23<00:05, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13383/16687 [00:23<00:05, 551.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13441/16687 [00:23<00:05, 557.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13500/16687 [00:24<00:05, 565.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13558/16687 [00:24<00:05, 567.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13616/16687 [00:24<00:05, 568.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13674/16687 [00:24<00:05, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13732/16687 [00:24<00:05, 570.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13790/16687 [00:24<00:05, 565.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13848/16687 [00:24<00:05, 567.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13907/16687 [00:24<00:04, 573.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13967/16687 [00:24<00:04, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14027/16687 [00:25<00:04, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14087/16687 [00:25<00:04, 585.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14147/16687 [00:25<00:04, 587.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14206/16687 [00:25<00:04, 587.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14265/16687 [00:25<00:04, 580.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14324/16687 [00:25<00:04, 577.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14382/16687 [00:25<00:04, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14440/16687 [00:25<00:03, 566.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14497/16687 [00:25<00:03, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14555/16687 [00:25<00:03, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14612/16687 [00:26<00:03, 564.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14670/16687 [00:26<00:03, 566.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14727/16687 [00:26<00:03, 561.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14785/16687 [00:26<00:03, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14842/16687 [00:26<00:03, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14901/16687 [00:26<00:03, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14959/16687 [00:26<00:03, 572.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15018/16687 [00:26<00:02, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15076/16687 [00:26<00:02, 574.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15135/16687 [00:26<00:02, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15194/16687 [00:27<00:02, 580.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15253/16687 [00:27<00:02, 562.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15310/16687 [00:27<00:02, 555.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15366/16687 [00:27<00:02, 552.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15422/16687 [00:27<00:02, 545.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15477/16687 [00:27<00:02, 544.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15536/16687 [00:27<00:02, 555.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15595/16687 [00:27<00:01, 564.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15654/16687 [00:27<00:01, 570.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15713/16687 [00:27<00:01, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▎ | 15772/16687 [00:28<00:01, 579.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15831/16687 [00:28<00:01, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15890/16687 [00:28<00:01, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15949/16687 [00:28<00:01, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16008/16687 [00:28<00:01, 585.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16067/16687 [00:28<00:01, 584.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16126/16687 [00:28<00:00, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16184/16687 [00:28<00:00, 558.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16240/16687 [00:28<00:00, 553.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16296/16687 [00:29<00:00, 544.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16352/16687 [00:29<00:00, 545.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16408/16687 [00:29<00:00, 547.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16464/16687 [00:29<00:00, 548.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16520/16687 [00:29<00:00, 549.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16576/16687 [00:29<00:00, 538.17batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16630/16687 [00:29<00:00, 529.87batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|██████████████████████████████| 16687/16687 [00:29<00:00, 423.52batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██        | 4/20 [02:29<07:57, 29.87s/epoch, loss=0.651, prev_loss=0.651]\u001b[AINFO:pykeen.evaluation.evaluator:Evaluation took 45.77s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 5: 0.003925417075564278. Saved model weights to /work/.data/pykeen/checkpoints/best-model-weights-788cfe08-4ab7-44b1-a674-0b8e013ba656.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 5.\n",
      "Training epochs on cuda:0:  25%|██▌       | 5/20 [03:15<11:36, 46.40s/epoch, loss=0.651, prev_loss=0.651]\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 16/16687 [00:00<01:44, 159.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 74/16687 [00:00<00:41, 404.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 132/16687 [00:00<00:34, 481.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 186/16687 [00:00<00:32, 502.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 241/16687 [00:00<00:31, 517.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 293/16687 [00:00<00:31, 514.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 349/16687 [00:00<00:30, 527.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 406/16687 [00:00<00:30, 538.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 463/16687 [00:00<00:29, 545.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 520/16687 [00:01<00:29, 551.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 577/16687 [00:01<00:29, 554.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 633/16687 [00:01<00:29, 552.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 690/16687 [00:01<00:28, 555.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 747/16687 [00:01<00:28, 557.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 804/16687 [00:01<00:28, 558.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 861/16687 [00:01<00:28, 559.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▊                              | 917/16687 [00:01<00:28, 558.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 973/16687 [00:01<00:28, 543.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1028/16687 [00:01<00:28, 543.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1085/16687 [00:02<00:28, 549.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1142/16687 [00:02<00:28, 554.03batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   7%|██▏                            | 1199/16687 [00:02<00:27, 557.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1255/16687 [00:02<00:27, 556.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1312/16687 [00:02<00:27, 559.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1370/16687 [00:02<00:27, 565.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1429/16687 [00:02<00:26, 569.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1487/16687 [00:02<00:26, 571.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1546/16687 [00:02<00:26, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1605/16687 [00:02<00:26, 577.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1664/16687 [00:03<00:25, 578.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1723/16687 [00:03<00:25, 580.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1782/16687 [00:03<00:25, 578.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1840/16687 [00:03<00:25, 574.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1898/16687 [00:03<00:25, 576.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1956/16687 [00:03<00:25, 575.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2014/16687 [00:03<00:25, 574.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2072/16687 [00:03<00:25, 570.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2130/16687 [00:03<00:26, 559.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2186/16687 [00:03<00:26, 551.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2245/16687 [00:04<00:25, 561.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2304/16687 [00:04<00:25, 569.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2363/16687 [00:04<00:24, 574.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▍                          | 2422/16687 [00:04<00:24, 577.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2480/16687 [00:04<00:24, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2538/16687 [00:04<00:24, 573.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2596/16687 [00:04<00:24, 571.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2654/16687 [00:04<00:24, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2713/16687 [00:04<00:24, 573.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2772/16687 [00:04<00:24, 577.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2831/16687 [00:05<00:23, 579.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2889/16687 [00:05<00:23, 579.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2947/16687 [00:05<00:23, 577.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3005/16687 [00:05<00:24, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3062/16687 [00:05<00:24, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3119/16687 [00:05<00:24, 563.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3176/16687 [00:05<00:24, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3233/16687 [00:05<00:23, 561.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3290/16687 [00:05<00:23, 561.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3347/16687 [00:06<00:23, 561.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3404/16687 [00:06<00:23, 559.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3461/16687 [00:06<00:23, 560.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3518/16687 [00:06<00:23, 561.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3575/16687 [00:06<00:23, 561.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3632/16687 [00:06<00:23, 562.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3689/16687 [00:06<00:23, 563.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3746/16687 [00:06<00:23, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3802/16687 [00:06<00:23, 552.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3858/16687 [00:06<00:23, 541.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▎                       | 3913/16687 [00:07<00:23, 534.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3968/16687 [00:07<00:23, 538.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4025/16687 [00:07<00:23, 545.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4080/16687 [00:07<00:23, 543.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4135/16687 [00:07<00:23, 541.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4190/16687 [00:07<00:23, 532.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4245/16687 [00:07<00:23, 537.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4300/16687 [00:07<00:22, 538.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4355/16687 [00:07<00:22, 541.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4410/16687 [00:07<00:22, 536.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4467/16687 [00:08<00:22, 545.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4524/16687 [00:08<00:22, 551.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4581/16687 [00:08<00:21, 554.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4637/16687 [00:08<00:21, 554.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4694/16687 [00:08<00:21, 555.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4750/16687 [00:08<00:21, 544.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4805/16687 [00:08<00:22, 533.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4861/16687 [00:08<00:21, 538.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████▏                     | 4918/16687 [00:08<00:21, 545.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4973/16687 [00:08<00:21, 546.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5028/16687 [00:09<00:21, 546.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5083/16687 [00:09<00:21, 547.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5138/16687 [00:09<00:21, 546.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5193/16687 [00:09<00:21, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▊                     | 5250/16687 [00:09<00:20, 551.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5308/16687 [00:09<00:20, 559.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5364/16687 [00:09<00:20, 557.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5421/16687 [00:09<00:20, 559.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5477/16687 [00:09<00:20, 555.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5534/16687 [00:09<00:19, 558.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▍                    | 5590/16687 [00:10<00:19, 555.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5647/16687 [00:10<00:19, 557.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5704/16687 [00:10<00:19, 559.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5761/16687 [00:10<00:19, 560.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5819/16687 [00:10<00:19, 565.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5876/16687 [00:10<00:19, 561.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5934/16687 [00:10<00:19, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5991/16687 [00:10<00:19, 559.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6048/16687 [00:10<00:19, 558.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6104/16687 [00:11<00:19, 551.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6160/16687 [00:11<00:19, 553.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6216/16687 [00:11<00:18, 552.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6272/16687 [00:11<00:18, 551.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6330/16687 [00:11<00:18, 558.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6386/16687 [00:11<00:18, 556.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6442/16687 [00:11<00:18, 553.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6499/16687 [00:11<00:18, 557.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6555/16687 [00:11<00:18, 554.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6611/16687 [00:11<00:18, 552.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6668/16687 [00:12<00:18, 556.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6724/16687 [00:12<00:18, 552.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6780/16687 [00:12<00:17, 551.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6837/16687 [00:12<00:17, 555.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6893/16687 [00:12<00:17, 553.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6950/16687 [00:12<00:17, 555.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7006/16687 [00:12<00:17, 556.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7062/16687 [00:12<00:17, 554.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7118/16687 [00:12<00:17, 552.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7174/16687 [00:12<00:17, 551.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7230/16687 [00:13<00:17, 551.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7286/16687 [00:13<00:17, 550.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7343/16687 [00:13<00:16, 554.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7399/16687 [00:13<00:16, 554.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7455/16687 [00:13<00:16, 552.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7512/16687 [00:13<00:16, 556.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7568/16687 [00:13<00:16, 554.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7624/16687 [00:13<00:16, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7680/16687 [00:13<00:16, 541.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7735/16687 [00:13<00:16, 535.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7790/16687 [00:14<00:16, 539.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7847/16687 [00:14<00:16, 546.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7902/16687 [00:14<00:16, 547.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7957/16687 [00:14<00:15, 547.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8012/16687 [00:14<00:15, 548.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8067/16687 [00:14<00:15, 548.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8122/16687 [00:14<00:15, 548.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8177/16687 [00:14<00:15, 548.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8232/16687 [00:14<00:15, 532.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8289/16687 [00:14<00:15, 541.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8346/16687 [00:15<00:15, 549.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8402/16687 [00:15<00:15, 550.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8459/16687 [00:15<00:14, 554.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8515/16687 [00:15<00:14, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8572/16687 [00:15<00:14, 557.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8628/16687 [00:15<00:14, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8684/16687 [00:15<00:14, 554.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8740/16687 [00:15<00:14, 553.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8796/16687 [00:15<00:14, 553.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8852/16687 [00:15<00:14, 552.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8908/16687 [00:16<00:14, 552.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8964/16687 [00:16<00:14, 551.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9020/16687 [00:16<00:13, 549.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9077/16687 [00:16<00:13, 553.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9133/16687 [00:16<00:13, 552.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9190/16687 [00:16<00:13, 556.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9246/16687 [00:16<00:13, 554.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9302/16687 [00:16<00:13, 554.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9358/16687 [00:16<00:13, 554.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9414/16687 [00:17<00:13, 555.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9470/16687 [00:17<00:13, 553.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9527/16687 [00:17<00:12, 556.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9584/16687 [00:17<00:12, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9641/16687 [00:17<00:12, 559.89batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  58%|██████████████████             | 9699/16687 [00:17<00:12, 563.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████▏            | 9757/16687 [00:17<00:12, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9815/16687 [00:17<00:12, 568.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9873/16687 [00:17<00:11, 571.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9931/16687 [00:17<00:11, 572.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9990/16687 [00:18<00:11, 576.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10048/16687 [00:18<00:11, 577.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10106/16687 [00:18<00:11, 575.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10164/16687 [00:18<00:11, 575.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10223/16687 [00:18<00:11, 578.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10281/16687 [00:18<00:11, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10339/16687 [00:18<00:10, 577.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10398/16687 [00:18<00:10, 580.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10457/16687 [00:18<00:10, 578.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10515/16687 [00:18<00:10, 572.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10573/16687 [00:19<00:10, 566.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10630/16687 [00:19<00:10, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10687/16687 [00:19<00:10, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10743/16687 [00:19<00:10, 555.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10800/16687 [00:19<00:10, 557.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10856/16687 [00:19<00:10, 555.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10913/16687 [00:19<00:10, 559.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10969/16687 [00:19<00:10, 556.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11025/16687 [00:19<00:10, 556.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11082/16687 [00:19<00:10, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11138/16687 [00:20<00:09, 557.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11195/16687 [00:20<00:09, 559.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11251/16687 [00:20<00:09, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11308/16687 [00:20<00:09, 557.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11365/16687 [00:20<00:09, 558.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11422/16687 [00:20<00:09, 560.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11479/16687 [00:20<00:09, 556.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11535/16687 [00:20<00:09, 555.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11591/16687 [00:20<00:09, 555.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11650/16687 [00:20<00:08, 564.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11708/16687 [00:21<00:08, 567.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11767/16687 [00:21<00:08, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11825/16687 [00:21<00:08, 572.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11884/16687 [00:21<00:08, 575.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11942/16687 [00:21<00:08, 575.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12001/16687 [00:21<00:08, 577.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12059/16687 [00:21<00:08, 576.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12117/16687 [00:21<00:07, 575.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12175/16687 [00:21<00:07, 575.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12233/16687 [00:21<00:07, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12291/16687 [00:22<00:07, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12349/16687 [00:22<00:07, 573.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12407/16687 [00:22<00:07, 573.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12465/16687 [00:22<00:07, 573.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12523/16687 [00:22<00:07, 572.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12581/16687 [00:22<00:07, 573.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12639/16687 [00:22<00:07, 573.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12697/16687 [00:22<00:06, 573.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12756/16687 [00:22<00:06, 576.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12814/16687 [00:22<00:06, 576.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12872/16687 [00:23<00:06, 570.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12930/16687 [00:23<00:06, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12987/16687 [00:23<00:06, 563.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13045/16687 [00:23<00:06, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13103/16687 [00:23<00:06, 568.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13161/16687 [00:23<00:06, 570.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13219/16687 [00:23<00:06, 571.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13277/16687 [00:23<00:05, 573.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13335/16687 [00:23<00:05, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13393/16687 [00:24<00:05, 572.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13451/16687 [00:24<00:05, 572.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13509/16687 [00:24<00:05, 573.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13567/16687 [00:24<00:05, 568.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13624/16687 [00:24<00:05, 568.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13681/16687 [00:24<00:05, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13738/16687 [00:24<00:05, 542.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13795/16687 [00:24<00:05, 549.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13852/16687 [00:24<00:05, 553.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13909/16687 [00:24<00:04, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13965/16687 [00:25<00:04, 554.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14021/16687 [00:25<00:04, 553.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14078/16687 [00:25<00:04, 557.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14134/16687 [00:25<00:04, 548.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14192/16687 [00:25<00:04, 556.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14250/16687 [00:25<00:04, 560.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14309/16687 [00:25<00:04, 567.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14368/16687 [00:25<00:04, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14426/16687 [00:25<00:03, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14484/16687 [00:25<00:03, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14542/16687 [00:26<00:03, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14600/16687 [00:26<00:03, 573.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14658/16687 [00:26<00:03, 573.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14716/16687 [00:26<00:03, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14773/16687 [00:26<00:03, 565.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14830/16687 [00:26<00:03, 566.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14887/16687 [00:26<00:03, 563.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▊   | 14946/16687 [00:26<00:03, 570.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15004/16687 [00:26<00:02, 571.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15062/16687 [00:26<00:02, 573.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15120/16687 [00:27<00:02, 568.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15177/16687 [00:27<00:02, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15234/16687 [00:27<00:02, 563.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15291/16687 [00:27<00:02, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15348/16687 [00:27<00:02, 559.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15406/16687 [00:27<00:02, 563.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15465/16687 [00:27<00:02, 569.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15523/16687 [00:27<00:02, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15581/16687 [00:27<00:01, 571.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15640/16687 [00:27<00:01, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15698/16687 [00:28<00:01, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15756/16687 [00:28<00:01, 574.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15815/16687 [00:28<00:01, 577.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15873/16687 [00:28<00:01, 568.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▋ | 15930/16687 [00:28<00:01, 568.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15987/16687 [00:28<00:01, 568.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16044/16687 [00:28<00:01, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16102/16687 [00:28<00:01, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16160/16687 [00:28<00:00, 569.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16219/16687 [00:28<00:00, 574.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16278/16687 [00:29<00:00, 577.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16336/16687 [00:29<00:00, 576.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16394/16687 [00:29<00:00, 574.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16452/16687 [00:29<00:00, 566.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16509/16687 [00:29<00:00, 563.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16568/16687 [00:29<00:00, 569.58batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16627/16687 [00:29<00:00, 574.30batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16685/16687 [00:29<00:00, 574.08batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  30%|███▎       | 6/20 [03:45<09:31, 40.83s/epoch, loss=0.65, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 15/16687 [00:00<01:52, 148.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 66/16687 [00:00<00:46, 359.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 123/16687 [00:00<00:36, 455.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 178/16687 [00:00<00:33, 491.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 234/16687 [00:00<00:31, 515.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 290/16687 [00:00<00:30, 530.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 346/16687 [00:00<00:30, 539.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 402/16687 [00:00<00:29, 545.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 458/16687 [00:00<00:29, 550.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 514/16687 [00:01<00:29, 548.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 569/16687 [00:01<00:29, 546.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 627/16687 [00:01<00:28, 553.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 684/16687 [00:01<00:28, 556.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 740/16687 [00:01<00:29, 543.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 795/16687 [00:01<00:29, 536.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 849/16687 [00:01<00:29, 534.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 906/16687 [00:01<00:29, 543.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 962/16687 [00:01<00:28, 547.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1018/16687 [00:01<00:28, 551.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1076/16687 [00:02<00:28, 556.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1132/16687 [00:02<00:27, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1188/16687 [00:02<00:28, 546.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1245/16687 [00:02<00:27, 553.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1301/16687 [00:02<00:27, 553.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1359/16687 [00:02<00:27, 559.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▋                            | 1415/16687 [00:02<00:27, 558.90batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   9%|██▋                            | 1473/16687 [00:02<00:27, 562.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1531/16687 [00:02<00:26, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1588/16687 [00:02<00:26, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1645/16687 [00:03<00:26, 561.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1702/16687 [00:03<00:26, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1759/16687 [00:03<00:26, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1816/16687 [00:03<00:26, 561.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1873/16687 [00:03<00:26, 560.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1930/16687 [00:03<00:26, 558.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1986/16687 [00:03<00:26, 558.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2043/16687 [00:03<00:26, 561.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2100/16687 [00:03<00:25, 563.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2157/16687 [00:03<00:25, 561.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2215/16687 [00:04<00:25, 564.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2273/16687 [00:04<00:25, 566.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2331/16687 [00:04<00:25, 568.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2389/16687 [00:04<00:25, 569.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2446/16687 [00:04<00:25, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2503/16687 [00:04<00:25, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2561/16687 [00:04<00:24, 566.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2619/16687 [00:04<00:24, 568.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2677/16687 [00:04<00:24, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2735/16687 [00:04<00:24, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2793/16687 [00:05<00:24, 570.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2851/16687 [00:05<00:24, 569.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2908/16687 [00:05<00:24, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2965/16687 [00:05<00:24, 564.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3022/16687 [00:05<00:24, 564.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3079/16687 [00:05<00:24, 563.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3136/16687 [00:05<00:24, 562.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3195/16687 [00:05<00:23, 568.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3252/16687 [00:05<00:23, 568.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3310/16687 [00:05<00:23, 570.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3368/16687 [00:06<00:23, 564.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3425/16687 [00:06<00:23, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3482/16687 [00:06<00:23, 555.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3538/16687 [00:06<00:23, 549.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3596/16687 [00:06<00:23, 555.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3652/16687 [00:06<00:23, 555.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3710/16687 [00:06<00:23, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3766/16687 [00:06<00:23, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3822/16687 [00:06<00:23, 557.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3878/16687 [00:07<00:23, 556.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3934/16687 [00:07<00:22, 556.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3990/16687 [00:07<00:22, 556.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4048/16687 [00:07<00:22, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4106/16687 [00:07<00:22, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4163/16687 [00:07<00:22, 560.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4220/16687 [00:07<00:22, 558.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4276/16687 [00:07<00:22, 557.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4334/16687 [00:07<00:21, 563.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4392/16687 [00:07<00:21, 565.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4449/16687 [00:08<00:21, 562.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4506/16687 [00:08<00:21, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4563/16687 [00:08<00:21, 562.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4620/16687 [00:08<00:21, 560.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4677/16687 [00:08<00:21, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4734/16687 [00:08<00:21, 563.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4791/16687 [00:08<00:21, 565.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4848/16687 [00:08<00:20, 565.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4906/16687 [00:08<00:20, 567.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4963/16687 [00:08<00:20, 568.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5020/16687 [00:09<00:20, 563.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5077/16687 [00:09<00:20, 562.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5135/16687 [00:09<00:20, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5192/16687 [00:09<00:20, 564.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▊                     | 5249/16687 [00:09<00:20, 560.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5306/16687 [00:09<00:20, 553.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5362/16687 [00:09<00:20, 553.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5418/16687 [00:09<00:20, 551.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5474/16687 [00:09<00:20, 550.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5530/16687 [00:09<00:20, 549.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▍                    | 5585/16687 [00:10<00:20, 548.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5642/16687 [00:10<00:19, 552.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5699/16687 [00:10<00:19, 555.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5756/16687 [00:10<00:19, 557.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5812/16687 [00:10<00:20, 538.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5867/16687 [00:10<00:19, 541.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5924/16687 [00:10<00:19, 548.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5980/16687 [00:10<00:19, 550.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6036/16687 [00:10<00:19, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6092/16687 [00:10<00:19, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6148/16687 [00:11<00:19, 554.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6207/16687 [00:11<00:18, 564.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6265/16687 [00:11<00:18, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6324/16687 [00:11<00:18, 574.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6382/16687 [00:11<00:17, 574.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6440/16687 [00:11<00:17, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6498/16687 [00:11<00:17, 570.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6556/16687 [00:11<00:18, 562.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6613/16687 [00:11<00:17, 562.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6670/16687 [00:12<00:17, 562.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6727/16687 [00:12<00:17, 557.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6784/16687 [00:12<00:17, 558.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6841/16687 [00:12<00:17, 559.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6897/16687 [00:12<00:17, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6954/16687 [00:12<00:17, 556.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7010/16687 [00:12<00:17, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7066/16687 [00:12<00:17, 556.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7122/16687 [00:12<00:17, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7179/16687 [00:12<00:16, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7235/16687 [00:13<00:16, 558.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7291/16687 [00:13<00:16, 558.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7347/16687 [00:13<00:16, 558.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7404/16687 [00:13<00:16, 561.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7461/16687 [00:13<00:16, 560.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7518/16687 [00:13<00:16, 562.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7575/16687 [00:13<00:16, 559.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7632/16687 [00:13<00:16, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7689/16687 [00:13<00:16, 556.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7746/16687 [00:13<00:16, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7803/16687 [00:14<00:15, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7859/16687 [00:14<00:15, 556.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7915/16687 [00:14<00:15, 553.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7972/16687 [00:14<00:15, 556.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8028/16687 [00:14<00:15, 553.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8085/16687 [00:14<00:15, 555.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8142/16687 [00:14<00:15, 557.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8201/16687 [00:14<00:15, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8259/16687 [00:14<00:14, 568.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8317/16687 [00:14<00:14, 570.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8375/16687 [00:15<00:14, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8433/16687 [00:15<00:14, 574.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8492/16687 [00:15<00:14, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8550/16687 [00:15<00:14, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8608/16687 [00:15<00:14, 576.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8666/16687 [00:15<00:13, 573.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8724/16687 [00:15<00:13, 568.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8781/16687 [00:15<00:13, 566.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8838/16687 [00:15<00:13, 560.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8895/16687 [00:15<00:13, 561.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8952/16687 [00:16<00:13, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9009/16687 [00:16<00:13, 557.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9067/16687 [00:16<00:13, 563.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9125/16687 [00:16<00:13, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9182/16687 [00:16<00:13, 564.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9239/16687 [00:16<00:13, 565.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9296/16687 [00:16<00:13, 564.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9353/16687 [00:16<00:12, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9410/16687 [00:16<00:12, 563.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9467/16687 [00:16<00:12, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9523/16687 [00:17<00:12, 554.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9579/16687 [00:17<00:12, 551.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9635/16687 [00:17<00:12, 552.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9691/16687 [00:17<00:12, 553.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9748/16687 [00:17<00:12, 556.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9804/16687 [00:17<00:12, 539.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9859/16687 [00:17<00:12, 530.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9913/16687 [00:17<00:13, 519.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9966/16687 [00:17<00:12, 517.60batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  60%|██████████████████            | 10024/16687 [00:18<00:12, 535.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10083/16687 [00:18<00:11, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10142/16687 [00:18<00:11, 561.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10201/16687 [00:18<00:11, 568.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10260/16687 [00:18<00:11, 573.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10318/16687 [00:18<00:11, 568.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10375/16687 [00:18<00:11, 567.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10434/16687 [00:18<00:10, 571.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10492/16687 [00:18<00:10, 565.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10551/16687 [00:18<00:10, 571.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10610/16687 [00:19<00:10, 576.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10669/16687 [00:19<00:10, 579.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10728/16687 [00:19<00:10, 582.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10787/16687 [00:19<00:10, 584.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10846/16687 [00:19<00:09, 585.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10905/16687 [00:19<00:09, 586.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10964/16687 [00:19<00:09, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11023/16687 [00:19<00:09, 586.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11082/16687 [00:19<00:09, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11141/16687 [00:19<00:09, 578.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11199/16687 [00:20<00:09, 570.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11257/16687 [00:20<00:09, 564.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11314/16687 [00:20<00:09, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11371/16687 [00:20<00:09, 554.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11427/16687 [00:20<00:09, 544.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11482/16687 [00:20<00:09, 544.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11537/16687 [00:20<00:09, 546.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11594/16687 [00:20<00:09, 551.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11650/16687 [00:20<00:09, 553.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11706/16687 [00:20<00:09, 552.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11762/16687 [00:21<00:08, 552.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11818/16687 [00:21<00:08, 551.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11874/16687 [00:21<00:08, 551.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11930/16687 [00:21<00:08, 551.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11986/16687 [00:21<00:08, 549.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12043/16687 [00:21<00:08, 553.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12101/16687 [00:21<00:08, 558.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12158/16687 [00:21<00:08, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12215/16687 [00:21<00:08, 552.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12271/16687 [00:21<00:08, 545.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12329/16687 [00:22<00:07, 555.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12385/16687 [00:22<00:07, 551.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12444/16687 [00:22<00:07, 561.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12503/16687 [00:22<00:07, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12561/16687 [00:22<00:07, 569.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12619/16687 [00:22<00:07, 569.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12676/16687 [00:22<00:07, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12733/16687 [00:22<00:06, 567.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12790/16687 [00:22<00:06, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12847/16687 [00:23<00:06, 562.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12904/16687 [00:23<00:06, 560.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12961/16687 [00:23<00:06, 555.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13017/16687 [00:23<00:06, 551.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13073/16687 [00:23<00:06, 548.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13128/16687 [00:23<00:06, 545.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13183/16687 [00:23<00:06, 542.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13238/16687 [00:23<00:06, 533.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13293/16687 [00:23<00:06, 536.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13348/16687 [00:23<00:06, 539.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13404/16687 [00:24<00:06, 543.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13460/16687 [00:24<00:05, 547.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13516/16687 [00:24<00:05, 550.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13572/16687 [00:24<00:05, 552.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13628/16687 [00:24<00:05, 544.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13685/16687 [00:24<00:05, 549.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13740/16687 [00:24<00:05, 543.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13796/16687 [00:24<00:05, 548.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13851/16687 [00:24<00:05, 537.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13908/16687 [00:24<00:05, 545.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13964/16687 [00:25<00:04, 549.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14022/16687 [00:25<00:04, 555.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14080/16687 [00:25<00:04, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14137/16687 [00:25<00:04, 562.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14194/16687 [00:25<00:04, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14251/16687 [00:25<00:04, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14308/16687 [00:25<00:04, 559.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14365/16687 [00:25<00:04, 559.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14422/16687 [00:25<00:04, 560.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14479/16687 [00:25<00:03, 560.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14536/16687 [00:26<00:03, 558.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14592/16687 [00:26<00:03, 557.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14648/16687 [00:26<00:03, 557.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14704/16687 [00:26<00:03, 557.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14760/16687 [00:26<00:03, 541.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14816/16687 [00:26<00:03, 546.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14872/16687 [00:26<00:03, 548.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14929/16687 [00:26<00:03, 554.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14985/16687 [00:26<00:03, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15042/16687 [00:26<00:02, 558.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15099/16687 [00:27<00:02, 561.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15156/16687 [00:27<00:02, 563.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15213/16687 [00:27<00:02, 564.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15270/16687 [00:27<00:02, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15327/16687 [00:27<00:02, 566.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15384/16687 [00:27<00:02, 564.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15441/16687 [00:27<00:02, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15498/16687 [00:27<00:02, 562.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15556/16687 [00:27<00:02, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15615/16687 [00:28<00:01, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15673/16687 [00:28<00:01, 566.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15730/16687 [00:28<00:01, 564.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15787/16687 [00:28<00:01, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15844/16687 [00:28<00:01, 561.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15901/16687 [00:28<00:01, 559.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15958/16687 [00:28<00:01, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16015/16687 [00:28<00:01, 558.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16072/16687 [00:28<00:01, 561.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16130/16687 [00:28<00:00, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16188/16687 [00:29<00:00, 568.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16245/16687 [00:29<00:00, 564.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16302/16687 [00:29<00:00, 558.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16359/16687 [00:29<00:00, 560.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16416/16687 [00:29<00:00, 562.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16473/16687 [00:29<00:00, 561.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16530/16687 [00:29<00:00, 561.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16587/16687 [00:29<00:00, 545.84batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16642/16687 [00:29<00:00, 536.93batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  35%|███▊       | 7/20 [04:15<08:05, 37.33s/epoch, loss=0.651, prev_loss=0.65]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:33, 178.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 68/16687 [00:00<00:45, 363.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 123/16687 [00:00<00:37, 445.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 180/16687 [00:00<00:33, 491.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 232/16687 [00:00<00:32, 499.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 286/16687 [00:00<00:32, 511.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 342/16687 [00:00<00:31, 525.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 399/16687 [00:00<00:30, 538.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 455/16687 [00:00<00:29, 543.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 510/16687 [00:01<00:30, 536.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 567/16687 [00:01<00:29, 544.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 625/16687 [00:01<00:28, 554.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 684/16687 [00:01<00:28, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 741/16687 [00:01<00:28, 562.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 798/16687 [00:01<00:28, 559.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 854/16687 [00:01<00:28, 546.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 911/16687 [00:01<00:28, 550.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 968/16687 [00:01<00:28, 555.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1025/16687 [00:01<00:28, 558.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|██                             | 1081/16687 [00:02<00:28, 549.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1137/16687 [00:02<00:28, 551.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1196/16687 [00:02<00:27, 560.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1255/16687 [00:02<00:27, 567.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1312/16687 [00:02<00:27, 567.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1369/16687 [00:02<00:27, 558.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1426/16687 [00:02<00:27, 560.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1485/16687 [00:02<00:26, 567.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1544/16687 [00:02<00:26, 571.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1603/16687 [00:02<00:26, 574.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1661/16687 [00:03<00:26, 567.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1720/16687 [00:03<00:26, 572.01batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  11%|███▎                           | 1779/16687 [00:03<00:25, 575.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1838/16687 [00:03<00:25, 576.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1896/16687 [00:03<00:26, 560.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1953/16687 [00:03<00:26, 558.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2009/16687 [00:03<00:27, 538.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2066/16687 [00:03<00:26, 547.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2121/16687 [00:03<00:26, 547.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2177/16687 [00:03<00:26, 549.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2233/16687 [00:04<00:26, 547.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2291/16687 [00:04<00:25, 556.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2347/16687 [00:04<00:25, 556.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2403/16687 [00:04<00:25, 552.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2459/16687 [00:04<00:25, 554.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2515/16687 [00:04<00:26, 544.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2572/16687 [00:04<00:25, 549.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2627/16687 [00:04<00:25, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2685/16687 [00:04<00:25, 553.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2742/16687 [00:05<00:24, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2798/16687 [00:05<00:25, 553.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2855/16687 [00:05<00:24, 557.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2911/16687 [00:05<00:25, 550.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2967/16687 [00:05<00:25, 548.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3022/16687 [00:05<00:24, 546.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3077/16687 [00:05<00:25, 537.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3134/16687 [00:05<00:24, 546.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3191/16687 [00:05<00:24, 552.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3247/16687 [00:05<00:24, 552.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3305/16687 [00:06<00:23, 558.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3361/16687 [00:06<00:24, 550.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3418/16687 [00:06<00:23, 554.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3474/16687 [00:06<00:23, 552.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3530/16687 [00:06<00:24, 542.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3585/16687 [00:06<00:24, 541.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3640/16687 [00:06<00:24, 530.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3695/16687 [00:06<00:24, 535.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3752/16687 [00:06<00:23, 544.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3809/16687 [00:06<00:23, 550.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3866/16687 [00:07<00:23, 554.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3924/16687 [00:07<00:22, 561.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3981/16687 [00:07<00:22, 561.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4038/16687 [00:07<00:22, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4096/16687 [00:07<00:22, 565.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4153/16687 [00:07<00:22, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4210/16687 [00:07<00:22, 561.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4267/16687 [00:07<00:22, 560.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4324/16687 [00:07<00:21, 563.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4382/16687 [00:07<00:21, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4439/16687 [00:08<00:21, 566.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4496/16687 [00:08<00:21, 565.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4553/16687 [00:08<00:21, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4610/16687 [00:08<00:21, 565.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4667/16687 [00:08<00:21, 563.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4724/16687 [00:08<00:21, 551.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4780/16687 [00:08<00:21, 553.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4837/16687 [00:08<00:21, 557.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4894/16687 [00:08<00:21, 559.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4951/16687 [00:08<00:21, 555.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5008/16687 [00:09<00:20, 557.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5064/16687 [00:09<00:21, 547.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5119/16687 [00:09<00:21, 531.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5173/16687 [00:09<00:21, 530.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5229/16687 [00:09<00:21, 536.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5284/16687 [00:09<00:21, 539.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5340/16687 [00:09<00:20, 544.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5397/16687 [00:09<00:20, 549.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5454/16687 [00:09<00:20, 554.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5511/16687 [00:10<00:20, 558.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5567/16687 [00:10<00:19, 558.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5624/16687 [00:10<00:19, 559.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5681/16687 [00:10<00:19, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5738/16687 [00:10<00:19, 561.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5795/16687 [00:10<00:19, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5852/16687 [00:10<00:19, 561.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5909/16687 [00:10<00:19, 551.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5965/16687 [00:10<00:19, 546.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6021/16687 [00:10<00:19, 548.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6079/16687 [00:11<00:19, 555.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6138/16687 [00:11<00:18, 564.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6195/16687 [00:11<00:18, 565.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6252/16687 [00:11<00:18, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6309/16687 [00:11<00:18, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6366/16687 [00:11<00:18, 548.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6421/16687 [00:11<00:18, 548.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6479/16687 [00:11<00:18, 555.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6536/16687 [00:11<00:18, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▏                  | 6593/16687 [00:11<00:17, 562.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6650/16687 [00:12<00:17, 563.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6707/16687 [00:12<00:17, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6764/16687 [00:12<00:17, 560.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6821/16687 [00:12<00:17, 561.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6878/16687 [00:12<00:17, 562.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6935/16687 [00:12<00:17, 561.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6992/16687 [00:12<00:17, 562.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7049/16687 [00:12<00:17, 553.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7105/16687 [00:12<00:17, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7161/16687 [00:12<00:17, 551.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7218/16687 [00:13<00:17, 555.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7274/16687 [00:13<00:16, 556.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7332/16687 [00:13<00:16, 561.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7389/16687 [00:13<00:16, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7447/16687 [00:13<00:16, 568.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7504/16687 [00:13<00:16, 566.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7561/16687 [00:13<00:16, 561.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7618/16687 [00:13<00:16, 560.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7675/16687 [00:13<00:16, 553.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7732/16687 [00:13<00:16, 557.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7789/16687 [00:14<00:15, 559.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7845/16687 [00:14<00:15, 553.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7901/16687 [00:14<00:15, 554.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7957/16687 [00:14<00:15, 555.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8013/16687 [00:14<00:15, 556.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8070/16687 [00:14<00:15, 557.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8126/16687 [00:14<00:15, 554.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8183/16687 [00:14<00:15, 556.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8241/16687 [00:14<00:15, 561.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8298/16687 [00:15<00:14, 561.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8355/16687 [00:15<00:14, 561.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8412/16687 [00:15<00:14, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8469/16687 [00:15<00:14, 560.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8526/16687 [00:15<00:14, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8583/16687 [00:15<00:14, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8640/16687 [00:15<00:14, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8697/16687 [00:15<00:14, 545.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▎              | 8752/16687 [00:15<00:14, 545.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8810/16687 [00:15<00:14, 554.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8866/16687 [00:16<00:14, 553.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8924/16687 [00:16<00:13, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8981/16687 [00:16<00:13, 559.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9039/16687 [00:16<00:13, 565.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9098/16687 [00:16<00:13, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9156/16687 [00:16<00:13, 567.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9213/16687 [00:16<00:13, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9270/16687 [00:16<00:13, 559.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9327/16687 [00:16<00:13, 559.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9383/16687 [00:16<00:13, 559.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9440/16687 [00:17<00:12, 560.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9497/16687 [00:17<00:13, 543.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9555/16687 [00:17<00:12, 551.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9611/16687 [00:17<00:12, 550.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9667/16687 [00:17<00:12, 549.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9723/16687 [00:17<00:12, 548.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9778/16687 [00:17<00:12, 536.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9835/16687 [00:17<00:12, 543.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9891/16687 [00:17<00:12, 546.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9946/16687 [00:17<00:12, 542.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10002/16687 [00:18<00:12, 545.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10057/16687 [00:18<00:12, 544.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10112/16687 [00:18<00:12, 539.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10166/16687 [00:18<00:12, 533.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10225/16687 [00:18<00:11, 547.58batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  62%|██████████████████▍           | 10280/16687 [00:18<00:11, 540.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10335/16687 [00:18<00:11, 534.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10392/16687 [00:18<00:11, 542.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10449/16687 [00:18<00:11, 548.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10505/16687 [00:19<00:11, 550.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10561/16687 [00:19<00:11, 551.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10619/16687 [00:19<00:10, 557.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10678/16687 [00:19<00:10, 565.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10735/16687 [00:19<00:10, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10794/16687 [00:19<00:10, 566.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10851/16687 [00:19<00:10, 548.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10906/16687 [00:19<00:10, 541.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10963/16687 [00:19<00:10, 548.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11020/16687 [00:19<00:10, 554.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11078/16687 [00:20<00:10, 559.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11135/16687 [00:20<00:09, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11192/16687 [00:20<00:09, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11249/16687 [00:20<00:09, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11306/16687 [00:20<00:09, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11363/16687 [00:20<00:09, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11420/16687 [00:20<00:09, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11477/16687 [00:20<00:09, 562.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11534/16687 [00:20<00:09, 564.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11591/16687 [00:20<00:09, 565.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11648/16687 [00:21<00:09, 556.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11704/16687 [00:21<00:09, 539.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11759/16687 [00:21<00:09, 541.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11815/16687 [00:21<00:08, 545.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11871/16687 [00:21<00:08, 547.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11926/16687 [00:21<00:08, 542.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11981/16687 [00:21<00:08, 541.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12036/16687 [00:21<00:08, 535.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12093/16687 [00:21<00:08, 543.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12148/16687 [00:21<00:08, 536.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12205/16687 [00:22<00:08, 544.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12262/16687 [00:22<00:08, 549.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12319/16687 [00:22<00:07, 555.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12376/16687 [00:22<00:07, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12432/16687 [00:22<00:07, 552.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12491/16687 [00:22<00:07, 561.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12548/16687 [00:22<00:07, 560.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12605/16687 [00:22<00:07, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12662/16687 [00:22<00:07, 559.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12718/16687 [00:23<00:07, 559.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12775/16687 [00:23<00:06, 559.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12832/16687 [00:23<00:06, 560.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12889/16687 [00:23<00:06, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12946/16687 [00:23<00:06, 562.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13003/16687 [00:23<00:06, 561.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13060/16687 [00:23<00:06, 561.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13117/16687 [00:23<00:06, 549.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13172/16687 [00:23<00:06, 537.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13226/16687 [00:23<00:06, 530.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13280/16687 [00:24<00:06, 525.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13333/16687 [00:24<00:06, 522.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13386/16687 [00:24<00:06, 523.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13439/16687 [00:24<00:06, 519.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13495/16687 [00:24<00:06, 531.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13552/16687 [00:24<00:05, 540.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13609/16687 [00:24<00:05, 547.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13665/16687 [00:24<00:05, 549.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13722/16687 [00:24<00:05, 554.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13780/16687 [00:24<00:05, 559.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13837/16687 [00:25<00:05, 561.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13894/16687 [00:25<00:04, 563.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13951/16687 [00:25<00:04, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14008/16687 [00:25<00:04, 563.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14065/16687 [00:25<00:04, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14122/16687 [00:25<00:04, 565.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14179/16687 [00:25<00:04, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14237/16687 [00:25<00:04, 567.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14294/16687 [00:25<00:04, 565.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14351/16687 [00:25<00:04, 547.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14406/16687 [00:26<00:04, 532.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14460/16687 [00:26<00:04, 526.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14513/16687 [00:26<00:04, 521.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14566/16687 [00:26<00:04, 518.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14619/16687 [00:26<00:03, 519.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14671/16687 [00:26<00:04, 473.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14721/16687 [00:26<00:04, 480.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14772/16687 [00:26<00:03, 486.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14822/16687 [00:26<00:03, 486.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14871/16687 [00:27<00:03, 479.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14920/16687 [00:27<00:03, 475.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14968/16687 [00:27<00:03, 476.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15016/16687 [00:27<00:03, 435.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15067/16687 [00:27<00:03, 454.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15114/16687 [00:27<00:03, 412.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15162/16687 [00:27<00:03, 428.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15206/16687 [00:27<00:03, 424.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15262/16687 [00:27<00:03, 457.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15309/16687 [00:28<00:03, 454.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15362/16687 [00:28<00:02, 475.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15410/16687 [00:28<00:02, 468.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15460/16687 [00:28<00:02, 473.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15508/16687 [00:28<00:02, 440.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15554/16687 [00:28<00:02, 443.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15599/16687 [00:28<00:02, 438.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15652/16687 [00:28<00:02, 463.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15699/16687 [00:28<00:02, 456.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15751/16687 [00:28<00:01, 473.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15800/16687 [00:29<00:01, 477.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15849/16687 [00:29<00:01, 479.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15898/16687 [00:29<00:01, 466.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15946/16687 [00:29<00:01, 469.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 15994/16687 [00:29<00:01, 470.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16042/16687 [00:29<00:01, 465.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16095/16687 [00:29<00:01, 483.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16144/16687 [00:29<00:01, 467.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16191/16687 [00:29<00:01, 464.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16238/16687 [00:30<00:00, 459.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16293/16687 [00:30<00:00, 483.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16342/16687 [00:30<00:00, 446.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16388/16687 [00:30<00:00, 449.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16434/16687 [00:30<00:00, 444.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16489/16687 [00:30<00:00, 469.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16537/16687 [00:30<00:00, 461.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16592/16687 [00:30<00:00, 486.54batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16641/16687 [00:30<00:00, 476.29batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|████      | 8/20 [04:46<07:04, 35.38s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                   | 8/16687 [00:00<03:30, 79.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 61/16687 [00:00<00:48, 341.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 103/16687 [00:00<00:44, 376.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 156/16687 [00:00<00:38, 434.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 202/16687 [00:00<00:37, 440.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▍                               | 257/16687 [00:00<00:34, 474.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 305/16687 [00:00<00:34, 472.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 359/16687 [00:00<00:33, 491.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 409/16687 [00:00<00:33, 485.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 461/16687 [00:01<00:32, 494.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 511/16687 [00:01<00:33, 485.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 563/16687 [00:01<00:32, 493.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 613/16687 [00:01<00:32, 492.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 663/16687 [00:01<00:33, 475.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 711/16687 [00:01<00:34, 460.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 758/16687 [00:01<00:35, 449.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 804/16687 [00:01<00:37, 426.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 854/16687 [00:01<00:35, 445.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 900/16687 [00:01<00:35, 449.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 946/16687 [00:02<00:35, 448.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 992/16687 [00:02<00:35, 442.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1037/16687 [00:02<00:35, 436.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1091/16687 [00:02<00:33, 466.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1138/16687 [00:02<00:34, 456.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1192/16687 [00:02<00:32, 478.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1241/16687 [00:02<00:32, 468.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1294/16687 [00:02<00:31, 486.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1343/16687 [00:02<00:32, 477.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1397/16687 [00:03<00:30, 495.55batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   9%|██▋                            | 1447/16687 [00:03<00:31, 491.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1499/16687 [00:03<00:30, 498.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1549/16687 [00:03<00:33, 449.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1596/16687 [00:03<00:33, 453.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1643/16687 [00:03<00:37, 401.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1695/16687 [00:03<00:34, 431.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1743/16687 [00:03<00:33, 443.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1801/16687 [00:03<00:30, 480.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1851/16687 [00:04<00:31, 467.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1907/16687 [00:04<00:29, 492.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1958/16687 [00:04<00:31, 470.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2010/16687 [00:04<00:30, 482.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2059/16687 [00:04<00:31, 465.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2111/16687 [00:04<00:30, 480.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2161/16687 [00:04<00:29, 485.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2210/16687 [00:04<00:31, 464.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2257/16687 [00:04<00:33, 435.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2308/16687 [00:05<00:31, 454.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2356/16687 [00:05<00:31, 459.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2408/16687 [00:05<00:30, 474.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2456/16687 [00:05<00:30, 472.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2504/16687 [00:05<00:30, 472.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2552/16687 [00:05<00:29, 473.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2600/16687 [00:05<00:29, 474.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2650/16687 [00:05<00:29, 481.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2699/16687 [00:05<00:30, 459.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2749/16687 [00:05<00:29, 471.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2797/16687 [00:06<00:30, 450.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2850/16687 [00:06<00:29, 472.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2898/16687 [00:06<00:29, 474.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2951/16687 [00:06<00:28, 487.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3000/16687 [00:06<00:29, 461.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3048/16687 [00:06<00:29, 466.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▋                         | 3095/16687 [00:06<00:30, 449.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3146/16687 [00:06<00:29, 465.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3194/16687 [00:06<00:28, 469.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3246/16687 [00:07<00:27, 481.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3296/16687 [00:07<00:27, 485.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3350/16687 [00:07<00:26, 499.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3401/16687 [00:07<00:26, 493.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3451/16687 [00:07<00:26, 490.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3501/16687 [00:07<00:28, 457.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3548/16687 [00:07<00:28, 460.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3595/16687 [00:07<00:28, 455.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3648/16687 [00:07<00:27, 473.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3697/16687 [00:07<00:27, 478.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3753/16687 [00:08<00:25, 500.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3804/16687 [00:08<00:26, 484.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3853/16687 [00:08<00:26, 483.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3902/16687 [00:08<00:26, 482.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3956/16687 [00:08<00:25, 492.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4006/16687 [00:08<00:26, 472.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4058/16687 [00:08<00:26, 485.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4107/16687 [00:08<00:26, 470.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4158/16687 [00:08<00:26, 481.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4207/16687 [00:09<00:25, 482.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4256/16687 [00:09<00:25, 484.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4305/16687 [00:09<00:25, 482.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4357/16687 [00:09<00:24, 493.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4407/16687 [00:09<00:25, 488.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4461/16687 [00:09<00:24, 502.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4512/16687 [00:09<00:25, 475.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4563/16687 [00:09<00:25, 480.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4613/16687 [00:09<00:24, 484.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4665/16687 [00:09<00:24, 492.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4715/16687 [00:10<00:24, 482.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4771/16687 [00:10<00:23, 504.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4822/16687 [00:10<00:24, 493.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4872/16687 [00:10<00:23, 492.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████▏                     | 4922/16687 [00:10<00:24, 476.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4977/16687 [00:10<00:23, 495.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5027/16687 [00:10<00:23, 489.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5083/16687 [00:10<00:22, 507.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5134/16687 [00:10<00:23, 490.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5189/16687 [00:10<00:22, 507.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5240/16687 [00:11<00:23, 497.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5292/16687 [00:11<00:22, 503.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5343/16687 [00:11<00:22, 494.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5393/16687 [00:11<00:23, 485.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5442/16687 [00:11<00:24, 467.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5489/16687 [00:11<00:24, 461.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5536/16687 [00:11<00:24, 454.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5591/16687 [00:11<00:23, 479.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5640/16687 [00:11<00:23, 476.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5695/16687 [00:12<00:22, 496.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5745/16687 [00:12<00:23, 468.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5800/16687 [00:12<00:22, 489.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5850/16687 [00:12<00:22, 478.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5904/16687 [00:12<00:21, 494.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5954/16687 [00:12<00:22, 469.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6010/16687 [00:12<00:21, 494.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6060/16687 [00:12<00:22, 476.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6117/16687 [00:12<00:21, 500.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6168/16687 [00:13<00:21, 486.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6220/16687 [00:13<00:21, 494.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6270/16687 [00:13<00:21, 488.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6325/16687 [00:13<00:20, 504.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6376/16687 [00:13<00:20, 493.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6429/16687 [00:13<00:20, 503.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6481/16687 [00:13<00:20, 507.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6532/16687 [00:13<00:20, 503.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6583/16687 [00:13<00:21, 481.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6633/16687 [00:13<00:20, 484.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6683/16687 [00:14<00:20, 488.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6732/16687 [00:14<00:20, 481.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6781/16687 [00:14<00:20, 482.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6831/16687 [00:14<00:20, 486.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6882/16687 [00:14<00:19, 490.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6932/16687 [00:14<00:20, 479.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6987/16687 [00:14<00:19, 498.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7037/16687 [00:14<00:19, 487.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7086/16687 [00:14<00:20, 477.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7134/16687 [00:15<00:20, 468.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7188/16687 [00:15<00:19, 487.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7237/16687 [00:15<00:19, 483.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7290/16687 [00:15<00:19, 494.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7340/16687 [00:15<00:19, 490.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7393/16687 [00:15<00:18, 500.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7444/16687 [00:15<00:18, 499.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7494/16687 [00:15<00:18, 489.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7547/16687 [00:15<00:18, 499.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7597/16687 [00:15<00:18, 491.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7653/16687 [00:16<00:17, 508.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7704/16687 [00:16<00:18, 489.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7759/16687 [00:16<00:17, 506.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7810/16687 [00:16<00:17, 493.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7865/16687 [00:16<00:17, 504.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7916/16687 [00:16<00:18, 474.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7972/16687 [00:16<00:17, 496.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8023/16687 [00:16<00:18, 477.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8073/16687 [00:16<00:17, 481.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8122/16687 [00:17<00:17, 482.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8177/16687 [00:17<00:17, 500.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8228/16687 [00:17<00:17, 482.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8278/16687 [00:17<00:17, 486.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8327/16687 [00:17<00:17, 485.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8381/16687 [00:17<00:16, 494.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8431/16687 [00:17<00:17, 477.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8486/16687 [00:17<00:16, 491.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8536/16687 [00:17<00:17, 473.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8591/16687 [00:17<00:16, 493.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8641/16687 [00:18<00:16, 488.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8693/16687 [00:18<00:16, 496.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8743/16687 [00:18<00:17, 445.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8791/16687 [00:18<00:17, 454.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8838/16687 [00:18<00:18, 418.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8882/16687 [00:18<00:18, 422.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8929/16687 [00:18<00:17, 434.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8975/16687 [00:18<00:17, 441.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9022/16687 [00:18<00:17, 446.99batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  54%|████████████████▊              | 9068/16687 [00:19<00:17, 442.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9114/16687 [00:19<00:16, 447.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9159/16687 [00:19<00:17, 435.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9209/16687 [00:19<00:16, 453.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9255/16687 [00:19<00:16, 453.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9309/16687 [00:19<00:15, 475.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9357/16687 [00:19<00:16, 449.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9403/16687 [00:19<00:16, 451.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9449/16687 [00:19<00:16, 446.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9505/16687 [00:20<00:15, 476.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9553/16687 [00:20<00:15, 453.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9599/16687 [00:20<00:15, 443.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9644/16687 [00:20<00:16, 435.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9698/16687 [00:20<00:15, 463.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9745/16687 [00:20<00:14, 463.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9792/16687 [00:20<00:15, 459.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9839/16687 [00:20<00:15, 439.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9888/16687 [00:20<00:15, 451.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9936/16687 [00:20<00:14, 459.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9983/16687 [00:21<00:14, 460.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10030/16687 [00:21<00:14, 454.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10076/16687 [00:21<00:15, 435.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10120/16687 [00:21<00:15, 435.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10168/16687 [00:21<00:14, 447.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10214/16687 [00:21<00:14, 450.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10260/16687 [00:21<00:14, 445.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10308/16687 [00:21<00:14, 453.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10354/16687 [00:21<00:14, 438.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10404/16687 [00:22<00:13, 455.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10453/16687 [00:22<00:13, 463.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10503/16687 [00:22<00:13, 473.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10551/16687 [00:22<00:13, 451.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10601/16687 [00:22<00:13, 463.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10648/16687 [00:22<00:13, 461.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10700/16687 [00:22<00:12, 476.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10748/16687 [00:22<00:12, 469.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10797/16687 [00:22<00:12, 475.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10846/16687 [00:22<00:12, 477.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10896/16687 [00:23<00:12, 481.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10945/16687 [00:23<00:11, 480.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10994/16687 [00:23<00:11, 482.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11048/16687 [00:23<00:11, 497.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11098/16687 [00:23<00:11, 492.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11148/16687 [00:23<00:11, 493.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11198/16687 [00:23<00:11, 470.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11250/16687 [00:23<00:11, 480.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11299/16687 [00:23<00:11, 480.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11351/16687 [00:23<00:10, 489.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11401/16687 [00:24<00:10, 487.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11453/16687 [00:24<00:10, 495.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11505/16687 [00:24<00:10, 501.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11556/16687 [00:24<00:10, 499.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11607/16687 [00:24<00:10, 491.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11657/16687 [00:24<00:10, 485.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11707/16687 [00:24<00:10, 489.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11757/16687 [00:24<00:10, 488.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11808/16687 [00:24<00:10, 487.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11857/16687 [00:25<00:10, 479.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11905/16687 [00:25<00:10, 476.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11953/16687 [00:25<00:10, 466.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12007/16687 [00:25<00:09, 487.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12056/16687 [00:25<00:09, 480.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12113/16687 [00:25<00:09, 504.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12164/16687 [00:25<00:09, 462.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12217/16687 [00:25<00:09, 478.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12266/16687 [00:25<00:09, 477.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12322/16687 [00:25<00:08, 500.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12373/16687 [00:26<00:08, 488.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12427/16687 [00:26<00:08, 502.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12478/16687 [00:26<00:08, 495.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12528/16687 [00:26<00:08, 493.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12578/16687 [00:26<00:08, 488.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12627/16687 [00:26<00:08, 481.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12676/16687 [00:26<00:08, 466.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12723/16687 [00:26<00:08, 445.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12768/16687 [00:26<00:09, 418.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12813/16687 [00:27<00:09, 425.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12856/16687 [00:27<00:09, 417.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12898/16687 [00:27<00:09, 416.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12943/16687 [00:27<00:08, 424.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12986/16687 [00:27<00:09, 408.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13037/16687 [00:27<00:08, 433.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13084/16687 [00:27<00:08, 441.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13138/16687 [00:27<00:07, 467.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13185/16687 [00:27<00:07, 447.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13240/16687 [00:28<00:07, 474.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13288/16687 [00:28<00:07, 471.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13344/16687 [00:28<00:06, 495.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13401/16687 [00:28<00:06, 516.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13458/16687 [00:28<00:06, 531.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13512/16687 [00:28<00:05, 531.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13568/16687 [00:28<00:05, 538.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13622/16687 [00:28<00:05, 537.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13679/16687 [00:28<00:05, 545.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13736/16687 [00:28<00:05, 550.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13792/16687 [00:29<00:05, 548.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13849/16687 [00:29<00:05, 552.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13906/16687 [00:29<00:05, 556.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13963/16687 [00:29<00:04, 558.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14019/16687 [00:29<00:04, 555.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14076/16687 [00:29<00:04, 558.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14133/16687 [00:29<00:04, 559.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14190/16687 [00:29<00:04, 560.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14247/16687 [00:29<00:04, 556.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14304/16687 [00:29<00:04, 558.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14360/16687 [00:30<00:04, 557.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14417/16687 [00:30<00:04, 559.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14474/16687 [00:30<00:03, 560.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14531/16687 [00:30<00:03, 557.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14588/16687 [00:30<00:03, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14644/16687 [00:30<00:03, 556.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14701/16687 [00:30<00:03, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14757/16687 [00:30<00:03, 554.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14813/16687 [00:30<00:03, 553.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14869/16687 [00:30<00:03, 551.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14926/16687 [00:31<00:03, 554.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14982/16687 [00:31<00:03, 514.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15035/16687 [00:31<00:03, 493.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15088/16687 [00:31<00:03, 502.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15139/16687 [00:31<00:03, 496.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15192/16687 [00:31<00:02, 506.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15243/16687 [00:31<00:02, 502.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15294/16687 [00:31<00:02, 498.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15345/16687 [00:31<00:02, 476.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15393/16687 [00:32<00:02, 468.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15442/16687 [00:32<00:02, 474.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15490/16687 [00:32<00:02, 468.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15540/16687 [00:32<00:02, 475.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15588/16687 [00:32<00:02, 475.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15641/16687 [00:32<00:02, 491.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15691/16687 [00:32<00:02, 448.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15737/16687 [00:32<00:02, 440.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15784/16687 [00:32<00:02, 447.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15837/16687 [00:33<00:01, 469.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15885/16687 [00:33<00:01, 472.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15937/16687 [00:33<00:01, 484.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15986/16687 [00:33<00:01, 481.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16036/16687 [00:33<00:01, 486.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16086/16687 [00:33<00:01, 487.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16136/16687 [00:33<00:01, 490.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16191/16687 [00:33<00:00, 507.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16242/16687 [00:33<00:00, 498.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16292/16687 [00:33<00:00, 485.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16342/16687 [00:34<00:00, 488.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16398/16687 [00:34<00:00, 506.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16449/16687 [00:34<00:00, 492.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16504/16687 [00:34<00:00, 506.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16555/16687 [00:34<00:00, 479.86batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16604/16687 [00:34<00:00, 476.67batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16652/16687 [00:34<00:00, 466.54batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0:  45%|████▌     | 9/20 [05:21<06:27, 35.24s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                  | 10/16687 [00:00<02:48, 99.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 64/16687 [00:00<00:46, 355.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 107/16687 [00:00<00:42, 385.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 159/16687 [00:00<00:37, 438.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 210/16687 [00:00<00:35, 463.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▍                               | 258/16687 [00:00<00:35, 468.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 313/16687 [00:00<00:33, 493.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 363/16687 [00:00<00:34, 477.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 419/16687 [00:00<00:32, 500.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 470/16687 [00:01<00:34, 473.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 522/16687 [00:01<00:33, 485.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 571/16687 [00:01<00:33, 476.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 622/16687 [00:01<00:33, 484.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 671/16687 [00:01<00:33, 474.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 722/16687 [00:01<00:33, 483.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 773/16687 [00:01<00:32, 488.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 823/16687 [00:01<00:32, 489.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 873/16687 [00:01<00:32, 488.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 922/16687 [00:01<00:32, 483.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 971/16687 [00:02<00:32, 477.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1019/16687 [00:02<00:33, 470.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1068/16687 [00:02<00:32, 475.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1116/16687 [00:02<00:33, 470.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1170/16687 [00:02<00:31, 489.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1220/16687 [00:02<00:32, 473.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1273/16687 [00:02<00:31, 486.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1322/16687 [00:02<00:31, 481.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1375/16687 [00:02<00:30, 495.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1425/16687 [00:03<00:30, 492.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1480/16687 [00:03<00:30, 506.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1531/16687 [00:03<00:31, 481.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1586/16687 [00:03<00:30, 498.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1637/16687 [00:03<00:30, 491.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1687/16687 [00:03<00:30, 491.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1737/16687 [00:03<00:31, 476.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1788/16687 [00:03<00:30, 484.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1838/16687 [00:03<00:30, 487.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1887/16687 [00:03<00:30, 486.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1936/16687 [00:04<00:31, 473.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1984/16687 [00:04<00:31, 461.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2031/16687 [00:04<00:31, 459.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2078/16687 [00:04<00:31, 460.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2125/16687 [00:04<00:31, 462.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2172/16687 [00:04<00:33, 429.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2216/16687 [00:04<00:33, 431.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2260/16687 [00:04<00:35, 402.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2301/16687 [00:04<00:35, 401.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2343/16687 [00:05<00:35, 406.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2394/16687 [00:05<00:32, 433.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2442/16687 [00:05<00:32, 443.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2490/16687 [00:05<00:31, 453.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2538/16687 [00:05<00:30, 459.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2587/16687 [00:05<00:30, 466.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2638/16687 [00:05<00:29, 474.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2686/16687 [00:05<00:30, 455.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2740/16687 [00:05<00:29, 478.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2789/16687 [00:05<00:29, 477.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2841/16687 [00:06<00:28, 487.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2890/16687 [00:06<00:29, 474.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2939/16687 [00:06<00:28, 478.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2988/16687 [00:06<00:29, 462.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3042/16687 [00:06<00:28, 482.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▋                         | 3091/16687 [00:06<00:29, 466.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3139/16687 [00:06<00:28, 469.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3187/16687 [00:06<00:30, 449.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3235/16687 [00:06<00:29, 458.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3282/16687 [00:07<00:29, 452.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3330/16687 [00:07<00:29, 458.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3377/16687 [00:07<00:29, 455.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3425/16687 [00:07<00:28, 461.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3474/16687 [00:07<00:28, 469.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3522/16687 [00:07<00:28, 465.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3574/16687 [00:07<00:27, 480.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3623/16687 [00:07<00:27, 471.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3678/16687 [00:07<00:26, 492.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3728/16687 [00:07<00:26, 490.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3781/16687 [00:08<00:25, 501.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3832/16687 [00:08<00:26, 477.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3884/16687 [00:08<00:26, 488.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3935/16687 [00:08<00:25, 494.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3987/16687 [00:08<00:25, 500.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4038/16687 [00:08<00:25, 492.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4088/16687 [00:08<00:26, 480.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4140/16687 [00:08<00:25, 491.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4190/16687 [00:08<00:26, 469.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4238/16687 [00:09<00:26, 463.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4285/16687 [00:09<00:27, 449.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4334/16687 [00:09<00:26, 458.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4380/16687 [00:09<00:27, 442.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4426/16687 [00:09<00:27, 446.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4474/16687 [00:09<00:26, 454.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4523/16687 [00:09<00:26, 463.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4570/16687 [00:09<00:26, 457.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4616/16687 [00:09<00:26, 447.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4661/16687 [00:09<00:26, 445.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4713/16687 [00:10<00:25, 464.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4760/16687 [00:10<00:25, 459.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4817/16687 [00:10<00:24, 490.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4867/16687 [00:10<00:25, 457.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████▏                     | 4921/16687 [00:10<00:24, 473.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4969/16687 [00:10<00:26, 448.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5018/16687 [00:10<00:25, 458.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5066/16687 [00:10<00:25, 464.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5120/16687 [00:10<00:24, 481.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5169/16687 [00:11<00:24, 479.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5224/16687 [00:11<00:23, 494.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5274/16687 [00:11<00:23, 481.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5328/16687 [00:11<00:22, 496.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5378/16687 [00:11<00:23, 488.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5428/16687 [00:11<00:22, 491.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5478/16687 [00:11<00:23, 479.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5529/16687 [00:11<00:22, 486.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5578/16687 [00:11<00:22, 484.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5630/16687 [00:11<00:22, 494.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5682/16687 [00:12<00:22, 499.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5732/16687 [00:12<00:22, 497.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5786/16687 [00:12<00:21, 507.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5837/16687 [00:12<00:22, 474.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5890/16687 [00:12<00:22, 489.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5940/16687 [00:12<00:24, 431.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5985/16687 [00:12<00:25, 426.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6029/16687 [00:12<00:25, 423.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6081/16687 [00:12<00:23, 447.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6127/16687 [00:13<00:23, 441.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6183/16687 [00:13<00:22, 472.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6231/16687 [00:13<00:22, 457.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6284/16687 [00:13<00:21, 478.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6335/16687 [00:13<00:21, 484.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6384/16687 [00:13<00:21, 479.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6435/16687 [00:13<00:21, 486.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6484/16687 [00:13<00:21, 478.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6536/16687 [00:13<00:20, 487.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6585/16687 [00:14<00:20, 481.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6641/16687 [00:14<00:19, 503.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6692/16687 [00:14<00:20, 477.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6746/16687 [00:14<00:20, 495.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6796/16687 [00:14<00:21, 463.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6850/16687 [00:14<00:20, 483.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6899/16687 [00:14<00:20, 480.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6954/16687 [00:14<00:19, 500.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7005/16687 [00:14<00:20, 466.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7058/16687 [00:15<00:20, 475.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7106/16687 [00:15<00:20, 468.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7162/16687 [00:15<00:19, 493.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7212/16687 [00:15<00:19, 489.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7267/16687 [00:15<00:18, 506.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7318/16687 [00:15<00:19, 488.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7375/16687 [00:15<00:18, 509.72batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  45%|█████████████▊                 | 7427/16687 [00:15<00:19, 478.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7484/16687 [00:15<00:18, 503.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7535/16687 [00:15<00:18, 490.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7591/16687 [00:16<00:17, 509.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7643/16687 [00:16<00:18, 487.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7696/16687 [00:16<00:18, 499.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7747/16687 [00:16<00:18, 494.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7800/16687 [00:16<00:17, 503.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7852/16687 [00:16<00:17, 508.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7903/16687 [00:16<00:17, 500.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7955/16687 [00:16<00:17, 504.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8006/16687 [00:16<00:17, 498.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8059/16687 [00:17<00:17, 506.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8110/16687 [00:17<00:17, 491.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8165/16687 [00:17<00:16, 506.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8216/16687 [00:17<00:17, 494.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▎               | 8272/16687 [00:17<00:16, 512.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8324/16687 [00:17<00:16, 502.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8379/16687 [00:17<00:16, 514.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8431/16687 [00:17<00:16, 501.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8484/16687 [00:17<00:16, 507.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8535/16687 [00:17<00:16, 500.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8588/16687 [00:18<00:15, 508.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8639/16687 [00:18<00:16, 499.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8692/16687 [00:18<00:15, 507.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8743/16687 [00:18<00:16, 495.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8793/16687 [00:18<00:16, 483.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8845/16687 [00:18<00:15, 493.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8898/16687 [00:18<00:15, 503.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8951/16687 [00:18<00:15, 510.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9006/16687 [00:18<00:14, 520.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9062/16687 [00:18<00:14, 532.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9116/16687 [00:19<00:14, 534.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9170/16687 [00:19<00:14, 534.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9226/16687 [00:19<00:13, 542.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9281/16687 [00:19<00:13, 542.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9338/16687 [00:19<00:13, 547.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9395/16687 [00:19<00:13, 551.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9451/16687 [00:19<00:13, 548.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9506/16687 [00:19<00:13, 538.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9560/16687 [00:19<00:13, 531.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9614/16687 [00:20<00:13, 526.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9669/16687 [00:20<00:13, 533.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9726/16687 [00:20<00:12, 541.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9782/16687 [00:20<00:12, 546.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9838/16687 [00:20<00:12, 550.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9895/16687 [00:20<00:12, 553.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9952/16687 [00:20<00:12, 555.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10008/16687 [00:20<00:12, 546.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10066/16687 [00:20<00:11, 556.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10124/16687 [00:20<00:11, 560.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10181/16687 [00:21<00:11, 563.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10238/16687 [00:21<00:11, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10295/16687 [00:21<00:11, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10352/16687 [00:21<00:11, 556.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10408/16687 [00:21<00:11, 554.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10465/16687 [00:21<00:11, 555.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10521/16687 [00:21<00:11, 552.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10577/16687 [00:21<00:11, 550.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10633/16687 [00:21<00:11, 549.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10688/16687 [00:21<00:10, 548.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10745/16687 [00:22<00:10, 552.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10802/16687 [00:22<00:10, 556.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10859/16687 [00:22<00:10, 557.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10915/16687 [00:22<00:10, 558.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10972/16687 [00:22<00:10, 558.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11029/16687 [00:22<00:10, 560.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11086/16687 [00:22<00:10, 557.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11142/16687 [00:22<00:09, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11199/16687 [00:22<00:09, 557.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11255/16687 [00:22<00:09, 557.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11312/16687 [00:23<00:09, 560.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11369/16687 [00:23<00:09, 561.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11426/16687 [00:23<00:09, 561.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11483/16687 [00:23<00:09, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11540/16687 [00:23<00:09, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11597/16687 [00:23<00:09, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11653/16687 [00:23<00:09, 545.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11710/16687 [00:23<00:09, 550.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11768/16687 [00:23<00:08, 559.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11826/16687 [00:23<00:08, 563.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11883/16687 [00:24<00:08, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11940/16687 [00:24<00:08, 564.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11997/16687 [00:24<00:08, 564.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12054/16687 [00:24<00:08, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12111/16687 [00:24<00:08, 555.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12168/16687 [00:24<00:08, 559.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12226/16687 [00:24<00:07, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12285/16687 [00:24<00:07, 569.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12342/16687 [00:24<00:07, 567.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12399/16687 [00:24<00:07, 567.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12456/16687 [00:25<00:07, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12513/16687 [00:25<00:07, 562.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12571/16687 [00:25<00:07, 567.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12628/16687 [00:25<00:07, 566.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12685/16687 [00:25<00:07, 553.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12743/16687 [00:25<00:07, 558.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12801/16687 [00:25<00:06, 563.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12858/16687 [00:25<00:06, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12915/16687 [00:25<00:06, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12972/16687 [00:26<00:06, 561.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13029/16687 [00:26<00:06, 563.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13086/16687 [00:26<00:06, 558.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13142/16687 [00:26<00:06, 557.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13198/16687 [00:26<00:06, 554.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13254/16687 [00:26<00:06, 553.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13310/16687 [00:26<00:06, 552.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13367/16687 [00:26<00:05, 555.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13423/16687 [00:26<00:05, 553.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13479/16687 [00:26<00:05, 551.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13536/16687 [00:27<00:05, 555.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13592/16687 [00:27<00:05, 552.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13648/16687 [00:27<00:05, 549.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13706/16687 [00:27<00:05, 556.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13763/16687 [00:27<00:05, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13820/16687 [00:27<00:05, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13877/16687 [00:27<00:05, 561.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13934/16687 [00:27<00:04, 558.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13990/16687 [00:27<00:04, 558.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14046/16687 [00:27<00:04, 549.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14103/16687 [00:28<00:04, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14160/16687 [00:28<00:04, 556.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14216/16687 [00:28<00:04, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14273/16687 [00:28<00:04, 558.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14330/16687 [00:28<00:04, 560.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14387/16687 [00:28<00:04, 561.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14446/16687 [00:28<00:03, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14505/16687 [00:28<00:03, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14564/16687 [00:28<00:03, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14622/16687 [00:28<00:03, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14679/16687 [00:29<00:03, 551.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14735/16687 [00:29<00:03, 546.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14792/16687 [00:29<00:03, 551.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14850/16687 [00:29<00:03, 557.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14908/16687 [00:29<00:03, 561.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14965/16687 [00:29<00:03, 563.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15023/16687 [00:29<00:02, 566.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15081/16687 [00:29<00:02, 567.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15138/16687 [00:29<00:02, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15195/16687 [00:29<00:02, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15252/16687 [00:30<00:02, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15309/16687 [00:30<00:02, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15366/16687 [00:30<00:02, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15424/16687 [00:30<00:02, 567.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15482/16687 [00:30<00:02, 568.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15539/16687 [00:30<00:02, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15596/16687 [00:30<00:01, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15653/16687 [00:30<00:01, 558.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15709/16687 [00:30<00:01, 546.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15764/16687 [00:31<00:01, 540.17batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15819/16687 [00:31<00:01, 539.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15877/16687 [00:31<00:01, 548.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▋ | 15934/16687 [00:31<00:01, 553.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15991/16687 [00:31<00:01, 558.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16048/16687 [00:31<00:01, 559.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16105/16687 [00:31<00:01, 562.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16162/16687 [00:31<00:00, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16219/16687 [00:31<00:00, 561.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16276/16687 [00:31<00:00, 563.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16333/16687 [00:32<00:00, 564.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16390/16687 [00:32<00:00, 560.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16449/16687 [00:32<00:00, 567.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16507/16687 [00:32<00:00, 570.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16565/16687 [00:32<00:00, 567.46batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16622/16687 [00:32<00:00, 565.18batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16679/16687 [00:32<00:00, 562.85batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  45%|████▌     | 9/20 [05:54<06:27, 35.24s/epoch, loss=0.651, prev_loss=0.651]\u001b[AINFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=1024.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 44.95s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.004011566496115785. Saved model weights to /work/.data/pykeen/checkpoints/best-model-weights-788cfe08-4ab7-44b1-a674-0b8e013ba656.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n",
      "Training epochs on cuda:0:  50%|████▌    | 10/20 [06:51<08:41, 52.13s/epoch, loss=0.651, prev_loss=0.651]\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 16/16687 [00:00<01:45, 158.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 72/16687 [00:00<00:42, 393.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 124/16687 [00:00<00:36, 449.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 180/16687 [00:00<00:33, 490.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 236/16687 [00:00<00:31, 514.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 292/16687 [00:00<00:31, 527.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 348/16687 [00:00<00:30, 535.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 404/16687 [00:00<00:30, 541.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 459/16687 [00:00<00:30, 540.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 514/16687 [00:01<00:29, 541.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 573/16687 [00:01<00:29, 554.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 630/16687 [00:01<00:28, 557.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 687/16687 [00:01<00:28, 559.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 745/16687 [00:01<00:28, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 802/16687 [00:01<00:28, 561.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 859/16687 [00:01<00:28, 560.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▊                              | 916/16687 [00:01<00:28, 554.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 973/16687 [00:01<00:28, 557.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1030/16687 [00:01<00:27, 559.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1086/16687 [00:02<00:27, 557.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1144/16687 [00:02<00:27, 562.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1202/16687 [00:02<00:27, 565.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1260/16687 [00:02<00:27, 567.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1318/16687 [00:02<00:27, 569.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1376/16687 [00:02<00:26, 570.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1434/16687 [00:02<00:26, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1492/16687 [00:02<00:27, 551.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1548/16687 [00:02<00:27, 552.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1605/16687 [00:02<00:27, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1662/16687 [00:03<00:26, 557.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1718/16687 [00:03<00:26, 555.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1775/16687 [00:03<00:26, 557.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1832/16687 [00:03<00:26, 559.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1888/16687 [00:03<00:26, 556.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1945/16687 [00:03<00:26, 558.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2001/16687 [00:03<00:26, 556.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2057/16687 [00:03<00:26, 545.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2114/16687 [00:03<00:26, 550.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2170/16687 [00:03<00:26, 553.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2226/16687 [00:04<00:26, 552.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2284/16687 [00:04<00:25, 559.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2342/16687 [00:04<00:25, 564.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2400/16687 [00:04<00:25, 567.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2458/16687 [00:04<00:24, 570.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2516/16687 [00:04<00:24, 569.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2573/16687 [00:04<00:24, 568.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2630/16687 [00:04<00:24, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2687/16687 [00:04<00:24, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2744/16687 [00:04<00:25, 551.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2801/16687 [00:05<00:25, 554.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2859/16687 [00:05<00:24, 560.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2917/16687 [00:05<00:24, 565.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2974/16687 [00:05<00:24, 564.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3031/16687 [00:05<00:24, 564.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▋                         | 3088/16687 [00:05<00:24, 562.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3145/16687 [00:05<00:24, 563.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3202/16687 [00:05<00:24, 558.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3259/16687 [00:05<00:23, 559.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3316/16687 [00:06<00:23, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3373/16687 [00:06<00:23, 561.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3430/16687 [00:06<00:23, 557.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3487/16687 [00:06<00:23, 559.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3543/16687 [00:06<00:23, 556.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3599/16687 [00:06<00:23, 555.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3656/16687 [00:06<00:23, 558.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3712/16687 [00:06<00:23, 555.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3769/16687 [00:06<00:23, 556.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3826/16687 [00:06<00:23, 559.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3882/16687 [00:07<00:23, 555.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3941/16687 [00:07<00:22, 563.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3998/16687 [00:07<00:22, 559.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4055/16687 [00:07<00:22, 560.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4112/16687 [00:07<00:22, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4169/16687 [00:07<00:22, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4226/16687 [00:07<00:22, 558.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4283/16687 [00:07<00:22, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4340/16687 [00:07<00:22, 557.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4398/16687 [00:07<00:21, 562.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4455/16687 [00:08<00:21, 557.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4513/16687 [00:08<00:21, 562.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4570/16687 [00:08<00:21, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4628/16687 [00:08<00:21, 566.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4686/16687 [00:08<00:21, 569.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4743/16687 [00:08<00:21, 551.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4799/16687 [00:08<00:21, 549.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4855/16687 [00:08<00:21, 549.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4911/16687 [00:08<00:21, 550.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4968/16687 [00:08<00:21, 555.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5025/16687 [00:09<00:20, 558.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5082/16687 [00:09<00:20, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5139/16687 [00:09<00:20, 563.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5196/16687 [00:09<00:20, 561.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▊                     | 5253/16687 [00:09<00:20, 559.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5309/16687 [00:09<00:20, 557.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5366/16687 [00:09<00:20, 560.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5423/16687 [00:09<00:20, 558.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5480/16687 [00:09<00:20, 559.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5536/16687 [00:09<00:20, 541.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5591/16687 [00:10<00:20, 531.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5648/16687 [00:10<00:20, 541.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5707/16687 [00:10<00:19, 552.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5765/16687 [00:10<00:19, 559.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5823/16687 [00:10<00:19, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5880/16687 [00:10<00:19, 554.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5936/16687 [00:10<00:19, 548.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5992/16687 [00:10<00:19, 549.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6047/16687 [00:10<00:19, 543.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6104/16687 [00:11<00:19, 548.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6159/16687 [00:11<00:19, 548.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6216/16687 [00:11<00:18, 552.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6273/16687 [00:11<00:18, 555.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6329/16687 [00:11<00:18, 554.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6385/16687 [00:11<00:18, 552.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6441/16687 [00:11<00:18, 551.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6497/16687 [00:11<00:18, 549.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6552/16687 [00:11<00:18, 546.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6607/16687 [00:11<00:18, 540.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6662/16687 [00:12<00:18, 543.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6719/16687 [00:12<00:18, 548.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6776/16687 [00:12<00:17, 552.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6833/16687 [00:12<00:17, 555.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6890/16687 [00:12<00:17, 557.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6947/16687 [00:12<00:17, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7003/16687 [00:12<00:17, 557.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7060/16687 [00:12<00:17, 558.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7117/16687 [00:12<00:17, 559.34batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  43%|█████████████▎                 | 7174/16687 [00:12<00:16, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7230/16687 [00:13<00:17, 556.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7287/16687 [00:13<00:16, 557.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7344/16687 [00:13<00:16, 559.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7401/16687 [00:13<00:16, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7458/16687 [00:13<00:16, 561.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7515/16687 [00:13<00:16, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7572/16687 [00:13<00:16, 562.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7629/16687 [00:13<00:16, 562.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7686/16687 [00:13<00:16, 562.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7743/16687 [00:13<00:15, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7800/16687 [00:14<00:15, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7856/16687 [00:14<00:15, 559.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7912/16687 [00:14<00:16, 545.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7969/16687 [00:14<00:15, 550.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8026/16687 [00:14<00:15, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8082/16687 [00:14<00:15, 554.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8139/16687 [00:14<00:15, 558.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8196/16687 [00:14<00:15, 561.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8253/16687 [00:14<00:15, 558.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8310/16687 [00:14<00:14, 560.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8367/16687 [00:15<00:14, 562.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8424/16687 [00:15<00:14, 553.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8482/16687 [00:15<00:14, 558.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8541/16687 [00:15<00:14, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8600/16687 [00:15<00:14, 571.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8658/16687 [00:15<00:14, 570.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8716/16687 [00:15<00:14, 568.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8775/16687 [00:15<00:13, 572.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8833/16687 [00:15<00:13, 572.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8892/16687 [00:16<00:13, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8950/16687 [00:16<00:13, 574.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9008/16687 [00:16<00:13, 572.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9066/16687 [00:16<00:13, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9124/16687 [00:16<00:13, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9181/16687 [00:16<00:13, 563.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9238/16687 [00:16<00:13, 559.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9294/16687 [00:16<00:13, 558.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9351/16687 [00:16<00:13, 559.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9409/16687 [00:16<00:12, 563.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9466/16687 [00:17<00:12, 564.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9523/16687 [00:17<00:12, 565.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9580/16687 [00:17<00:12, 562.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9637/16687 [00:17<00:12, 559.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9693/16687 [00:17<00:12, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9750/16687 [00:17<00:12, 558.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9806/16687 [00:17<00:12, 558.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9862/16687 [00:17<00:12, 554.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9919/16687 [00:17<00:12, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9975/16687 [00:17<00:12, 556.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10031/16687 [00:18<00:11, 556.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10088/16687 [00:18<00:11, 558.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10144/16687 [00:18<00:11, 558.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10201/16687 [00:18<00:11, 559.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10257/16687 [00:18<00:11, 555.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10315/16687 [00:18<00:11, 562.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10373/16687 [00:18<00:11, 565.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10430/16687 [00:18<00:11, 562.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10487/16687 [00:18<00:10, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10546/16687 [00:18<00:10, 569.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10605/16687 [00:19<00:10, 573.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10663/16687 [00:19<00:10, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10721/16687 [00:19<00:10, 560.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10778/16687 [00:19<00:10, 557.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10837/16687 [00:19<00:10, 565.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10896/16687 [00:19<00:10, 570.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10954/16687 [00:19<00:10, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11011/16687 [00:19<00:10, 566.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11070/16687 [00:19<00:09, 572.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11128/16687 [00:19<00:09, 571.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11186/16687 [00:20<00:09, 568.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11243/16687 [00:20<00:09, 565.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11301/16687 [00:20<00:09, 568.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11358/16687 [00:20<00:09, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11415/16687 [00:20<00:09, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11472/16687 [00:20<00:09, 562.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11529/16687 [00:20<00:09, 562.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11586/16687 [00:20<00:09, 558.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11643/16687 [00:20<00:09, 559.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11700/16687 [00:20<00:08, 559.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11756/16687 [00:21<00:08, 555.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11812/16687 [00:21<00:08, 556.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11868/16687 [00:21<00:08, 557.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11924/16687 [00:21<00:08, 557.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11980/16687 [00:21<00:08, 558.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12036/16687 [00:21<00:08, 554.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12092/16687 [00:21<00:08, 555.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12148/16687 [00:21<00:08, 557.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12205/16687 [00:21<00:08, 558.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12261/16687 [00:22<00:07, 558.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12317/16687 [00:22<00:07, 554.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12374/16687 [00:22<00:07, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12431/16687 [00:22<00:07, 558.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12488/16687 [00:22<00:07, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12544/16687 [00:22<00:07, 555.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12600/16687 [00:22<00:07, 553.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12656/16687 [00:22<00:07, 553.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12714/16687 [00:22<00:07, 559.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12773/16687 [00:22<00:06, 566.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12831/16687 [00:23<00:06, 568.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12889/16687 [00:23<00:06, 569.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12946/16687 [00:23<00:06, 569.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13003/16687 [00:23<00:06, 569.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13060/16687 [00:23<00:06, 565.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13117/16687 [00:23<00:06, 563.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13174/16687 [00:23<00:06, 558.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13230/16687 [00:23<00:06, 559.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13286/16687 [00:23<00:06, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13342/16687 [00:23<00:06, 555.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13398/16687 [00:24<00:05, 556.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13455/16687 [00:24<00:05, 558.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13511/16687 [00:24<00:05, 558.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13567/16687 [00:24<00:05, 558.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13623/16687 [00:24<00:05, 559.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13679/16687 [00:24<00:05, 554.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13736/16687 [00:24<00:05, 557.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13793/16687 [00:24<00:05, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13850/16687 [00:24<00:05, 559.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13906/16687 [00:24<00:04, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13962/16687 [00:25<00:04, 553.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14018/16687 [00:25<00:04, 550.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14074/16687 [00:25<00:04, 552.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14131/16687 [00:25<00:04, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14188/16687 [00:25<00:04, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14245/16687 [00:25<00:04, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14302/16687 [00:25<00:04, 562.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14359/16687 [00:25<00:04, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14416/16687 [00:25<00:04, 564.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14473/16687 [00:25<00:03, 565.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14530/16687 [00:26<00:03, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14587/16687 [00:26<00:03, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14643/16687 [00:26<00:03, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14699/16687 [00:26<00:03, 553.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14756/16687 [00:26<00:03, 557.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14812/16687 [00:26<00:03, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14868/16687 [00:26<00:03, 554.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14925/16687 [00:26<00:03, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14981/16687 [00:26<00:03, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15037/16687 [00:26<00:02, 556.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15094/16687 [00:27<00:02, 560.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15151/16687 [00:27<00:02, 558.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15207/16687 [00:27<00:02, 557.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15264/16687 [00:27<00:02, 559.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15321/16687 [00:27<00:02, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15378/16687 [00:27<00:02, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15434/16687 [00:27<00:02, 557.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15490/16687 [00:27<00:02, 556.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15546/16687 [00:27<00:02, 556.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15602/16687 [00:27<00:01, 554.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15659/16687 [00:28<00:01, 558.17batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15717/16687 [00:28<00:01, 561.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▎ | 15774/16687 [00:28<00:01, 563.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15831/16687 [00:28<00:01, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15888/16687 [00:28<00:01, 561.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15945/16687 [00:28<00:01, 558.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16001/16687 [00:28<00:01, 557.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16058/16687 [00:28<00:01, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16115/16687 [00:28<00:01, 559.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16171/16687 [00:28<00:00, 558.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16227/16687 [00:29<00:00, 557.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16283/16687 [00:29<00:00, 545.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16341/16687 [00:29<00:00, 553.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16397/16687 [00:29<00:00, 551.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16453/16687 [00:29<00:00, 553.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16510/16687 [00:29<00:00, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16567/16687 [00:29<00:00, 557.24batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16623/16687 [00:29<00:00, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16680/16687 [00:29<00:00, 556.15batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  55%|█████▌    | 11/20 [07:21<06:48, 45.40s/epoch, loss=0.65, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                   | 8/16687 [00:00<03:29, 79.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 65/16687 [00:00<00:48, 346.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 122/16687 [00:00<00:37, 442.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 180/16687 [00:00<00:33, 493.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 238/16687 [00:00<00:31, 523.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 296/16687 [00:00<00:30, 541.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 353/16687 [00:00<00:29, 549.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 412/16687 [00:00<00:28, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 470/16687 [00:00<00:28, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 528/16687 [00:01<00:28, 568.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█                               | 585/16687 [00:01<00:28, 556.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 642/16687 [00:01<00:28, 558.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 698/16687 [00:01<00:29, 546.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 755/16687 [00:01<00:28, 552.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 812/16687 [00:01<00:28, 555.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 868/16687 [00:01<00:28, 555.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 927/16687 [00:01<00:27, 564.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 986/16687 [00:01<00:27, 571.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1045/16687 [00:01<00:27, 576.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1104/16687 [00:02<00:26, 577.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1162/16687 [00:02<00:27, 572.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1220/16687 [00:02<00:26, 573.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1278/16687 [00:02<00:27, 567.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1337/16687 [00:02<00:26, 572.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1395/16687 [00:02<00:26, 572.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1453/16687 [00:02<00:26, 573.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1511/16687 [00:02<00:26, 574.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1570/16687 [00:02<00:26, 578.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1628/16687 [00:02<00:26, 576.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1686/16687 [00:03<00:26, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1744/16687 [00:03<00:26, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1802/16687 [00:03<00:26, 563.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1859/16687 [00:03<00:26, 555.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1918/16687 [00:03<00:26, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1976/16687 [00:03<00:25, 567.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2035/16687 [00:03<00:25, 573.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2093/16687 [00:03<00:25, 574.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2151/16687 [00:03<00:25, 574.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2209/16687 [00:03<00:25, 575.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2267/16687 [00:04<00:25, 575.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2325/16687 [00:04<00:25, 571.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2383/16687 [00:04<00:24, 572.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2441/16687 [00:04<00:24, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2499/16687 [00:04<00:24, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2558/16687 [00:04<00:24, 577.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2616/16687 [00:04<00:24, 576.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2674/16687 [00:04<00:24, 576.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2733/16687 [00:04<00:24, 579.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2792/16687 [00:04<00:23, 581.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2851/16687 [00:05<00:23, 583.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2910/16687 [00:05<00:24, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2968/16687 [00:05<00:24, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3026/16687 [00:05<00:24, 566.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3084/16687 [00:05<00:23, 568.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3142/16687 [00:05<00:23, 570.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3200/16687 [00:05<00:23, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3258/16687 [00:05<00:23, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3317/16687 [00:05<00:23, 577.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3376/16687 [00:06<00:22, 580.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3435/16687 [00:06<00:22, 579.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3493/16687 [00:06<00:23, 570.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3551/16687 [00:06<00:22, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3609/16687 [00:06<00:23, 566.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3666/16687 [00:06<00:23, 551.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3722/16687 [00:06<00:23, 551.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3779/16687 [00:06<00:23, 557.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3837/16687 [00:06<00:22, 561.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3894/16687 [00:06<00:22, 563.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3951/16687 [00:07<00:22, 560.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4008/16687 [00:07<00:22, 563.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4065/16687 [00:07<00:23, 546.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4121/16687 [00:07<00:22, 549.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4177/16687 [00:07<00:22, 545.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4232/16687 [00:07<00:23, 539.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4289/16687 [00:07<00:22, 546.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4348/16687 [00:07<00:22, 557.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4407/16687 [00:07<00:21, 565.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4466/16687 [00:07<00:21, 571.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4524/16687 [00:08<00:21, 572.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4582/16687 [00:08<00:21, 572.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4640/16687 [00:08<00:21, 561.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4697/16687 [00:08<00:21, 561.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4754/16687 [00:08<00:21, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4811/16687 [00:08<00:21, 557.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4867/16687 [00:08<00:21, 555.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4923/16687 [00:08<00:21, 553.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4980/16687 [00:08<00:20, 557.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5036/16687 [00:08<00:20, 555.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5092/16687 [00:09<00:20, 554.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5148/16687 [00:09<00:20, 552.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5204/16687 [00:09<00:21, 542.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5261/16687 [00:09<00:20, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5316/16687 [00:09<00:20, 542.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5372/16687 [00:09<00:20, 546.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5429/16687 [00:09<00:20, 553.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5485/16687 [00:09<00:20, 551.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5542/16687 [00:09<00:20, 554.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5599/16687 [00:10<00:19, 556.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5655/16687 [00:10<00:19, 554.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5711/16687 [00:10<00:19, 552.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5767/16687 [00:10<00:20, 539.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5822/16687 [00:10<00:20, 536.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5876/16687 [00:10<00:20, 537.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5930/16687 [00:10<00:20, 533.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5984/16687 [00:10<00:20, 529.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6039/16687 [00:10<00:19, 535.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6094/16687 [00:10<00:19, 537.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6153/16687 [00:11<00:19, 552.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6212/16687 [00:11<00:18, 563.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6271/16687 [00:11<00:18, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6330/16687 [00:11<00:18, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6389/16687 [00:11<00:17, 578.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6448/16687 [00:11<00:17, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6507/16687 [00:11<00:17, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6565/16687 [00:11<00:17, 566.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6622/16687 [00:11<00:17, 566.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6679/16687 [00:11<00:17, 566.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6736/16687 [00:12<00:17, 560.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6793/16687 [00:12<00:17, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6850/16687 [00:12<00:17, 561.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6907/16687 [00:12<00:17, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6964/16687 [00:12<00:17, 562.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7021/16687 [00:12<00:17, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7078/16687 [00:12<00:17, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7135/16687 [00:12<00:17, 561.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7192/16687 [00:12<00:16, 559.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7248/16687 [00:12<00:16, 557.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7304/16687 [00:13<00:16, 556.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7362/16687 [00:13<00:16, 562.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7420/16687 [00:13<00:16, 566.46batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  45%|█████████████▉                 | 7478/16687 [00:13<00:16, 568.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7536/16687 [00:13<00:16, 571.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7594/16687 [00:13<00:15, 569.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7652/16687 [00:13<00:15, 572.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7710/16687 [00:13<00:15, 570.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7768/16687 [00:13<00:15, 564.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7825/16687 [00:13<00:15, 563.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7882/16687 [00:14<00:15, 561.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▋                | 7939/16687 [00:14<00:15, 562.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7996/16687 [00:14<00:15, 564.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8053/16687 [00:14<00:15, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8112/16687 [00:14<00:15, 570.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8170/16687 [00:14<00:14, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8228/16687 [00:14<00:14, 570.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8286/16687 [00:14<00:14, 571.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8344/16687 [00:14<00:14, 567.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8401/16687 [00:14<00:14, 566.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8458/16687 [00:15<00:14, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8515/16687 [00:15<00:14, 561.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8572/16687 [00:15<00:14, 562.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8629/16687 [00:15<00:14, 560.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8686/16687 [00:15<00:14, 550.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8742/16687 [00:15<00:14, 550.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8798/16687 [00:15<00:14, 551.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8855/16687 [00:15<00:14, 555.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8911/16687 [00:15<00:14, 554.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8968/16687 [00:16<00:13, 558.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9024/16687 [00:16<00:13, 551.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9080/16687 [00:16<00:13, 551.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9139/16687 [00:16<00:13, 561.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9198/16687 [00:16<00:13, 569.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9257/16687 [00:16<00:12, 574.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9316/16687 [00:16<00:12, 578.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9375/16687 [00:16<00:12, 581.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9434/16687 [00:16<00:12, 583.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9493/16687 [00:16<00:12, 585.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9552/16687 [00:17<00:12, 582.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9611/16687 [00:17<00:12, 584.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9670/16687 [00:17<00:12, 582.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9729/16687 [00:17<00:11, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9788/16687 [00:17<00:11, 581.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9847/16687 [00:17<00:11, 579.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9906/16687 [00:17<00:11, 580.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9965/16687 [00:17<00:11, 576.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10023/16687 [00:17<00:11, 570.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10081/16687 [00:17<00:11, 565.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10138/16687 [00:18<00:11, 562.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10195/16687 [00:18<00:11, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10252/16687 [00:18<00:11, 560.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10310/16687 [00:18<00:11, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10368/16687 [00:18<00:11, 568.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10426/16687 [00:18<00:10, 571.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10485/16687 [00:18<00:10, 574.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10543/16687 [00:18<00:10, 573.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10602/16687 [00:18<00:10, 576.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10661/16687 [00:18<00:10, 580.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10720/16687 [00:19<00:10, 583.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10779/16687 [00:19<00:10, 584.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10838/16687 [00:19<00:10, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10897/16687 [00:19<00:09, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10956/16687 [00:19<00:09, 580.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11015/16687 [00:19<00:09, 580.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11074/16687 [00:19<00:09, 577.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11132/16687 [00:19<00:09, 567.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11189/16687 [00:19<00:09, 567.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11247/16687 [00:19<00:09, 568.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11304/16687 [00:20<00:09, 567.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11361/16687 [00:20<00:09, 567.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11418/16687 [00:20<00:09, 566.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11476/16687 [00:20<00:09, 567.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11534/16687 [00:20<00:09, 569.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11592/16687 [00:20<00:08, 571.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11650/16687 [00:20<00:08, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11708/16687 [00:20<00:08, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11767/16687 [00:20<00:08, 577.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11826/16687 [00:20<00:08, 579.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11885/16687 [00:21<00:08, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11944/16687 [00:21<00:08, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12003/16687 [00:21<00:08, 578.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12061/16687 [00:21<00:08, 576.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12119/16687 [00:21<00:07, 571.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12177/16687 [00:21<00:07, 570.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12235/16687 [00:21<00:07, 565.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12292/16687 [00:21<00:07, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12349/16687 [00:21<00:07, 566.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12406/16687 [00:22<00:07, 567.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12463/16687 [00:22<00:07, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12520/16687 [00:22<00:07, 565.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12577/16687 [00:22<00:07, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12635/16687 [00:22<00:07, 565.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12692/16687 [00:22<00:07, 565.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12749/16687 [00:22<00:06, 566.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12806/16687 [00:22<00:06, 562.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12864/16687 [00:22<00:06, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12923/16687 [00:22<00:06, 570.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12982/16687 [00:23<00:06, 575.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13040/16687 [00:23<00:06, 575.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13098/16687 [00:23<00:06, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13156/16687 [00:23<00:06, 576.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13214/16687 [00:23<00:06, 576.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13273/16687 [00:23<00:05, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13331/16687 [00:23<00:05, 576.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13389/16687 [00:23<00:05, 573.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13447/16687 [00:23<00:05, 573.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13506/16687 [00:23<00:05, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13564/16687 [00:24<00:05, 577.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13622/16687 [00:24<00:05, 577.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13681/16687 [00:24<00:05, 580.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13740/16687 [00:24<00:05, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13799/16687 [00:24<00:04, 584.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13858/16687 [00:24<00:04, 575.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13916/16687 [00:24<00:04, 572.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13974/16687 [00:24<00:04, 570.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14032/16687 [00:24<00:04, 543.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14088/16687 [00:24<00:04, 547.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14144/16687 [00:25<00:04, 549.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14201/16687 [00:25<00:04, 554.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14258/16687 [00:25<00:04, 557.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14314/16687 [00:25<00:04, 555.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14371/16687 [00:25<00:04, 559.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14428/16687 [00:25<00:04, 560.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14485/16687 [00:25<00:03, 561.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14542/16687 [00:25<00:03, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14599/16687 [00:25<00:03, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14656/16687 [00:25<00:03, 561.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14713/16687 [00:26<00:03, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14769/16687 [00:26<00:03, 549.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14826/16687 [00:26<00:03, 555.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14884/16687 [00:26<00:03, 559.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▊   | 14941/16687 [00:26<00:03, 560.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14998/16687 [00:26<00:03, 545.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15055/16687 [00:26<00:02, 549.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15113/16687 [00:26<00:02, 558.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15169/16687 [00:26<00:02, 556.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15225/16687 [00:27<00:02, 556.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15282/16687 [00:27<00:02, 559.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15339/16687 [00:27<00:02, 562.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15396/16687 [00:27<00:02, 564.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15453/16687 [00:27<00:02, 561.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15510/16687 [00:27<00:02, 554.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15566/16687 [00:27<00:02, 548.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15623/16687 [00:27<00:01, 552.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15680/16687 [00:27<00:01, 555.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15737/16687 [00:27<00:01, 558.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15794/16687 [00:28<00:01, 561.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15851/16687 [00:28<00:01, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15907/16687 [00:28<00:01, 556.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15964/16687 [00:28<00:01, 559.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16021/16687 [00:28<00:01, 561.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16078/16687 [00:28<00:01, 558.02batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16134/16687 [00:28<00:00, 555.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16191/16687 [00:28<00:00, 557.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16247/16687 [00:28<00:00, 553.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16303/16687 [00:28<00:00, 554.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16359/16687 [00:29<00:00, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16417/16687 [00:29<00:00, 560.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16475/16687 [00:29<00:00, 565.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16534/16687 [00:29<00:00, 571.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16593/16687 [00:29<00:00, 576.25batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16651/16687 [00:29<00:00, 576.21batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  60%|██████▌    | 12/20 [07:51<05:25, 40.65s/epoch, loss=0.65, prev_loss=0.65]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 14/16687 [00:00<02:01, 137.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 65/16687 [00:00<00:48, 342.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 121/16687 [00:00<00:37, 437.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 176/16687 [00:00<00:34, 481.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 233/16687 [00:00<00:32, 512.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 289/16687 [00:00<00:31, 527.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 346/16687 [00:00<00:30, 540.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 403/16687 [00:00<00:29, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 459/16687 [00:00<00:29, 550.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 517/16687 [00:01<00:29, 556.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 573/16687 [00:01<00:28, 555.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 629/16687 [00:01<00:28, 554.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 687/16687 [00:01<00:28, 559.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 744/16687 [00:01<00:28, 558.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 802/16687 [00:01<00:28, 562.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 859/16687 [00:01<00:28, 564.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▊                              | 916/16687 [00:01<00:27, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 973/16687 [00:01<00:27, 565.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1030/16687 [00:01<00:27, 561.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1087/16687 [00:02<00:27, 559.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1144/16687 [00:02<00:27, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1201/16687 [00:02<00:27, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1258/16687 [00:02<00:27, 565.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1315/16687 [00:02<00:27, 562.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1372/16687 [00:02<00:27, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1429/16687 [00:02<00:27, 562.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1486/16687 [00:02<00:26, 564.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1543/16687 [00:02<00:26, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1600/16687 [00:02<00:26, 563.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1657/16687 [00:03<00:26, 564.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1714/16687 [00:03<00:26, 556.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1770/16687 [00:03<00:26, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1827/16687 [00:03<00:26, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1883/16687 [00:03<00:27, 546.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1938/16687 [00:03<00:26, 547.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1993/16687 [00:03<00:26, 545.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2048/16687 [00:03<00:27, 541.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2103/16687 [00:03<00:26, 541.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2159/16687 [00:03<00:26, 544.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2214/16687 [00:04<00:26, 544.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2269/16687 [00:04<00:27, 531.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2323/16687 [00:04<00:27, 526.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2381/16687 [00:04<00:26, 540.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2437/16687 [00:04<00:26, 543.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2492/16687 [00:04<00:26, 543.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2547/16687 [00:04<00:26, 541.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2605/16687 [00:04<00:25, 552.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2661/16687 [00:04<00:25, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2717/16687 [00:04<00:25, 553.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2774/16687 [00:05<00:24, 557.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2831/16687 [00:05<00:24, 561.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2888/16687 [00:05<00:24, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2945/16687 [00:05<00:24, 565.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3002/16687 [00:05<00:24, 566.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3060/16687 [00:05<00:24, 567.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3117/16687 [00:05<00:23, 568.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3174/16687 [00:05<00:23, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3231/16687 [00:05<00:23, 567.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3289/16687 [00:05<00:23, 569.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3347/16687 [00:06<00:23, 571.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3405/16687 [00:06<00:23, 572.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3463/16687 [00:06<00:23, 567.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3521/16687 [00:06<00:23, 568.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3579/16687 [00:06<00:23, 569.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3637/16687 [00:06<00:22, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3695/16687 [00:06<00:22, 570.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3753/16687 [00:06<00:22, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3810/16687 [00:06<00:22, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3868/16687 [00:07<00:22, 567.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3926/16687 [00:07<00:22, 568.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3983/16687 [00:07<00:22, 569.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4040/16687 [00:07<00:22, 569.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4097/16687 [00:07<00:22, 565.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4155/16687 [00:07<00:22, 566.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4213/16687 [00:07<00:21, 568.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4272/16687 [00:07<00:21, 572.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4330/16687 [00:07<00:21, 572.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4388/16687 [00:07<00:21, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4446/16687 [00:08<00:21, 569.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4504/16687 [00:08<00:21, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4562/16687 [00:08<00:21, 569.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4619/16687 [00:08<00:21, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4676/16687 [00:08<00:21, 556.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4733/16687 [00:08<00:21, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4790/16687 [00:08<00:21, 563.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4847/16687 [00:08<00:20, 565.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4905/16687 [00:08<00:20, 566.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4962/16687 [00:08<00:20, 566.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5019/16687 [00:09<00:20, 562.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5076/16687 [00:09<00:20, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5133/16687 [00:09<00:20, 565.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5190/16687 [00:09<00:20, 561.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5247/16687 [00:09<00:20, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5304/16687 [00:09<00:20, 565.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5362/16687 [00:09<00:19, 566.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5419/16687 [00:09<00:19, 567.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5477/16687 [00:09<00:19, 568.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5534/16687 [00:09<00:19, 567.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5591/16687 [00:10<00:19, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5648/16687 [00:10<00:19, 565.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5705/16687 [00:10<00:19, 555.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5761/16687 [00:10<00:19, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5818/16687 [00:10<00:19, 559.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5875/16687 [00:10<00:19, 561.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5932/16687 [00:10<00:19, 563.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5989/16687 [00:10<00:19, 561.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6046/16687 [00:10<00:18, 563.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6103/16687 [00:10<00:18, 563.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6160/16687 [00:11<00:18, 558.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6217/16687 [00:11<00:18, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6274/16687 [00:11<00:18, 555.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6331/16687 [00:11<00:18, 558.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6387/16687 [00:11<00:18, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6445/16687 [00:11<00:18, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6502/16687 [00:11<00:18, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6559/16687 [00:11<00:17, 564.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6616/16687 [00:11<00:17, 564.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6673/16687 [00:11<00:17, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6730/16687 [00:12<00:17, 564.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6787/16687 [00:12<00:17, 561.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6844/16687 [00:12<00:17, 553.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6900/16687 [00:12<00:17, 553.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6957/16687 [00:12<00:17, 557.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7014/16687 [00:12<00:17, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7071/16687 [00:12<00:17, 562.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7128/16687 [00:12<00:16, 564.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7185/16687 [00:12<00:16, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7242/16687 [00:12<00:16, 562.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7299/16687 [00:13<00:16, 562.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7356/16687 [00:13<00:16, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7413/16687 [00:13<00:16, 559.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7469/16687 [00:13<00:16, 558.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7526/16687 [00:13<00:16, 561.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7583/16687 [00:13<00:16, 563.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7640/16687 [00:13<00:16, 561.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7697/16687 [00:13<00:15, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7754/16687 [00:13<00:15, 564.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7811/16687 [00:14<00:15, 564.76batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  47%|██████████████▌                | 7868/16687 [00:14<00:15, 562.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7925/16687 [00:14<00:15, 563.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7982/16687 [00:14<00:15, 554.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8038/16687 [00:14<00:15, 552.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8095/16687 [00:14<00:15, 556.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8152/16687 [00:14<00:15, 558.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8209/16687 [00:14<00:15, 560.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▎               | 8266/16687 [00:14<00:14, 562.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8323/16687 [00:14<00:14, 562.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8380/16687 [00:15<00:14, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8437/16687 [00:15<00:14, 562.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8494/16687 [00:15<00:14, 559.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8550/16687 [00:15<00:14, 559.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8607/16687 [00:15<00:14, 561.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8666/16687 [00:15<00:14, 567.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8723/16687 [00:15<00:14, 567.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8780/16687 [00:15<00:13, 567.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8837/16687 [00:15<00:14, 554.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8894/16687 [00:15<00:13, 557.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8951/16687 [00:16<00:13, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9008/16687 [00:16<00:13, 561.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9065/16687 [00:16<00:13, 546.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9120/16687 [00:16<00:14, 533.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9177/16687 [00:16<00:13, 543.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9234/16687 [00:16<00:13, 550.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9291/16687 [00:16<00:13, 555.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9348/16687 [00:16<00:13, 559.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9405/16687 [00:16<00:13, 557.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9462/16687 [00:16<00:12, 560.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9519/16687 [00:17<00:12, 561.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9576/16687 [00:17<00:12, 558.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9633/16687 [00:17<00:12, 560.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9690/16687 [00:17<00:12, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9747/16687 [00:17<00:12, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9804/16687 [00:17<00:12, 563.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9861/16687 [00:17<00:12, 564.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9918/16687 [00:17<00:11, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9975/16687 [00:17<00:11, 565.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10032/16687 [00:17<00:11, 566.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10089/16687 [00:18<00:11, 565.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10146/16687 [00:18<00:11, 564.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10203/16687 [00:18<00:11, 565.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10260/16687 [00:18<00:11, 565.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10317/16687 [00:18<00:11, 564.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10374/16687 [00:18<00:11, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10431/16687 [00:18<00:11, 562.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10488/16687 [00:18<00:11, 563.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10545/16687 [00:18<00:10, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10602/16687 [00:18<00:10, 565.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10659/16687 [00:19<00:10, 566.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10716/16687 [00:19<00:10, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▎          | 10773/16687 [00:19<00:10, 553.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10829/16687 [00:19<00:10, 552.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10887/16687 [00:19<00:10, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10945/16687 [00:19<00:10, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11004/16687 [00:19<00:09, 570.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11063/16687 [00:19<00:09, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11122/16687 [00:19<00:09, 579.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11180/16687 [00:20<00:09, 577.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11238/16687 [00:20<00:09, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11296/16687 [00:20<00:09, 568.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11353/16687 [00:20<00:09, 565.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11410/16687 [00:20<00:09, 551.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11466/16687 [00:20<00:09, 550.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11522/16687 [00:20<00:09, 552.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11579/16687 [00:20<00:09, 556.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11636/16687 [00:20<00:09, 559.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11693/16687 [00:20<00:08, 562.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11750/16687 [00:21<00:08, 563.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11807/16687 [00:21<00:08, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11864/16687 [00:21<00:08, 552.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11922/16687 [00:21<00:08, 558.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11981/16687 [00:21<00:08, 565.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12039/16687 [00:21<00:08, 568.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12097/16687 [00:21<00:08, 571.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12155/16687 [00:21<00:07, 566.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12212/16687 [00:21<00:07, 564.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12270/16687 [00:21<00:07, 566.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12328/16687 [00:22<00:07, 567.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12385/16687 [00:22<00:07, 560.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12442/16687 [00:22<00:07, 546.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12498/16687 [00:22<00:07, 548.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12553/16687 [00:22<00:07, 547.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12608/16687 [00:22<00:07, 547.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12665/16687 [00:22<00:07, 553.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12722/16687 [00:22<00:07, 557.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12779/16687 [00:22<00:06, 560.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12836/16687 [00:22<00:06, 559.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12894/16687 [00:23<00:06, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12951/16687 [00:23<00:06, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13008/16687 [00:23<00:06, 548.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13063/16687 [00:23<00:06, 542.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13122/16687 [00:23<00:06, 555.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13179/16687 [00:23<00:06, 557.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13235/16687 [00:23<00:06, 555.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13292/16687 [00:23<00:06, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13351/16687 [00:23<00:05, 566.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13411/16687 [00:23<00:05, 573.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13471/16687 [00:24<00:05, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13529/16687 [00:24<00:05, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13587/16687 [00:24<00:05, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13647/16687 [00:24<00:05, 577.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13706/16687 [00:24<00:05, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13764/16687 [00:24<00:05, 571.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13822/16687 [00:24<00:05, 571.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13880/16687 [00:24<00:04, 571.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13938/16687 [00:24<00:04, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13996/16687 [00:25<00:04, 567.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14055/16687 [00:25<00:04, 573.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14113/16687 [00:25<00:04, 571.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14171/16687 [00:25<00:04, 572.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14230/16687 [00:25<00:04, 577.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14288/16687 [00:25<00:04, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14346/16687 [00:25<00:04, 570.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14404/16687 [00:25<00:03, 570.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14462/16687 [00:25<00:03, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14520/16687 [00:25<00:03, 568.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14578/16687 [00:26<00:03, 569.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14635/16687 [00:26<00:03, 565.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14692/16687 [00:26<00:03, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14751/16687 [00:26<00:03, 564.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14809/16687 [00:26<00:03, 567.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14867/16687 [00:26<00:03, 569.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14925/16687 [00:26<00:03, 571.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14984/16687 [00:26<00:02, 576.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15042/16687 [00:26<00:02, 576.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15100/16687 [00:26<00:02, 577.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15159/16687 [00:27<00:02, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15219/16687 [00:27<00:02, 583.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15278/16687 [00:27<00:02, 579.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15336/16687 [00:27<00:02, 571.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15394/16687 [00:27<00:02, 558.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15450/16687 [00:27<00:02, 546.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15506/16687 [00:27<00:02, 549.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15564/16687 [00:27<00:02, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15622/16687 [00:27<00:01, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15681/16687 [00:27<00:01, 570.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15739/16687 [00:28<00:01, 572.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15797/16687 [00:28<00:01, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15855/16687 [00:28<00:01, 570.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15913/16687 [00:28<00:01, 568.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15970/16687 [00:28<00:01, 567.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16027/16687 [00:28<00:01, 565.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16084/16687 [00:28<00:01, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16141/16687 [00:28<00:00, 567.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16198/16687 [00:28<00:00, 553.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16254/16687 [00:29<00:00, 541.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16309/16687 [00:29<00:00, 532.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16363/16687 [00:29<00:00, 529.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16419/16687 [00:29<00:00, 536.84batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16475/16687 [00:29<00:00, 541.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16533/16687 [00:29<00:00, 549.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16590/16687 [00:29<00:00, 555.12batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16646/16687 [00:29<00:00, 553.90batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  65%|██████▌   | 13/20 [08:21<04:21, 37.42s/epoch, loss=0.651, prev_loss=0.65]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 16/16687 [00:00<01:44, 159.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 66/16687 [00:00<00:46, 359.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 119/16687 [00:00<00:38, 434.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 178/16687 [00:00<00:33, 494.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 237/16687 [00:00<00:31, 527.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 296/16687 [00:00<00:29, 547.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 354/16687 [00:00<00:29, 556.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 413/16687 [00:00<00:28, 567.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 472/16687 [00:00<00:28, 573.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 530/16687 [00:01<00:28, 567.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 587/16687 [00:01<00:28, 566.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 644/16687 [00:01<00:28, 564.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 701/16687 [00:01<00:28, 564.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 758/16687 [00:01<00:28, 565.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 815/16687 [00:01<00:28, 560.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 872/16687 [00:01<00:28, 561.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 929/16687 [00:01<00:28, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 986/16687 [00:01<00:27, 563.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1043/16687 [00:01<00:27, 563.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1100/16687 [00:02<00:27, 564.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1157/16687 [00:02<00:27, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1214/16687 [00:02<00:27, 564.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1271/16687 [00:02<00:27, 564.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1328/16687 [00:02<00:27, 563.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1385/16687 [00:02<00:27, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1442/16687 [00:02<00:27, 560.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1499/16687 [00:02<00:27, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1557/16687 [00:02<00:26, 565.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1614/16687 [00:02<00:27, 550.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1671/16687 [00:03<00:27, 555.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1728/16687 [00:03<00:26, 559.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1785/16687 [00:03<00:26, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1842/16687 [00:03<00:26, 559.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1899/16687 [00:03<00:26, 561.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1956/16687 [00:03<00:26, 563.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2013/16687 [00:03<00:25, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2070/16687 [00:03<00:26, 561.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2127/16687 [00:03<00:25, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2184/16687 [00:03<00:25, 560.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2241/16687 [00:04<00:25, 558.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2298/16687 [00:04<00:25, 561.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2355/16687 [00:04<00:25, 563.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2412/16687 [00:04<00:25, 564.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2469/16687 [00:04<00:25, 560.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2526/16687 [00:04<00:25, 558.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2583/16687 [00:04<00:25, 560.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2640/16687 [00:04<00:25, 557.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2696/16687 [00:04<00:25, 557.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2752/16687 [00:04<00:25, 554.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2809/16687 [00:05<00:24, 558.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2865/16687 [00:05<00:24, 557.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2924/16687 [00:05<00:24, 567.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2984/16687 [00:05<00:23, 574.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3043/16687 [00:05<00:23, 578.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3101/16687 [00:05<00:23, 577.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3159/16687 [00:05<00:23, 575.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3217/16687 [00:05<00:23, 572.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3275/16687 [00:05<00:23, 567.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3332/16687 [00:05<00:23, 567.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3389/16687 [00:06<00:23, 566.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3446/16687 [00:06<00:23, 563.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3503/16687 [00:06<00:23, 563.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3560/16687 [00:06<00:23, 563.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3617/16687 [00:06<00:23, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3675/16687 [00:06<00:23, 564.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3732/16687 [00:06<00:23, 555.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3789/16687 [00:06<00:23, 556.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3846/16687 [00:06<00:22, 560.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▎                       | 3903/16687 [00:07<00:22, 562.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3960/16687 [00:07<00:22, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4017/16687 [00:07<00:22, 564.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4076/16687 [00:07<00:22, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4134/16687 [00:07<00:21, 572.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4192/16687 [00:07<00:22, 561.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4249/16687 [00:07<00:22, 554.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4305/16687 [00:07<00:22, 550.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4362/16687 [00:07<00:22, 554.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4419/16687 [00:07<00:22, 557.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4476/16687 [00:08<00:21, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4533/16687 [00:08<00:21, 561.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4590/16687 [00:08<00:21, 562.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4647/16687 [00:08<00:21, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4704/16687 [00:08<00:21, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4761/16687 [00:08<00:21, 562.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4818/16687 [00:08<00:21, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4875/16687 [00:08<00:20, 562.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4932/16687 [00:08<00:20, 560.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4989/16687 [00:08<00:20, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5045/16687 [00:09<00:21, 552.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5101/16687 [00:09<00:21, 540.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5156/16687 [00:09<00:21, 540.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5211/16687 [00:09<00:21, 530.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5265/16687 [00:09<00:21, 525.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5318/16687 [00:09<00:21, 518.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5371/16687 [00:09<00:21, 521.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5428/16687 [00:09<00:21, 532.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5484/16687 [00:09<00:20, 538.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5540/16687 [00:09<00:20, 541.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5595/16687 [00:10<00:20, 542.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5651/16687 [00:10<00:20, 545.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5708/16687 [00:10<00:19, 551.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5765/16687 [00:10<00:19, 556.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5822/16687 [00:10<00:19, 558.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5878/16687 [00:10<00:19, 551.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5935/16687 [00:10<00:19, 555.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5992/16687 [00:10<00:19, 557.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6049/16687 [00:10<00:19, 559.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6106/16687 [00:10<00:18, 561.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6163/16687 [00:11<00:18, 559.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6219/16687 [00:11<00:18, 553.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6275/16687 [00:11<00:19, 547.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6331/16687 [00:11<00:18, 548.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6386/16687 [00:11<00:18, 547.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6442/16687 [00:11<00:18, 549.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6497/16687 [00:11<00:18, 547.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6552/16687 [00:11<00:18, 535.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6611/16687 [00:11<00:18, 549.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6670/16687 [00:12<00:17, 558.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6728/16687 [00:12<00:17, 563.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6785/16687 [00:12<00:17, 565.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6842/16687 [00:12<00:17, 566.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6899/16687 [00:12<00:17, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6956/16687 [00:12<00:17, 566.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7013/16687 [00:12<00:17, 556.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7069/16687 [00:12<00:17, 551.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7125/16687 [00:12<00:17, 535.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7179/16687 [00:12<00:18, 526.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7238/16687 [00:13<00:17, 543.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7297/16687 [00:13<00:16, 556.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7356/16687 [00:13<00:16, 565.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7414/16687 [00:13<00:16, 567.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7472/16687 [00:13<00:16, 568.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7529/16687 [00:13<00:16, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7586/16687 [00:13<00:16, 565.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7644/16687 [00:13<00:15, 567.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7701/16687 [00:13<00:15, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7758/16687 [00:13<00:15, 565.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7815/16687 [00:14<00:15, 565.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7872/16687 [00:14<00:15, 565.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▋                | 7929/16687 [00:14<00:15, 564.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7986/16687 [00:14<00:15, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8043/16687 [00:14<00:15, 552.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8100/16687 [00:14<00:15, 556.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8156/16687 [00:14<00:15, 553.10batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  49%|███████████████▎               | 8212/16687 [00:14<00:15, 553.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▎               | 8269/16687 [00:14<00:15, 555.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8326/16687 [00:14<00:14, 558.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8382/16687 [00:15<00:15, 541.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8439/16687 [00:15<00:15, 547.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8497/16687 [00:15<00:14, 554.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8553/16687 [00:15<00:14, 548.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8612/16687 [00:15<00:14, 560.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8669/16687 [00:15<00:14, 560.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8726/16687 [00:15<00:14, 560.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8783/16687 [00:15<00:14, 560.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8840/16687 [00:15<00:14, 560.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8897/16687 [00:16<00:13, 561.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8954/16687 [00:16<00:13, 561.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9011/16687 [00:16<00:13, 562.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9068/16687 [00:16<00:13, 562.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9125/16687 [00:16<00:13, 562.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9182/16687 [00:16<00:13, 562.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9239/16687 [00:16<00:13, 558.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9295/16687 [00:16<00:13, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9351/16687 [00:16<00:13, 554.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9407/16687 [00:16<00:13, 555.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9463/16687 [00:17<00:13, 552.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9519/16687 [00:17<00:12, 554.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9576/16687 [00:17<00:12, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9632/16687 [00:17<00:12, 556.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9689/16687 [00:17<00:12, 557.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9745/16687 [00:17<00:12, 558.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9802/16687 [00:17<00:12, 559.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9858/16687 [00:17<00:12, 558.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9915/16687 [00:17<00:12, 559.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9971/16687 [00:17<00:12, 559.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10027/16687 [00:18<00:11, 559.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10084/16687 [00:18<00:11, 559.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10141/16687 [00:18<00:11, 559.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10198/16687 [00:18<00:11, 560.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10255/16687 [00:18<00:11, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10312/16687 [00:18<00:11, 556.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10369/16687 [00:18<00:11, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10425/16687 [00:18<00:11, 558.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10482/16687 [00:18<00:11, 561.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10539/16687 [00:18<00:10, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10595/16687 [00:19<00:10, 558.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10651/16687 [00:19<00:10, 551.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10708/16687 [00:19<00:10, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▎          | 10765/16687 [00:19<00:10, 557.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10822/16687 [00:19<00:10, 559.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10879/16687 [00:19<00:10, 560.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10936/16687 [00:19<00:10, 561.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10993/16687 [00:19<00:10, 561.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11050/16687 [00:19<00:10, 553.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11106/16687 [00:19<00:10, 547.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11161/16687 [00:20<00:10, 547.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11218/16687 [00:20<00:09, 552.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11275/16687 [00:20<00:09, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11332/16687 [00:20<00:09, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11389/16687 [00:20<00:09, 560.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11446/16687 [00:20<00:09, 551.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11502/16687 [00:20<00:09, 548.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11558/16687 [00:20<00:09, 550.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11616/16687 [00:20<00:09, 557.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11674/16687 [00:20<00:08, 561.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11732/16687 [00:21<00:08, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11791/16687 [00:21<00:08, 569.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11848/16687 [00:21<00:08, 560.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11905/16687 [00:21<00:08, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11962/16687 [00:21<00:08, 565.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12019/16687 [00:21<00:08, 566.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12076/16687 [00:21<00:08, 567.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12133/16687 [00:21<00:08, 567.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12190/16687 [00:21<00:07, 567.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12247/16687 [00:22<00:07, 556.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12304/16687 [00:22<00:07, 559.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12363/16687 [00:22<00:07, 566.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12421/16687 [00:22<00:07, 569.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12480/16687 [00:22<00:07, 573.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12538/16687 [00:22<00:07, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12596/16687 [00:22<00:07, 572.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12654/16687 [00:22<00:07, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12712/16687 [00:22<00:07, 563.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12769/16687 [00:22<00:06, 561.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12826/16687 [00:23<00:06, 554.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12882/16687 [00:23<00:06, 555.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12941/16687 [00:23<00:06, 562.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12999/16687 [00:23<00:06, 567.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13056/16687 [00:23<00:06, 554.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13112/16687 [00:23<00:06, 555.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13171/16687 [00:23<00:06, 563.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13229/16687 [00:23<00:06, 564.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13286/16687 [00:23<00:06, 566.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13344/16687 [00:23<00:05, 569.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13402/16687 [00:24<00:05, 565.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13459/16687 [00:24<00:05, 547.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13514/16687 [00:24<00:05, 536.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13568/16687 [00:24<00:05, 526.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13623/16687 [00:24<00:05, 530.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13678/16687 [00:24<00:05, 534.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13732/16687 [00:24<00:05, 532.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13787/16687 [00:24<00:05, 536.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13841/16687 [00:24<00:05, 530.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13895/16687 [00:24<00:05, 523.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13949/16687 [00:25<00:05, 526.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14003/16687 [00:25<00:05, 529.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14058/16687 [00:25<00:04, 534.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14117/16687 [00:25<00:04, 550.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14173/16687 [00:25<00:04, 553.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14230/16687 [00:25<00:04, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14287/16687 [00:25<00:04, 561.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14344/16687 [00:25<00:04, 563.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14401/16687 [00:25<00:04, 560.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14459/16687 [00:25<00:03, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14516/16687 [00:26<00:03, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14573/16687 [00:26<00:03, 547.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14629/16687 [00:26<00:03, 551.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14685/16687 [00:26<00:03, 551.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14741/16687 [00:26<00:03, 546.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14796/16687 [00:26<00:03, 546.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14851/16687 [00:26<00:03, 540.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14906/16687 [00:26<00:03, 542.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14962/16687 [00:26<00:03, 547.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15017/16687 [00:27<00:03, 547.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15072/16687 [00:27<00:03, 538.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15128/16687 [00:27<00:02, 541.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15185/16687 [00:27<00:02, 548.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15240/16687 [00:27<00:02, 547.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15297/16687 [00:27<00:02, 553.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15353/16687 [00:27<00:02, 550.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15410/16687 [00:27<00:02, 554.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15466/16687 [00:27<00:02, 555.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15522/16687 [00:27<00:02, 545.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15577/16687 [00:28<00:02, 534.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15631/16687 [00:28<00:02, 526.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15684/16687 [00:28<00:01, 520.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15737/16687 [00:28<00:01, 515.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15790/16687 [00:28<00:01, 517.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15846/16687 [00:28<00:01, 529.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15903/16687 [00:28<00:01, 541.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15960/16687 [00:28<00:01, 547.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16016/16687 [00:28<00:01, 551.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16073/16687 [00:28<00:01, 554.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16131/16687 [00:29<00:00, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16187/16687 [00:29<00:00, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16244/16687 [00:29<00:00, 560.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16301/16687 [00:29<00:00, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16357/16687 [00:29<00:00, 554.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16413/16687 [00:29<00:00, 548.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16469/16687 [00:29<00:00, 549.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16526/16687 [00:29<00:00, 554.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16583/16687 [00:29<00:00, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16639/16687 [00:29<00:00, 558.38batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cuda:0:  70%|███████   | 14/20 [08:51<03:31, 35.26s/epoch, loss=0.65, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 15/16687 [00:00<01:51, 149.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 68/16687 [00:00<00:46, 361.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 119/16687 [00:00<00:38, 427.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 174/16687 [00:00<00:34, 474.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 227/16687 [00:00<00:33, 491.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 277/16687 [00:00<00:33, 491.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 333/16687 [00:00<00:31, 512.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 388/16687 [00:00<00:31, 521.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 442/16687 [00:00<00:30, 527.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 501/16687 [00:01<00:29, 545.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 560/16687 [00:01<00:28, 557.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 619/16687 [00:01<00:28, 566.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 678/16687 [00:01<00:27, 572.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 737/16687 [00:01<00:27, 576.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 795/16687 [00:01<00:27, 576.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 853/16687 [00:01<00:27, 572.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 911/16687 [00:01<00:27, 571.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 969/16687 [00:01<00:27, 571.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1027/16687 [00:01<00:27, 567.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1086/16687 [00:02<00:27, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1145/16687 [00:02<00:26, 577.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1204/16687 [00:02<00:26, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1262/16687 [00:02<00:27, 569.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1319/16687 [00:02<00:27, 557.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1375/16687 [00:02<00:28, 543.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1430/16687 [00:02<00:28, 539.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1485/16687 [00:02<00:28, 539.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1541/16687 [00:02<00:27, 545.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1596/16687 [00:02<00:28, 535.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1653/16687 [00:03<00:27, 544.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1710/16687 [00:03<00:27, 550.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1767/16687 [00:03<00:26, 555.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1824/16687 [00:03<00:26, 559.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1881/16687 [00:03<00:26, 562.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1938/16687 [00:03<00:26, 560.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1995/16687 [00:03<00:26, 562.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2052/16687 [00:03<00:25, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2109/16687 [00:03<00:25, 563.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2166/16687 [00:03<00:25, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2223/16687 [00:04<00:25, 564.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2280/16687 [00:04<00:25, 564.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2337/16687 [00:04<00:25, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2394/16687 [00:04<00:25, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2451/16687 [00:04<00:25, 566.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2508/16687 [00:04<00:25, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2565/16687 [00:04<00:24, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2622/16687 [00:04<00:25, 554.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2681/16687 [00:04<00:24, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2738/16687 [00:04<00:25, 554.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2795/16687 [00:05<00:24, 558.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2853/16687 [00:05<00:24, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2910/16687 [00:05<00:24, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2968/16687 [00:05<00:24, 566.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3026/16687 [00:05<00:23, 569.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3083/16687 [00:05<00:24, 562.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3140/16687 [00:05<00:24, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3197/16687 [00:05<00:24, 557.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3255/16687 [00:05<00:23, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3312/16687 [00:06<00:23, 560.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3369/16687 [00:06<00:23, 560.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3426/16687 [00:06<00:23, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3483/16687 [00:06<00:23, 564.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3540/16687 [00:06<00:23, 565.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3597/16687 [00:06<00:23, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3654/16687 [00:06<00:22, 567.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3711/16687 [00:06<00:23, 557.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3767/16687 [00:06<00:23, 545.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3824/16687 [00:06<00:23, 550.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3881/16687 [00:07<00:23, 554.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3937/16687 [00:07<00:22, 554.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3993/16687 [00:07<00:23, 550.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4049/16687 [00:07<00:23, 540.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4104/16687 [00:07<00:23, 539.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4158/16687 [00:07<00:23, 537.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4212/16687 [00:07<00:23, 528.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4269/16687 [00:07<00:22, 540.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4326/16687 [00:07<00:22, 547.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4383/16687 [00:07<00:22, 552.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4439/16687 [00:08<00:22, 550.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4495/16687 [00:08<00:22, 543.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4550/16687 [00:08<00:22, 537.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4608/16687 [00:08<00:22, 547.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4667/16687 [00:08<00:21, 559.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4725/16687 [00:08<00:21, 564.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4782/16687 [00:08<00:21, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4839/16687 [00:08<00:21, 560.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4896/16687 [00:08<00:20, 562.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4953/16687 [00:08<00:20, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5010/16687 [00:09<00:21, 555.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5066/16687 [00:09<00:21, 543.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5121/16687 [00:09<00:21, 541.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5176/16687 [00:09<00:21, 540.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5231/16687 [00:09<00:21, 536.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5286/16687 [00:09<00:21, 537.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5340/16687 [00:09<00:21, 534.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5396/16687 [00:09<00:20, 539.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5453/16687 [00:09<00:20, 547.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5511/16687 [00:10<00:20, 554.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5567/16687 [00:10<00:20, 554.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5623/16687 [00:10<00:20, 552.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5679/16687 [00:10<00:19, 553.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5737/16687 [00:10<00:19, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5794/16687 [00:10<00:19, 559.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5851/16687 [00:10<00:19, 562.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5908/16687 [00:10<00:19, 563.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5965/16687 [00:10<00:19, 562.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6022/16687 [00:10<00:18, 562.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6079/16687 [00:11<00:18, 564.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6136/16687 [00:11<00:18, 564.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6193/16687 [00:11<00:18, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6250/16687 [00:11<00:18, 562.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6307/16687 [00:11<00:18, 563.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6364/16687 [00:11<00:18, 564.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6421/16687 [00:11<00:18, 565.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6478/16687 [00:11<00:18, 565.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6535/16687 [00:11<00:17, 565.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▏                  | 6592/16687 [00:11<00:17, 565.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6649/16687 [00:12<00:17, 566.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6706/16687 [00:12<00:17, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6763/16687 [00:12<00:17, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6820/16687 [00:12<00:17, 566.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6877/16687 [00:12<00:17, 566.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6934/16687 [00:12<00:17, 566.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6991/16687 [00:12<00:17, 562.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7048/16687 [00:12<00:17, 563.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7105/16687 [00:12<00:16, 563.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7162/16687 [00:12<00:16, 564.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7219/16687 [00:13<00:16, 565.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7276/16687 [00:13<00:16, 565.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7333/16687 [00:13<00:16, 565.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7390/16687 [00:13<00:16, 566.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7447/16687 [00:13<00:16, 566.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7504/16687 [00:13<00:16, 566.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7561/16687 [00:13<00:16, 566.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7618/16687 [00:13<00:15, 567.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7675/16687 [00:13<00:15, 564.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7732/16687 [00:13<00:15, 565.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7789/16687 [00:14<00:15, 566.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7846/16687 [00:14<00:15, 557.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7902/16687 [00:14<00:15, 551.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7958/16687 [00:14<00:15, 551.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8014/16687 [00:14<00:15, 550.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8073/16687 [00:14<00:15, 559.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8130/16687 [00:14<00:15, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8187/16687 [00:14<00:15, 561.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8244/16687 [00:14<00:15, 559.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8300/16687 [00:14<00:15, 554.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8356/16687 [00:15<00:15, 547.76batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|███████████████▋               | 8413/16687 [00:15<00:14, 553.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8469/16687 [00:15<00:14, 548.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8526/16687 [00:15<00:14, 553.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8584/16687 [00:15<00:14, 559.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8640/16687 [00:15<00:14, 545.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8697/16687 [00:15<00:14, 551.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▎              | 8753/16687 [00:15<00:14, 546.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8808/16687 [00:15<00:14, 536.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8862/16687 [00:16<00:14, 531.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8918/16687 [00:16<00:14, 537.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8974/16687 [00:16<00:14, 543.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9029/16687 [00:16<00:14, 544.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▉              | 9086/16687 [00:16<00:13, 550.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9142/16687 [00:16<00:13, 551.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9199/16687 [00:16<00:13, 556.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9256/16687 [00:16<00:13, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9313/16687 [00:16<00:13, 558.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9370/16687 [00:16<00:13, 560.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▌             | 9427/16687 [00:17<00:13, 558.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9483/16687 [00:17<00:12, 556.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9540/16687 [00:17<00:12, 559.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9597/16687 [00:17<00:12, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9654/16687 [00:17<00:12, 562.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9711/16687 [00:17<00:12, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9768/16687 [00:17<00:12, 557.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9825/16687 [00:17<00:12, 560.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9882/16687 [00:17<00:12, 558.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9938/16687 [00:17<00:12, 553.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9995/16687 [00:18<00:12, 556.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10051/16687 [00:18<00:11, 556.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10110/16687 [00:18<00:11, 566.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10167/16687 [00:18<00:11, 566.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10226/16687 [00:18<00:11, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10284/16687 [00:18<00:11, 565.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10341/16687 [00:18<00:11, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10398/16687 [00:18<00:11, 560.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10456/16687 [00:18<00:11, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10513/16687 [00:18<00:11, 551.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10569/16687 [00:19<00:11, 548.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10624/16687 [00:19<00:11, 545.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10679/16687 [00:19<00:11, 534.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10733/16687 [00:19<00:11, 535.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10787/16687 [00:19<00:11, 532.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10844/16687 [00:19<00:10, 542.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10901/16687 [00:19<00:10, 549.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10958/16687 [00:19<00:10, 554.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11015/16687 [00:19<00:10, 557.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11072/16687 [00:19<00:10, 559.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11129/16687 [00:20<00:09, 561.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11186/16687 [00:20<00:09, 559.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11242/16687 [00:20<00:10, 540.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11297/16687 [00:20<00:09, 540.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11355/16687 [00:20<00:09, 550.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11413/16687 [00:20<00:09, 556.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11469/16687 [00:20<00:09, 551.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11525/16687 [00:20<00:09, 538.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11580/16687 [00:20<00:09, 541.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11635/16687 [00:21<00:09, 529.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11691/16687 [00:21<00:09, 536.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11749/16687 [00:21<00:09, 546.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11805/16687 [00:21<00:08, 548.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11862/16687 [00:21<00:08, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11918/16687 [00:21<00:08, 554.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11974/16687 [00:21<00:08, 539.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12031/16687 [00:21<00:08, 545.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12086/16687 [00:21<00:08, 545.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12141/16687 [00:21<00:08, 544.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12196/16687 [00:22<00:08, 532.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12250/16687 [00:22<00:08, 532.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12304/16687 [00:22<00:08, 528.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12357/16687 [00:22<00:08, 520.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12410/16687 [00:22<00:08, 520.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12468/16687 [00:22<00:07, 537.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12527/16687 [00:22<00:07, 551.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12585/16687 [00:22<00:07, 558.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12644/16687 [00:22<00:07, 565.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12703/16687 [00:22<00:06, 571.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12761/16687 [00:23<00:06, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12818/16687 [00:23<00:07, 549.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12874/16687 [00:23<00:07, 540.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12929/16687 [00:23<00:07, 530.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12986/16687 [00:23<00:06, 540.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13044/16687 [00:23<00:06, 551.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13103/16687 [00:23<00:06, 561.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13160/16687 [00:23<00:06, 550.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13216/16687 [00:23<00:06, 550.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13273/16687 [00:24<00:06, 554.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13329/16687 [00:24<00:06, 552.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13385/16687 [00:24<00:05, 554.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13443/16687 [00:24<00:05, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13499/16687 [00:24<00:05, 556.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13556/16687 [00:24<00:05, 560.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13614/16687 [00:24<00:05, 563.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13671/16687 [00:24<00:05, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13728/16687 [00:24<00:05, 566.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13785/16687 [00:24<00:05, 556.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13841/16687 [00:25<00:05, 550.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13897/16687 [00:25<00:05, 543.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13952/16687 [00:25<00:05, 539.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14008/16687 [00:25<00:04, 543.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14063/16687 [00:25<00:04, 544.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14121/16687 [00:25<00:04, 552.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14181/16687 [00:25<00:04, 564.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14239/16687 [00:25<00:04, 568.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14296/16687 [00:25<00:04, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14353/16687 [00:25<00:04, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14410/16687 [00:26<00:04, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14467/16687 [00:26<00:03, 561.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14524/16687 [00:26<00:03, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14581/16687 [00:26<00:03, 560.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14638/16687 [00:26<00:03, 557.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14696/16687 [00:26<00:03, 563.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14754/16687 [00:26<00:03, 566.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14813/16687 [00:26<00:03, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14872/16687 [00:26<00:03, 577.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14931/16687 [00:26<00:03, 580.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14990/16687 [00:27<00:02, 583.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15049/16687 [00:27<00:02, 575.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15107/16687 [00:27<00:02, 576.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15165/16687 [00:27<00:02, 576.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15223/16687 [00:27<00:02, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15281/16687 [00:27<00:02, 571.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15339/16687 [00:27<00:02, 571.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15397/16687 [00:27<00:02, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15455/16687 [00:27<00:02, 568.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15513/16687 [00:27<00:02, 568.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15571/16687 [00:28<00:01, 569.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15629/16687 [00:28<00:01, 571.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15687/16687 [00:28<00:01, 571.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15746/16687 [00:28<00:01, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15805/16687 [00:28<00:01, 578.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15863/16687 [00:28<00:01, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15921/16687 [00:28<00:01, 569.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15978/16687 [00:28<00:01, 564.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16035/16687 [00:28<00:01, 548.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16090/16687 [00:29<00:01, 533.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16147/16687 [00:29<00:00, 542.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16204/16687 [00:29<00:00, 548.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16261/16687 [00:29<00:00, 553.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16318/16687 [00:29<00:00, 558.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16375/16687 [00:29<00:00, 560.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16432/16687 [00:29<00:00, 562.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16489/16687 [00:29<00:00, 564.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16546/16687 [00:29<00:00, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16603/16687 [00:29<00:00, 562.53batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16660/16687 [00:30<00:00, 564.73batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  70%|███████   | 14/20 [09:21<03:31, 35.26s/epoch, loss=0.651, prev_loss=0.65]\u001b[AINFO:pykeen.evaluation.evaluator:Evaluation took 45.01s seconds\n",
      "Training epochs on cuda:0:  75%|███████▌  | 15/20 [10:06<03:56, 47.32s/epoch, loss=0.651, prev_loss=0.65]\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:33, 179.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 76/16687 [00:00<00:40, 412.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 127/16687 [00:00<00:36, 454.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 184/16687 [00:00<00:33, 498.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 240/16687 [00:00<00:31, 518.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 297/16687 [00:00<00:30, 535.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 353/16687 [00:00<00:30, 541.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 410/16687 [00:00<00:29, 549.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 467/16687 [00:00<00:29, 555.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 525/16687 [00:01<00:28, 560.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 582/16687 [00:01<00:28, 557.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 638/16687 [00:01<00:28, 557.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 696/16687 [00:01<00:28, 562.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 753/16687 [00:01<00:28, 564.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 810/16687 [00:01<00:28, 566.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 868/16687 [00:01<00:27, 567.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 926/16687 [00:01<00:27, 568.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 983/16687 [00:01<00:28, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1040/16687 [00:01<00:28, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1096/16687 [00:02<00:27, 558.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1152/16687 [00:02<00:28, 554.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1208/16687 [00:02<00:27, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1267/16687 [00:02<00:27, 563.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1324/16687 [00:02<00:27, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1381/16687 [00:02<00:27, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1438/16687 [00:02<00:27, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1495/16687 [00:02<00:27, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1552/16687 [00:02<00:27, 550.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1608/16687 [00:02<00:27, 552.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1664/16687 [00:03<00:27, 553.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1720/16687 [00:03<00:27, 554.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1776/16687 [00:03<00:26, 554.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1833/16687 [00:03<00:26, 559.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1889/16687 [00:03<00:26, 558.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1945/16687 [00:03<00:26, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2001/16687 [00:03<00:26, 558.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2058/16687 [00:03<00:26, 561.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2115/16687 [00:03<00:26, 558.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2172/16687 [00:03<00:25, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2229/16687 [00:04<00:25, 563.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2286/16687 [00:04<00:25, 564.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2343/16687 [00:04<00:25, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2399/16687 [00:04<00:25, 555.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2455/16687 [00:04<00:26, 538.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2511/16687 [00:04<00:26, 544.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2568/16687 [00:04<00:25, 550.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2624/16687 [00:04<00:25, 551.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2680/16687 [00:04<00:25, 552.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2738/16687 [00:04<00:24, 558.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2795/16687 [00:05<00:24, 560.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2852/16687 [00:05<00:25, 551.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2908/16687 [00:05<00:25, 549.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2963/16687 [00:05<00:25, 548.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3020/16687 [00:05<00:24, 552.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3077/16687 [00:05<00:24, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3133/16687 [00:05<00:24, 555.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3190/16687 [00:05<00:24, 558.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3247/16687 [00:05<00:24, 559.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3303/16687 [00:05<00:24, 556.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3360/16687 [00:06<00:23, 558.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3417/16687 [00:06<00:23, 559.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3474/16687 [00:06<00:23, 560.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3532/16687 [00:06<00:23, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3590/16687 [00:06<00:23, 567.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3647/16687 [00:06<00:23, 565.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3704/16687 [00:06<00:22, 565.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3761/16687 [00:06<00:22, 564.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3818/16687 [00:06<00:22, 562.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3875/16687 [00:07<00:22, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3932/16687 [00:07<00:22, 562.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3989/16687 [00:07<00:22, 561.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4046/16687 [00:07<00:22, 556.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4103/16687 [00:07<00:22, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4160/16687 [00:07<00:22, 559.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4217/16687 [00:07<00:22, 560.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4274/16687 [00:07<00:22, 560.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4331/16687 [00:07<00:22, 556.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4388/16687 [00:07<00:22, 558.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4444/16687 [00:08<00:22, 556.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4500/16687 [00:08<00:21, 554.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4557/16687 [00:08<00:21, 557.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4613/16687 [00:08<00:21, 554.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4669/16687 [00:08<00:21, 554.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4726/16687 [00:08<00:21, 557.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4782/16687 [00:08<00:21, 552.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4838/16687 [00:08<00:21, 552.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4895/16687 [00:08<00:21, 557.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4953/16687 [00:08<00:20, 561.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5011/16687 [00:09<00:20, 566.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5069/16687 [00:09<00:20, 568.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5128/16687 [00:09<00:20, 572.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5186/16687 [00:09<00:20, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5244/16687 [00:09<00:20, 571.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5302/16687 [00:09<00:19, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5361/16687 [00:09<00:19, 573.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5420/16687 [00:09<00:19, 576.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5478/16687 [00:09<00:19, 575.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5536/16687 [00:09<00:19, 572.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5594/16687 [00:10<00:19, 571.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5652/16687 [00:10<00:19, 566.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5709/16687 [00:10<00:19, 566.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5766/16687 [00:10<00:19, 567.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5823/16687 [00:10<00:19, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5880/16687 [00:10<00:19, 560.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5939/16687 [00:10<00:18, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5998/16687 [00:10<00:18, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6056/16687 [00:10<00:18, 572.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6114/16687 [00:10<00:18, 569.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6171/16687 [00:11<00:18, 569.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6228/16687 [00:11<00:18, 564.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6285/16687 [00:11<00:18, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6342/16687 [00:11<00:18, 561.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6399/16687 [00:11<00:18, 563.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6456/16687 [00:11<00:18, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6513/16687 [00:11<00:18, 558.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6570/16687 [00:11<00:18, 561.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6627/16687 [00:11<00:17, 559.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6684/16687 [00:11<00:17, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6741/16687 [00:12<00:17, 559.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6797/16687 [00:12<00:17, 558.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6853/16687 [00:12<00:17, 556.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6909/16687 [00:12<00:17, 556.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6966/16687 [00:12<00:17, 560.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7023/16687 [00:12<00:17, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7081/16687 [00:12<00:17, 564.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7139/16687 [00:12<00:16, 567.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7198/16687 [00:12<00:16, 572.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7256/16687 [00:13<00:16, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7314/16687 [00:13<00:16, 566.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7373/16687 [00:13<00:16, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7431/16687 [00:13<00:16, 571.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7489/16687 [00:13<00:16, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7545/16687 [00:13<00:16, 551.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7602/16687 [00:13<00:16, 554.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7659/16687 [00:13<00:16, 557.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7716/16687 [00:13<00:16, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7773/16687 [00:13<00:15, 561.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7830/16687 [00:14<00:15, 562.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7887/16687 [00:14<00:15, 558.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7944/16687 [00:14<00:15, 560.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8001/16687 [00:14<00:15, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8058/16687 [00:14<00:15, 562.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8115/16687 [00:14<00:15, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8172/16687 [00:14<00:15, 561.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8229/16687 [00:14<00:15, 563.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8286/16687 [00:14<00:14, 561.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8343/16687 [00:14<00:14, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8400/16687 [00:15<00:14, 561.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8457/16687 [00:15<00:14, 563.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8514/16687 [00:15<00:14, 565.47batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  51%|███████████████▉               | 8571/16687 [00:15<00:14, 565.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8628/16687 [00:15<00:14, 566.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8685/16687 [00:15<00:14, 553.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8741/16687 [00:15<00:14, 553.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8798/16687 [00:15<00:14, 556.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8855/16687 [00:15<00:14, 557.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8912/16687 [00:15<00:13, 559.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8968/16687 [00:16<00:13, 551.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9024/16687 [00:16<00:13, 554.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9081/16687 [00:16<00:13, 558.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9138/16687 [00:16<00:13, 560.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9195/16687 [00:16<00:13, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9252/16687 [00:16<00:13, 560.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9309/16687 [00:16<00:13, 563.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9367/16687 [00:16<00:12, 565.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▌             | 9424/16687 [00:16<00:12, 566.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9481/16687 [00:16<00:12, 566.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9538/16687 [00:17<00:12, 565.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9595/16687 [00:17<00:12, 566.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9653/16687 [00:17<00:12, 568.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9710/16687 [00:17<00:12, 567.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9767/16687 [00:17<00:12, 566.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9824/16687 [00:17<00:12, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9881/16687 [00:17<00:12, 566.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9938/16687 [00:17<00:11, 566.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9995/16687 [00:17<00:11, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10052/16687 [00:17<00:11, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10109/16687 [00:18<00:11, 563.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10166/16687 [00:18<00:11, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10223/16687 [00:18<00:11, 557.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10279/16687 [00:18<00:11, 555.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10335/16687 [00:18<00:11, 552.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10391/16687 [00:18<00:11, 551.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10448/16687 [00:18<00:11, 554.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10505/16687 [00:18<00:11, 557.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10562/16687 [00:18<00:10, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10619/16687 [00:19<00:10, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10676/16687 [00:19<00:10, 560.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10733/16687 [00:19<00:10, 560.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10790/16687 [00:19<00:10, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10847/16687 [00:19<00:10, 561.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10904/16687 [00:19<00:10, 560.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10961/16687 [00:19<00:10, 559.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11018/16687 [00:19<00:10, 560.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11075/16687 [00:19<00:10, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11132/16687 [00:19<00:09, 557.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11188/16687 [00:20<00:10, 547.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11243/16687 [00:20<00:10, 540.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11298/16687 [00:20<00:10, 537.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11353/16687 [00:20<00:09, 540.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11409/16687 [00:20<00:09, 546.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11466/16687 [00:20<00:09, 551.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11523/16687 [00:20<00:09, 554.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11579/16687 [00:20<00:09, 553.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11636/16687 [00:20<00:09, 556.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11693/16687 [00:20<00:08, 558.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11750/16687 [00:21<00:08, 562.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11807/16687 [00:21<00:08, 562.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11864/16687 [00:21<00:08, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11921/16687 [00:21<00:08, 562.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11978/16687 [00:21<00:08, 555.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12034/16687 [00:21<00:08, 554.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12091/16687 [00:21<00:08, 557.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12147/16687 [00:21<00:08, 556.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12204/16687 [00:21<00:08, 558.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12260/16687 [00:21<00:07, 557.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12317/16687 [00:22<00:07, 559.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12373/16687 [00:22<00:07, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12429/16687 [00:22<00:07, 549.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12485/16687 [00:22<00:07, 537.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12539/16687 [00:22<00:07, 536.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12593/16687 [00:22<00:07, 529.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12648/16687 [00:22<00:07, 533.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12705/16687 [00:22<00:07, 542.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12762/16687 [00:22<00:07, 549.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12819/16687 [00:22<00:06, 553.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12875/16687 [00:23<00:06, 552.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12931/16687 [00:23<00:06, 545.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12986/16687 [00:23<00:06, 546.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13043/16687 [00:23<00:06, 551.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13099/16687 [00:23<00:06, 541.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13155/16687 [00:23<00:06, 544.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13212/16687 [00:23<00:06, 549.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13268/16687 [00:23<00:06, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13326/16687 [00:23<00:06, 557.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13384/16687 [00:24<00:05, 562.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13442/16687 [00:24<00:05, 566.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13499/16687 [00:24<00:05, 560.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13556/16687 [00:24<00:05, 558.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13613/16687 [00:24<00:05, 559.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13669/16687 [00:24<00:05, 553.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13726/16687 [00:24<00:05, 556.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13783/16687 [00:24<00:05, 558.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13840/16687 [00:24<00:05, 559.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13899/16687 [00:24<00:04, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13958/16687 [00:25<00:04, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14017/16687 [00:25<00:04, 576.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14075/16687 [00:25<00:04, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14132/16687 [00:25<00:04, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14189/16687 [00:25<00:04, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14246/16687 [00:25<00:04, 556.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14302/16687 [00:25<00:04, 544.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14358/16687 [00:25<00:04, 546.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14414/16687 [00:25<00:04, 548.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14471/16687 [00:25<00:04, 552.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14528/16687 [00:26<00:03, 555.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14585/16687 [00:26<00:03, 557.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14641/16687 [00:26<00:03, 550.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14697/16687 [00:26<00:03, 542.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14754/16687 [00:26<00:03, 548.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14809/16687 [00:26<00:03, 543.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14865/16687 [00:26<00:03, 545.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14922/16687 [00:26<00:03, 550.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14979/16687 [00:26<00:03, 553.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15036/16687 [00:26<00:02, 556.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15093/16687 [00:27<00:02, 558.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15150/16687 [00:27<00:02, 559.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15206/16687 [00:27<00:02, 550.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15263/16687 [00:27<00:02, 553.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15319/16687 [00:27<00:02, 554.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15375/16687 [00:27<00:02, 551.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15431/16687 [00:27<00:02, 540.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15487/16687 [00:27<00:02, 543.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15542/16687 [00:27<00:02, 534.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15597/16687 [00:28<00:02, 537.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15653/16687 [00:28<00:01, 541.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15710/16687 [00:28<00:01, 548.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15765/16687 [00:28<00:01, 547.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15822/16687 [00:28<00:01, 552.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15878/16687 [00:28<00:01, 553.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▋ | 15934/16687 [00:28<00:01, 544.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15989/16687 [00:28<00:01, 530.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16046/16687 [00:28<00:01, 539.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16103/16687 [00:28<00:01, 546.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16159/16687 [00:29<00:00, 547.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16215/16687 [00:29<00:00, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16270/16687 [00:29<00:00, 548.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16325/16687 [00:29<00:00, 544.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16381/16687 [00:29<00:00, 546.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16438/16687 [00:29<00:00, 550.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16494/16687 [00:29<00:00, 553.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16550/16687 [00:29<00:00, 551.60batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16607/16687 [00:29<00:00, 555.29batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16664/16687 [00:29<00:00, 557.61batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  80%|███████▏ | 16/20 [10:37<02:48, 42.17s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 15/16687 [00:00<01:51, 149.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 66/16687 [00:00<00:46, 361.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 122/16687 [00:00<00:36, 449.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 179/16687 [00:00<00:33, 495.24batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   1%|▍                               | 236/16687 [00:00<00:31, 519.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 291/16687 [00:00<00:30, 529.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 348/16687 [00:00<00:30, 540.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 403/16687 [00:00<00:29, 543.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 458/16687 [00:00<00:29, 544.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 513/16687 [00:01<00:29, 545.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 570/16687 [00:01<00:29, 550.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 626/16687 [00:01<00:29, 553.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 682/16687 [00:01<00:28, 552.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 738/16687 [00:01<00:29, 543.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 794/16687 [00:01<00:29, 547.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 851/16687 [00:01<00:28, 551.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 908/16687 [00:01<00:28, 555.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 965/16687 [00:01<00:28, 557.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1022/16687 [00:01<00:28, 559.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|██                             | 1078/16687 [00:02<00:28, 556.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1135/16687 [00:02<00:27, 558.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1192/16687 [00:02<00:27, 558.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1249/16687 [00:02<00:27, 559.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1306/16687 [00:02<00:27, 560.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1363/16687 [00:02<00:27, 557.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1421/16687 [00:02<00:27, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1478/16687 [00:02<00:27, 560.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1537/16687 [00:02<00:26, 567.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1594/16687 [00:02<00:26, 565.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1651/16687 [00:03<00:26, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1708/16687 [00:03<00:26, 564.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1765/16687 [00:03<00:26, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1822/16687 [00:03<00:26, 561.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1879/16687 [00:03<00:26, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1936/16687 [00:03<00:26, 560.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1993/16687 [00:03<00:26, 557.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2050/16687 [00:03<00:26, 558.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2107/16687 [00:03<00:26, 559.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2164/16687 [00:03<00:25, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2221/16687 [00:04<00:25, 560.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2278/16687 [00:04<00:25, 561.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2335/16687 [00:04<00:25, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2392/16687 [00:04<00:25, 560.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2449/16687 [00:04<00:25, 561.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2506/16687 [00:04<00:25, 560.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2563/16687 [00:04<00:25, 560.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2620/16687 [00:04<00:25, 561.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2677/16687 [00:04<00:24, 561.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2734/16687 [00:04<00:24, 561.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2791/16687 [00:05<00:24, 561.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2848/16687 [00:05<00:24, 557.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2904/16687 [00:05<00:24, 557.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2961/16687 [00:05<00:24, 559.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3017/16687 [00:05<00:24, 558.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3073/16687 [00:05<00:24, 550.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3129/16687 [00:05<00:24, 549.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3185/16687 [00:05<00:24, 549.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3241/16687 [00:05<00:24, 549.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3296/16687 [00:06<00:24, 537.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3350/16687 [00:06<00:24, 533.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3406/16687 [00:06<00:24, 538.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3464/16687 [00:06<00:24, 550.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3522/16687 [00:06<00:23, 558.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3581/16687 [00:06<00:23, 566.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3638/16687 [00:06<00:23, 564.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3696/16687 [00:06<00:22, 567.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3755/16687 [00:06<00:22, 573.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3814/16687 [00:06<00:22, 577.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3873/16687 [00:07<00:22, 579.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3932/16687 [00:07<00:21, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3991/16687 [00:07<00:22, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4049/16687 [00:07<00:22, 568.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4106/16687 [00:07<00:22, 568.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4165/16687 [00:07<00:21, 574.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4223/16687 [00:07<00:22, 564.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4280/16687 [00:07<00:21, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4339/16687 [00:07<00:21, 570.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4397/16687 [00:07<00:21, 571.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4456/16687 [00:08<00:21, 576.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4515/16687 [00:08<00:20, 580.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4574/16687 [00:08<00:21, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4632/16687 [00:08<00:21, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4690/16687 [00:08<00:20, 573.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4748/16687 [00:08<00:20, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4806/16687 [00:08<00:20, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4864/16687 [00:08<00:20, 571.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4923/16687 [00:08<00:20, 576.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4981/16687 [00:08<00:20, 575.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5040/16687 [00:09<00:20, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5098/16687 [00:09<00:20, 555.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5154/16687 [00:09<00:21, 548.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5210/16687 [00:09<00:20, 548.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5268/16687 [00:09<00:20, 555.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5324/16687 [00:09<00:20, 556.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5380/16687 [00:09<00:20, 557.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5437/16687 [00:09<00:20, 559.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5495/16687 [00:09<00:19, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5552/16687 [00:09<00:19, 560.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5609/16687 [00:10<00:19, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5665/16687 [00:10<00:19, 556.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5722/16687 [00:10<00:19, 559.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5778/16687 [00:10<00:19, 556.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5834/16687 [00:10<00:19, 555.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5891/16687 [00:10<00:19, 558.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5947/16687 [00:10<00:19, 558.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6005/16687 [00:10<00:18, 563.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6063/16687 [00:10<00:18, 565.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6121/16687 [00:10<00:18, 567.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6179/16687 [00:11<00:18, 568.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6237/16687 [00:11<00:18, 569.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6295/16687 [00:11<00:18, 570.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6353/16687 [00:11<00:18, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6411/16687 [00:11<00:18, 567.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6469/16687 [00:11<00:17, 568.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6526/16687 [00:11<00:18, 555.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6582/16687 [00:11<00:18, 546.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6641/16687 [00:11<00:17, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6700/16687 [00:12<00:17, 567.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6759/16687 [00:12<00:17, 572.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6818/16687 [00:12<00:17, 576.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6877/16687 [00:12<00:16, 577.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6935/16687 [00:12<00:17, 560.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6994/16687 [00:12<00:17, 567.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7051/16687 [00:12<00:17, 552.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7107/16687 [00:12<00:17, 550.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7165/16687 [00:12<00:17, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7223/16687 [00:12<00:16, 562.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7282/16687 [00:13<00:16, 569.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7340/16687 [00:13<00:16, 571.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7398/16687 [00:13<00:16, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7455/16687 [00:13<00:16, 553.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7512/16687 [00:13<00:16, 555.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7568/16687 [00:13<00:16, 548.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7625/16687 [00:13<00:16, 552.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7681/16687 [00:13<00:16, 549.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7736/16687 [00:13<00:16, 549.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7793/16687 [00:13<00:16, 553.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7850/16687 [00:14<00:15, 557.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7907/16687 [00:14<00:15, 559.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7964/16687 [00:14<00:15, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8021/16687 [00:14<00:15, 561.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8078/16687 [00:14<00:15, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8135/16687 [00:14<00:15, 564.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8192/16687 [00:14<00:15, 564.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8249/16687 [00:14<00:14, 564.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8306/16687 [00:14<00:14, 563.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8363/16687 [00:14<00:14, 557.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8422/16687 [00:15<00:14, 564.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8481/16687 [00:15<00:14, 570.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8540/16687 [00:15<00:14, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8598/16687 [00:15<00:14, 570.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8656/16687 [00:15<00:14, 568.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8714/16687 [00:15<00:14, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8771/16687 [00:15<00:13, 568.03batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  53%|████████████████▍              | 8828/16687 [00:15<00:13, 568.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8885/16687 [00:15<00:13, 564.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8942/16687 [00:16<00:13, 562.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8999/16687 [00:16<00:13, 564.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9056/16687 [00:16<00:13, 565.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9113/16687 [00:16<00:13, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9170/16687 [00:16<00:13, 557.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9228/16687 [00:16<00:13, 562.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9286/16687 [00:16<00:13, 566.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9343/16687 [00:16<00:13, 562.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9402/16687 [00:16<00:12, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9460/16687 [00:16<00:12, 571.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9518/16687 [00:17<00:12, 569.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9575/16687 [00:17<00:12, 569.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9632/16687 [00:17<00:12, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9689/16687 [00:17<00:12, 561.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9746/16687 [00:17<00:12, 555.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9802/16687 [00:17<00:12, 550.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9859/16687 [00:17<00:12, 554.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9915/16687 [00:17<00:12, 548.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9971/16687 [00:17<00:12, 549.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10027/16687 [00:17<00:12, 551.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10084/16687 [00:18<00:11, 556.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10140/16687 [00:18<00:11, 557.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10198/16687 [00:18<00:11, 561.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10255/16687 [00:18<00:11, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10311/16687 [00:18<00:11, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10368/16687 [00:18<00:11, 557.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10427/16687 [00:18<00:11, 565.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10486/16687 [00:18<00:10, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10544/16687 [00:18<00:10, 571.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10602/16687 [00:18<00:10, 570.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10660/16687 [00:19<00:10, 572.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10718/16687 [00:19<00:10, 572.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▎          | 10776/16687 [00:19<00:10, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10835/16687 [00:19<00:10, 573.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10893/16687 [00:19<00:10, 564.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10952/16687 [00:19<00:10, 570.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11011/16687 [00:19<00:09, 573.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11069/16687 [00:19<00:09, 575.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11128/16687 [00:19<00:09, 578.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11187/16687 [00:19<00:09, 581.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11246/16687 [00:20<00:09, 584.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11305/16687 [00:20<00:09, 585.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11364/16687 [00:20<00:09, 586.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11423/16687 [00:20<00:08, 586.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11482/16687 [00:20<00:08, 586.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11541/16687 [00:20<00:08, 582.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11600/16687 [00:20<00:08, 584.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11659/16687 [00:20<00:08, 584.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11718/16687 [00:20<00:08, 573.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11776/16687 [00:20<00:08, 571.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11834/16687 [00:21<00:08, 568.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11891/16687 [00:21<00:08, 567.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11948/16687 [00:21<00:08, 566.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12005/16687 [00:21<00:08, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12062/16687 [00:21<00:08, 564.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12119/16687 [00:21<00:08, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12176/16687 [00:21<00:08, 563.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12233/16687 [00:21<00:07, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12290/16687 [00:21<00:07, 563.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12347/16687 [00:22<00:07, 563.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12404/16687 [00:22<00:07, 563.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12461/16687 [00:22<00:07, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12518/16687 [00:22<00:07, 564.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12575/16687 [00:22<00:07, 564.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12632/16687 [00:22<00:07, 564.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12689/16687 [00:22<00:07, 564.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12746/16687 [00:22<00:06, 564.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12803/16687 [00:22<00:06, 564.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12860/16687 [00:22<00:06, 563.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12917/16687 [00:23<00:06, 563.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12974/16687 [00:23<00:06, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13031/16687 [00:23<00:06, 563.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13088/16687 [00:23<00:06, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13145/16687 [00:23<00:06, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13202/16687 [00:23<00:06, 564.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13259/16687 [00:23<00:06, 563.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13316/16687 [00:23<00:05, 562.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13373/16687 [00:23<00:05, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13430/16687 [00:23<00:05, 563.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13487/16687 [00:24<00:05, 564.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13544/16687 [00:24<00:05, 565.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13601/16687 [00:24<00:05, 564.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13658/16687 [00:24<00:05, 553.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13716/16687 [00:24<00:05, 558.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13773/16687 [00:24<00:05, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13829/16687 [00:24<00:05, 541.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13884/16687 [00:24<00:05, 534.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13938/16687 [00:24<00:05, 529.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13994/16687 [00:24<00:05, 538.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14051/16687 [00:25<00:04, 546.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14108/16687 [00:25<00:04, 552.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14164/16687 [00:25<00:04, 546.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14220/16687 [00:25<00:04, 549.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14278/16687 [00:25<00:04, 556.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14335/16687 [00:25<00:04, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14393/16687 [00:25<00:04, 562.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14450/16687 [00:25<00:03, 563.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14507/16687 [00:25<00:03, 554.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14564/16687 [00:25<00:03, 556.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14622/16687 [00:26<00:03, 562.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14681/16687 [00:26<00:03, 568.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14740/16687 [00:26<00:03, 573.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14799/16687 [00:26<00:03, 577.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14858/16687 [00:26<00:03, 579.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14917/16687 [00:26<00:03, 581.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14976/16687 [00:26<00:02, 579.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15035/16687 [00:26<00:02, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15094/16687 [00:26<00:02, 576.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15152/16687 [00:26<00:02, 574.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15210/16687 [00:27<00:02, 572.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15268/16687 [00:27<00:02, 569.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15326/16687 [00:27<00:02, 571.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15384/16687 [00:27<00:02, 572.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15442/16687 [00:27<00:02, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15500/16687 [00:27<00:02, 571.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15558/16687 [00:27<00:01, 564.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15615/16687 [00:27<00:01, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15672/16687 [00:27<00:01, 564.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15729/16687 [00:28<00:01, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15786/16687 [00:28<00:01, 560.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15843/16687 [00:28<00:01, 561.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15900/16687 [00:28<00:01, 562.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15957/16687 [00:28<00:01, 550.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16015/16687 [00:28<00:01, 556.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16072/16687 [00:28<00:01, 560.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16129/16687 [00:28<00:00, 558.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16186/16687 [00:28<00:00, 562.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16243/16687 [00:28<00:00, 558.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16300/16687 [00:29<00:00, 561.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16357/16687 [00:29<00:00, 563.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16414/16687 [00:29<00:00, 560.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16471/16687 [00:29<00:00, 563.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16529/16687 [00:29<00:00, 565.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16586/16687 [00:29<00:00, 566.51batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16643/16687 [00:29<00:00, 566.52batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  85%|████████▌ | 17/20 [11:06<01:55, 38.48s/epoch, loss=0.65, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 14/16687 [00:00<01:59, 139.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 65/16687 [00:00<00:49, 337.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 117/16687 [00:00<00:39, 417.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 169/16687 [00:00<00:36, 455.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 223/16687 [00:00<00:33, 484.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 279/16687 [00:00<00:32, 509.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 338/16687 [00:00<00:30, 535.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 395/16687 [00:00<00:29, 544.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 452/16687 [00:00<00:29, 550.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 510/16687 [00:01<00:29, 556.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 566/16687 [00:01<00:29, 548.95batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   4%|█▏                              | 623/16687 [00:01<00:28, 554.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 680/16687 [00:01<00:28, 558.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 736/16687 [00:01<00:28, 557.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 792/16687 [00:01<00:28, 556.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 848/16687 [00:01<00:28, 555.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 904/16687 [00:01<00:28, 555.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 960/16687 [00:01<00:28, 548.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1017/16687 [00:01<00:28, 552.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1074/16687 [00:02<00:28, 556.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1131/16687 [00:02<00:27, 558.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1188/16687 [00:02<00:27, 559.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1245/16687 [00:02<00:27, 561.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1304/16687 [00:02<00:27, 568.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1363/16687 [00:02<00:26, 574.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1422/16687 [00:02<00:26, 579.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1481/16687 [00:02<00:26, 582.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1540/16687 [00:02<00:26, 569.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1598/16687 [00:02<00:26, 564.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1655/16687 [00:03<00:26, 564.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1712/16687 [00:03<00:26, 564.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1769/16687 [00:03<00:26, 565.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1826/16687 [00:03<00:26, 565.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1883/16687 [00:03<00:26, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1940/16687 [00:03<00:26, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1997/16687 [00:03<00:25, 566.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2054/16687 [00:03<00:25, 566.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2111/16687 [00:03<00:25, 565.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2168/16687 [00:03<00:26, 557.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2225/16687 [00:04<00:25, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2282/16687 [00:04<00:26, 550.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2339/16687 [00:04<00:25, 555.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2396/16687 [00:04<00:25, 559.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2452/16687 [00:04<00:25, 558.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2509/16687 [00:04<00:25, 561.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2566/16687 [00:04<00:25, 559.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2623/16687 [00:04<00:25, 561.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2680/16687 [00:04<00:24, 562.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2737/16687 [00:04<00:24, 562.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2794/16687 [00:05<00:24, 563.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2851/16687 [00:05<00:24, 560.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2908/16687 [00:05<00:24, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2964/16687 [00:05<00:24, 557.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3021/16687 [00:05<00:24, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3078/16687 [00:05<00:24, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3135/16687 [00:05<00:24, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3192/16687 [00:05<00:24, 559.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3249/16687 [00:05<00:23, 561.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3306/16687 [00:05<00:23, 558.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3363/16687 [00:06<00:23, 561.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3420/16687 [00:06<00:24, 552.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3477/16687 [00:06<00:23, 556.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3534/16687 [00:06<00:23, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3591/16687 [00:06<00:23, 561.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3648/16687 [00:06<00:23, 562.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3705/16687 [00:06<00:23, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3762/16687 [00:06<00:22, 563.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3819/16687 [00:06<00:22, 563.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3876/16687 [00:07<00:22, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3933/16687 [00:07<00:22, 562.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3990/16687 [00:07<00:22, 560.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4047/16687 [00:07<00:22, 559.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4104/16687 [00:07<00:22, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4161/16687 [00:07<00:22, 564.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4218/16687 [00:07<00:22, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4275/16687 [00:07<00:22, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4332/16687 [00:07<00:21, 562.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4389/16687 [00:07<00:21, 562.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4446/16687 [00:08<00:21, 562.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4503/16687 [00:08<00:21, 563.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4560/16687 [00:08<00:21, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4617/16687 [00:08<00:21, 563.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4674/16687 [00:08<00:21, 564.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4731/16687 [00:08<00:21, 565.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4788/16687 [00:08<00:21, 565.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4845/16687 [00:08<00:20, 565.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4902/16687 [00:08<00:20, 565.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4959/16687 [00:08<00:20, 564.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5016/16687 [00:09<00:20, 564.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5073/16687 [00:09<00:20, 564.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5130/16687 [00:09<00:20, 563.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5187/16687 [00:09<00:20, 558.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5243/16687 [00:09<00:20, 554.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5301/16687 [00:09<00:20, 560.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5359/16687 [00:09<00:20, 563.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5417/16687 [00:09<00:19, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5475/16687 [00:09<00:19, 567.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5532/16687 [00:09<00:19, 567.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▍                    | 5589/16687 [00:10<00:19, 563.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5647/16687 [00:10<00:19, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5704/16687 [00:10<00:19, 566.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5761/16687 [00:10<00:19, 562.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5818/16687 [00:10<00:19, 551.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5874/16687 [00:10<00:19, 545.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5933/16687 [00:10<00:19, 558.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5989/16687 [00:10<00:19, 553.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6045/16687 [00:10<00:19, 551.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6101/16687 [00:10<00:19, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6156/16687 [00:11<00:19, 544.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6211/16687 [00:11<00:19, 540.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6266/16687 [00:11<00:19, 536.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6320/16687 [00:11<00:19, 535.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6376/16687 [00:11<00:19, 542.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6433/16687 [00:11<00:18, 550.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6489/16687 [00:11<00:18, 540.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6544/16687 [00:11<00:18, 537.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6601/16687 [00:11<00:18, 546.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6656/16687 [00:12<00:18, 542.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6712/16687 [00:12<00:18, 546.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6768/16687 [00:12<00:18, 549.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6824/16687 [00:12<00:17, 550.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6880/16687 [00:12<00:17, 551.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6937/16687 [00:12<00:17, 557.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6993/16687 [00:12<00:17, 555.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7051/16687 [00:12<00:17, 560.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7109/16687 [00:12<00:17, 563.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7166/16687 [00:12<00:16, 561.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7223/16687 [00:13<00:16, 563.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7280/16687 [00:13<00:16, 561.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7337/16687 [00:13<00:16, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7394/16687 [00:13<00:16, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7451/16687 [00:13<00:16, 559.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7508/16687 [00:13<00:16, 561.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7565/16687 [00:13<00:16, 563.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7622/16687 [00:13<00:16, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7679/16687 [00:13<00:16, 561.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7737/16687 [00:13<00:15, 564.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7794/16687 [00:14<00:15, 565.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7851/16687 [00:14<00:15, 562.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7909/16687 [00:14<00:15, 564.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7966/16687 [00:14<00:15, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8023/16687 [00:14<00:15, 561.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8081/16687 [00:14<00:15, 563.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8138/16687 [00:14<00:15, 565.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8195/16687 [00:14<00:14, 566.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8252/16687 [00:14<00:14, 567.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8309/16687 [00:14<00:14, 563.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8366/16687 [00:15<00:14, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8423/16687 [00:15<00:14, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8481/16687 [00:15<00:14, 566.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8538/16687 [00:15<00:14, 566.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8595/16687 [00:15<00:14, 567.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8652/16687 [00:15<00:14, 567.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8709/16687 [00:15<00:14, 568.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8768/16687 [00:15<00:13, 574.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8826/16687 [00:15<00:13, 574.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8885/16687 [00:15<00:13, 579.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8943/16687 [00:16<00:13, 578.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9001/16687 [00:16<00:13, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9059/16687 [00:16<00:13, 567.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9116/16687 [00:16<00:13, 563.06batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  55%|█████████████████              | 9173/16687 [00:16<00:13, 561.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9231/16687 [00:16<00:13, 564.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9288/16687 [00:16<00:13, 557.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9344/16687 [00:16<00:13, 550.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9400/16687 [00:16<00:13, 548.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9455/16687 [00:16<00:13, 542.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9510/16687 [00:17<00:13, 532.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9565/16687 [00:17<00:13, 536.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9619/16687 [00:17<00:13, 528.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9672/16687 [00:17<00:13, 528.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9726/16687 [00:17<00:13, 531.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9780/16687 [00:17<00:13, 527.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9833/16687 [00:17<00:13, 524.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9889/16687 [00:17<00:12, 534.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9947/16687 [00:17<00:12, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10004/16687 [00:18<00:12, 552.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10060/16687 [00:18<00:12, 551.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10119/16687 [00:18<00:11, 562.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10177/16687 [00:18<00:11, 565.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10234/16687 [00:18<00:11, 563.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10291/16687 [00:18<00:11, 564.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10348/16687 [00:18<00:11, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10405/16687 [00:18<00:11, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10462/16687 [00:18<00:11, 565.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10519/16687 [00:18<00:10, 565.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10576/16687 [00:19<00:10, 565.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10633/16687 [00:19<00:10, 560.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10690/16687 [00:19<00:10, 558.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10747/16687 [00:19<00:10, 560.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10804/16687 [00:19<00:10, 561.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10861/16687 [00:19<00:10, 562.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▋          | 10918/16687 [00:19<00:10, 562.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10975/16687 [00:19<00:10, 563.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11032/16687 [00:19<00:10, 563.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11089/16687 [00:19<00:09, 563.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11146/16687 [00:20<00:09, 559.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11203/16687 [00:20<00:09, 551.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11260/16687 [00:20<00:09, 555.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11317/16687 [00:20<00:09, 557.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11374/16687 [00:20<00:09, 558.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11430/16687 [00:20<00:09, 544.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11489/16687 [00:20<00:09, 556.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11548/16687 [00:20<00:09, 565.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11607/16687 [00:20<00:08, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11665/16687 [00:20<00:08, 567.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11722/16687 [00:21<00:08, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11779/16687 [00:21<00:08, 561.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11837/16687 [00:21<00:08, 565.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11895/16687 [00:21<00:08, 569.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11952/16687 [00:21<00:08, 562.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12009/16687 [00:21<00:08, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12064/16687 [00:21<00:08, 535.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12118/16687 [00:21<00:08, 537.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12175/16687 [00:21<00:08, 545.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12232/16687 [00:21<00:08, 552.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12289/16687 [00:22<00:07, 556.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12345/16687 [00:22<00:07, 554.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12401/16687 [00:22<00:07, 553.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12457/16687 [00:22<00:07, 553.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12514/16687 [00:22<00:07, 556.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12570/16687 [00:22<00:07, 555.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12627/16687 [00:22<00:07, 559.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12684/16687 [00:22<00:07, 561.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12741/16687 [00:22<00:07, 563.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12798/16687 [00:23<00:06, 560.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12855/16687 [00:23<00:06, 558.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12911/16687 [00:23<00:06, 556.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12967/16687 [00:23<00:06, 556.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13023/16687 [00:23<00:06, 555.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13080/16687 [00:23<00:06, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13136/16687 [00:23<00:06, 556.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13194/16687 [00:23<00:06, 560.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13251/16687 [00:23<00:06, 558.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13308/16687 [00:23<00:06, 561.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13365/16687 [00:24<00:05, 563.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13422/16687 [00:24<00:05, 560.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13479/16687 [00:24<00:05, 560.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13536/16687 [00:24<00:05, 557.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13594/16687 [00:24<00:05, 561.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13651/16687 [00:24<00:05, 555.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13707/16687 [00:24<00:05, 554.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13764/16687 [00:24<00:05, 556.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13821/16687 [00:24<00:05, 559.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13878/16687 [00:24<00:05, 561.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13935/16687 [00:25<00:04, 559.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13992/16687 [00:25<00:04, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14049/16687 [00:25<00:04, 559.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14106/16687 [00:25<00:04, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14163/16687 [00:25<00:04, 558.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14220/16687 [00:25<00:04, 560.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14277/16687 [00:25<00:04, 558.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14334/16687 [00:25<00:04, 560.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14391/16687 [00:25<00:04, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14448/16687 [00:25<00:03, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14505/16687 [00:26<00:03, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14562/16687 [00:26<00:03, 565.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14619/16687 [00:26<00:03, 555.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14675/16687 [00:26<00:03, 554.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14732/16687 [00:26<00:03, 557.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14789/16687 [00:26<00:03, 558.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14846/16687 [00:26<00:03, 561.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14903/16687 [00:26<00:03, 563.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14960/16687 [00:26<00:03, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15017/16687 [00:26<00:02, 558.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15073/16687 [00:27<00:02, 557.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15129/16687 [00:27<00:02, 556.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15185/16687 [00:27<00:02, 547.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15240/16687 [00:27<00:02, 536.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15294/16687 [00:27<00:02, 528.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15347/16687 [00:27<00:02, 523.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15405/16687 [00:27<00:02, 538.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15461/16687 [00:27<00:02, 544.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15519/16687 [00:27<00:02, 552.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15578/16687 [00:27<00:01, 560.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15635/16687 [00:28<00:01, 557.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15692/16687 [00:28<00:01, 560.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15749/16687 [00:28<00:01, 548.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15806/16687 [00:28<00:01, 554.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15862/16687 [00:28<00:01, 553.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15918/16687 [00:28<00:01, 546.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15974/16687 [00:28<00:01, 548.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16031/16687 [00:28<00:01, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16088/16687 [00:28<00:01, 558.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16144/16687 [00:29<00:00, 557.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16200/16687 [00:29<00:00, 556.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16256/16687 [00:29<00:00, 556.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16313/16687 [00:29<00:00, 559.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16369/16687 [00:29<00:00, 557.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16426/16687 [00:29<00:00, 561.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16483/16687 [00:29<00:00, 558.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16540/16687 [00:29<00:00, 561.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16597/16687 [00:29<00:00, 558.74batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16654/16687 [00:29<00:00, 561.85batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  90%|█████████ | 18/20 [11:37<01:11, 35.99s/epoch, loss=0.651, prev_loss=0.65]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:34, 177.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 68/16687 [00:00<00:46, 360.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 123/16687 [00:00<00:37, 445.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 180/16687 [00:00<00:33, 492.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 236/16687 [00:00<00:31, 514.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 293/16687 [00:00<00:30, 531.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 350/16687 [00:00<00:30, 543.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 407/16687 [00:00<00:29, 550.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 465/16687 [00:00<00:29, 558.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 521/16687 [00:01<00:28, 557.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 578/16687 [00:01<00:28, 558.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 635/16687 [00:01<00:28, 560.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 692/16687 [00:01<00:28, 561.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 749/16687 [00:01<00:28, 557.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 806/16687 [00:01<00:28, 558.73batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   5%|█▋                              | 863/16687 [00:01<00:28, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 920/16687 [00:01<00:28, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 977/16687 [00:01<00:27, 563.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1034/16687 [00:01<00:27, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1091/16687 [00:02<00:27, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1148/16687 [00:02<00:27, 565.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1206/16687 [00:02<00:27, 568.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1263/16687 [00:02<00:27, 559.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1320/16687 [00:02<00:27, 559.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1377/16687 [00:02<00:27, 560.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1434/16687 [00:02<00:27, 562.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1491/16687 [00:02<00:26, 563.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1548/16687 [00:02<00:26, 563.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1605/16687 [00:02<00:26, 564.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1662/16687 [00:03<00:26, 565.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1719/16687 [00:03<00:26, 565.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1776/16687 [00:03<00:26, 561.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1833/16687 [00:03<00:26, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1890/16687 [00:03<00:26, 557.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1947/16687 [00:03<00:26, 559.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2004/16687 [00:03<00:26, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2061/16687 [00:03<00:25, 562.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2118/16687 [00:03<00:26, 560.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2175/16687 [00:03<00:25, 561.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2232/16687 [00:04<00:25, 562.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2289/16687 [00:04<00:25, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2346/16687 [00:04<00:25, 562.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2403/16687 [00:04<00:25, 561.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2460/16687 [00:04<00:25, 554.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2517/16687 [00:04<00:25, 557.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2573/16687 [00:04<00:25, 557.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2629/16687 [00:04<00:25, 556.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2686/16687 [00:04<00:25, 559.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2743/16687 [00:04<00:24, 562.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2800/16687 [00:05<00:24, 564.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2857/16687 [00:05<00:24, 565.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2914/16687 [00:05<00:24, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2971/16687 [00:05<00:24, 562.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3028/16687 [00:05<00:24, 561.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3085/16687 [00:05<00:24, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3144/16687 [00:05<00:23, 568.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3202/16687 [00:05<00:23, 571.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3260/16687 [00:05<00:23, 573.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3319/16687 [00:05<00:23, 577.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3378/16687 [00:06<00:22, 581.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3437/16687 [00:06<00:23, 575.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3495/16687 [00:06<00:23, 570.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3553/16687 [00:06<00:23, 570.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3611/16687 [00:06<00:23, 568.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3668/16687 [00:06<00:22, 566.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3725/16687 [00:06<00:23, 562.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3782/16687 [00:06<00:22, 563.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3839/16687 [00:06<00:22, 564.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3896/16687 [00:06<00:22, 564.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3953/16687 [00:07<00:22, 565.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4010/16687 [00:07<00:22, 552.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4066/16687 [00:07<00:23, 542.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4122/16687 [00:07<00:22, 547.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4177/16687 [00:07<00:23, 543.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4234/16687 [00:07<00:22, 550.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4293/16687 [00:07<00:22, 560.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4350/16687 [00:07<00:21, 561.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4409/16687 [00:07<00:21, 568.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4468/16687 [00:08<00:21, 574.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4526/16687 [00:08<00:21, 572.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4584/16687 [00:08<00:21, 568.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4641/16687 [00:08<00:21, 560.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4698/16687 [00:08<00:21, 559.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4754/16687 [00:08<00:21, 545.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4811/16687 [00:08<00:21, 552.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4868/16687 [00:08<00:21, 556.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4925/16687 [00:08<00:21, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4983/16687 [00:08<00:20, 563.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5040/16687 [00:09<00:20, 564.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5097/16687 [00:09<00:20, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5154/16687 [00:09<00:20, 555.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5210/16687 [00:09<00:21, 538.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5265/16687 [00:09<00:21, 531.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5319/16687 [00:09<00:21, 526.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5372/16687 [00:09<00:21, 525.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5427/16687 [00:09<00:21, 532.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5484/16687 [00:09<00:20, 541.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5541/16687 [00:09<00:20, 548.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5598/16687 [00:10<00:20, 553.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5655/16687 [00:10<00:19, 557.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5711/16687 [00:10<00:20, 548.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5766/16687 [00:10<00:19, 547.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5825/16687 [00:10<00:19, 559.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5884/16687 [00:10<00:19, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5943/16687 [00:10<00:18, 573.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6001/16687 [00:10<00:18, 575.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6059/16687 [00:10<00:18, 575.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6118/16687 [00:10<00:18, 580.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6177/16687 [00:11<00:18, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6236/16687 [00:11<00:17, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6295/16687 [00:11<00:18, 573.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6353/16687 [00:11<00:18, 567.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6410/16687 [00:11<00:18, 567.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6467/16687 [00:11<00:17, 568.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6524/16687 [00:11<00:18, 564.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6582/16687 [00:11<00:17, 566.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6640/16687 [00:11<00:17, 567.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6697/16687 [00:12<00:17, 568.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6754/16687 [00:12<00:17, 564.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6811/16687 [00:12<00:17, 561.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6868/16687 [00:12<00:17, 563.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6925/16687 [00:12<00:17, 559.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6982/16687 [00:12<00:17, 562.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7040/16687 [00:12<00:17, 566.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7098/16687 [00:12<00:16, 569.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7157/16687 [00:12<00:16, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7215/16687 [00:12<00:16, 574.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7273/16687 [00:13<00:16, 571.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7331/16687 [00:13<00:16, 570.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7389/16687 [00:13<00:16, 568.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7446/16687 [00:13<00:16, 558.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7502/16687 [00:13<00:16, 543.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7558/16687 [00:13<00:16, 546.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7615/16687 [00:13<00:16, 553.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7672/16687 [00:13<00:16, 556.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7729/16687 [00:13<00:16, 558.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7786/16687 [00:13<00:15, 560.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7843/16687 [00:14<00:15, 562.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7900/16687 [00:14<00:15, 563.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7957/16687 [00:14<00:15, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8014/16687 [00:14<00:15, 554.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8071/16687 [00:14<00:15, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8127/16687 [00:14<00:15, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8183/16687 [00:14<00:15, 545.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8238/16687 [00:14<00:15, 545.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8294/16687 [00:14<00:15, 547.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8349/16687 [00:14<00:15, 545.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8408/16687 [00:15<00:14, 557.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8467/16687 [00:15<00:14, 565.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8526/16687 [00:15<00:14, 571.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8584/16687 [00:15<00:14, 569.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8642/16687 [00:15<00:14, 571.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8701/16687 [00:15<00:13, 575.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▎              | 8760/16687 [00:15<00:13, 578.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8818/16687 [00:15<00:13, 577.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8877/16687 [00:15<00:13, 580.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8936/16687 [00:15<00:13, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8995/16687 [00:16<00:13, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9053/16687 [00:16<00:13, 576.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9111/16687 [00:16<00:13, 573.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9169/16687 [00:16<00:13, 557.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9226/16687 [00:16<00:13, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9284/16687 [00:16<00:13, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9342/16687 [00:16<00:12, 566.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9399/16687 [00:16<00:12, 564.00batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  57%|█████████████████▌             | 9457/16687 [00:16<00:12, 567.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9514/16687 [00:17<00:12, 559.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9570/16687 [00:17<00:13, 543.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9626/16687 [00:17<00:12, 545.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9683/16687 [00:17<00:12, 551.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9739/16687 [00:17<00:12, 545.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9794/16687 [00:17<00:12, 542.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9851/16687 [00:17<00:12, 549.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9907/16687 [00:17<00:12, 549.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9964/16687 [00:17<00:12, 553.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10020/16687 [00:17<00:12, 552.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10076/16687 [00:18<00:11, 552.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10133/16687 [00:18<00:11, 556.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10190/16687 [00:18<00:11, 560.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10247/16687 [00:18<00:11, 545.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10302/16687 [00:18<00:11, 539.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10357/16687 [00:18<00:11, 542.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10414/16687 [00:18<00:11, 550.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10470/16687 [00:18<00:11, 552.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10529/16687 [00:18<00:10, 562.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10588/16687 [00:18<00:10, 570.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10646/16687 [00:19<00:10, 572.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10704/16687 [00:19<00:10, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10762/16687 [00:19<00:10, 565.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10819/16687 [00:19<00:10, 565.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10876/16687 [00:19<00:10, 563.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10933/16687 [00:19<00:10, 564.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10990/16687 [00:19<00:10, 564.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11047/16687 [00:19<00:09, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11104/16687 [00:19<00:09, 559.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11161/16687 [00:19<00:09, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11218/16687 [00:20<00:09, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11275/16687 [00:20<00:09, 564.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11332/16687 [00:20<00:09, 560.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11389/16687 [00:20<00:09, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11446/16687 [00:20<00:09, 552.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11504/16687 [00:20<00:09, 557.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11563/16687 [00:20<00:09, 565.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11620/16687 [00:20<00:08, 566.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11677/16687 [00:20<00:08, 565.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11734/16687 [00:20<00:08, 565.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11791/16687 [00:21<00:08, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11848/16687 [00:21<00:08, 565.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11905/16687 [00:21<00:08, 565.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11962/16687 [00:21<00:08, 565.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12019/16687 [00:21<00:08, 564.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12076/16687 [00:21<00:08, 558.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12133/16687 [00:21<00:08, 560.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12190/16687 [00:21<00:08, 561.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12247/16687 [00:21<00:07, 562.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12304/16687 [00:22<00:07, 563.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12362/16687 [00:22<00:07, 565.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12419/16687 [00:22<00:07, 565.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12476/16687 [00:22<00:07, 566.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12533/16687 [00:22<00:07, 566.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12590/16687 [00:22<00:07, 565.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12647/16687 [00:22<00:07, 564.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12704/16687 [00:22<00:07, 560.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12761/16687 [00:22<00:06, 561.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12818/16687 [00:22<00:06, 558.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12875/16687 [00:23<00:06, 560.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12932/16687 [00:23<00:06, 562.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12989/16687 [00:23<00:06, 563.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13046/16687 [00:23<00:06, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13103/16687 [00:23<00:06, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13160/16687 [00:23<00:06, 564.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13217/16687 [00:23<00:06, 564.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13274/16687 [00:23<00:06, 564.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13331/16687 [00:23<00:05, 564.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13389/16687 [00:23<00:05, 566.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13446/16687 [00:24<00:05, 560.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13503/16687 [00:24<00:05, 549.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13559/16687 [00:24<00:05, 533.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13613/16687 [00:24<00:05, 535.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13671/16687 [00:24<00:05, 547.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13726/16687 [00:24<00:05, 545.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13781/16687 [00:24<00:05, 545.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13836/16687 [00:24<00:05, 540.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13891/16687 [00:24<00:05, 534.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13945/16687 [00:24<00:05, 529.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14004/16687 [00:25<00:04, 544.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14062/16687 [00:25<00:04, 553.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14119/16687 [00:25<00:04, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14176/16687 [00:25<00:04, 559.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14233/16687 [00:25<00:04, 562.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14292/16687 [00:25<00:04, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14349/16687 [00:25<00:04, 566.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14406/16687 [00:25<00:04, 566.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14464/16687 [00:25<00:03, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14521/16687 [00:25<00:03, 562.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14578/16687 [00:26<00:03, 560.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14635/16687 [00:26<00:03, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14692/16687 [00:26<00:03, 562.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14749/16687 [00:26<00:03, 560.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14806/16687 [00:26<00:03, 562.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14863/16687 [00:26<00:03, 561.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14920/16687 [00:26<00:03, 561.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14977/16687 [00:26<00:03, 563.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15035/16687 [00:26<00:02, 567.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████▏  | 15094/16687 [00:26<00:02, 571.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15153/16687 [00:27<00:02, 574.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15212/16687 [00:27<00:02, 576.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15270/16687 [00:27<00:02, 575.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15328/16687 [00:27<00:02, 575.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15386/16687 [00:27<00:02, 574.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15444/16687 [00:27<00:02, 573.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15502/16687 [00:27<00:02, 570.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15560/16687 [00:27<00:01, 568.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15617/16687 [00:27<00:01, 568.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15675/16687 [00:28<00:01, 570.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15733/16687 [00:28<00:01, 571.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15791/16687 [00:28<00:01, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15849/16687 [00:28<00:01, 566.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15906/16687 [00:28<00:01, 558.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15962/16687 [00:28<00:01, 554.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16020/16687 [00:28<00:01, 560.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16077/16687 [00:28<00:01, 552.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16133/16687 [00:28<00:00, 554.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16190/16687 [00:28<00:00, 557.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16248/16687 [00:29<00:00, 561.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16305/16687 [00:29<00:00, 559.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16362/16687 [00:29<00:00, 559.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16419/16687 [00:29<00:00, 562.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16476/16687 [00:29<00:00, 563.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16533/16687 [00:29<00:00, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16590/16687 [00:29<00:00, 563.54batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16647/16687 [00:29<00:00, 559.56batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  95%|████████▌| 19/20 [12:07<00:34, 34.19s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 17/16687 [00:00<01:38, 169.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 68/16687 [00:00<00:45, 361.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 126/16687 [00:00<00:36, 456.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 183/16687 [00:00<00:33, 499.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 240/16687 [00:00<00:31, 523.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 297/16687 [00:00<00:30, 537.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 352/16687 [00:00<00:30, 539.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 409/16687 [00:00<00:29, 547.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 466/16687 [00:00<00:29, 552.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 523/16687 [00:01<00:29, 555.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 580/16687 [00:01<00:28, 557.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 637/16687 [00:01<00:28, 560.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 694/16687 [00:01<00:28, 562.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 751/16687 [00:01<00:28, 564.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 808/16687 [00:01<00:28, 564.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 865/16687 [00:01<00:27, 565.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 922/16687 [00:01<00:28, 558.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 978/16687 [00:01<00:28, 555.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1035/16687 [00:01<00:28, 557.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1092/16687 [00:02<00:27, 559.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1149/16687 [00:02<00:27, 560.74batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   7%|██▏                            | 1206/16687 [00:02<00:27, 562.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1263/16687 [00:02<00:27, 563.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1320/16687 [00:02<00:27, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1377/16687 [00:02<00:27, 566.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1435/16687 [00:02<00:26, 568.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1492/16687 [00:02<00:26, 565.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1549/16687 [00:02<00:26, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1606/16687 [00:02<00:26, 562.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1663/16687 [00:03<00:26, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1720/16687 [00:03<00:26, 562.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1778/16687 [00:03<00:26, 565.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1835/16687 [00:03<00:26, 561.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1892/16687 [00:03<00:26, 562.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1949/16687 [00:03<00:26, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2006/16687 [00:03<00:26, 559.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2062/16687 [00:03<00:26, 548.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2118/16687 [00:03<00:26, 549.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2176/16687 [00:03<00:26, 557.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2232/16687 [00:04<00:26, 554.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2289/16687 [00:04<00:25, 558.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2346/16687 [00:04<00:25, 561.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2403/16687 [00:04<00:25, 563.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2460/16687 [00:04<00:25, 561.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2517/16687 [00:04<00:25, 559.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2574/16687 [00:04<00:25, 561.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2631/16687 [00:04<00:24, 562.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2688/16687 [00:04<00:25, 559.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2745/16687 [00:04<00:24, 562.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2802/16687 [00:05<00:24, 562.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2859/16687 [00:05<00:24, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2916/16687 [00:05<00:24, 561.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2973/16687 [00:05<00:24, 563.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3030/16687 [00:05<00:24, 565.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3087/16687 [00:05<00:24, 561.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3144/16687 [00:05<00:24, 563.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3201/16687 [00:05<00:23, 563.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3258/16687 [00:05<00:23, 564.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3315/16687 [00:05<00:23, 561.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3372/16687 [00:06<00:23, 562.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▎                        | 3429/16687 [00:06<00:23, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3486/16687 [00:06<00:23, 557.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3543/16687 [00:06<00:23, 560.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3600/16687 [00:06<00:23, 563.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3657/16687 [00:06<00:23, 564.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3714/16687 [00:06<00:22, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3771/16687 [00:06<00:22, 565.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3828/16687 [00:06<00:22, 561.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3885/16687 [00:06<00:22, 563.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3942/16687 [00:07<00:22, 563.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3999/16687 [00:07<00:22, 559.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4056/16687 [00:07<00:22, 562.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4113/16687 [00:07<00:22, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4170/16687 [00:07<00:22, 565.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4227/16687 [00:07<00:22, 561.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4284/16687 [00:07<00:22, 563.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4341/16687 [00:07<00:21, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4398/16687 [00:07<00:21, 560.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4455/16687 [00:08<00:21, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4512/16687 [00:08<00:21, 558.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4569/16687 [00:08<00:21, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4626/16687 [00:08<00:21, 563.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4683/16687 [00:08<00:21, 564.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4740/16687 [00:08<00:21, 565.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4797/16687 [00:08<00:21, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4854/16687 [00:08<00:20, 566.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4911/16687 [00:08<00:21, 556.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4967/16687 [00:08<00:21, 545.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5022/16687 [00:09<00:21, 544.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5077/16687 [00:09<00:22, 526.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5131/16687 [00:09<00:21, 528.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5186/16687 [00:09<00:21, 533.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5240/16687 [00:09<00:21, 532.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5297/16687 [00:09<00:20, 542.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5354/16687 [00:09<00:20, 549.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5411/16687 [00:09<00:20, 552.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5467/16687 [00:09<00:20, 548.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5526/16687 [00:09<00:19, 558.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▍                    | 5585/16687 [00:10<00:19, 566.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5643/16687 [00:10<00:19, 568.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5700/16687 [00:10<00:19, 565.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5758/16687 [00:10<00:19, 568.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5817/16687 [00:10<00:18, 572.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5875/16687 [00:10<00:18, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5934/16687 [00:10<00:18, 576.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5992/16687 [00:10<00:18, 575.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6050/16687 [00:10<00:18, 572.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6108/16687 [00:10<00:18, 571.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6166/16687 [00:11<00:18, 570.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6224/16687 [00:11<00:18, 557.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6280/16687 [00:11<00:18, 551.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6336/16687 [00:11<00:18, 549.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6395/16687 [00:11<00:18, 559.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6454/16687 [00:11<00:18, 568.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6513/16687 [00:11<00:17, 574.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6572/16687 [00:11<00:17, 578.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6631/16687 [00:11<00:17, 580.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6690/16687 [00:11<00:17, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6749/16687 [00:12<00:17, 574.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6807/16687 [00:12<00:17, 566.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6864/16687 [00:12<00:17, 562.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6922/16687 [00:12<00:17, 566.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6981/16687 [00:12<00:16, 572.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7040/16687 [00:12<00:16, 577.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7099/16687 [00:12<00:16, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7158/16687 [00:12<00:16, 583.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7217/16687 [00:12<00:16, 583.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7276/16687 [00:13<00:16, 580.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7335/16687 [00:13<00:16, 576.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7393/16687 [00:13<00:16, 570.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7451/16687 [00:13<00:16, 566.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7508/16687 [00:13<00:16, 565.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7565/16687 [00:13<00:16, 564.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7622/16687 [00:13<00:16, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7679/16687 [00:13<00:16, 562.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7736/16687 [00:13<00:15, 561.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7793/16687 [00:13<00:15, 561.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7850/16687 [00:14<00:15, 562.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7907/16687 [00:14<00:15, 563.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7964/16687 [00:14<00:15, 563.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8021/16687 [00:14<00:15, 558.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8078/16687 [00:14<00:15, 560.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8135/16687 [00:14<00:15, 561.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8192/16687 [00:14<00:15, 562.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8249/16687 [00:14<00:14, 564.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8306/16687 [00:14<00:14, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8363/16687 [00:14<00:14, 558.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8419/16687 [00:15<00:15, 548.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8475/16687 [00:15<00:14, 549.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8532/16687 [00:15<00:14, 553.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8589/16687 [00:15<00:14, 556.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8648/16687 [00:15<00:14, 565.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8707/16687 [00:15<00:13, 571.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8766/16687 [00:15<00:13, 575.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8825/16687 [00:15<00:13, 578.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8883/16687 [00:15<00:13, 563.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8940/16687 [00:15<00:14, 549.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8998/16687 [00:16<00:13, 556.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9055/16687 [00:16<00:13, 558.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9112/16687 [00:16<00:13, 560.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9169/16687 [00:16<00:13, 555.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9226/16687 [00:16<00:13, 558.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9282/16687 [00:16<00:13, 556.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9338/16687 [00:16<00:13, 556.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9395/16687 [00:16<00:13, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9452/16687 [00:16<00:12, 561.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9509/16687 [00:16<00:12, 562.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9566/16687 [00:17<00:12, 558.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9622/16687 [00:17<00:12, 548.91batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  95%|████████▌| 19/20 [12:24<00:39, 39.18s/epoch, loss=0.651, prev_loss=0.651]\u001b[A\n",
      "\u001b[33m[W 2023-01-30 09:23:07,357]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py\", line 259, in __call__\n",
      "    result = pipeline(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py\", line 1291, in pipeline\n",
      "    losses = training_loop_instance.train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 378, in train\n",
      "    result = self._train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 642, in _train\n",
      "    batch_loss = self._forward_pass(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 817, in _forward_pass\n",
      "    loss = self._process_batch(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py\", line 139, in _process_batch\n",
      "    return self._process_batch_static(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py\", line 116, in _process_batch_static\n",
      "    positive_scores = model.score_hrt(positive_batch, mode=mode)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/models/nbase.py\", line 445, in score_hrt\n",
      "    return self.interaction.score_hrt(h=h, r=r, t=t)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py\", line 283, in score_hrt\n",
      "    return self.score(h=h, r=r, t=t).unsqueeze(dim=-1)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py\", line 255, in score\n",
      "    return self(h=h, r=r, t=t)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py\", line 402, in forward\n",
      "    return self.__class__.func(**self._prepare_for_functional(h=h, r=r, t=t))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/nn/functional.py\", line 809, in transe_interaction\n",
      "    return negative_norm_of_sum(h, r, -t, p=p, power_norm=power_norm)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/utils.py\", line 651, in negative_norm_of_sum\n",
      "    return negative_norm(tensor_sum(*x), p=p, power_norm=power_norm)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/utils.py\", line 625, in tensor_sum\n",
      "    return sum(_reorder(tensors=tensors))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hpo_pipeline_result \u001b[38;5;241m=\u001b[39m \u001b[43mhpo_pipeline_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:486\u001b[0m, in \u001b[0;36mhpo_pipeline_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhpo_pipeline_from_config\u001b[39m(config: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HpoPipelineResult:\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the HPO pipeline using a properly formatted configuration dictionary.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhpo_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:857\u001b[0m, in \u001b[0;36mhpo_pipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, model_kwargs_ranges, loss, loss_kwargs, loss_kwargs_ranges, regularizer, regularizer_kwargs, regularizer_kwargs_ranges, optimizer, optimizer_kwargs, optimizer_kwargs_ranges, lr_scheduler, lr_scheduler_kwargs, lr_scheduler_kwargs_ranges, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, negative_sampler_kwargs_ranges, epochs, training_kwargs, training_kwargs_ranges, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, metric, filter_validation_when_testing, result_tracker, result_tracker_kwargs, device, storage, sampler, sampler_kwargs, pruner, pruner_kwargs, study_name, direction, load_if_exists, n_trials, timeout, n_jobs, save_model_directory)\u001b[0m\n\u001b[1;32m    801\u001b[0m objective \u001b[38;5;241m=\u001b[39m Objective(\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# 1. Dataset\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    854\u001b[0m )\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# Invoke optimization of the objective function.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrial\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mMemoryError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HpoPipelineResult(\n\u001b[1;32m    866\u001b[0m     study\u001b[38;5;241m=\u001b[39mstudy,\n\u001b[1;32m    867\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    868\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:259\u001b[0m, in \u001b[0;36mObjective.__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_stopper_callbacks(_stopper_kwargs, trial, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric, result_tracker\u001b[38;5;241m=\u001b[39mresult_tracker)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 1. Dataset\u001b[39;49;00m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 2. Model\u001b[39;49;00m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 3. Loss\u001b[39;49;00m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_loss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 4. Regularizer\u001b[39;49;00m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_regularizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5. Optimizer\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_optimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5.1 Learning Rate Scheduler\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lr_scheduler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 6. Training Loop\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_negative_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 7. Training\u001b[39;49;00m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_training_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 8. Evaluation\u001b[39;49;00m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 9. Tracker\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Misc.\u001b[39;49;00m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use validation set during HPO!\u001b[39;49;00m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# close run in result tracker\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     result_tracker\u001b[38;5;241m.\u001b[39mend_run(success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:642\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    639\u001b[0m stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m _sub_batch_size, current_batch_size)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# forward pass call\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m current_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m    651\u001b[0m num_training_instances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:817\u001b[0m, in \u001b[0;36mTrainingLoop._forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_pass\u001b[39m(\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    809\u001b[0m     batch: BatchType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;66;03m# raise error when non-finite loss occurs (NaN, +/-inf)\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misfinite(loss):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py:139\u001b[0m, in \u001b[0;36mSLCWATrainingLoop._process_batch\u001b[0;34m(self, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_batch\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch: SLCWABatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     slice_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch_static\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py:116\u001b[0m, in \u001b[0;36mSLCWATrainingLoop._process_batch_static\u001b[0;34m(model, loss, mode, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m negative_batch \u001b[38;5;241m=\u001b[39m negative_batch\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Compute negative and positive scores\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m positive_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_hrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m negative_scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore_hrt(negative_batch, mode\u001b[38;5;241m=\u001b[39mmode)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mnegative_score_shape)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    120\u001b[0m     loss\u001b[38;5;241m.\u001b[39mprocess_slcwa_scores(\n\u001b[1;32m    121\u001b[0m         positive_scores\u001b[38;5;241m=\u001b[39mpositive_scores,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39mcollect_regularization_term()\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/models/nbase.py:445\u001b[0m, in \u001b[0;36mERModel.score_hrt\u001b[0;34m(self, hrt_batch, mode)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Note: slicing cannot be used here: the indices for score_hrt only have a batch\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# dimension, and slicing along this dimension is already considered by sub-batching.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# Note: we do not delegate to the general method for performance reasons\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Note: repetition is not necessary here\u001b[39;00m\n\u001b[1;32m    444\u001b[0m h, r, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_representations(h\u001b[38;5;241m=\u001b[39mhrt_batch[:, \u001b[38;5;241m0\u001b[39m], r\u001b[38;5;241m=\u001b[39mhrt_batch[:, \u001b[38;5;241m1\u001b[39m], t\u001b[38;5;241m=\u001b[39mhrt_batch[:, \u001b[38;5;241m2\u001b[39m], mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_hrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py:283\u001b[0m, in \u001b[0;36mInteraction.score_hrt\u001b[0;34m(self, h, r, t)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_hrt\u001b[39m(\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    267\u001b[0m     h: HeadRepresentation,\n\u001b[1;32m    268\u001b[0m     r: RelationRepresentation,\n\u001b[1;32m    269\u001b[0m     t: TailRepresentation,\n\u001b[1;32m    270\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Score a batch of triples.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    :param h: shape: (batch_size, d_e)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py:255\u001b[0m, in \u001b[0;36mInteraction.score\u001b[0;34m(self, h, r, t, slice_size, slice_dim)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores with optional slicing.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m.. note ::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    The scores.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m slice_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    258\u001b[0m     [\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m(h\u001b[38;5;241m=\u001b[39mh_batch, r\u001b[38;5;241m=\u001b[39mr_batch, t\u001b[38;5;241m=\u001b[39mt_batch)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m     dim\u001b[38;5;241m=\u001b[39mslice_dim,\n\u001b[1;32m    263\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py:402\u001b[0m, in \u001b[0;36mFunctionalInteraction.forward\u001b[0;34m(self, h, r, t)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    386\u001b[0m     h: HeadRepresentation,\n\u001b[1;32m    387\u001b[0m     r: RelationRepresentation,\n\u001b[1;32m    388\u001b[0m     t: TailRepresentation,\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores given broadcasted representations for head, relation and tails.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, `*dims`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/functional.py:809\u001b[0m, in \u001b[0;36mtranse_interaction\u001b[0;34m(h, r, t, p, power_norm)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranse_interaction\u001b[39m(\n\u001b[1;32m    787\u001b[0m     h: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m    788\u001b[0m     r: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    792\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the TransE interaction function.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnegative_norm_of_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/utils.py:651\u001b[0m, in \u001b[0;36mnegative_norm_of_sum\u001b[0;34m(p, power_norm, *x)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnegative_norm_of_sum\u001b[39m(\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39mx: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m    636\u001b[0m     p: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    637\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    638\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    639\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate negative norm of a sum of vectors on already broadcasted representations.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    :param x: shape: (batch_size, num_heads, num_relations, num_tails, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m negative_norm(\u001b[43mtensor_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, p\u001b[38;5;241m=\u001b[39mp, power_norm\u001b[38;5;241m=\u001b[39mpower_norm)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/utils.py:625\u001b[0m, in \u001b[0;36mtensor_sum\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_sum\u001b[39m(\u001b[38;5;241m*\u001b[39mtensors: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute element-wise sum of tensors in broadcastable shape.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_reorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hpo_pipeline_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhpo_pipeline_result\u001b[49m\u001b[38;5;241m.\u001b[39msave_to_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhpo_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hpo_pipeline_result' is not defined"
     ]
    }
   ],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from OGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, split_edge, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "#         print('h:', h)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "#         print('Train: edge:', edge)\n",
    "#         print()\n",
    "#         print('h[edge[0]]:', h[edge[0]])\n",
    "#         print()\n",
    "#         print('h[edge[1]]:', h[edge[1]])\n",
    "#         print()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "#         print('pos out:', pos_out)\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "#     print('test')\n",
    "    \n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "    \n",
    "#     print('pos_train_pred:', pos_train_pred)\n",
    "#     print('neg_train_pred:', neg_valid_pred)\n",
    "#     print()\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: Embedding(4267, 256)\n",
      "\n",
      "Hits@10\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 0.03%, Valid: 0.02%, Test: 0.01%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 3.96%, Valid: 3.64%, Test: 2.58%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 4.55%, Valid: 4.17%, Test: 3.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 3.10%, Valid: 2.87%, Test: 5.68%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 4.74%, Valid: 4.37%, Test: 6.92%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 5.45%, Valid: 5.01%, Test: 7.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.26%, Valid: 0.24%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.56%, Valid: 0.51%, Test: 0.08%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.75%, Valid: 0.70%, Test: 0.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 2.34%, Valid: 2.15%, Test: 3.71%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 3.19%, Valid: 2.99%, Test: 4.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 4.13%, Valid: 3.85%, Test: 5.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 11.42%, Valid: 10.23%, Test: 5.50%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 14.15%, Valid: 12.74%, Test: 8.07%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 15.53%, Valid: 14.05%, Test: 10.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 1.85%, Valid: 1.68%, Test: 1.89%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 2.54%, Valid: 2.31%, Test: 3.93%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 3.27%, Valid: 2.98%, Test: 5.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 2.24%, Valid: 2.03%, Test: 5.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 2.96%, Valid: 2.76%, Test: 6.26%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 3.51%, Valid: 3.28%, Test: 7.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 0.01%, Valid: 0.01%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 3.82%, Valid: 3.54%, Test: 0.68%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 4.12%, Valid: 3.85%, Test: 0.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 0.08%, Valid: 0.07%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 0.94%, Valid: 0.82%, Test: 0.46%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 2.58%, Valid: 2.38%, Test: 1.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 0.08%, Valid: 0.07%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 3.21%, Valid: 2.77%, Test: 0.12%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 9.13%, Valid: 8.10%, Test: 4.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 2.52%, Valid: 2.35%, Test: 4.53%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 3.55%, Valid: 3.30%, Test: 5.95%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 4.32%, Valid: 3.98%, Test: 6.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 1.82%, Valid: 1.60%, Test: 3.81%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 2.47%, Valid: 2.18%, Test: 5.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 2.75%, Valid: 2.47%, Test: 6.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 0.87%, Valid: 0.66%, Test: 0.04%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 4.18%, Valid: 3.79%, Test: 0.64%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 5.75%, Valid: 5.28%, Test: 4.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 2.11%, Valid: 1.86%, Test: 1.60%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 3.90%, Valid: 3.40%, Test: 3.19%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 6.68%, Valid: 5.87%, Test: 5.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 12.81%, Valid: 11.61%, Test: 6.73%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 13.97%, Valid: 12.68%, Test: 11.25%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 14.80%, Valid: 13.53%, Test: 13.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 2.25%, Valid: 2.07%, Test: 4.32%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 3.23%, Valid: 3.00%, Test: 5.84%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 4.14%, Valid: 3.81%, Test: 6.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 1.79%, Valid: 1.57%, Test: 2.65%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 2.30%, Valid: 2.04%, Test: 3.99%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 2.76%, Valid: 2.54%, Test: 4.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 5.26%, Valid: 4.80%, Test: 1.83%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 6.05%, Valid: 5.59%, Test: 3.85%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 6.63%, Valid: 6.13%, Test: 4.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 0.08%, Valid: 0.08%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 0.70%, Valid: 0.62%, Test: 0.05%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 2.30%, Valid: 2.09%, Test: 0.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 3.59%, Valid: 3.06%, Test: 0.07%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 8.51%, Valid: 7.52%, Test: 0.77%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 12.65%, Valid: 11.30%, Test: 2.98%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hidden_channels = 256\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "runs = 4\n",
    "lr = 0.005\n",
    "batch_size = 64 * 1024\n",
    "epochs = 5\n",
    "log_steps = 1\n",
    "eval_steps = 1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "adj_t = data.adj_t.to(device)\n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "\n",
    "# We randomly pick some training samples that we want to evaluate on:\n",
    "torch.manual_seed(12345)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "\n",
    "model = GCN(hidden_channels, hidden_channels,\n",
    "                hidden_channels, num_layers,\n",
    "                dropout).to(device)\n",
    "\n",
    "emb = torch.nn.Embedding(data.adj_t.size(0),\n",
    "                         hidden_channels).to(device)\n",
    "\n",
    "print('Embedding:', emb)\n",
    "print()\n",
    "predictor = LinkPredictor(hidden_channels, hidden_channels, 1,\n",
    "                          num_layers, dropout).to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "# loggers = {\n",
    "#     'Hits@10': Logger(args.runs, args),\n",
    "#     'Hits@20': Logger(args.runs, args),\n",
    "#     'Hits@30': Logger(args.runs, args),\n",
    "# }\n",
    "\n",
    "for run in range(runs):\n",
    "    torch.nn.init.xavier_uniform_(emb.weight)\n",
    "#     print('Weights:', emb.weight)\n",
    "#     print()\n",
    "    model.reset_parameters()\n",
    "    predictor.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.parameters()) + list(emb.parameters()) +\n",
    "        list(predictor.parameters()), lr=lr)\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        loss = train(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                     optimizer, batch_size)\n",
    "\n",
    "        if epoch % eval_steps == 0:\n",
    "#             print('Eval')\n",
    "            results = test(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                           evaluator, batch_size)\n",
    "#             for key, result in results.items():\n",
    "#                 loggers[key].add_result(run, result)\n",
    "\n",
    "            if epoch % log_steps == 0:\n",
    "                for key, result in results.items():\n",
    "                    train_hits, valid_hits, test_hits = result\n",
    "                    print(key)\n",
    "                    print(f'Run: {run + 1:02d}, '\n",
    "                          f'Epoch: {epoch:02d}, '\n",
    "                          f'Loss: {loss:.4f}, '\n",
    "                          f'Train: {100 * train_hits:.2f}%, '\n",
    "                          f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                          f'Test: {100 * test_hits:.2f}%')\n",
    "                print('---')\n",
    "\n",
    "#     for key in loggers.keys():\n",
    "#         print(key)\n",
    "#         loggers[key].print_statistics(run)\n",
    "\n",
    "# for key in loggers.keys():\n",
    "#     print(key)\n",
    "#     loggers[key].print_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (default, Jan 22 2021, 20:04:44) \n[GCC 8.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
