{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from kg_model import KG_model\n",
    "\n",
    "from ogb.linkproppred import Evaluator, PygLinkPropPredDataset\n",
    "\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=4267, edge_index=[2, 2135822])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4039, 2424, 4039,  ...,  338,  835, 3554],\n",
       "        [2424, 4039,  225,  ...,  708, 3554,  835]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge': tensor([[4039, 2424],\n",
       "         [4039,  225],\n",
       "         [4039, 3901],\n",
       "         ...,\n",
       "         [ 647,  708],\n",
       "         [ 708,  338],\n",
       "         [ 835, 3554]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "train_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "        data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "        create_inverse_triples=True,\n",
    "        entity_to_id=None,\n",
    "        relation_to_id=None,\n",
    "        compact_id=False \n",
    "    )\n",
    "\n",
    "    print(tf_data.mapped_triples)\n",
    "\n",
    "    return tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,  667],\n",
      "        [   0,    0, 1182],\n",
      "        [   0,    0, 1280],\n",
      "        ...,\n",
      "        [4266,    0, 4250],\n",
      "        [4266,    0, 4252],\n",
      "        [4266,    0, 4260]])\n",
      "tensor([[   0,    0,  729],\n",
      "        [   1,    0,  681],\n",
      "        [   1,    0,  768],\n",
      "        ...,\n",
      "        [3812,    0, 3722],\n",
      "        [3812,    0, 3758],\n",
      "        [3812,    0, 3802]])\n",
      "tensor([[   0,    0,    3],\n",
      "        [   0,    0,  185],\n",
      "        [   0,    0,  187],\n",
      "        ...,\n",
      "        [1611,    0, 1562],\n",
      "        [1611,    0, 1573],\n",
      "        [1611,    0, 1601]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# add relation type - interacts with\n",
    "\n",
    "\n",
    "train = train_edge['edge']\n",
    "train = torch.tensor([[x[0], 0, x[1]] for x in train])\n",
    "train_df = pd.DataFrame(train, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "valid = valid_edge['edge']\n",
    "valid = torch.tensor([[x[0], 0, x[1]] for x in valid])\n",
    "valid_df = pd.DataFrame(valid, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "test = test_edge['edge']\n",
    "test = torch.tensor([[x[0], 0, x[1]] for x in test])\n",
    "test_df = pd.DataFrame(test, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "train_tf = convert_to_triples_factory(train_df)\n",
    "valid_tf = convert_to_triples_factory(valid_df)\n",
    "test_tf = convert_to_triples_factory(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriplesFactory(num_entities=4267, num_relations=2, create_inverse_triples=True, num_triples=1067911)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 2584837398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.training.training_loop:=> no checkpoint found at 'kg_checkpoints/TransE-ogb_checkpoint.pt'. Creating a new file.\n",
      "INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "Training epochs on cuda:0:   0%|                       | 0/5 [00:00<?, ?epoch/s]INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "\n",
      "Training batches on cuda:0:   0%|                   | 0/8344 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|          | 10/8344 [00:00<01:24, 98.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|         | 52/8344 [00:00<00:29, 285.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 101/8344 [00:00<00:21, 375.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 153/8344 [00:00<00:19, 429.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 200/8344 [00:00<00:18, 443.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏       | 249/8344 [00:00<00:17, 456.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 303/8344 [00:00<00:16, 481.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 357/8344 [00:00<00:16, 498.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▍       | 411/8344 [00:00<00:15, 509.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 465/8344 [00:01<00:15, 516.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 519/8344 [00:01<00:14, 521.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 573/8344 [00:01<00:14, 525.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌       | 627/8344 [00:01<00:14, 527.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▋       | 681/8344 [00:01<00:14, 529.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 735/8344 [00:01<00:14, 532.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▊       | 789/8344 [00:01<00:14, 533.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 843/8344 [00:01<00:14, 533.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▊       | 897/8344 [00:01<00:13, 534.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▉       | 951/8344 [00:01<00:13, 534.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▊      | 1005/8344 [00:02<00:13, 534.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1059/8344 [00:02<00:13, 533.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1113/8344 [00:02<00:13, 533.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1167/8344 [00:02<00:13, 533.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1221/8344 [00:02<00:13, 532.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1277/8344 [00:02<00:13, 538.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█      | 1333/8344 [00:02<00:12, 543.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1389/8344 [00:02<00:12, 547.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1445/8344 [00:02<00:12, 550.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▎     | 1501/8344 [00:02<00:12, 552.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1557/8344 [00:03<00:12, 554.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1613/8344 [00:03<00:12, 555.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1669/8344 [00:03<00:12, 556.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1725/8344 [00:03<00:11, 556.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1781/8344 [00:03<00:11, 556.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1837/8344 [00:03<00:11, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▌     | 1893/8344 [00:03<00:11, 556.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▋     | 1949/8344 [00:03<00:11, 555.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 2005/8344 [00:03<00:11, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▋     | 2061/8344 [00:03<00:11, 552.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▊     | 2117/8344 [00:04<00:11, 553.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2173/8344 [00:04<00:11, 553.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▊     | 2229/8344 [00:04<00:11, 554.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▉     | 2285/8344 [00:04<00:11, 547.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2340/8344 [00:04<00:11, 544.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2395/8344 [00:04<00:10, 541.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2450/8344 [00:04<00:10, 541.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2505/8344 [00:04<00:10, 540.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2561/8344 [00:04<00:10, 544.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2617/8344 [00:04<00:10, 547.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▏    | 2672/8344 [00:05<00:10, 545.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2727/8344 [00:05<00:10, 545.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2783/8344 [00:05<00:10, 547.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▍    | 2839/8344 [00:05<00:10, 549.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2895/8344 [00:05<00:09, 551.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2951/8344 [00:05<00:09, 552.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 3007/8344 [00:05<00:09, 552.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3063/8344 [00:05<00:09, 553.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3119/8344 [00:05<00:09, 553.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3175/8344 [00:05<00:09, 554.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3231/8344 [00:06<00:09, 554.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▊    | 3287/8344 [00:06<00:09, 554.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3343/8344 [00:06<00:09, 554.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▊    | 3399/8344 [00:06<00:08, 554.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▉    | 3455/8344 [00:06<00:08, 554.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3511/8344 [00:06<00:08, 554.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▉    | 3567/8344 [00:06<00:08, 548.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|███    | 3622/8344 [00:06<00:08, 544.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3677/8344 [00:06<00:08, 541.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3732/8344 [00:06<00:08, 540.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3787/8344 [00:07<00:08, 539.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3841/8344 [00:07<00:08, 538.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3895/8344 [00:07<00:08, 537.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3949/8344 [00:07<00:08, 537.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▎   | 4004/8344 [00:07<00:08, 538.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4060/8344 [00:07<00:07, 543.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4116/8344 [00:07<00:07, 546.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▌   | 4172/8344 [00:07<00:07, 549.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4227/8344 [00:07<00:07, 544.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4282/8344 [00:08<00:07, 541.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▋   | 4337/8344 [00:08<00:07, 539.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4393/8344 [00:08<00:07, 543.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4448/8344 [00:08<00:07, 543.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4503/8344 [00:08<00:07, 543.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4558/8344 [00:08<00:06, 544.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4613/8344 [00:08<00:06, 543.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4668/8344 [00:08<00:06, 536.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|███▉   | 4722/8344 [00:08<00:06, 532.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|████   | 4776/8344 [00:08<00:06, 529.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4830/8344 [00:09<00:06, 532.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████   | 4886/8344 [00:09<00:06, 538.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████▏  | 4941/8344 [00:09<00:06, 540.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 4996/8344 [00:09<00:06, 537.48batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  61%|████▏  | 5050/8344 [00:09<00:06, 538.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5104/8344 [00:09<00:06, 537.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5158/8344 [00:09<00:05, 534.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5212/8344 [00:09<00:05, 526.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5266/8344 [00:09<00:05, 528.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▍  | 5320/8344 [00:09<00:05, 531.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▌  | 5374/8344 [00:10<00:05, 533.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5428/8344 [00:10<00:05, 535.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▌  | 5483/8344 [00:10<00:05, 536.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▋  | 5537/8344 [00:10<00:05, 536.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5591/8344 [00:10<00:05, 536.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▋  | 5645/8344 [00:10<00:05, 536.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▊  | 5700/8344 [00:10<00:04, 538.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████▊  | 5754/8344 [00:10<00:04, 537.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▊  | 5808/8344 [00:10<00:04, 537.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5862/8344 [00:10<00:04, 537.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|████▉  | 5916/8344 [00:11<00:04, 538.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 5970/8344 [00:11<00:04, 538.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 6024/8344 [00:11<00:04, 538.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████  | 6079/8344 [00:11<00:04, 540.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6134/8344 [00:11<00:04, 541.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6189/8344 [00:11<00:04, 534.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▏ | 6243/8344 [00:11<00:03, 531.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▎ | 6297/8344 [00:11<00:03, 527.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6351/8344 [00:11<00:03, 530.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▎ | 6405/8344 [00:11<00:03, 532.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6461/8344 [00:12<00:03, 538.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6517/8344 [00:12<00:03, 543.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6573/8344 [00:12<00:03, 547.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6629/8344 [00:12<00:03, 549.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6685/8344 [00:12<00:03, 551.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6741/8344 [00:12<00:02, 552.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6797/8344 [00:12<00:02, 553.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▋ | 6853/8344 [00:12<00:02, 553.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6909/8344 [00:12<00:02, 553.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6965/8344 [00:12<00:02, 554.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▉ | 7021/8344 [00:13<00:02, 554.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7077/8344 [00:13<00:02, 554.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7133/8344 [00:13<00:02, 554.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████ | 7189/8344 [00:13<00:02, 554.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7245/8344 [00:13<00:01, 554.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7301/8344 [00:13<00:01, 555.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7357/8344 [00:13<00:01, 555.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7413/8344 [00:13<00:01, 555.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7469/8344 [00:13<00:01, 555.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7525/8344 [00:13<00:01, 555.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▎| 7581/8344 [00:14<00:01, 555.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7637/8344 [00:14<00:01, 555.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7693/8344 [00:14<00:01, 555.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▌| 7749/8344 [00:14<00:01, 555.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7805/8344 [00:14<00:00, 555.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7861/8344 [00:14<00:00, 549.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7916/8344 [00:14<00:00, 545.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 7971/8344 [00:14<00:00, 542.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 8026/8344 [00:14<00:00, 541.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8082/8344 [00:14<00:00, 545.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8138/8344 [00:15<00:00, 548.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8194/8344 [00:15<00:00, 550.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8250/8344 [00:15<00:00, 551.96batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|██████▉| 8306/8344 [00:15<00:00, 552.93batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|▏| 1/5 [00:15<01:03, 15.80s/epoch, loss=0.55, pr\u001b[A\n",
      "Training batches on cuda:0:   0%|                   | 0/8344 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 13/8344 [00:00<01:04, 128.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|         | 66/8344 [00:00<00:24, 341.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 119/8344 [00:00<00:19, 422.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 173/8344 [00:00<00:17, 464.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏       | 226/8344 [00:00<00:16, 486.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▎       | 280/8344 [00:00<00:15, 504.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 334/8344 [00:00<00:15, 514.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎       | 388/8344 [00:00<00:15, 521.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▍       | 442/8344 [00:00<00:15, 525.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 496/8344 [00:01<00:14, 529.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 550/8344 [00:01<00:14, 531.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 605/8344 [00:01<00:14, 534.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▋       | 659/8344 [00:01<00:14, 535.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 713/8344 [00:01<00:14, 536.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 767/8344 [00:01<00:14, 537.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 821/8344 [00:01<00:14, 537.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 876/8344 [00:01<00:13, 538.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▉       | 930/8344 [00:01<00:13, 537.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▉       | 984/8344 [00:01<00:13, 536.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▊      | 1040/8344 [00:02<00:13, 541.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1096/8344 [00:02<00:13, 545.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1152/8344 [00:02<00:13, 548.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|█      | 1208/8344 [00:02<00:12, 550.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1264/8344 [00:02<00:12, 551.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█      | 1320/8344 [00:02<00:12, 552.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█▏     | 1376/8344 [00:02<00:12, 552.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1432/8344 [00:02<00:12, 548.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▏     | 1487/8344 [00:02<00:12, 543.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▎     | 1542/8344 [00:02<00:12, 540.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1597/8344 [00:03<00:12, 537.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1651/8344 [00:03<00:12, 536.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1705/8344 [00:03<00:12, 534.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1759/8344 [00:03<00:12, 534.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1813/8344 [00:03<00:12, 533.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1867/8344 [00:03<00:12, 533.51batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  23%|█▌     | 1921/8344 [00:03<00:12, 533.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 1975/8344 [00:03<00:11, 533.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 2029/8344 [00:03<00:11, 532.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▋     | 2083/8344 [00:03<00:11, 533.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2137/8344 [00:04<00:11, 533.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2191/8344 [00:04<00:11, 534.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▉     | 2245/8344 [00:04<00:11, 534.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2301/8344 [00:04<00:11, 540.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2357/8344 [00:04<00:10, 544.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2413/8344 [00:04<00:10, 547.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2468/8344 [00:04<00:10, 546.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2523/8344 [00:04<00:10, 544.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2578/8344 [00:04<00:10, 541.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▏    | 2633/8344 [00:04<00:10, 539.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▎    | 2688/8344 [00:05<00:10, 540.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2743/8344 [00:05<00:10, 542.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▎    | 2799/8344 [00:05<00:10, 546.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▍    | 2854/8344 [00:05<00:10, 544.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2910/8344 [00:05<00:09, 547.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▍    | 2966/8344 [00:05<00:09, 549.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 3022/8344 [00:05<00:09, 550.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3078/8344 [00:05<00:09, 548.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3133/8344 [00:05<00:09, 543.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3188/8344 [00:05<00:09, 542.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3243/8344 [00:06<00:09, 538.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3297/8344 [00:06<00:09, 532.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3351/8344 [00:06<00:09, 526.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▊    | 3407/8344 [00:06<00:09, 534.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3463/8344 [00:06<00:09, 539.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3519/8344 [00:06<00:08, 543.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▉    | 3575/8344 [00:06<00:08, 546.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3631/8344 [00:06<00:08, 548.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3687/8344 [00:06<00:08, 550.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3743/8344 [00:07<00:08, 551.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3799/8344 [00:07<00:08, 551.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3855/8344 [00:07<00:08, 552.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3911/8344 [00:07<00:08, 552.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▎   | 3967/8344 [00:07<00:07, 552.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▍   | 4023/8344 [00:07<00:07, 552.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4079/8344 [00:07<00:07, 553.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▍   | 4135/8344 [00:07<00:07, 552.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▌   | 4191/8344 [00:07<00:07, 552.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4247/8344 [00:07<00:07, 552.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▌   | 4303/8344 [00:08<00:07, 553.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▋   | 4359/8344 [00:08<00:07, 553.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4415/8344 [00:08<00:07, 553.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4471/8344 [00:08<00:06, 553.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4527/8344 [00:08<00:06, 553.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4583/8344 [00:08<00:06, 552.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4639/8344 [00:08<00:06, 547.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4694/8344 [00:08<00:06, 544.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|███▉   | 4749/8344 [00:08<00:06, 541.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4805/8344 [00:08<00:06, 545.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4861/8344 [00:09<00:06, 547.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████▏  | 4917/8344 [00:09<00:06, 549.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 4973/8344 [00:09<00:06, 550.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 5029/8344 [00:09<00:06, 551.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5085/8344 [00:09<00:05, 552.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5141/8344 [00:09<00:05, 553.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5197/8344 [00:09<00:05, 553.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5253/8344 [00:09<00:05, 550.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▍  | 5309/8344 [00:09<00:05, 541.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▌  | 5364/8344 [00:09<00:05, 541.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5419/8344 [00:10<00:05, 542.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▌  | 5475/8344 [00:10<00:05, 546.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▋  | 5531/8344 [00:10<00:05, 548.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5586/8344 [00:10<00:05, 546.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▋  | 5641/8344 [00:10<00:04, 541.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▊  | 5696/8344 [00:10<00:04, 538.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████▊  | 5750/8344 [00:10<00:04, 535.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▊  | 5804/8344 [00:10<00:04, 525.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5859/8344 [00:10<00:04, 529.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|████▉  | 5914/8344 [00:10<00:04, 534.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 5969/8344 [00:11<00:04, 538.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 6023/8344 [00:11<00:04, 535.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████  | 6077/8344 [00:11<00:04, 533.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6133/8344 [00:11<00:04, 539.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6189/8344 [00:11<00:03, 543.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▏ | 6245/8344 [00:11<00:03, 546.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6301/8344 [00:11<00:03, 548.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6357/8344 [00:11<00:03, 549.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6413/8344 [00:11<00:03, 550.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6469/8344 [00:11<00:03, 550.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6525/8344 [00:12<00:03, 551.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6581/8344 [00:12<00:03, 551.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6637/8344 [00:12<00:03, 552.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6693/8344 [00:12<00:02, 552.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6749/8344 [00:12<00:02, 552.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▋ | 6805/8344 [00:12<00:02, 552.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▊ | 6861/8344 [00:12<00:02, 552.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6917/8344 [00:12<00:02, 552.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▊ | 6973/8344 [00:12<00:02, 552.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▉ | 7029/8344 [00:13<00:02, 552.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7085/8344 [00:13<00:02, 552.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████▉ | 7141/8344 [00:13<00:02, 552.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████ | 7197/8344 [00:13<00:02, 551.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7253/8344 [00:13<00:01, 546.36batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  88%|██████▏| 7308/8344 [00:13<00:01, 543.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7363/8344 [00:13<00:01, 535.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7417/8344 [00:13<00:01, 534.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7471/8344 [00:13<00:01, 533.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7525/8344 [00:13<00:01, 532.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▎| 7580/8344 [00:14<00:01, 537.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▍| 7634/8344 [00:14<00:01, 524.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7689/8344 [00:14<00:01, 529.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▍| 7744/8344 [00:14<00:01, 534.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▌| 7799/8344 [00:14<00:01, 536.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7854/8344 [00:14<00:00, 539.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7909/8344 [00:14<00:00, 541.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7964/8344 [00:14<00:00, 539.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 8018/8344 [00:14<00:00, 538.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8072/8344 [00:14<00:00, 537.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8126/8344 [00:15<00:00, 537.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8180/8344 [00:15<00:00, 536.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8234/8344 [00:15<00:00, 537.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8288/8344 [00:15<00:00, 536.90batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|██████▉| 8342/8344 [00:15<00:00, 533.28batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|▍| 2/5 [00:31<00:47, 15.78s/epoch, loss=0.27, pr\u001b[A\n",
      "Training batches on cuda:0:   0%|                   | 0/8344 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 11/8344 [00:00<01:16, 108.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|         | 65/8344 [00:00<00:23, 358.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 110/8344 [00:00<00:20, 399.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 163/8344 [00:00<00:18, 448.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏       | 217/8344 [00:00<00:16, 478.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▎       | 269/8344 [00:00<00:16, 492.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 321/8344 [00:00<00:16, 501.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 375/8344 [00:00<00:15, 512.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▍       | 431/8344 [00:00<00:15, 525.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 487/8344 [00:01<00:14, 534.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 543/8344 [00:01<00:14, 540.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 599/8344 [00:01<00:14, 544.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▋       | 655/8344 [00:01<00:14, 546.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 711/8344 [00:01<00:13, 548.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 767/8344 [00:01<00:13, 550.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 823/8344 [00:01<00:13, 551.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▊       | 879/8344 [00:01<00:13, 551.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▉       | 935/8344 [00:01<00:13, 552.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▉       | 991/8344 [00:01<00:13, 552.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1047/8344 [00:02<00:13, 553.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1103/8344 [00:02<00:13, 553.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1159/8344 [00:02<00:12, 553.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1215/8344 [00:02<00:12, 552.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1271/8344 [00:02<00:12, 552.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█      | 1327/8344 [00:02<00:12, 552.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1383/8344 [00:02<00:12, 550.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1439/8344 [00:02<00:12, 545.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▎     | 1494/8344 [00:02<00:12, 542.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1550/8344 [00:02<00:12, 545.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1606/8344 [00:03<00:12, 547.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1661/8344 [00:03<00:12, 548.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1717/8344 [00:03<00:12, 549.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1773/8344 [00:03<00:11, 549.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1829/8344 [00:03<00:11, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▌     | 1885/8344 [00:03<00:11, 550.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▋     | 1941/8344 [00:03<00:11, 551.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 1997/8344 [00:03<00:11, 551.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▋     | 2053/8344 [00:03<00:11, 551.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▊     | 2109/8344 [00:03<00:11, 551.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2165/8344 [00:04<00:11, 551.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▊     | 2221/8344 [00:04<00:11, 551.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▉     | 2277/8344 [00:04<00:11, 549.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2332/8344 [00:04<00:10, 548.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2387/8344 [00:04<00:10, 545.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2442/8344 [00:04<00:10, 541.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2497/8344 [00:04<00:10, 539.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2551/8344 [00:04<00:10, 537.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2605/8344 [00:04<00:10, 537.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▏    | 2659/8344 [00:04<00:10, 536.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2713/8344 [00:05<00:10, 533.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2767/8344 [00:05<00:10, 535.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▎    | 2821/8344 [00:05<00:10, 534.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▍    | 2875/8344 [00:05<00:10, 526.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2928/8344 [00:05<00:10, 515.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 2982/8344 [00:05<00:10, 521.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 3038/8344 [00:05<00:09, 531.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3092/8344 [00:05<00:09, 533.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3147/8344 [00:05<00:09, 537.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3202/8344 [00:05<00:09, 538.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3257/8344 [00:06<00:09, 539.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3312/8344 [00:06<00:09, 539.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3366/8344 [00:06<00:09, 539.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▊    | 3420/8344 [00:06<00:09, 539.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3476/8344 [00:06<00:08, 543.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3531/8344 [00:06<00:08, 538.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|███    | 3585/8344 [00:06<00:08, 535.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3639/8344 [00:06<00:08, 531.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3694/8344 [00:06<00:08, 534.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3748/8344 [00:07<00:08, 534.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3804/8344 [00:07<00:08, 540.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3860/8344 [00:07<00:08, 543.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3916/8344 [00:07<00:08, 546.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▎   | 3972/8344 [00:07<00:07, 548.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▍   | 4028/8344 [00:07<00:07, 549.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4084/8344 [00:07<00:07, 550.69batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|███▍   | 4140/8344 [00:07<00:07, 551.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▌   | 4196/8344 [00:07<00:07, 545.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4251/8344 [00:07<00:07, 542.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▌   | 4306/8344 [00:08<00:07, 539.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▋   | 4360/8344 [00:08<00:07, 537.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4414/8344 [00:08<00:07, 535.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▋   | 4468/8344 [00:08<00:07, 536.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4524/8344 [00:08<00:07, 540.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4580/8344 [00:08<00:06, 543.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4636/8344 [00:08<00:06, 546.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4692/8344 [00:08<00:06, 547.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|███▉   | 4748/8344 [00:08<00:06, 548.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4804/8344 [00:08<00:06, 549.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4860/8344 [00:09<00:06, 550.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████   | 4916/8344 [00:09<00:06, 550.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 4972/8344 [00:09<00:06, 551.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 5028/8344 [00:09<00:06, 547.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5084/8344 [00:09<00:05, 548.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5140/8344 [00:09<00:05, 549.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5196/8344 [00:09<00:05, 550.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5252/8344 [00:09<00:05, 550.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▍  | 5308/8344 [00:09<00:05, 550.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▌  | 5364/8344 [00:09<00:05, 551.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5420/8344 [00:10<00:05, 550.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▌  | 5476/8344 [00:10<00:05, 547.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▋  | 5532/8344 [00:10<00:05, 548.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5588/8344 [00:10<00:05, 549.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▋  | 5644/8344 [00:10<00:04, 549.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▊  | 5700/8344 [00:10<00:04, 550.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████▊  | 5756/8344 [00:10<00:04, 550.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5812/8344 [00:10<00:04, 550.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5868/8344 [00:10<00:04, 547.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|████▉  | 5923/8344 [00:10<00:04, 543.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 5978/8344 [00:11<00:04, 538.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 6033/8344 [00:11<00:04, 539.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████  | 6088/8344 [00:11<00:04, 539.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6142/8344 [00:11<00:04, 531.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6196/8344 [00:11<00:04, 529.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▏ | 6250/8344 [00:11<00:03, 528.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6303/8344 [00:11<00:03, 514.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6356/8344 [00:11<00:03, 516.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6408/8344 [00:11<00:03, 513.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6460/8344 [00:12<00:03, 503.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6514/8344 [00:12<00:03, 512.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6570/8344 [00:12<00:03, 524.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6626/8344 [00:12<00:03, 532.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6682/8344 [00:12<00:03, 538.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6738/8344 [00:12<00:02, 542.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6794/8344 [00:12<00:02, 545.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▋ | 6850/8344 [00:12<00:02, 547.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6906/8344 [00:12<00:02, 549.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6962/8344 [00:12<00:02, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▉ | 7018/8344 [00:13<00:02, 551.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7074/8344 [00:13<00:02, 551.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7130/8344 [00:13<00:02, 551.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████ | 7186/8344 [00:13<00:02, 551.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7242/8344 [00:13<00:01, 552.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7298/8344 [00:13<00:01, 552.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7354/8344 [00:13<00:01, 552.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7410/8344 [00:13<00:01, 552.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▎| 7466/8344 [00:13<00:01, 551.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7522/8344 [00:13<00:01, 544.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▎| 7577/8344 [00:14<00:01, 531.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▍| 7631/8344 [00:14<00:01, 533.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7685/8344 [00:14<00:01, 531.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▍| 7739/8344 [00:14<00:01, 530.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▌| 7793/8344 [00:14<00:01, 529.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7846/8344 [00:14<00:00, 528.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7899/8344 [00:14<00:00, 528.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7952/8344 [00:14<00:00, 528.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 8006/8344 [00:14<00:00, 529.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8061/8344 [00:14<00:00, 534.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8116/8344 [00:15<00:00, 538.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8170/8344 [00:15<00:00, 536.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8224/8344 [00:15<00:00, 533.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8278/8344 [00:15<00:00, 532.15batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|██████▉| 8332/8344 [00:15<00:00, 530.47batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  60%|▌| 3/5 [00:47<00:31, 15.80s/epoch, loss=0.243, p\u001b[A\n",
      "Training batches on cuda:0:   0%|                   | 0/8344 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 13/8344 [00:00<01:04, 128.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|         | 67/8344 [00:00<00:22, 367.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 115/8344 [00:00<00:19, 415.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 169/8344 [00:00<00:17, 462.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏       | 223/8344 [00:00<00:16, 487.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▎       | 276/8344 [00:00<00:16, 500.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 329/8344 [00:00<00:15, 509.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎       | 382/8344 [00:00<00:15, 514.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▍       | 434/8344 [00:00<00:15, 515.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 488/8344 [00:01<00:15, 520.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▌       | 541/8344 [00:01<00:14, 522.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 594/8344 [00:01<00:14, 523.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌       | 647/8344 [00:01<00:14, 524.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▋       | 700/8344 [00:01<00:14, 526.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 753/8344 [00:01<00:14, 527.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 807/8344 [00:01<00:14, 528.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 861/8344 [00:01<00:14, 529.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▉       | 915/8344 [00:01<00:14, 530.14batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  12%|▉       | 971/8344 [00:01<00:13, 536.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▊      | 1027/8344 [00:02<00:13, 540.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1082/8344 [00:02<00:13, 536.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1137/8344 [00:02<00:13, 537.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|█      | 1192/8344 [00:02<00:13, 538.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1247/8344 [00:02<00:13, 539.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█      | 1301/8344 [00:02<00:13, 538.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█▏     | 1355/8344 [00:02<00:13, 535.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1409/8344 [00:02<00:13, 532.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▏     | 1463/8344 [00:02<00:12, 530.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▎     | 1517/8344 [00:02<00:12, 529.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1570/8344 [00:03<00:12, 529.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1623/8344 [00:03<00:12, 529.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1676/8344 [00:03<00:12, 528.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1729/8344 [00:03<00:12, 528.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1782/8344 [00:03<00:12, 527.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1835/8344 [00:03<00:12, 527.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▌     | 1888/8344 [00:03<00:12, 527.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▋     | 1941/8344 [00:03<00:12, 526.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 1994/8344 [00:03<00:12, 526.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▋     | 2047/8344 [00:03<00:11, 526.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▊     | 2100/8344 [00:04<00:11, 526.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2153/8344 [00:04<00:11, 526.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2206/8344 [00:04<00:11, 527.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▉     | 2259/8344 [00:04<00:11, 527.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2312/8344 [00:04<00:11, 528.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2365/8344 [00:04<00:11, 521.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2418/8344 [00:04<00:11, 508.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2472/8344 [00:04<00:11, 517.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2526/8344 [00:04<00:11, 522.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2581/8344 [00:04<00:10, 529.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▏    | 2637/8344 [00:05<00:10, 536.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▎    | 2693/8344 [00:05<00:10, 540.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2749/8344 [00:05<00:10, 543.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▎    | 2805/8344 [00:05<00:10, 545.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▍    | 2860/8344 [00:05<00:10, 545.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2915/8344 [00:05<00:09, 546.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▍    | 2971/8344 [00:05<00:09, 547.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 3026/8344 [00:05<00:09, 547.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3081/8344 [00:05<00:09, 543.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3136/8344 [00:05<00:09, 539.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3190/8344 [00:06<00:09, 535.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3244/8344 [00:06<00:09, 534.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3298/8344 [00:06<00:09, 533.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3353/8344 [00:06<00:09, 537.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▊    | 3409/8344 [00:06<00:09, 541.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3464/8344 [00:06<00:08, 543.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3520/8344 [00:06<00:08, 545.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|██▉    | 3575/8344 [00:06<00:08, 546.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3631/8344 [00:06<00:08, 547.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3686/8344 [00:06<00:08, 542.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3741/8344 [00:07<00:08, 538.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3796/8344 [00:07<00:08, 542.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3851/8344 [00:07<00:08, 541.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3906/8344 [00:07<00:08, 538.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3960/8344 [00:07<00:08, 534.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▎   | 4014/8344 [00:07<00:08, 531.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4068/8344 [00:07<00:08, 530.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4122/8344 [00:07<00:07, 528.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▌   | 4175/8344 [00:07<00:07, 528.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4228/8344 [00:08<00:07, 524.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4283/8344 [00:08<00:07, 529.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▋   | 4336/8344 [00:08<00:07, 511.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4388/8344 [00:08<00:07, 513.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4441/8344 [00:08<00:07, 518.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4494/8344 [00:08<00:07, 521.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4547/8344 [00:08<00:07, 520.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4600/8344 [00:08<00:07, 522.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4653/8344 [00:08<00:07, 521.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4706/8344 [00:08<00:06, 523.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|███▉   | 4759/8344 [00:09<00:06, 525.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4812/8344 [00:09<00:06, 526.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4865/8344 [00:09<00:06, 526.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████▏  | 4918/8344 [00:09<00:06, 527.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 4971/8344 [00:09<00:06, 527.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 5024/8344 [00:09<00:06, 527.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5077/8344 [00:09<00:06, 527.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5130/8344 [00:09<00:06, 528.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5183/8344 [00:09<00:06, 524.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5236/8344 [00:09<00:05, 520.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5289/8344 [00:10<00:05, 514.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▍  | 5342/8344 [00:10<00:05, 518.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5395/8344 [00:10<00:05, 521.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5449/8344 [00:10<00:05, 524.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▌  | 5502/8344 [00:10<00:05, 525.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5555/8344 [00:10<00:05, 527.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5608/8344 [00:10<00:05, 527.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▋  | 5661/8344 [00:10<00:05, 528.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▊  | 5714/8344 [00:10<00:04, 528.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████▊  | 5767/8344 [00:10<00:04, 528.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5821/8344 [00:11<00:04, 529.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5874/8344 [00:11<00:04, 529.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|████▉  | 5928/8344 [00:11<00:04, 529.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 5981/8344 [00:11<00:04, 529.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 6034/8344 [00:11<00:04, 529.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████  | 6087/8344 [00:11<00:04, 529.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6140/8344 [00:11<00:04, 523.86batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  74%|█████▏ | 6193/8344 [00:11<00:04, 523.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▏ | 6246/8344 [00:11<00:04, 519.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▎ | 6298/8344 [00:11<00:03, 518.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6350/8344 [00:12<00:03, 518.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▎ | 6404/8344 [00:12<00:03, 523.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6457/8344 [00:12<00:03, 518.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6509/8344 [00:12<00:03, 514.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6561/8344 [00:12<00:03, 511.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6613/8344 [00:12<00:03, 508.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6664/8344 [00:12<00:03, 506.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▋ | 6715/8344 [00:12<00:03, 493.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6765/8344 [00:12<00:03, 488.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▋ | 6814/8344 [00:13<00:03, 478.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▊ | 6862/8344 [00:13<00:03, 477.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6914/8344 [00:13<00:02, 489.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6963/8344 [00:13<00:02, 488.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▉ | 7016/8344 [00:13<00:02, 498.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7068/8344 [00:13<00:02, 505.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7123/8344 [00:13<00:02, 516.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████ | 7177/8344 [00:13<00:02, 521.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7231/8344 [00:13<00:02, 526.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7285/8344 [00:13<00:01, 529.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7340/8344 [00:14<00:01, 533.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7394/8344 [00:14<00:01, 535.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7448/8344 [00:14<00:01, 535.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7502/8344 [00:14<00:01, 536.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▎| 7556/8344 [00:14<00:01, 534.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▍| 7610/8344 [00:14<00:01, 531.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7664/8344 [00:14<00:01, 530.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7718/8344 [00:14<00:01, 527.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▌| 7771/8344 [00:14<00:01, 523.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7824/8344 [00:14<00:00, 522.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7877/8344 [00:15<00:00, 523.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7930/8344 [00:15<00:00, 514.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 7983/8344 [00:15<00:00, 518.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 8035/8344 [00:15<00:00, 504.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8088/8344 [00:15<00:00, 508.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8139/8344 [00:15<00:00, 502.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8190/8344 [00:15<00:00, 501.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8244/8344 [00:15<00:00, 510.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8296/8344 [00:15<00:00, 510.90batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  80%|▊| 4/5 [01:03<00:15, 15.98s/epoch, loss=0.234, p\u001b[A\n",
      "Training batches on cuda:0:   0%|                   | 0/8344 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 14/8344 [00:00<01:00, 138.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|         | 68/8344 [00:00<00:22, 371.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 115/8344 [00:00<00:19, 412.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▏       | 167/8344 [00:00<00:18, 453.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▏       | 220/8344 [00:00<00:16, 480.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▎       | 273/8344 [00:00<00:16, 496.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|▎       | 327/8344 [00:00<00:15, 509.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▎       | 378/8344 [00:00<00:15, 502.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|▍       | 433/8344 [00:00<00:15, 515.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|▍       | 488/8344 [00:01<00:15, 523.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 543/8344 [00:01<00:14, 529.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|▌       | 596/8344 [00:01<00:14, 523.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▌       | 650/8344 [00:01<00:14, 527.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|▋       | 705/8344 [00:01<00:14, 532.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|▋       | 759/8344 [00:01<00:14, 534.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 813/8344 [00:01<00:14, 526.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|▊       | 866/8344 [00:01<00:14, 520.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|▉       | 919/8344 [00:01<00:14, 515.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▉       | 972/8344 [00:01<00:14, 517.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|▊      | 1025/8344 [00:02<00:14, 520.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|▉      | 1078/8344 [00:02<00:13, 521.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1131/8344 [00:02<00:13, 522.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|▉      | 1184/8344 [00:02<00:13, 517.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1236/8344 [00:02<00:13, 517.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|█      | 1289/8344 [00:02<00:13, 520.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█▏     | 1344/8344 [00:02<00:13, 527.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1398/8344 [00:02<00:13, 531.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█▏     | 1452/8344 [00:02<00:12, 533.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█▎     | 1506/8344 [00:02<00:12, 534.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1560/8344 [00:03<00:12, 533.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█▎     | 1614/8344 [00:03<00:12, 533.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|█▍     | 1668/8344 [00:03<00:12, 533.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1722/8344 [00:03<00:12, 534.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|█▍     | 1776/8344 [00:03<00:12, 531.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|█▌     | 1830/8344 [00:03<00:12, 533.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▌     | 1884/8344 [00:03<00:12, 529.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|█▋     | 1937/8344 [00:03<00:12, 527.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|█▋     | 1991/8344 [00:03<00:12, 529.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▋     | 2045/8344 [00:03<00:11, 532.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|█▊     | 2099/8344 [00:04<00:11, 528.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2154/8344 [00:04<00:11, 533.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|█▊     | 2208/8344 [00:04<00:11, 531.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|█▉     | 2262/8344 [00:04<00:11, 530.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2316/8344 [00:04<00:11, 529.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|█▉     | 2370/8344 [00:04<00:11, 529.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|██     | 2423/8344 [00:04<00:11, 529.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2476/8344 [00:04<00:11, 529.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|██     | 2529/8344 [00:04<00:10, 528.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|██▏    | 2582/8344 [00:04<00:10, 528.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▏    | 2635/8344 [00:05<00:10, 528.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██▎    | 2688/8344 [00:05<00:10, 528.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2741/8344 [00:05<00:10, 528.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██▎    | 2794/8344 [00:05<00:10, 528.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██▍    | 2847/8344 [00:05<00:10, 528.72batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  35%|██▍    | 2900/8344 [00:05<00:10, 528.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██▍    | 2953/8344 [00:05<00:10, 527.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|██▌    | 3006/8344 [00:05<00:10, 524.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3059/8344 [00:05<00:10, 523.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|██▌    | 3112/8344 [00:05<00:09, 523.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|██▋    | 3165/8344 [00:06<00:09, 519.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3217/8344 [00:06<00:09, 519.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|██▋    | 3270/8344 [00:06<00:09, 520.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3323/8344 [00:06<00:09, 520.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|██▊    | 3376/8344 [00:06<00:09, 521.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|██▉    | 3429/8344 [00:06<00:09, 521.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3482/8344 [00:06<00:09, 521.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|██▉    | 3535/8344 [00:06<00:09, 522.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|███    | 3588/8344 [00:06<00:09, 522.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3641/8344 [00:07<00:09, 522.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|███    | 3694/8344 [00:07<00:08, 522.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|███▏   | 3747/8344 [00:07<00:08, 522.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3800/8344 [00:07<00:08, 522.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|███▏   | 3853/8344 [00:07<00:08, 522.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3906/8344 [00:07<00:08, 522.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|███▎   | 3959/8344 [00:07<00:08, 522.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███▎   | 4012/8344 [00:07<00:08, 522.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4065/8344 [00:07<00:08, 522.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███▍   | 4118/8344 [00:07<00:08, 522.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███▍   | 4171/8344 [00:08<00:07, 522.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4224/8344 [00:08<00:07, 522.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███▌   | 4277/8344 [00:08<00:07, 522.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███▋   | 4330/8344 [00:08<00:07, 522.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4383/8344 [00:08<00:07, 522.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|███▋   | 4436/8344 [00:08<00:07, 522.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4489/8344 [00:08<00:07, 522.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|███▊   | 4542/8344 [00:08<00:07, 522.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|███▊   | 4595/8344 [00:08<00:07, 522.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4648/8344 [00:08<00:07, 522.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|███▉   | 4701/8344 [00:09<00:06, 522.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|███▉   | 4754/8344 [00:09<00:06, 522.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4807/8344 [00:09<00:06, 522.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|████   | 4860/8344 [00:09<00:06, 522.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|████   | 4913/8344 [00:09<00:06, 522.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 4966/8344 [00:09<00:06, 522.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|████▏  | 5019/8344 [00:09<00:06, 522.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5072/8344 [00:09<00:06, 522.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|████▎  | 5125/8344 [00:09<00:06, 522.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|████▎  | 5178/8344 [00:09<00:06, 522.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5231/8344 [00:10<00:05, 522.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|████▍  | 5284/8344 [00:10<00:05, 522.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|████▍  | 5337/8344 [00:10<00:05, 522.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5390/8344 [00:10<00:05, 522.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|████▌  | 5443/8344 [00:10<00:05, 522.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|████▌  | 5496/8344 [00:10<00:05, 522.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5549/8344 [00:10<00:05, 522.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████▋  | 5602/8344 [00:10<00:05, 522.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▋  | 5655/8344 [00:10<00:05, 522.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████▊  | 5708/8344 [00:10<00:05, 522.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████▊  | 5761/8344 [00:11<00:04, 518.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5814/8344 [00:11<00:04, 519.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████▉  | 5867/8344 [00:11<00:04, 520.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|████▉  | 5920/8344 [00:11<00:04, 520.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 5973/8344 [00:11<00:04, 521.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████  | 6027/8344 [00:11<00:04, 524.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████  | 6080/8344 [00:11<00:04, 525.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6133/8344 [00:11<00:04, 523.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|█████▏ | 6186/8344 [00:11<00:04, 522.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▏ | 6240/8344 [00:11<00:04, 524.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|█████▎ | 6295/8344 [00:12<00:03, 529.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|█████▎ | 6348/8344 [00:12<00:03, 528.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▎ | 6401/8344 [00:12<00:03, 528.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|█████▍ | 6454/8344 [00:12<00:03, 528.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|█████▍ | 6507/8344 [00:12<00:03, 528.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6560/8344 [00:12<00:03, 528.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|█████▌ | 6613/8344 [00:12<00:03, 529.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|█████▌ | 6666/8344 [00:12<00:03, 529.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6719/8344 [00:12<00:03, 529.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|█████▋ | 6772/8344 [00:12<00:02, 529.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▋ | 6825/8344 [00:13<00:02, 529.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████▊ | 6878/8344 [00:13<00:02, 529.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████▊ | 6931/8344 [00:13<00:02, 529.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▊ | 6984/8344 [00:13<00:02, 529.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████▉ | 7037/8344 [00:13<00:02, 529.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████▉ | 7090/8344 [00:13<00:02, 529.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████▉ | 7143/8344 [00:13<00:02, 529.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████ | 7197/8344 [00:13<00:02, 529.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████ | 7250/8344 [00:13<00:02, 529.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7303/8344 [00:13<00:01, 529.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████▏| 7356/8344 [00:14<00:01, 529.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▏| 7409/8344 [00:14<00:01, 528.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████▎| 7462/8344 [00:14<00:01, 526.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████▎| 7515/8344 [00:14<00:01, 524.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▎| 7568/8344 [00:14<00:01, 523.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|██████▍| 7621/8344 [00:14<00:01, 522.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|██████▍| 7674/8344 [00:14<00:01, 522.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▍| 7727/8344 [00:14<00:01, 521.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|██████▌| 7780/8344 [00:14<00:01, 521.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|██████▌| 7833/8344 [00:14<00:00, 521.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▌| 7886/8344 [00:15<00:00, 521.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|██████▋| 7939/8344 [00:15<00:00, 521.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████▋| 7992/8344 [00:15<00:00, 520.95batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  96%|██████▋| 8045/8344 [00:15<00:00, 520.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|██████▊| 8098/8344 [00:15<00:00, 520.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▊| 8151/8344 [00:15<00:00, 516.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|██████▉| 8204/8344 [00:15<00:00, 518.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|██████▉| 8257/8344 [00:15<00:00, 518.98batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|██████▉| 8310/8344 [00:15<00:00, 519.72batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  80%|▊| 4/5 [01:19<00:15, 15.98s/epoch, loss=0.229, p\u001b[AINFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 5.\n",
      "Training epochs on cuda:0: 100%|█| 5/5 [01:19<00:00, 15.99s/epoch, loss=0.229, p\n",
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=1024.\n",
      "Evaluating on cuda:0: 100%|█████████████| 133k/133k [00:41<00:00, 3.22ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 44.67s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    }
   ],
   "source": [
    "model = KG_model('TransE', train_tf, valid_tf, test_tf, 'ogb')\n",
    "model.set_params(5, 'Adam', RankBasedEvaluator, 'gpu')\n",
    "print('Training...')\n",
    "model.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ddi\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n"
     ]
    }
   ],
   "source": [
    "from ogb.linkproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbl-ddi')\n",
    "# You can learn the input and output format specification of the evaluator as follows.\n",
    "print(evaluator.expected_input_format) \n",
    "# print(evaluator.expected_output_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_result = pipeline(\n",
    "#     dataset='BioKG',\n",
    "#     model='TransE',\n",
    "#     epochs=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KG_model' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241m.\u001b[39mget_metric(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KG_model' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "pipeline_result.get_metric('MRR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Side</th>\n",
       "      <th>Type</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>763.334352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>774.100216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>1087.127262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>763.334343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>774.100210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>1087.127251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>763.334327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>774.100202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>z_arithmetic_mean_rank</td>\n",
       "      <td>1087.127234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>6107.172591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>3908.957742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>5139.842846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>6107.175293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>3908.959473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>5139.845215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>6107.177437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>3908.961357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>standard_deviation</td>\n",
       "      <td>5139.847124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>median_rank</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Side         Type                  Metric        Value\n",
       "0   head   optimistic  z_arithmetic_mean_rank   763.334352\n",
       "1   tail   optimistic  z_arithmetic_mean_rank   774.100216\n",
       "2   both   optimistic  z_arithmetic_mean_rank  1087.127262\n",
       "3   head    realistic  z_arithmetic_mean_rank   763.334343\n",
       "4   tail    realistic  z_arithmetic_mean_rank   774.100210\n",
       "5   both    realistic  z_arithmetic_mean_rank  1087.127251\n",
       "6   head  pessimistic  z_arithmetic_mean_rank   763.334327\n",
       "7   tail  pessimistic  z_arithmetic_mean_rank   774.100202\n",
       "8   both  pessimistic  z_arithmetic_mean_rank  1087.127234\n",
       "9   head   optimistic      standard_deviation  6107.172591\n",
       "10  tail   optimistic      standard_deviation  3908.957742\n",
       "11  both   optimistic      standard_deviation  5139.842846\n",
       "12  head    realistic      standard_deviation  6107.175293\n",
       "13  tail    realistic      standard_deviation  3908.959473\n",
       "14  both    realistic      standard_deviation  5139.845215\n",
       "15  head  pessimistic      standard_deviation  6107.177437\n",
       "16  tail  pessimistic      standard_deviation  3908.961357\n",
       "17  both  pessimistic      standard_deviation  5139.847124\n",
       "18  head   optimistic             median_rank   193.000000\n",
       "19  tail   optimistic             median_rank   215.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ddi = pd.read_csv(\"data/triplets/ddi.tsv\", sep='\\t', index_col=[0])\n",
    "drug_ingredients = pd.read_csv(\"data/triplets/ingredients.tsv\", sep='\\t', index_col=[0])\n",
    "food_compounds = pd.read_csv(\"data/triplets/food_compound.tsv\", sep='\\t', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>interaction</th>\n",
       "      <th>drug2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apixaban</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dabigatran etexilate</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>increase_bleeding</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>increase_hemorrhage</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deferasirox</td>\n",
       "      <td>increase_gastrointestinal_bleeding</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  drug1                         interaction      drug2\n",
       "0              Apixaban   increase_anticoagulant_activities  Lepirudin\n",
       "1  Dabigatran etexilate   increase_anticoagulant_activities  Lepirudin\n",
       "2             Dasatinib                   increase_bleeding  Lepirudin\n",
       "3             Dasatinib                 increase_hemorrhage  Lepirudin\n",
       "4           Deferasirox  increase_gastrointestinal_bleeding  Lepirudin"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Garden onion',\n",
       " 'Mugwort',\n",
       " 'Roman camomile',\n",
       " 'Ceylon cinnamon',\n",
       " 'Common hazelnut',\n",
       " 'Wild carrot',\n",
       " 'Cornmint',\n",
       " 'Evening primrose',\n",
       " 'Scarlet bean',\n",
       " 'Cloudberry']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds = set(food_compounds.compound)\n",
    "\n",
    "food_compound_dict = dict()\n",
    "\n",
    "for c in compounds:\n",
    "    food_compound_dict[c] = list(food_compounds[food_compounds['compound'] == c].food)\n",
    "\n",
    "food_compound_dict['Zinc'][:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Galantamine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_compound_dict = dict()\n",
    "drugs = set(drug_ingredients.drug_name)\n",
    "interacting_drugs = set(ddi.drug1)\n",
    "interacting_drugs.union(set(ddi.drug2))\n",
    "\n",
    "for d in drugs:\n",
    "    if d in interacting_drugs:\n",
    "        drug_compound_dict[d] = list(drug_ingredients[drug_ingredients['drug_name'] == d].ingredient)\n",
    "\n",
    "drug_compound_dict['Galantamine'][:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/drug_compound_dict.json', 'w') as f:\n",
    "    f.write(json.dumps(drug_compound_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interacting drugs ingredients: 758\n",
      "Number of food compounds: 276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Adenosine',\n",
       " 'Allantoin',\n",
       " 'Ascorbic acid',\n",
       " 'Atropine',\n",
       " 'Caffeine',\n",
       " 'Calcium',\n",
       " 'Capsaicin',\n",
       " 'Chromium',\n",
       " 'Diazepam',\n",
       " 'Dopamine',\n",
       " 'Ethanol',\n",
       " 'Formaldehyde',\n",
       " 'Glycine',\n",
       " 'Iron',\n",
       " 'Melatonin',\n",
       " 'Nicotinamide',\n",
       " 'Nicotine',\n",
       " 'Phenol',\n",
       " 'Progesterone',\n",
       " 'Pyridoxine',\n",
       " 'Selenium',\n",
       " 'Testosterone',\n",
       " 'Theophylline',\n",
       " 'Thiamine',\n",
       " 'Vitamin D'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools \n",
    "\n",
    "ingredients = list(drug_compound_dict.values())\n",
    "ingredients = list(itertools.chain.from_iterable(ingredients))\n",
    "ingredients = set([x.strip() for x in ingredients])\n",
    "print('Number of interacting drugs ingredients:', len(ingredients))\n",
    "\n",
    "print('Number of food compounds:', len(food_compound_dict.keys()))\n",
    "ingredients.intersection(food_compound_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_similar_food(drug_ingredients, food_compound_dict):\n",
    "    sim_food = []\n",
    "\n",
    "    for ingredient in drug_ingredients:\n",
    "        # print(ingredient)\n",
    "        foods = food_compound_dict.get(ingredient)\n",
    "        if foods is not None:\n",
    "            sim_food += foods    \n",
    "\n",
    "    if len(sim_food) < 1:\n",
    "        return []\n",
    "\n",
    "    counts = Counter(sim_food)\n",
    "    counts = dict(sorted(counts.items(), key=lambda item: item[1]))\n",
    "    print(counts)\n",
    "    return sim_food    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Savoy cabbage': 1, 'Kiwi': 1, 'Allium': 1, 'Garden onion': 1, 'Leek': 1, 'Garlic': 1, 'Chives': 1, 'Cashew nut': 1, 'Pineapple': 1, 'Dill': 1, 'Wild celery': 1, 'Peanut': 1, 'Burdock': 1, 'Horseradish': 1, 'Tarragon': 1, 'Asparagus': 1, 'Oat': 1, 'Star fruit': 1, 'Brazil nut': 1, 'Common beet': 1, 'Borage': 1, 'Swede': 1, 'Rape': 1, 'Common cabbage': 1, 'Cauliflower': 1, 'Brussel sprouts': 1, 'Broccoli': 1, 'Chinese cabbage': 1, 'Turnip': 1, 'Pigeon pea': 1, 'Tea': 1, 'Pepper': 1, 'Papaya': 1, 'Safflower': 1, 'Caraway': 1, 'Pecan nut': 1, 'Chestnut': 1, 'Chickpea': 1, 'Endive': 1, 'Chicory': 1, 'Chinese cinnamon': 1, 'Watermelon': 1, 'Lemon': 1, 'Mandarin orange (Clementine, Tangerine)': 1, 'Sweet orange': 1, 'Coffee': 1, 'Arabica coffee': 1, 'Robusta coffee': 1, 'Coriander': 1, 'Saffron': 1, 'Muskmelon': 1, 'Cucumber': 1, 'Cucurbita': 1, 'Wild carrot': 1, 'Japanese persimmon': 1, 'Loquat': 1, 'Common buckwheat': 1, 'Fig': 1, 'Fennel': 1, 'Strawberry': 1, 'Soy bean': 1, 'Sunflower': 1, 'Barley': 1, 'Swamp cabbage': 1, 'Sweet potato': 1, 'Black walnut': 1, 'Common walnut': 1, 'Lettuce': 1, 'Lentils': 1, 'Garden cress': 1, 'Flaxseed': 1, 'Apple': 1, 'Mango': 1, 'Spearmint': 1, 'Peppermint': 1, 'Bitter gourd': 1, 'Nutmeg': 1, 'Sweet basil': 1, 'Evening primrose': 1, 'Olive': 1, 'Common oregano': 1, 'Rice': 1, 'Millet': 1, 'Poppy': 1, 'Parsnip': 1, 'Avocado': 1, 'Parsley': 1, 'Lima bean': 1, 'Common bean': 1, 'Date': 1, 'Pine nut': 1, 'Pepper (Spice)': 1, 'Pistachio': 1, 'Common pea': 1, 'Purslane': 1, 'Prunus (Cherry, Plum)': 1, 'Apricot': 1, 'Sweet cherry': 1, 'Sour cherry': 1, 'European plum': 1, 'Almond': 1, 'Peach': 1, 'Guava': 1, 'Pear': 1, 'Radish': 1, 'Garden rhubarb': 1, 'Watercress': 1, 'Rosemary': 1, 'Sorrel': 1, 'Common sage': 1, 'Rye': 1, 'Sesame': 1, 'Garden tomato': 1, 'Garden tomato (var.)': 1, 'Eggplant': 1, 'Potato': 1, 'Sorghum': 1, 'Spinach': 1, 'Cloves': 1, 'Cocoa bean': 1, 'Common thyme': 1, 'Linden': 1, 'Fenugreek': 1, 'Common wheat': 1, 'Vaccinium (Blueberry, Cranberry, Huckleberry)': 1, 'Highbush blueberry': 1, 'American cranberry': 1, 'Broad bean': 1, 'Adzuki bean': 1, 'Gram bean': 1, 'Mung bean': 1, 'Cowpea': 1, 'Common grape': 1, 'Corn': 1, 'Ginger': 1, 'Banana': 1, 'Celeriac': 1, 'Longan': 1, 'Nectarine': 1, 'Welsh onion': 1, 'Hard wheat': 1, 'Shallot': 1, 'Carrot': 1, 'Triticale': 1, 'Black cabbage': 1, 'Celery leaves': 1, 'Pak choy': 1, 'Napa cabbage': 1, 'Grapefruit': 1, 'Daikon radish': 1, 'Red beetroot': 1, 'Beer': 1, 'Other bread': 1, 'Breakfast cereal': 1, 'Other soy product': 1, 'Pasta': 1, 'Biscuit': 1, 'Spirit': 1, 'Other alcoholic beverage': 1, 'Abalone': 1, 'Acorn': 1, 'Winter squash': 1, 'Red king crab': 1, 'Amaranth': 1, 'Arrowroot': 1, 'Asian pear': 1, 'Atlantic herring': 1, 'Atlantic mackerel': 1, 'Painted comber': 1, 'Atlantic pollock': 1, 'Atlantic wolffish': 1, 'Bamboo shoots': 1, 'Striped bass': 1, 'Beech nut': 1, 'Beluga whale': 1, 'Blue crab': 1, 'Blue mussel': 1, 'Northern bluefin tuna': 1, 'Bluefish': 1, 'Breadfruit': 1, 'Breadnut tree seed': 1, 'Rapini': 1, 'Burbot': 1, 'American butterfish': 1, 'Butternut': 1, 'Butternut squash': 1, 'Carob': 1, 'Common carp': 1, 'Cassava': 1, 'Channel catfish': 1, 'Chayote': 1, 'Cherimoya': 1, 'Chervil': 1, 'Chia': 1, 'Chinese chestnut': 1, 'Cisco': 1, 'Coconut': 1, 'Pacific cod': 1, 'Atlantic cod': 1, 'Common octopus': 1, 'Corn salad': 1, 'Cottonseed': 1, 'Catjang pea': 1, 'Malus (Crab apple)': 1, 'Atlantic croaker': 1, 'Cusk': 1, 'Cuttlefish': 1, 'Dock': 1, 'Dolphin fish': 1, 'Freshwater drum': 1, 'Dungeness crab': 1, 'Eastern oyster': 1, 'Freshwater eel': 1, 'Elderberry': 1, 'European anchovy': 1, 'European chestnut': 1, 'Turbot': 1, 'Florida pompano': 1, 'Ginkgo nuts': 1, 'Grape': 1, 'Greenland halibut/turbot': 1, 'Grouper': 1, 'Haddock': 1, 'Hippoglossus (Common halibut)': 1, 'Hazelnut': 1, 'Hickory nut': 1, 'Horseradish tree': 1, 'Hyacinth bean': 1, 'Pacific jack mackerel': 1, 'Jackfruit': 1, 'Japanese chestnut': 1, 'Jerusalem artichoke': 1, 'Jute': 1, 'Kale': 1, 'Kelp': 1, 'King mackerel': 1, 'Lambsquarters': 1, 'Wild leek': 1, 'Common ling': 1, 'Lingcod': 1, 'American lobster': 1, 'Lotus': 1, 'Sacred lotus': 1, 'White lupine': 1, 'Malabar spinach': 1, 'Milkfish': 1, 'Monkfish': 1, 'Mountain yam': 1, 'Striped mullet': 1, 'White mustard': 1, 'Nopal': 1, 'Ocean pout': 1, 'Okra': 1, 'Pacific herring': 1, 'Pacific oyster': 1, 'Pacific rockfish': 1, 'Pepper (C. frutescens)': 1, 'Common persimmon': 1, 'Northern pike': 1, 'Pili nut': 1, 'Colorado pinyon': 1, 'French plantain': 1, 'Opium poppy': 1, 'Prairie turnip': 1, 'Quinoa': 1, 'Rainbow smelt': 1, 'Rainbow trout': 1, 'Orange roughy': 1, 'Sablefish': 1, 'Pink salmon': 1, 'Chum salmon': 1, 'Coho salmon': 1, 'Sockeye salmon': 1, 'Chinook salmon': 1, 'Atlantic salmon': 1, 'Sapodilla': 1, 'Mamey sapote': 1, 'Spanish mackerel': 1, 'Pacific sardine': 1, 'Scallop': 1, 'Scup': 1, 'Steller sea lion': 1, 'Bearded seal': 1, 'Sea trout': 1, 'American shad': 1, 'Shark': 1, 'Sheefish': 1, 'Sheepshead': 1, 'Hedge mustard': 1, 'Skipjack tuna': 1, 'Snapper': 1, 'Spelt': 1, 'Spirulina': 1, 'Strawberry guava': 1, 'Greater sturgeon': 1, 'White sucker': 1, 'Pumpkinseed sunfish': 1, 'Swordfish': 1, 'Taro': 1, 'Teff': 1, 'Tilefish': 1, 'Salmonidae (Salmon, Trout)': 1, 'Turkey': 1, 'Cattle (Beef, Veal)': 1, 'Walleye': 1, 'Alaska pollock': 1, 'Whelk': 1, 'Whitefish': 1, 'Whiting': 1, 'Wild rice': 1, 'Winged bean': 1, 'Yam': 1, 'Jicama': 1, 'Yellowfin tuna': 1, 'Yellowtail amberjack': 1, 'Albacore tuna': 1, 'Gadus (Common cod)': 1, 'Atlantic halibut': 1, 'Smelt': 1, 'Clupeinae (Herring, Sardine, Sprat)': 1, 'Spiny lobster': 1, 'Snow crab': 1, 'Black-eyed pea': 1, 'Deer': 1, 'Macadamia nut': 1, 'Percoidei (Bass and others)': 1, 'Perciformes': 1, 'Rabbit': 1, 'Bivalvia (Clam, Mussel, Oyster)': 1, 'Squid': 1, 'Shrimp': 1, 'Crayfish': 1, 'Flatfish': 1, 'Domestic pig': 1, 'Oriental wheat': 1, 'Yardlong bean': 1, 'Quail': 1, 'Persian lime': 1, 'Feijoa': 1, 'Common mushroom': 1, 'Shiitake': 1, 'Purple laver': 1, 'Wakame': 1, 'Enokitake': 1, 'Oyster mushroom': 1, 'Maitake': 1, 'Spot croaker': 1, 'Wheat': 1, 'Agave': 1, 'Anchovy': 1, 'Sturgeon': 1, 'Cinnamon': 1, 'Crab': 1, 'Anatidae': 1, 'Anguilliformes': 1, 'Garfish': 1, 'Mountain hare': 1, 'Lemon sole': 1, 'Clawed lobster': 1, 'Scombridae (Bonito, Mackerel, Tuna)': 1, 'Marine mussel': 1, 'Norway lobster': 1, 'Oil palm': 1, 'True oyster': 1, 'Persimmon': 1, 'Pleuronectidae (Dab, Halibut, Plaice)': 1, 'True sole': 1, 'Catfish': 1, 'Thunnus': 1, 'Walnut': 1, 'Liquor': 1, 'Cheese': 1, 'Milk (Cow)': 1, 'Eggs': 1, 'Yogurt': 1, 'Vodka': 1, 'Whisky': 1, 'Ice cream': 1, 'Gin': 1, 'Honey': 1, 'Vinegar': 1, 'Rum': 1, 'Cake': 1, 'Pizza': 1, 'Ymer': 1, 'Other snack food': 1, 'Crisp bread': 1, 'Pastry': 1, 'Marzipan': 1, 'Salad dressing': 1, 'Sauce': 1, 'Salt': 1, 'Butter': 1, 'Cream': 1, 'Sugar': 1, 'Sausage': 1, 'Mustard': 1, 'Pate': 1, 'Sugar substitute': 1, 'Meat bouillon': 1, 'Whey': 1, 'Casein': 1, 'Fruit preserve': 1, 'Leavening agent': 1, 'Marshmallow': 1, 'Gelatin': 1, 'Water': 1, 'Other fish product': 1, 'Milk (Human)': 1, 'Other beverage': 1, 'Baby food': 1, 'Soup': 1, 'Other vegetable product': 1, 'Unclassified food or beverage': 1, 'Syrup': 1, 'Tallow': 1, 'Remoulade': 1, 'Other candy': 1, 'Lard': 1, 'Other animal fat': 1, 'Cocoa butter': 1, 'Cocoa powder': 1, 'Chocolate': 1, 'Hot chocolate': 1, 'Dried milk': 1, 'Milk (Other mammals)': 1, 'Kefir': 1, 'Buttermilk': 1, 'Other fermented milk': 1, 'Soy sauce': 1, 'Miso': 1, 'Tofu': 1, 'Roe': 1, 'Cichlidae (Tilapia)': 1, 'Icing': 1, 'Snack bar': 1, 'Burrito': 1, 'Hamburger': 1, 'Baked beans': 1, 'Chili': 1, 'Taco': 1, 'Tortilla': 1, 'Nachos': 1, 'Processed cheese': 1, 'Salad': 1, 'Cream substitute': 1, 'Topping': 1, 'Sweet custard': 1, 'Egg roll': 1, 'Heart of palm': 1, 'Popcorn': 1, 'Potato chip': 1, 'Tortilla chip': 1, 'Corn chip': 1, 'Stew': 1, 'Gelatin dessert': 1, 'Junket': 1, 'Falafel': 1, 'Other frozen dessert': 1, 'Lasagna': 1, 'Pancake': 1, 'Pudding': 1, 'Waffle': 1, 'Soy milk': 1, 'Meatloaf': 1, 'Couscous': 1, 'Bulgur': 1, 'Coffee substitute': 1, 'Chimichanga': 1, 'Semolina': 1, 'Tapioca pearl': 1, 'Tostada': 1, 'Baked potato': 1, 'Hot dog': 1, 'Spread': 1, 'Enchilada': 1, 'Egg substitute': 1, 'Nutritional drink': 1, 'Other sandwich': 1, 'Ketchup': 1, 'Breakfast sandwich': 1, 'Macaroni and cheese': 1, 'Butterfat': 1, 'Hushpuppy': 1, 'Relish': 1, 'Other fruit product': 1, 'Vegetarian food': 1, 'Cold cut': 1, 'Mixed nuts': 1, 'Babassu palm': 1, 'Cupuaçu': 1, 'Shea tree': 1, 'Oil-seed Camellia': 1, 'Ucuhuba': 1, 'Phyllo dough': 1, 'Cooking oil': 1, 'Pie crust': 1, 'Pie filling': 1, 'Pie': 1, 'Shortening': 1, 'Ice cream cone': 1, 'Cracker': 1, 'Natto': 1, 'Ravioli': 1, 'Other pasta dish': 1, 'Succotash': 1, 'Tamale': 1, 'Evaporated milk': 1, 'Pita bread': 1, 'Bagel': 1, 'Other bread product': 1, 'French toast': 1, 'Wheat bread': 1, 'Rye bread': 1, 'Oat bread': 1, 'Potato bread': 1, 'Cornbread': 1, 'Corn grits': 1, 'Multigrain bread': 1, 'Rice bread': 1, 'Raisin bread': 1, 'Wonton wrapper': 1, 'Trail mix': 1, 'Fruit-flavor drink': 1, 'Soft drink': 1, 'Frozen yogurt': 1, 'Milkshake': 1, 'Pupusa': 1, 'Empanada': 1, 'Arepa': 1, 'Gefilte fish': 1, 'Other dish': 1, 'Pot pie': 1, 'Stuffing': 1, 'Edible shell': 1, 'Condensed milk': 1, 'Margarine': 1, 'Margarine-like spread': 1, 'Hummus': 1, 'Potato puffs': 1, 'Potato gratin': 1, 'Milk substitute': 1, 'Soft-necked garlic': 1, 'Cabbage': 1, 'Italian sweet red pepper': 1, 'Cow milk, pasteurized, vitamin A + D added, 0% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 1% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 2% fat': 1, 'Cow milk, pasteurized, vitamin D added, 3.25% fat': 1, 'Black tea': 1, 'Green tea': 1, 'Red tea': 1, 'Sour cream': 1, 'White bread': 1, 'Herbal tea': 1, 'Taco shell': 1}\n",
      "{'Orange bell pepper': 1}\n",
      "{'Cocoa bean': 1, 'Saskatoon berry': 1}\n",
      "{'Wild celery': 1, 'Papaya': 1, 'Common walnut': 1, 'Potato': 1}\n",
      "{'Kiwi': 1, 'Allium': 1, 'Garlic': 1, 'Chives': 1, 'Cashew nut': 1, 'Pineapple': 1, 'Dill': 1, 'Wild celery': 1, 'Peanut': 1, 'Burdock': 1, 'Horseradish': 1, 'Tarragon': 1, 'Asparagus': 1, 'Oat': 1, 'Star fruit': 1, 'Brazil nut': 1, 'Common beet': 1, 'Chinese mustard': 1, 'Swede': 1, 'Common cabbage': 1, 'Cauliflower': 1, 'Brussel sprouts': 1, 'Kohlrabi': 1, 'Broccoli': 1, 'Chinese cabbage': 1, 'Turnip': 1, 'Pigeon pea': 1, 'Tea': 1, 'Capers': 1, 'Pepper': 1, 'Papaya': 1, 'Safflower': 1, 'Caraway': 1, 'Pecan nut': 1, 'Chickpea': 1, 'Endive': 1, 'Chicory': 1, 'Chinese cinnamon': 1, 'Watermelon': 1, 'Lemon': 1, 'Pummelo': 1, 'Mandarin orange (Clementine, Tangerine)': 1, 'Sweet orange': 1, 'Coffee': 1, 'Arabica coffee': 1, 'Robusta coffee': 1, 'Coriander': 1, 'Saffron': 1, 'Muskmelon': 1, 'Cucumber': 1, 'Cucurbita': 1, 'Cumin': 1, 'Turmeric': 1, 'Globe artichoke': 1, 'Japanese persimmon': 1, 'Rocket salad (ssp.)': 1, 'Common buckwheat': 1, 'Fig': 1, 'Strawberry': 1, 'Soy bean': 1, 'Sunflower': 1, 'Barley': 1, 'Sweet potato': 1, 'Black walnut': 1, 'Common walnut': 1, 'Lettuce': 1, 'Lentils': 1, 'Garden cress': 1, 'Flaxseed': 1, 'Lichee': 1, 'Apple': 1, 'Mango': 1, 'Bitter gourd': 1, 'Black mulberry': 1, 'Nutmeg': 1, 'Sweet basil': 1, 'Olive': 1, 'Sweet marjoram': 1, 'Common oregano': 1, 'Rice': 1, 'Millet': 1, 'Poppy': 1, 'Passion fruit': 1, 'Parsnip': 1, 'Avocado': 1, 'Parsley': 1, 'Lima bean': 1, 'Common bean': 1, 'Date': 1, 'Anise': 1, 'Pine nut': 1, 'Pepper (Spice)': 1, 'Pistachio': 1, 'Common pea': 1, 'Prunus (Cherry, Plum)': 1, 'Apricot': 1, 'Sweet cherry': 1, 'Sour cherry': 1, 'European plum': 1, 'Almond': 1, 'Peach': 1, 'Guava': 1, 'Pomegranate': 1, 'Pear': 1, 'Radish': 1, 'Garden rhubarb': 1, 'Redcurrant': 1, 'Watercress': 1, 'Rubus (Blackberry, Raspberry)': 1, 'Red raspberry': 1, 'Common sage': 1, 'Rye': 1, 'Sesame': 1, 'Garden tomato': 1, 'Eggplant': 1, 'Potato': 1, 'Spinach': 1, 'Cloves': 1, 'Tamarind': 1, 'Dandelion': 1, 'Cocoa bean': 1, 'Common thyme': 1, 'Common wheat': 1, 'Vaccinium (Blueberry, Cranberry, Huckleberry)': 1, 'American cranberry': 1, 'Vanilla': 1, 'Broad bean': 1, 'Gram bean': 1, 'Mung bean': 1, 'Cowpea': 1, 'Common grape': 1, 'Corn': 1, 'Ginger': 1, 'Banana': 1, 'Nectarine': 1, 'Swiss chard': 1, 'Welsh onion': 1, 'Shallot': 1, 'Carrot': 1, 'Black cabbage': 1, 'Pak choy': 1, 'Napa cabbage': 1, 'Grapefruit': 1, 'Daikon radish': 1, 'Beer': 1, 'Other bread': 1, 'Breakfast cereal': 1, 'Other soy product': 1, 'Other cereal product': 1, 'Pasta': 1, 'Biscuit': 1, 'Other alcoholic beverage': 1, 'Abalone': 1, 'Acerola': 1, 'Winter squash': 1, 'Agar': 1, 'Alfalfa': 1, 'Allspice': 1, 'Asian pear': 1, 'Atlantic herring': 1, 'Atlantic mackerel': 1, 'Painted comber': 1, 'Atlantic pollock': 1, 'Bamboo shoots': 1, 'Beluga whale': 1, 'Blue crab': 1, 'Blue mussel': 1, 'Northern bluefin tuna': 1, 'Breadfruit': 1, 'Butternut squash': 1, 'Calabash': 1, 'Carob': 1, 'Common carp': 1, 'Cassava': 1, 'Channel catfish': 1, 'Chayote': 1, 'Cherimoya': 1, 'Chervil': 1, 'Chinese broccoli': 1, 'Chinese water chestnut': 1, 'Garland chrysanthemum': 1, 'Cisco': 1, 'Coconut': 1, 'Pacific cod': 1, 'Atlantic cod': 1, 'Common octopus': 1, 'Cottonseed': 1, 'Atlantic croaker': 1, 'Eastern oyster': 1, 'Freshwater eel': 1, 'European anchovy': 1, 'European chestnut': 1, 'Florida pompano': 1, 'Ginkgo nuts': 1, 'Grape': 1, 'Greenland halibut/turbot': 1, 'Haddock': 1, 'Hippoglossus (Common halibut)': 1, 'Hazelnut': 1, 'Horseradish tree': 1, 'Alaska blueberry': 1, 'Hyacinth bean': 1, 'Irish moss': 1, 'Pacific jack mackerel': 1, 'Jerusalem artichoke': 1, 'Jute': 1, 'Kale': 1, 'Kelp': 1, 'Kumquat': 1, 'Lambsquarters': 1, 'Wild leek': 1, 'American lobster': 1, 'Loganberry': 1, 'Sacred lotus': 1, 'Striped mullet': 1, 'White mustard': 1, 'New Zealand spinach': 1, 'Nopal': 1, 'Okra': 1, 'Spotted seal': 1, 'Pacific oyster': 1, 'Pacific rockfish': 1, 'Northern pike': 1, 'French plantain': 1, 'American pokeweed': 1, 'Opium poppy': 1, 'Rainbow smelt': 1, 'Rainbow trout': 1, 'Orange roughy': 1, 'Pink salmon': 1, 'Chum salmon': 1, 'Coho salmon': 1, 'Sockeye salmon': 1, 'Chinook salmon': 1, 'Common salsify': 1, 'Spanish mackerel': 1, 'Pacific sardine': 1, 'Scallop': 1, 'Scup': 1, 'Bearded seal': 1, 'American shad': 1, 'Shark': 1, 'Sheefish': 1, 'Snapper': 1, 'Soursop': 1, 'Spirulina': 1, 'Greater sturgeon': 1, 'Swordfish': 1, 'Taro': 1, 'Mexican groundcherry': 1, 'Towel gourd': 1, 'Salmonidae (Salmon, Trout)': 1, 'Turkey': 1, 'Cattle (Beef, Veal)': 1, 'Alaska pollock': 1, 'Wax gourd': 1, 'Whelk': 1, 'Whitefish': 1, 'Whiting': 1, 'Wild rice': 1, 'Yam': 1, 'Jicama': 1, 'Yellowfin tuna': 1, 'Albacore tuna': 1, 'Smelt': 1, 'Black-eyed pea': 1, 'Deer': 1, 'Macadamia nut': 1, 'Percoidei (Bass and others)': 1, 'Perciformes': 1, 'Rabbit': 1, 'Domestic goat': 1, 'Bivalvia (Clam, Mussel, Oyster)': 1, 'Squid': 1, 'Shrimp': 1, 'Crayfish': 1, 'Flatfish': 1, 'Domestic pig': 1, 'Quail': 1, 'Boysenberry': 1, 'Persian lime': 1, 'Common mushroom': 1, 'Shiitake': 1, 'Purple laver': 1, 'Wakame': 1, 'Enokitake': 1, 'Oyster mushroom': 1, 'Maitake': 1, 'Wheat': 1, 'Common chokecherry': 1, 'Agave': 1, 'Jellyfish': 1, 'True frog': 1, 'Oil palm': 1, 'Snail': 1, 'Thunnus': 1, 'Walnut': 1, 'Columbidae (Dove, Pigeon)': 1, 'Conch': 1, 'Grape wine': 1, 'Liquor': 1, 'Cheese': 1, 'Milk (Cow)': 1, 'Eggs': 1, 'Yogurt': 1, 'Bean': 1, 'Whisky': 1, 'Ice cream': 1, 'Gin': 1, 'Honey': 1, 'Vinegar': 1, 'Rum': 1, 'Nougat': 1, 'Cake': 1, 'Pizza': 1, 'Other snack food': 1, 'Crisp bread': 1, 'Pastry': 1, 'Chewing gum': 1, 'Salad dressing': 1, 'Sauce': 1, 'Salt': 1, 'Butter': 1, 'Butter substitute': 1, 'Cream': 1, 'Sugar': 1, 'Sausage': 1, 'Mustard': 1, 'Pate': 1, 'Sugar substitute': 1, 'Whey': 1, 'Fruit preserve': 1, 'Leavening agent': 1, 'Marshmallow': 1, 'Water': 1, 'Other fish product': 1, 'Milk (Human)': 1, 'Other beverage': 1, 'Baby food': 1, 'Soup': 1, 'Other vegetable product': 1, 'Unclassified food or beverage': 1, 'Syrup': 1, 'Tallow': 1, 'Chocolate spread': 1, 'Curry powder': 1, 'Other candy': 1, 'Lard': 1, 'Other animal fat': 1, 'Cocoa butter': 1, 'Cocoa powder': 1, 'Chocolate': 1, 'Hot chocolate': 1, 'Dried milk': 1, 'Milk (Other mammals)': 1, 'Buttermilk': 1, 'Soy sauce': 1, 'Miso': 1, 'Tofu': 1, 'Zwieback': 1, 'Roe': 1, 'Cichlidae (Tilapia)': 1, 'Icing': 1, 'Snack bar': 1, 'Green turtle': 1, 'Energy drink': 1, 'Burrito': 1, 'Hamburger': 1, 'Baked beans': 1, 'Chili': 1, 'Taco': 1, 'Tortilla': 1, 'Processed cheese': 1, 'Salad': 1, 'Cream substitute': 1, 'Dulce de leche': 1, 'Topping': 1, 'Sweet custard': 1, 'Egg roll': 1, 'Heart of palm': 1, 'Popcorn': 1, 'Potato chip': 1, 'Tortilla chip': 1, 'Corn chip': 1, 'Hibiscus tea': 1, 'Stew': 1, 'Gelatin dessert': 1, 'Junket': 1, 'Other frozen dessert': 1, 'Lasagna': 1, 'Pancake': 1, 'Pectin': 1, 'Pudding': 1, 'Waffle': 1, 'Soy milk': 1, 'Meatloaf': 1, 'Sake': 1, 'Cocktail': 1, 'Couscous': 1, 'Bulgur': 1, 'Coffee substitute': 1, 'Coffee mocha': 1, 'Tapioca pearl': 1, 'Quesadilla': 1, 'Spread': 1, 'Egg substitute': 1, 'Nutritional drink': 1, 'Other sandwich': 1, 'Ketchup': 1, 'Breakfast sandwich': 1, 'Adobo': 1, 'Macaroni and cheese': 1, 'Butterfat': 1, 'Hushpuppy': 1, 'Fruit juice': 1, 'Relish': 1, 'Other fruit product': 1, 'Fruit salad': 1, 'Soy yogurt': 1, 'Vegetarian food': 1, 'Cold cut': 1, 'Mixed nuts': 1, 'Canola': 1, 'Babassu palm': 1, 'Cupuaçu': 1, 'Shea tree': 1, 'Oil-seed Camellia': 1, 'Ucuhuba': 1, 'Phyllo dough': 1, 'Cooking oil': 1, 'Pie crust': 1, 'Pie filling': 1, 'Pie': 1, 'Shortening': 1, 'Ice cream cone': 1, 'Molasses': 1, 'Cracker': 1, 'Natto': 1, 'Ravioli': 1, 'Scrapple': 1, 'Other pasta dish': 1, 'Succotash': 1, 'Rice cake': 1, 'Evaporated milk': 1, 'Pita bread': 1, 'Focaccia': 1, 'Bagel': 1, 'Other bread product': 1, 'French toast': 1, 'Wheat bread': 1, 'Rye bread': 1, 'Oat bread': 1, 'Potato bread': 1, 'Cornbread': 1, 'Corn grits': 1, 'Multigrain bread': 1, 'Rice bread': 1, 'Pan dulce': 1, 'Raisin bread': 1, 'Fruit-flavor drink': 1, 'Vegetable juice': 1, 'Horchata': 1, 'Soft drink': 1, 'Frozen yogurt': 1, 'Milkshake': 1, 'Chocolate mousse': 1, 'Dripping': 1, 'Yellow pond-lily': 1, 'Other dish': 1, 'Pot pie': 1, 'Stuffing': 1, 'Edible shell': 1, 'Fudge': 1, 'Candy bar': 1, 'Condensed milk': 1, 'Margarine': 1, 'Margarine-like spread': 1, 'Hummus': 1, 'Potato puffs': 1, 'Milk substitute': 1, 'Sunburst squash (pattypan squash)': 1, 'Green zucchini': 1, 'Yellow zucchini': 1, 'Green bell pepper': 1, 'Red bell pepper': 1, 'Italian sweet red pepper': 1, 'Yellow wax bean': 1, 'Green bean': 1, 'Japanese pumpkin': 1, 'White cabbage': 1, 'Romaine lettuce': 1, 'Cow milk, pasteurized, vitamin A + D added, 0% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 1% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 2% fat': 1, 'Cow milk, pasteurized, vitamin D added, 3.25% fat': 1, 'Red tea': 1, 'Sour cream': 1, 'White bread': 1, 'Herbal tea': 1, 'Taco shell': 1}\n",
      "{'Tea': 1, 'Lemon': 1, 'Pummelo': 1, 'Arabica coffee': 1, 'Cocoa bean': 1, 'Black tea': 1, 'Green tea': 1, 'Red tea': 1, 'Herbal tea': 1}\n",
      "{'Garden onion': 1, 'Apple': 1, 'Rice': 1, 'Common pea': 1, 'Garden tomato (var.)': 1, 'Potato': 1, 'Adzuki bean': 1, 'Mung bean': 1}\n",
      "{'Burdock': 1}\n",
      "{'Pomegranate': 1}\n",
      "{'Garden onion': 1, 'Wild celery': 1, 'Lemon': 1, 'Saffron': 1, 'Muskmelon': 1, 'Cucumber': 1, 'Soy bean': 1, 'Garden tomato (var.)': 1, 'Common wheat': 1, 'Common verbena': 1, 'Corn': 1, 'Soft-necked garlic': 1}\n",
      "{'Potato': 1, 'Common wheat': 1}\n",
      "{'Garden onion': 1, 'Pummelo': 1, 'Wild carrot': 1, 'Spearmint': 1, 'Garden tomato (var.)': 1, 'Roselle': 1}\n",
      "{'Custard apple': 1, 'Avocado': 1, 'Purslane': 1, 'Garden tomato': 1, 'Potato': 1, 'Cocoa bean': 1, 'French plantain': 1, 'Opium poppy': 1}\n",
      "{'Garden onion': 1, 'Oat': 1, 'Barley': 1, 'Common walnut': 1, 'Apple': 1, 'Pomegranate': 1, 'Corn': 1, 'Ginger': 1, 'Giant butterbur': 1}\n",
      "{'Garden onion': 1, 'Mugwort': 1, 'Roman camomile': 1, 'Ceylon cinnamon': 1, 'Arabica coffee': 1, 'Common hazelnut': 1, 'Wild carrot': 1, 'Cornmint': 1, 'Evening primrose': 1, 'Scarlet bean': 1, 'Black elderberry': 1, 'Garden tomato (var.)': 1, 'Cocoa bean': 1, 'Highbush blueberry': 1, 'Pepper (C. frutescens)': 1, 'Soft-necked garlic': 1, 'Cabbage': 1, 'Orange bell pepper': 1, 'Saskatoon berry': 1, 'Nanking cherry': 1}\n",
      "{'Garden onion': 1, 'Mugwort': 1, 'Roman camomile': 1, 'Ceylon cinnamon': 1, 'Arabica coffee': 1, 'Common hazelnut': 1, 'Wild carrot': 1, 'Cornmint': 1, 'Evening primrose': 1, 'Scarlet bean': 1, 'Black elderberry': 1, 'Garden tomato (var.)': 1, 'Cocoa bean': 1, 'Highbush blueberry': 1, 'Pepper (C. frutescens)': 1, 'Soft-necked garlic': 1, 'Cabbage': 1, 'Orange bell pepper': 1, 'Saskatoon berry': 1, 'Nanking cherry': 1}\n",
      "{'Tarragon': 1, 'Asparagus': 1, 'Pepper': 1, 'Safflower': 1, 'Ceylon cinnamon': 1, 'Coffee': 1, 'Arabica coffee': 1, 'Robusta coffee': 1, 'Mulberry': 1, 'Sweet marjoram': 1, 'Winter savory': 1, 'Sesame': 1, 'Garden tomato (var.)': 1, 'Tamarind': 1, 'Highbush blueberry': 1, 'Bilberry': 1, 'Cocoa powder': 1, 'Green bell pepper': 1, 'Yellow bell pepper': 1, 'Orange bell pepper': 1, 'Red bell pepper': 1}\n",
      "{'Wild celery': 1, 'Oat': 1, 'Pear': 1, 'Blackcurrant': 1, 'Red beetroot': 1}\n",
      "{'Pepper': 1, 'Ginger': 1, 'Pepper (C. frutescens)': 1, 'Green bell pepper': 1, 'Yellow bell pepper': 1, 'Orange bell pepper': 1, 'Red bell pepper': 1}\n",
      "{'Savoy cabbage': 1, 'Kiwi': 1, 'Allium': 1, 'Leek': 1, 'Garlic': 1, 'Chives': 1, 'Cashew nut': 1, 'Pineapple': 1, 'Dill': 1, 'Wild celery': 1, 'Peanut': 1, 'Burdock': 1, 'Horseradish': 1, 'Tarragon': 1, 'Asparagus': 1, 'Oat': 1, 'Star fruit': 1, 'Brazil nut': 1, 'Common beet': 1, 'Borage': 1, 'Chinese mustard': 1, 'Swede': 1, 'Rape': 1, 'Common cabbage': 1, 'Cauliflower': 1, 'Brussel sprouts': 1, 'Kohlrabi': 1, 'Broccoli': 1, 'Chinese cabbage': 1, 'Turnip': 1, 'Pigeon pea': 1, 'Tea': 1, 'Capers': 1, 'Pepper': 1, 'Papaya': 1, 'Safflower': 1, 'Caraway': 1, 'Pecan nut': 1, 'Chestnut': 1, 'Chickpea': 1, 'Endive': 1, 'Chicory': 1, 'Chinese cinnamon': 1, 'Watermelon': 1, 'Lime': 1, 'Lemon': 1, 'Mandarin orange (Clementine, Tangerine)': 1, 'Sweet orange': 1, 'Coffee': 1, 'Arabica coffee': 1, 'Robusta coffee': 1, 'Coriander': 1, 'Saffron': 1, 'Muskmelon': 1, 'Cucumber': 1, 'Cucurbita': 1, 'Cumin': 1, 'Turmeric': 1, 'Quince': 1, 'Lemon grass': 1, 'Globe artichoke': 1, 'Japanese persimmon': 1, 'Cardamom': 1, 'Loquat': 1, 'Rocket salad (ssp.)': 1, 'Common buckwheat': 1, 'Fig': 1, 'Fennel': 1, 'Strawberry': 1, 'Soy bean': 1, 'Sunflower': 1, 'Barley': 1, 'Swamp cabbage': 1, 'Sweet potato': 1, 'Black walnut': 1, 'Common walnut': 1, 'Lettuce': 1, 'Sweet bay': 1, 'Lentils': 1, 'Garden cress': 1, 'Flaxseed': 1, 'Lichee': 1, 'Apple': 1, 'Mango': 1, 'Spearmint': 1, 'Peppermint': 1, 'Bitter gourd': 1, 'Black mulberry': 1, 'Nutmeg': 1, 'Sweet basil': 1, 'Olive': 1, 'Sweet marjoram': 1, 'Common oregano': 1, 'Rice': 1, 'Millet': 1, 'Poppy': 1, 'Passion fruit': 1, 'Parsnip': 1, 'Avocado': 1, 'Parsley': 1, 'Lima bean': 1, 'Common bean': 1, 'Date': 1, 'Anise': 1, 'Pine nut': 1, 'Pepper (Spice)': 1, 'Pistachio': 1, 'Common pea': 1, 'Purslane': 1, 'Prunus (Cherry, Plum)': 1, 'Apricot': 1, 'Sweet cherry': 1, 'Sour cherry': 1, 'European plum': 1, 'Almond': 1, 'Peach': 1, 'Guava': 1, 'Pomegranate': 1, 'Pear': 1, 'Radish': 1, 'Garden rhubarb': 1, 'Blackcurrant': 1, 'Redcurrant': 1, 'Gooseberry': 1, 'Watercress': 1, 'Rosemary': 1, 'Rubus (Blackberry, Raspberry)': 1, 'Red raspberry': 1, 'Sorrel': 1, 'Common sage': 1, 'Summer savory': 1, 'Rye': 1, 'Sesame': 1, 'Garden tomato': 1, 'Eggplant': 1, 'Potato': 1, 'Sorghum': 1, 'Spinach': 1, 'Cloves': 1, 'Tamarind': 1, 'Dandelion': 1, 'Common thyme': 1, 'Fenugreek': 1, 'Common wheat': 1, 'Vaccinium (Blueberry, Cranberry, Huckleberry)': 1, 'American cranberry': 1, 'Bilberry': 1, 'Lingonberry': 1, 'Vanilla': 1, 'Broad bean': 1, 'Adzuki bean': 1, 'Gram bean': 1, 'Mung bean': 1, 'Cowpea': 1, 'Common grape': 1, 'Corn': 1, 'Ginger': 1, 'Banana': 1, 'Celeriac': 1, 'Nectarine': 1, 'Swiss chard': 1, 'Welsh onion': 1, 'Hard wheat': 1, 'Shallot': 1, 'Carrot': 1, 'Triticale': 1, 'Black cabbage': 1, 'Celery leaves': 1, 'Pak choy': 1, 'Napa cabbage': 1, 'Grapefruit': 1, 'Daikon radish': 1, 'Red beetroot': 1, 'Beer': 1, 'Other bread': 1, 'Breakfast cereal': 1, 'Other soy product': 1, 'Other cereal product': 1, 'Pasta': 1, 'Biscuit': 1, 'Spirit': 1, 'Other alcoholic beverage': 1, 'Abalone': 1, 'Winter squash': 1, 'Agar': 1, 'Alfalfa': 1, 'Allspice': 1, 'Amaranth': 1, 'Arrowhead': 1, 'Arrowroot': 1, 'Asian pear': 1, 'Atlantic herring': 1, 'Atlantic mackerel': 1, 'Painted comber': 1, 'Atlantic pollock': 1, 'Atlantic wolffish': 1, 'Bamboo shoots': 1, 'Beluga whale': 1, 'Blue crab': 1, 'Blue mussel': 1, 'Northern bluefin tuna': 1, 'Breadfruit': 1, 'Breadnut tree seed': 1, 'Rapini': 1, 'Burbot': 1, 'Giant butterbur': 1, 'Butternut': 1, 'Butternut squash': 1, 'Calabash': 1, 'Cardoon': 1, 'Carob': 1, 'Common carp': 1, 'Cassava': 1, 'Channel catfish': 1, 'Chayote': 1, 'Cherimoya': 1, 'Chervil': 1, 'Chinese broccoli': 1, 'Chinese chestnut': 1, 'Chinese water chestnut': 1, 'Garland chrysanthemum': 1, 'Cisco': 1, 'Coconut': 1, 'Pacific cod': 1, 'Atlantic cod': 1, 'Common octopus': 1, 'Corn salad': 1, 'Cottonseed': 1, 'Catjang pea': 1, 'Malus (Crab apple)': 1, 'Atlantic croaker': 1, 'Dock': 1, 'Eastern oyster': 1, 'Freshwater eel': 1, 'Elderberry': 1, 'Oregon yampah': 1, 'European anchovy': 1, 'European chestnut': 1, 'Turbot': 1, 'Fireweed': 1, 'Florida pompano': 1, 'Ginkgo nuts': 1, 'Grape': 1, 'Greenland halibut/turbot': 1, 'Groundcherry': 1, 'Haddock': 1, 'Hippoglossus (Common halibut)': 1, 'Hazelnut': 1, 'Hickory nut': 1, 'Horseradish tree': 1, 'Alaska blueberry': 1, 'Hyacinth bean': 1, 'Irish moss': 1, 'Pacific jack mackerel': 1, 'Japanese chestnut': 1, 'Jerusalem artichoke': 1, 'Jute': 1, 'Kale': 1, 'Kelp': 1, 'Kumquat': 1, 'Lambsquarters': 1, 'Wild leek': 1, 'Common ling': 1, 'American lobster': 1, 'Loganberry': 1, 'Lotus': 1, 'Sacred lotus': 1, 'White lupine': 1, 'Malabar spinach': 1, 'Purple mangosteen': 1, 'Moth bean': 1, 'Mountain yam': 1, 'Striped mullet': 1, 'White mustard': 1, 'Mustard spinach': 1, 'New Zealand spinach': 1, 'Nopal': 1, 'Okra': 1, 'Spotted seal': 1, 'Pacific rockfish': 1, 'Northern pike': 1, 'Colorado pinyon': 1, 'French plantain': 1, 'American pokeweed': 1, 'Opium poppy': 1, 'Prickly pear': 1, 'Quinoa': 1, 'Rainbow smelt': 1, 'Rainbow trout': 1, 'Rose hip': 1, 'Pink salmon': 1, 'Chum salmon': 1, 'Coho salmon': 1, 'Sockeye salmon': 1, 'Chinook salmon': 1, 'Common salsify': 1, 'Spanish mackerel': 1, 'Pacific sardine': 1, 'Scallop': 1, 'Scup': 1, 'Steller sea lion': 1, 'Bearded seal': 1, 'Sesbania flower': 1, 'American shad': 1, 'Shark': 1, 'Snapper': 1, 'Soursop': 1, 'Spirulina': 1, 'Greater sturgeon': 1, 'Swordfish': 1, 'Taro': 1, 'Mexican groundcherry': 1, 'Towel gourd': 1, 'Salmonidae (Salmon, Trout)': 1, 'Turkey': 1, 'Cattle (Beef, Veal)': 1, 'Alaska pollock': 1, 'Wasabi': 1, 'Wax gourd': 1, 'Whelk': 1, 'Whitefish': 1, 'Whiting': 1, 'Wild rice': 1, 'Winged bean': 1, 'Yam': 1, 'Jicama': 1, 'Yautia': 1, 'Yellowfin tuna': 1, 'Pollock': 1, 'Albacore tuna': 1, 'Gadus (Common cod)': 1, 'Atlantic halibut': 1, 'Clupeinae (Herring, Sardine, Sprat)': 1, 'Black-eyed pea': 1, 'Deer': 1, 'Macadamia nut': 1, 'Percoidei (Bass and others)': 1, 'Perciformes': 1, 'Rabbit': 1, 'Domestic goat': 1, 'Bivalvia (Clam, Mussel, Oyster)': 1, 'Squid': 1, 'Shrimp': 1, 'Crayfish': 1, 'Flatfish': 1, 'Domestic pig': 1, 'Yardlong bean': 1, 'Quail': 1, 'Boysenberry': 1, 'Persian lime': 1, \"Jew's ear\": 1, 'Common mushroom': 1, 'Shiitake': 1, 'Purple laver': 1, 'Wakame': 1, 'Enokitake': 1, 'Epazote': 1, 'Oyster mushroom': 1, 'Cloud ear fungus': 1, 'Maitake': 1, 'Ostrich fern': 1, 'Wheat': 1, 'Common chokecherry': 1, 'Agave': 1, 'Jellyfish': 1, 'Anchovy': 1, 'Blue whiting': 1, 'Carp bream': 1, 'Chanterelle': 1, 'Sturgeon': 1, 'Charr': 1, 'Cinnamon': 1, 'Crab': 1, 'Common dab': 1, 'Spiny dogfish': 1, 'Anatidae': 1, 'Anguilliformes': 1, 'True frog': 1, 'Garfish': 1, 'Gadiformes': 1, 'Mountain hare': 1, 'Lake trout': 1, 'Lemon sole': 1, 'Clawed lobster': 1, 'Lumpsucker': 1, 'Scombridae (Bonito, Mackerel, Tuna)': 1, 'Marine mussel': 1, 'Norway haddock': 1, 'Norway lobster': 1, 'Norway pout': 1, 'Oil palm': 1, 'True oyster': 1, 'Persimmon': 1, 'Pikeperch': 1, 'Pleuronectidae (Dab, Halibut, Plaice)': 1, 'Rock ptarmigan': 1, 'Pacific ocean perch': 1, 'Black salsify': 1, 'True seal': 1, 'Red algae': 1, 'Kombu': 1, 'Snail': 1, 'True sole': 1, 'Catfish': 1, 'Thistle': 1, 'Thunnus': 1, 'Walnut': 1, 'Cetacea (Dolphin, Porpoise, Whale)': 1, 'Columbidae (Dove, Pigeon)': 1, 'Conch': 1, 'Grape wine': 1, 'Liquor': 1, 'Cheese': 1, 'Milk (Cow)': 1, 'Eggs': 1, 'Yogurt': 1, 'Bean': 1, 'Vodka': 1, 'Whisky': 1, 'Ice cream': 1, 'Gin': 1, 'Honey': 1, 'Liquorice': 1, 'Vinegar': 1, 'Rum': 1, 'Port wine': 1, 'Vermouth': 1, 'Sherry': 1, 'Madeira wine': 1, 'Nougat': 1, 'Toffee': 1, 'Cake': 1, 'Pizza': 1, 'Ymer': 1, 'Other snack food': 1, 'Crisp bread': 1, 'Pastry': 1, 'Dragée': 1, 'Chewing gum': 1, 'Marzipan': 1, 'Salad dressing': 1, 'Sauce': 1, 'Salt': 1, 'Butter': 1, 'Butter substitute': 1, 'Cream': 1, 'Sugar': 1, 'Sausage': 1, 'Meatball': 1, 'Mustard': 1, 'Pate': 1, 'Sugar substitute': 1, 'Meat bouillon': 1, 'Whey': 1, 'Casein': 1, 'Fruit preserve': 1, 'Leavening agent': 1, 'Marshmallow': 1, 'Gelatin': 1, 'Water': 1, 'Other fish product': 1, 'Milk (Human)': 1, 'Other beverage': 1, 'Baby food': 1, 'Dumpling': 1, 'Soup': 1, 'Other vegetable product': 1, 'Unclassified food or beverage': 1, 'Syrup': 1, 'Tallow': 1, 'Remoulade': 1, 'Chocolate spread': 1, 'Fruit gum': 1, 'Curry powder': 1, 'Other candy': 1, 'Meringue': 1, 'Lard': 1, 'Other animal fat': 1, 'Cocoa butter': 1, 'Cocoa powder': 1, 'Chocolate': 1, 'Hot chocolate': 1, 'Dried milk': 1, 'Milk (Other mammals)': 1, 'Kefir': 1, 'Buttermilk': 1, 'Other fermented milk': 1, 'Soy sauce': 1, 'Miso': 1, 'Tofu': 1, 'Zwieback': 1, 'Roe': 1, 'Cichlidae (Tilapia)': 1, 'Icing': 1, 'Snack bar': 1, 'Green turtle': 1, 'Energy drink': 1, 'Burrito': 1, 'Hamburger': 1, 'Baked beans': 1, 'Chili': 1, 'Taco': 1, 'Tortilla': 1, 'Processed cheese': 1, 'Salad': 1, 'Cream substitute': 1, 'Dulce de leche': 1, 'Topping': 1, 'Sweet custard': 1, 'Egg roll': 1, 'Heart of palm': 1, 'Popcorn': 1, 'Potato chip': 1, 'Tortilla chip': 1, 'Corn chip': 1, 'Hibiscus tea': 1, 'Stew': 1, 'Gelatin dessert': 1, 'Junket': 1, 'Falafel': 1, 'Other frozen dessert': 1, 'Lasagna': 1, 'Morchella (Morel)': 1, 'Pancake': 1, 'Pectin': 1, 'Pudding': 1, 'Waffle': 1, 'Soy milk': 1, 'Meatloaf': 1, 'Sake': 1, 'Couscous': 1, 'Bulgur': 1, 'Coffee substitute': 1, 'Coffee mocha': 1, 'Semolina': 1, 'Tapioca pearl': 1, 'Quesadilla': 1, 'Spread': 1, 'Egg substitute': 1, 'Nutritional drink': 1, 'Other sandwich': 1, 'Ketchup': 1, 'Breakfast sandwich': 1, 'Adobo': 1, 'Macaroni and cheese': 1, 'Butterfat': 1, 'Hushpuppy': 1, 'Fruit juice': 1, 'Relish': 1, 'Other fruit product': 1, 'Fruit salad': 1, 'Soy yogurt': 1, 'Vegetarian food': 1, 'Cold cut': 1, 'Mixed nuts': 1, 'Canola': 1, 'Phyllo dough': 1, 'Cooking oil': 1, 'Pie crust': 1, 'Pie filling': 1, 'Pie': 1, 'Shortening': 1, 'Ice cream cone': 1, 'Molasses': 1, 'Cracker': 1, 'Natto': 1, 'Ravioli': 1, 'Scrapple': 1, 'Other pasta dish': 1, 'Succotash': 1, 'Rice cake': 1, 'Tree fern': 1, 'Evaporated milk': 1, 'Pita bread': 1, 'Focaccia': 1, 'Bagel': 1, 'Other bread product': 1, 'French toast': 1, 'Wheat bread': 1, 'Rye bread': 1, 'Oat bread': 1, 'Potato bread': 1, 'Cornbread': 1, 'Corn grits': 1, 'Multigrain bread': 1, 'Rice bread': 1, 'Pan dulce': 1, 'Raisin bread': 1, 'Fruit-flavor drink': 1, 'Vegetable juice': 1, 'Horchata': 1, 'Soft drink': 1, 'Frozen yogurt': 1, 'Milkshake': 1, 'Dripping': 1, 'Other dish': 1, 'Pot pie': 1, 'Stuffing': 1, 'Edible shell': 1, 'Fudge': 1, 'Candy bar': 1, 'Condensed milk': 1, 'Margarine': 1, 'Margarine-like spread': 1, 'Hummus': 1, 'Potato puffs': 1, 'Potato gratin': 1, 'Milk substitute': 1, 'Sunburst squash (pattypan squash)': 1, 'Green zucchini': 1, 'Yellow zucchini': 1, 'Green bell pepper': 1, 'Yellow bell pepper': 1, 'Red bell pepper': 1, 'Italian sweet red pepper': 1, 'Yellow wax bean': 1, 'Green bean': 1, 'Japanese pumpkin': 1, 'White cabbage': 1, 'Romaine lettuce': 1, 'Cow milk, pasteurized, vitamin A + D added, 0% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 1% fat': 1, 'Cow milk, pasteurized, vitamin A + D added, 2% fat': 1, 'Cow milk, pasteurized, vitamin D added, 3.25% fat': 1, 'Black tea': 1, 'Green tea': 1, 'Red tea': 1, 'Sour cream': 1, 'White bread': 1, 'Herbal tea': 1, 'Fish oil': 1, 'Taco shell': 1}\n",
      "{'Borage': 1, 'Tea': 1, 'Watermelon': 1, 'Arabica coffee': 1, 'Soy bean': 1, 'Rice': 1, 'Common pea': 1, 'Sour cherry': 1, 'Potato': 1, 'Common wheat': 1, 'Gram bean': 1, 'Corn': 1, 'Red beetroot': 1, 'White lupine': 1, 'Shea tree': 1, 'Black tea': 1, 'Green tea': 1, 'Red tea': 1, 'Herbal tea': 1}\n",
      "{'Garden onion': 1, 'Roman camomile': 1, 'Common hazelnut': 1, 'Wild carrot': 1, 'Peppermint': 1, 'Cloudberry': 1, 'Garden tomato (var.)': 1, 'Roselle': 1, 'Soft-necked garlic': 1, 'Cabbage': 1, 'Orange bell pepper': 1}\n",
      "{'Garden onion': 1, 'Burdock': 1, 'Mugwort': 1, 'Caraway': 1, 'Roman camomile': 1, 'Chinese cinnamon': 1, 'Ceylon cinnamon': 1, 'Common hazelnut': 1, 'Cumin': 1, 'Turmeric': 1, 'Lemon grass': 1, 'Wild carrot': 1, 'Cardamom': 1, 'Black walnut': 1, 'Peppermint': 1, 'Scarlet bean': 1, 'Lima bean': 1, 'Cloudberry': 1, 'Red raspberry': 1, 'Common sage': 1, 'Garden tomato (var.)': 1, 'Cloves': 1, 'Common thyme': 1, 'Fenugreek': 1, 'American cranberry': 1, 'Common grape': 1, 'Allspice': 1, 'Giant butterbur': 1, 'Butternut': 1, 'Ginkgo nuts': 1, 'Irish moss': 1, 'White mustard': 1, 'Pepper (C. frutescens)': 1, 'Common persimmon': 1, 'Opium poppy': 1, 'Roselle': 1, 'Spirulina': 1, 'Black-eyed pea': 1, 'Soft-necked garlic': 1, 'Cabbage': 1, 'Orange bell pepper': 1}\n"
     ]
    }
   ],
   "source": [
    "# Find a food with the most overlapping content with the interacting drug:\n",
    "\n",
    "stop = 0\n",
    "inspected_drugs = []\n",
    "\n",
    "for row in ddi.itertuples():\n",
    "    drug1 = row[1]\n",
    "    effect = row[2]\n",
    "    drug2 = row[3]\n",
    "\n",
    "    if drug2 in inspected_drugs:\n",
    "        continue\n",
    "\n",
    "    inspected_drugs.append(drug2)\n",
    "  \n",
    "    drug2_ingredients = drug_compound_dict.get(drug2)\n",
    "    \n",
    "    if drug2_ingredients is not None:\n",
    "        sim_food = get_similar_food(drug2_ingredients, food_compound_dict)\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
