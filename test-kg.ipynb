{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating my KG on OGB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from kg_model import KG_model\n",
    "\n",
    "from ogb.linkproppred import Evaluator, PygLinkPropPredDataset\n",
    "\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([   0,    0,    0,  ..., 4266, 4266, 4266]),\n",
       "             col=tensor([   4,    6,    7,  ..., 3953, 3972, 4014]),\n",
       "             size=(4267, 4267), nnz=2135822, density=11.73%)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "data.adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge': tensor([[4039, 2424],\n",
       "         [4039,  225],\n",
       "         [4039, 3901],\n",
       "         ...,\n",
       "         [ 647,  708],\n",
       "         [ 708,  338],\n",
       "         [ 835, 3554]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "train_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101882, 2])\n",
      "torch.Size([133489, 2])\n"
     ]
    }
   ],
   "source": [
    "print(valid_edge['edge_neg'].shape)\n",
    "print(valid_edge['edge'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "        data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "        create_inverse_triples=True,\n",
    "        entity_to_id=None,\n",
    "        relation_to_id=None,\n",
    "        compact_id=False \n",
    "    )\n",
    "\n",
    "    print(tf_data.mapped_triples)\n",
    "\n",
    "    return tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,  667],\n",
      "        [   0,    0, 1182],\n",
      "        [   0,    0, 1280],\n",
      "        ...,\n",
      "        [4266,    0, 4250],\n",
      "        [4266,    0, 4252],\n",
      "        [4266,    0, 4260]])\n",
      "tensor([[   0,    0,  729],\n",
      "        [   1,    0,  681],\n",
      "        [   1,    0,  768],\n",
      "        ...,\n",
      "        [3812,    0, 3722],\n",
      "        [3812,    0, 3758],\n",
      "        [3812,    0, 3802]])\n",
      "tensor([[   0,    0,    3],\n",
      "        [   0,    0,  185],\n",
      "        [   0,    0,  187],\n",
      "        ...,\n",
      "        [1611,    0, 1562],\n",
      "        [1611,    0, 1573],\n",
      "        [1611,    0, 1601]])\n"
     ]
    }
   ],
   "source": [
    "# add relation type - interacts with\n",
    "\n",
    "train = train_edge['edge']\n",
    "train = torch.tensor([[x[0], 0, x[1]] for x in train])\n",
    "train_df = pd.DataFrame(train, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "valid = valid_edge['edge']\n",
    "valid = torch.tensor([[x[0], 0, x[1]] for x in valid])\n",
    "valid_df = pd.DataFrame(valid, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "valid_neg = valid_edge['edge_neg']\n",
    "valid_neg = torch.tensor([[x[0], 0, x[1]] for x in valid_neg])\n",
    "\n",
    "test = test_edge['edge']\n",
    "test = torch.tensor([[x[0], 0, x[1]] for x in test])\n",
    "test_df = pd.DataFrame(test, columns=['head', 'relation', 'tail']).astype(str)\n",
    "\n",
    "test_neg = test_edge['edge_neg']\n",
    "test_neg = torch.tensor([[x[0], 0, x[1]] for x in test_neg])\n",
    "\n",
    "train_tf = convert_to_triples_factory(train_df)\n",
    "valid_tf = convert_to_triples_factory(valid_df)\n",
    "test_tf = convert_to_triples_factory(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train my KG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kg = KG_model('TransE', train_tf, valid_tf, test_tf, 'ogb')\n",
    "model_kg.set_params(20, 'Adam', RankBasedEvaluator, 'gpu')\n",
    "print('Training...')\n",
    "model_kg.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores for given triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute scores for positive and negative triplets \n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "n = train.size(0) // batch_size\n",
    "pos_train_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, train.size(0))\n",
    "    edge = train[start_idx:end_idx]\n",
    "    pos_train_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "n = valid.size(0) // batch_size\n",
    "pos_valid_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, valid.size(0))\n",
    "    edge = valid[start_idx:end_idx]\n",
    "    pos_valid_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "n = valid_neg.size(0) // batch_size\n",
    "neg_valid_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, valid_neg.size(0))\n",
    "    edge = valid_neg[start_idx:end_idx]\n",
    "    neg_valid_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "n = test.size(0) // batch_size\n",
    "pos_test_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, test.size(0))\n",
    "    edge = test[start_idx:end_idx]\n",
    "    pos_test_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "n = test_neg.size(0) // batch_size\n",
    "neg_test_preds = []\n",
    "for i in range(n+1):\n",
    "    start_idx = i*batch_size\n",
    "    end_idx = min((i+1)*batch_size, test_neg.size(0))\n",
    "    edge = test_neg[start_idx:end_idx]\n",
    "    neg_test_preds += [model_kg.trained_model.model.score_hrt(edge).squeeze().cpu().detach()]\n",
    "neg_test_pred = torch.cat(neg_test_preds, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate my results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@10\n",
      "Train: 0.01%\n",
      "Valid: 0.01%\n",
      "Test: 0.01%\n",
      "Hits@20\n",
      "Train: 0.02%\n",
      "Valid: 0.02%\n",
      "Test: 0.02%\n",
      "Hits@30\n",
      "Train: 0.03%\n",
      "Valid: 0.03%\n",
      "Test: 0.03%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the coputed scores - hits@K\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbl-ddi')\n",
    "\n",
    "results = {}\n",
    "for K in [10, 20, 30]:\n",
    "    evaluator.K = K\n",
    "    train_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_train_pred,\n",
    "        'y_pred_neg': neg_valid_pred,\n",
    "    })[f'hits@{K}']\n",
    "    valid_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_valid_pred,\n",
    "        'y_pred_neg': neg_valid_pred,\n",
    "    })[f'hits@{K}']\n",
    "    test_hits = evaluator.eval({\n",
    "        'y_pred_pos': pos_test_pred,\n",
    "        'y_pred_neg': neg_test_pred,\n",
    "    })[f'hits@{K}']\n",
    "    \n",
    "    results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "    \n",
    "    \n",
    "for hits, result in results.items():\n",
    "    print(hits)\n",
    "#     print(result)\n",
    "    train_hits, valid_hits, test_hits = result\n",
    "    print(f'Train: {100 * train_hits:.2f}%')\n",
    "    print(f'Valid: {100 * valid_hits:.2f}%')\n",
    "    print(f'Test: {100 * test_hits:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leuprolide - decrease_adverse_effects:\n",
      "      head_id head_label     score  in_training\n",
      "1776     1776       2597 -4.225868         True\n",
      "1787     1787       2606 -4.259010         True\n",
      "1549     1549       2392 -4.277555         True\n",
      "3626     3626       4261 -4.303725         True\n",
      "4148     4148        892 -4.309386         True\n",
      "1917     1917       2723 -4.312338        False\n",
      "1929     1929       2734 -4.312355         True\n",
      "1610     1610       2447 -4.334918         True\n",
      "3955     3955        718 -4.335896        False\n",
      "1236     1236        211 -4.366917         True\n"
     ]
    }
   ],
   "source": [
    "model_kg.predict_head('2424', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005993003168800426\n",
      "0.0036557319329682597\n",
      "0.007348920135741521\n"
     ]
    }
   ],
   "source": [
    "print(model_kg.trained_model.get_metric('hits@1'))\n",
    "print(model_kg.trained_model.get_metric('hits@5'))\n",
    "print(model_kg.trained_model.get_metric('hits@10'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config\n",
    "\n",
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "#         dataset='Nations',\n",
    "        training = train_tf,\n",
    "        testing = test_tf,\n",
    "        validation = valid_tf,\n",
    "        model='TransE',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=50, high=220, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=20, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-30 08:57:20,367]\u001b[0m A new study created in memory with name: no-name-c73c846a-6d4b-4b64-a2f9-afaca0b6b610\u001b[0m\n",
      "/usr/local/lib/python3.8/dist-packages/optuna/distributions.py:683: UserWarning: The distribution is specified by [50, 220] and step=20, but the range is not divisible by `step`. It will be replaced by [50, 210].\n",
      "  warnings.warn(\n",
      "No random seed is specified. Setting to 1486788349.\n",
      "INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "Training epochs on cuda:0:   0%|                                               | 0/20 [00:00<?, ?epoch/s]INFO:pykeen.triples.triples_factory:Creating inverse triples.\n",
      "\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 14/16687 [00:00<02:00, 138.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 55/16687 [00:00<00:56, 296.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 101/16687 [00:00<00:45, 367.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 155/16687 [00:00<00:38, 433.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 214/16687 [00:00<00:33, 486.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 273/16687 [00:00<00:31, 521.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 334/16687 [00:00<00:29, 547.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 394/16687 [00:00<00:28, 563.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 453/16687 [00:00<00:28, 570.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 512/16687 [00:01<00:28, 575.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 571/16687 [00:01<00:27, 578.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 630/16687 [00:01<00:27, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 689/16687 [00:01<00:27, 583.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 748/16687 [00:01<00:28, 563.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 805/16687 [00:01<00:28, 562.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 864/16687 [00:01<00:27, 570.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 924/16687 [00:01<00:27, 576.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 983/16687 [00:01<00:27, 580.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1042/16687 [00:01<00:26, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1101/16687 [00:02<00:26, 584.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1160/16687 [00:02<00:26, 586.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1219/16687 [00:02<00:26, 587.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1278/16687 [00:02<00:26, 585.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1338/16687 [00:02<00:26, 589.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1398/16687 [00:02<00:25, 590.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1458/16687 [00:02<00:25, 591.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1518/16687 [00:02<00:25, 592.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1578/16687 [00:02<00:25, 593.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1638/16687 [00:02<00:25, 593.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1698/16687 [00:03<00:25, 593.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1758/16687 [00:03<00:25, 594.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1818/16687 [00:03<00:25, 594.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1878/16687 [00:03<00:24, 594.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1938/16687 [00:03<00:24, 595.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1998/16687 [00:03<00:24, 594.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2058/16687 [00:03<00:24, 595.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2118/16687 [00:03<00:24, 594.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2178/16687 [00:03<00:24, 594.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2238/16687 [00:03<00:24, 595.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2298/16687 [00:04<00:24, 595.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2358/16687 [00:04<00:24, 595.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2418/16687 [00:04<00:24, 594.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2478/16687 [00:04<00:24, 583.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2537/16687 [00:04<00:24, 576.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2595/16687 [00:04<00:24, 564.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2652/16687 [00:04<00:24, 561.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2709/16687 [00:04<00:25, 556.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2769/16687 [00:04<00:24, 566.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2826/16687 [00:04<00:25, 553.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2884/16687 [00:05<00:24, 558.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2946/16687 [00:05<00:23, 574.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3004/16687 [00:05<00:23, 572.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3062/16687 [00:05<00:24, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3122/16687 [00:05<00:23, 568.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3182/16687 [00:05<00:23, 575.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3242/16687 [00:05<00:23, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3301/16687 [00:05<00:23, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3358/16687 [00:05<00:23, 557.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3418/16687 [00:06<00:23, 568.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3476/16687 [00:06<00:23, 570.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3536/16687 [00:06<00:22, 577.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3594/16687 [00:06<00:22, 572.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3652/16687 [00:06<00:23, 566.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3710/16687 [00:06<00:22, 568.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3767/16687 [00:06<00:23, 560.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3828/16687 [00:06<00:22, 574.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3888/16687 [00:06<00:22, 580.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3948/16687 [00:06<00:21, 583.89batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  24%|███████▍                       | 4007/16687 [00:07<00:21, 580.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4067/16687 [00:07<00:21, 583.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4127/16687 [00:07<00:21, 586.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4187/16687 [00:07<00:21, 588.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4247/16687 [00:07<00:21, 589.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4307/16687 [00:07<00:20, 590.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4367/16687 [00:07<00:20, 591.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4427/16687 [00:07<00:20, 591.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4487/16687 [00:07<00:20, 592.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4547/16687 [00:07<00:20, 592.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4607/16687 [00:08<00:20, 593.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4667/16687 [00:08<00:20, 593.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4727/16687 [00:08<00:20, 593.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4787/16687 [00:08<00:20, 573.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4845/16687 [00:08<00:21, 559.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4902/16687 [00:08<00:21, 551.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4958/16687 [00:08<00:21, 546.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5013/16687 [00:08<00:21, 542.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5068/16687 [00:08<00:21, 539.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5122/16687 [00:08<00:21, 537.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5176/16687 [00:09<00:21, 536.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5230/16687 [00:09<00:21, 535.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5284/16687 [00:09<00:21, 534.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5338/16687 [00:09<00:21, 532.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5392/16687 [00:09<00:21, 532.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5446/16687 [00:09<00:21, 531.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5500/16687 [00:09<00:21, 531.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5554/16687 [00:09<00:20, 531.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5608/16687 [00:09<00:20, 532.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5662/16687 [00:10<00:20, 531.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5718/16687 [00:10<00:20, 539.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5778/16687 [00:10<00:19, 554.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5838/16687 [00:10<00:19, 565.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5895/16687 [00:10<00:19, 566.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5956/16687 [00:10<00:18, 577.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6018/16687 [00:10<00:18, 587.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6080/16687 [00:10<00:17, 594.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6140/16687 [00:10<00:17, 593.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6200/16687 [00:10<00:17, 591.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6260/16687 [00:11<00:17, 590.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6320/16687 [00:11<00:17, 592.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6380/16687 [00:11<00:17, 578.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6440/16687 [00:11<00:17, 582.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6500/16687 [00:11<00:17, 585.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6560/16687 [00:11<00:17, 586.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6620/16687 [00:11<00:17, 588.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6680/16687 [00:11<00:16, 588.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6740/16687 [00:11<00:16, 589.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6800/16687 [00:11<00:16, 589.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6860/16687 [00:12<00:16, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6920/16687 [00:12<00:16, 590.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6980/16687 [00:12<00:16, 580.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7040/16687 [00:12<00:16, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7099/16687 [00:12<00:16, 585.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7158/16687 [00:12<00:16, 586.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7217/16687 [00:12<00:16, 587.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7276/16687 [00:12<00:16, 587.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7335/16687 [00:12<00:15, 588.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7394/16687 [00:12<00:15, 588.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7453/16687 [00:13<00:15, 588.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7512/16687 [00:13<00:15, 588.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7571/16687 [00:13<00:15, 588.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7630/16687 [00:13<00:15, 588.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7689/16687 [00:13<00:15, 588.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7748/16687 [00:13<00:15, 588.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7808/16687 [00:13<00:15, 589.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7867/16687 [00:13<00:14, 589.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7926/16687 [00:13<00:14, 589.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7986/16687 [00:13<00:14, 589.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8046/16687 [00:14<00:14, 589.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8106/16687 [00:14<00:14, 590.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8166/16687 [00:14<00:14, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8226/16687 [00:14<00:14, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8286/16687 [00:14<00:14, 590.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8346/16687 [00:14<00:14, 589.99batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|███████████████▌               | 8406/16687 [00:14<00:14, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8466/16687 [00:14<00:13, 590.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8526/16687 [00:14<00:13, 590.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8586/16687 [00:14<00:13, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8646/16687 [00:15<00:13, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8706/16687 [00:15<00:13, 590.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8766/16687 [00:15<00:13, 590.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8826/16687 [00:15<00:13, 590.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8886/16687 [00:15<00:13, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8946/16687 [00:15<00:13, 590.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9006/16687 [00:15<00:13, 590.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9066/16687 [00:15<00:12, 590.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9126/16687 [00:15<00:12, 590.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9186/16687 [00:15<00:12, 590.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9246/16687 [00:16<00:12, 591.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9306/16687 [00:16<00:12, 590.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9366/16687 [00:16<00:12, 590.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▌             | 9426/16687 [00:16<00:12, 590.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9486/16687 [00:16<00:12, 590.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9546/16687 [00:16<00:12, 590.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9606/16687 [00:16<00:11, 590.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9666/16687 [00:16<00:11, 590.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9726/16687 [00:16<00:11, 590.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9786/16687 [00:17<00:11, 590.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9846/16687 [00:17<00:11, 591.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9906/16687 [00:17<00:11, 591.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9966/16687 [00:17<00:11, 591.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10026/16687 [00:17<00:11, 591.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10086/16687 [00:17<00:11, 590.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10146/16687 [00:17<00:11, 590.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10206/16687 [00:17<00:10, 590.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10266/16687 [00:17<00:10, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10326/16687 [00:17<00:10, 590.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10386/16687 [00:18<00:10, 590.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10446/16687 [00:18<00:10, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10506/16687 [00:18<00:10, 590.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10566/16687 [00:18<00:10, 590.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10626/16687 [00:18<00:10, 590.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10686/16687 [00:18<00:10, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10746/16687 [00:18<00:10, 590.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10806/16687 [00:18<00:09, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10866/16687 [00:18<00:09, 590.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▋          | 10926/16687 [00:18<00:09, 590.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10986/16687 [00:19<00:09, 590.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11046/16687 [00:19<00:09, 589.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11105/16687 [00:19<00:09, 589.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11165/16687 [00:19<00:09, 589.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11225/16687 [00:19<00:09, 589.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11285/16687 [00:19<00:09, 590.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11345/16687 [00:19<00:09, 590.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11405/16687 [00:19<00:08, 590.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11465/16687 [00:19<00:08, 590.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11525/16687 [00:19<00:08, 590.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11585/16687 [00:20<00:08, 590.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11645/16687 [00:20<00:08, 590.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11705/16687 [00:20<00:08, 590.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11765/16687 [00:20<00:08, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11825/16687 [00:20<00:08, 591.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11885/16687 [00:20<00:08, 590.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11945/16687 [00:20<00:08, 590.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12005/16687 [00:20<00:07, 590.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12065/16687 [00:20<00:07, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12125/16687 [00:20<00:07, 590.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12185/16687 [00:21<00:07, 589.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12244/16687 [00:21<00:07, 589.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12303/16687 [00:21<00:07, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12363/16687 [00:21<00:07, 589.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12423/16687 [00:21<00:07, 589.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12483/16687 [00:21<00:07, 590.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12545/16687 [00:21<00:06, 597.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12605/16687 [00:21<00:06, 595.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12665/16687 [00:21<00:06, 596.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12725/16687 [00:21<00:06, 596.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12785/16687 [00:22<00:06, 575.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12843/16687 [00:22<00:06, 557.75batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12899/16687 [00:22<00:06, 541.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12954/16687 [00:22<00:07, 527.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13007/16687 [00:22<00:07, 518.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13059/16687 [00:22<00:07, 509.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13110/16687 [00:22<00:07, 509.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13161/16687 [00:22<00:07, 503.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13215/16687 [00:22<00:06, 513.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13274/16687 [00:23<00:06, 536.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13332/16687 [00:23<00:06, 546.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13391/16687 [00:23<00:05, 559.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13450/16687 [00:23<00:05, 567.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13507/16687 [00:23<00:05, 566.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13566/16687 [00:23<00:05, 572.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13625/16687 [00:23<00:05, 577.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13685/16687 [00:23<00:05, 581.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13744/16687 [00:23<00:05, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13803/16687 [00:23<00:04, 580.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13862/16687 [00:24<00:04, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13921/16687 [00:24<00:04, 584.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13980/16687 [00:24<00:04, 585.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14039/16687 [00:24<00:04, 586.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14098/16687 [00:24<00:04, 580.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14157/16687 [00:24<00:04, 582.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14216/16687 [00:24<00:04, 584.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14275/16687 [00:24<00:04, 585.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14334/16687 [00:24<00:04, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14394/16687 [00:24<00:03, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14453/16687 [00:25<00:03, 588.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14512/16687 [00:25<00:03, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14571/16687 [00:25<00:03, 588.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14630/16687 [00:25<00:03, 588.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14689/16687 [00:25<00:03, 588.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14748/16687 [00:25<00:03, 588.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14807/16687 [00:25<00:03, 588.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14866/16687 [00:25<00:03, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14925/16687 [00:25<00:02, 588.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14984/16687 [00:25<00:02, 588.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15043/16687 [00:26<00:02, 588.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15103/16687 [00:26<00:02, 590.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15163/16687 [00:26<00:02, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15223/16687 [00:26<00:02, 593.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15283/16687 [00:26<00:02, 592.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15343/16687 [00:26<00:02, 591.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15403/16687 [00:26<00:02, 591.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15463/16687 [00:26<00:02, 590.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15523/16687 [00:26<00:01, 590.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15583/16687 [00:26<00:01, 590.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15643/16687 [00:27<00:01, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15703/16687 [00:27<00:01, 590.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15763/16687 [00:27<00:01, 590.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15823/16687 [00:27<00:01, 583.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15882/16687 [00:27<00:01, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15941/16687 [00:27<00:01, 585.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16000/16687 [00:27<00:01, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16059/16687 [00:27<00:01, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16118/16687 [00:27<00:00, 584.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16178/16687 [00:27<00:00, 587.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16240/16687 [00:28<00:00, 595.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16300/16687 [00:28<00:00, 593.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16360/16687 [00:28<00:00, 592.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16420/16687 [00:28<00:00, 591.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16480/16687 [00:28<00:00, 591.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16540/16687 [00:28<00:00, 590.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16600/16687 [00:28<00:00, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16660/16687 [00:28<00:00, 589.96batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   5%|▌           | 1/20 [00:29<09:11, 29.05s/epoch, loss=0.708, prev_loss=nan]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 16/16687 [00:00<01:44, 159.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 70/16687 [00:00<00:43, 381.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 130/16687 [00:00<00:34, 478.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 190/16687 [00:00<00:31, 522.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 249/16687 [00:00<00:30, 546.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 308/16687 [00:00<00:29, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 367/16687 [00:00<00:28, 570.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 427/16687 [00:00<00:28, 576.58batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   3%|▉                               | 486/16687 [00:00<00:27, 580.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 545/16687 [00:01<00:27, 583.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 604/16687 [00:01<00:27, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 663/16687 [00:01<00:27, 585.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 722/16687 [00:01<00:27, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 781/16687 [00:01<00:27, 587.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 840/16687 [00:01<00:26, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 899/16687 [00:01<00:26, 588.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 958/16687 [00:01<00:26, 588.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1017/16687 [00:01<00:26, 588.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1076/16687 [00:01<00:26, 588.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1135/16687 [00:02<00:26, 588.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1194/16687 [00:02<00:26, 588.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1253/16687 [00:02<00:26, 588.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1312/16687 [00:02<00:26, 588.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1371/16687 [00:02<00:26, 588.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1430/16687 [00:02<00:25, 588.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1489/16687 [00:02<00:25, 588.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1549/16687 [00:02<00:25, 589.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1608/16687 [00:02<00:25, 589.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1667/16687 [00:02<00:25, 589.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1727/16687 [00:03<00:25, 589.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1787/16687 [00:03<00:25, 589.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1846/16687 [00:03<00:25, 589.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1905/16687 [00:03<00:25, 586.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1965/16687 [00:03<00:25, 587.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2025/16687 [00:03<00:24, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2085/16687 [00:03<00:24, 589.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2145/16687 [00:03<00:24, 590.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2205/16687 [00:03<00:24, 590.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2265/16687 [00:03<00:24, 590.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2325/16687 [00:04<00:24, 591.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2385/16687 [00:04<00:24, 591.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2445/16687 [00:04<00:24, 591.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2505/16687 [00:04<00:23, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2565/16687 [00:04<00:23, 591.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2625/16687 [00:04<00:23, 591.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2685/16687 [00:04<00:23, 591.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2745/16687 [00:04<00:23, 591.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2805/16687 [00:04<00:23, 591.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2865/16687 [00:04<00:23, 586.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2925/16687 [00:05<00:23, 587.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2985/16687 [00:05<00:23, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3045/16687 [00:05<00:23, 589.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3105/16687 [00:05<00:23, 590.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3165/16687 [00:05<00:22, 590.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3225/16687 [00:05<00:22, 590.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3285/16687 [00:05<00:22, 590.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3345/16687 [00:05<00:22, 591.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3405/16687 [00:05<00:22, 591.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3465/16687 [00:05<00:22, 591.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3525/16687 [00:06<00:22, 591.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3585/16687 [00:06<00:22, 591.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3645/16687 [00:06<00:22, 592.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3705/16687 [00:06<00:21, 592.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3765/16687 [00:06<00:21, 592.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3825/16687 [00:06<00:21, 591.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3885/16687 [00:06<00:21, 591.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3945/16687 [00:06<00:21, 591.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4005/16687 [00:06<00:21, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4065/16687 [00:06<00:21, 584.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4125/16687 [00:07<00:21, 586.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4185/16687 [00:07<00:21, 587.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4245/16687 [00:07<00:21, 588.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4305/16687 [00:07<00:21, 589.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4365/16687 [00:07<00:20, 590.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4425/16687 [00:07<00:20, 591.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4485/16687 [00:07<00:20, 591.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4545/16687 [00:07<00:20, 591.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4605/16687 [00:07<00:20, 592.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4665/16687 [00:07<00:20, 592.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4725/16687 [00:08<00:20, 591.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4785/16687 [00:08<00:20, 591.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4845/16687 [00:08<00:20, 591.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4905/16687 [00:08<00:19, 591.51batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  30%|█████████▏                     | 4965/16687 [00:08<00:19, 591.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5025/16687 [00:08<00:19, 591.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5085/16687 [00:08<00:19, 591.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5145/16687 [00:08<00:20, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5204/16687 [00:08<00:19, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5263/16687 [00:09<00:19, 581.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5322/16687 [00:09<00:19, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5381/16687 [00:09<00:19, 585.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5440/16687 [00:09<00:19, 586.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5500/16687 [00:09<00:19, 587.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5559/16687 [00:09<00:19, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5618/16687 [00:09<00:18, 583.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5677/16687 [00:09<00:18, 584.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5736/16687 [00:09<00:18, 585.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5795/16687 [00:09<00:18, 585.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5854/16687 [00:10<00:18, 586.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5913/16687 [00:10<00:18, 586.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5972/16687 [00:10<00:18, 586.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6031/16687 [00:10<00:18, 586.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6090/16687 [00:10<00:18, 587.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6149/16687 [00:10<00:17, 587.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6208/16687 [00:10<00:17, 584.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6268/16687 [00:10<00:17, 587.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6327/16687 [00:10<00:17, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6387/16687 [00:10<00:17, 586.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6446/16687 [00:11<00:17, 585.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6507/16687 [00:11<00:17, 591.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6568/16687 [00:11<00:16, 597.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6628/16687 [00:11<00:16, 594.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6688/16687 [00:11<00:17, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6747/16687 [00:11<00:16, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6807/16687 [00:11<00:16, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6867/16687 [00:11<00:16, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▊                  | 6926/16687 [00:11<00:16, 589.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6987/16687 [00:11<00:16, 595.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7047/16687 [00:12<00:16, 595.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7107/16687 [00:12<00:16, 592.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7167/16687 [00:12<00:16, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7225/16687 [00:12<00:16, 571.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7284/16687 [00:12<00:16, 575.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7343/16687 [00:12<00:16, 578.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7402/16687 [00:12<00:15, 580.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7461/16687 [00:12<00:15, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7520/16687 [00:12<00:15, 579.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7579/16687 [00:12<00:15, 581.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7640/16687 [00:13<00:15, 590.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7702/16687 [00:13<00:15, 596.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7763/16687 [00:13<00:14, 598.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7823/16687 [00:13<00:14, 595.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7883/16687 [00:13<00:14, 593.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7943/16687 [00:13<00:14, 592.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8003/16687 [00:13<00:14, 591.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8063/16687 [00:13<00:14, 591.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8123/16687 [00:13<00:14, 590.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8183/16687 [00:13<00:14, 592.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8243/16687 [00:14<00:14, 590.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8303/16687 [00:14<00:14, 590.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8363/16687 [00:14<00:14, 586.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8422/16687 [00:14<00:14, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8480/16687 [00:14<00:14, 570.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8541/16687 [00:14<00:14, 581.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8602/16687 [00:14<00:13, 589.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8664/16687 [00:14<00:13, 596.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8724/16687 [00:14<00:13, 594.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8784/16687 [00:15<00:13, 593.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8844/16687 [00:15<00:13, 592.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8904/16687 [00:15<00:13, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8964/16687 [00:15<00:13, 592.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9024/16687 [00:15<00:12, 592.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▉              | 9084/16687 [00:15<00:12, 591.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9144/16687 [00:15<00:12, 591.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9204/16687 [00:15<00:12, 591.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9264/16687 [00:15<00:12, 591.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9324/16687 [00:15<00:12, 591.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9385/16687 [00:16<00:12, 594.93batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  57%|█████████████████▌             | 9446/16687 [00:16<00:12, 596.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9506/16687 [00:16<00:12, 595.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9566/16687 [00:16<00:11, 594.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9626/16687 [00:16<00:11, 593.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9686/16687 [00:16<00:11, 593.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9746/16687 [00:16<00:11, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9806/16687 [00:16<00:11, 592.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9866/16687 [00:16<00:11, 586.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9926/16687 [00:16<00:11, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9986/16687 [00:17<00:11, 580.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10045/16687 [00:17<00:11, 563.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10102/16687 [00:17<00:11, 552.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10158/16687 [00:17<00:11, 550.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10218/16687 [00:17<00:11, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10277/16687 [00:17<00:11, 570.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10336/16687 [00:17<00:11, 575.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10395/16687 [00:17<00:10, 578.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10454/16687 [00:17<00:10, 580.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10513/16687 [00:17<00:10, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10572/16687 [00:18<00:10, 579.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10631/16687 [00:18<00:10, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10690/16687 [00:18<00:10, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10749/16687 [00:18<00:10, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10808/16687 [00:18<00:10, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10867/16687 [00:18<00:09, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▋          | 10926/16687 [00:18<00:09, 584.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10985/16687 [00:18<00:09, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11044/16687 [00:18<00:09, 585.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11103/16687 [00:18<00:09, 585.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11162/16687 [00:19<00:09, 585.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11221/16687 [00:19<00:09, 586.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11280/16687 [00:19<00:09, 586.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11339/16687 [00:19<00:09, 586.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11398/16687 [00:19<00:09, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11457/16687 [00:19<00:08, 586.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11516/16687 [00:19<00:08, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11575/16687 [00:19<00:08, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11634/16687 [00:19<00:08, 586.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11693/16687 [00:19<00:08, 586.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11752/16687 [00:20<00:08, 586.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11811/16687 [00:20<00:08, 576.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11870/16687 [00:20<00:08, 579.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11928/16687 [00:20<00:08, 564.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11985/16687 [00:20<00:08, 551.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12042/16687 [00:20<00:08, 555.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12103/16687 [00:20<00:08, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12164/16687 [00:20<00:07, 581.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12223/16687 [00:20<00:07, 581.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12282/16687 [00:21<00:07, 581.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12343/16687 [00:21<00:07, 588.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12403/16687 [00:21<00:07, 591.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12464/16687 [00:21<00:07, 596.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12525/16687 [00:21<00:06, 598.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12585/16687 [00:21<00:06, 598.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12645/16687 [00:21<00:06, 596.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12705/16687 [00:21<00:06, 595.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12765/16687 [00:21<00:06, 594.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12825/16687 [00:21<00:06, 593.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12885/16687 [00:22<00:06, 592.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12945/16687 [00:22<00:06, 592.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13006/16687 [00:22<00:06, 595.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13067/16687 [00:22<00:06, 600.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13128/16687 [00:22<00:05, 598.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13188/16687 [00:22<00:05, 596.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13248/16687 [00:22<00:05, 595.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13308/16687 [00:22<00:05, 594.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13368/16687 [00:22<00:05, 593.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13428/16687 [00:22<00:05, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13487/16687 [00:23<00:05, 583.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13546/16687 [00:23<00:05, 582.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13605/16687 [00:23<00:05, 576.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13666/16687 [00:23<00:05, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13727/16687 [00:23<00:05, 588.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13787/16687 [00:23<00:04, 590.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13847/16687 [00:23<00:04, 591.39batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  83%|█████████████████████████     | 13907/16687 [00:23<00:04, 590.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13967/16687 [00:23<00:04, 589.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14026/16687 [00:23<00:04, 586.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14085/16687 [00:24<00:04, 586.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14144/16687 [00:24<00:04, 587.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14206/16687 [00:24<00:04, 594.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14266/16687 [00:24<00:04, 593.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14326/16687 [00:24<00:04, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14386/16687 [00:24<00:03, 589.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14446/16687 [00:24<00:03, 590.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14506/16687 [00:24<00:03, 590.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14566/16687 [00:24<00:03, 590.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14626/16687 [00:24<00:03, 590.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14686/16687 [00:25<00:03, 591.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14746/16687 [00:25<00:03, 591.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14806/16687 [00:25<00:03, 591.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14866/16687 [00:25<00:03, 591.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14926/16687 [00:25<00:02, 591.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14986/16687 [00:25<00:02, 591.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15046/16687 [00:25<00:02, 591.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15106/16687 [00:25<00:02, 591.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15166/16687 [00:25<00:02, 591.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15226/16687 [00:25<00:02, 591.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15286/16687 [00:26<00:02, 591.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15346/16687 [00:26<00:02, 591.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15406/16687 [00:26<00:02, 591.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15466/16687 [00:26<00:02, 591.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15526/16687 [00:26<00:01, 591.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15586/16687 [00:26<00:01, 591.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15646/16687 [00:26<00:01, 591.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15706/16687 [00:26<00:01, 591.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15766/16687 [00:26<00:01, 591.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15828/16687 [00:27<00:01, 597.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15890/16687 [00:27<00:01, 602.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15951/16687 [00:27<00:01, 603.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16012/16687 [00:27<00:01, 604.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16073/16687 [00:27<00:01, 600.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16134/16687 [00:27<00:00, 597.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16194/16687 [00:27<00:00, 595.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16254/16687 [00:27<00:00, 593.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16314/16687 [00:27<00:00, 593.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16374/16687 [00:27<00:00, 593.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16435/16687 [00:28<00:00, 596.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16497/16687 [00:28<00:00, 600.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16558/16687 [00:28<00:00, 598.56batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16618/16687 [00:28<00:00, 596.44batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16678/16687 [00:28<00:00, 594.90batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  10%|█▏          | 2/20 [00:57<08:38, 28.79s/epoch, loss=0.7, prev_loss=0.708]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 20/16687 [00:00<01:23, 198.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 74/16687 [00:00<00:42, 394.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 134/16687 [00:00<00:34, 484.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 195/16687 [00:00<00:31, 531.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▍                               | 256/16687 [00:00<00:29, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 313/16687 [00:00<00:29, 560.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 372/16687 [00:00<00:28, 568.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 433/16687 [00:00<00:28, 580.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 492/16687 [00:00<00:27, 579.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 552/16687 [00:01<00:27, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 612/16687 [00:01<00:27, 585.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 672/16687 [00:01<00:27, 586.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 732/16687 [00:01<00:27, 588.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 792/16687 [00:01<00:26, 591.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 852/16687 [00:01<00:26, 588.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 912/16687 [00:01<00:26, 590.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 972/16687 [00:01<00:26, 590.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1032/16687 [00:01<00:26, 586.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1092/16687 [00:01<00:26, 588.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1152/16687 [00:02<00:26, 589.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1212/16687 [00:02<00:26, 589.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1272/16687 [00:02<00:26, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1332/16687 [00:02<00:26, 588.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1393/16687 [00:02<00:25, 591.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1455/16687 [00:02<00:25, 598.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1517/16687 [00:02<00:25, 602.04batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   9%|██▉                            | 1578/16687 [00:02<00:25, 599.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1638/16687 [00:02<00:25, 597.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1698/16687 [00:02<00:25, 595.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1758/16687 [00:03<00:25, 594.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1818/16687 [00:03<00:25, 593.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1878/16687 [00:03<00:24, 593.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1938/16687 [00:03<00:24, 594.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2000/16687 [00:03<00:24, 599.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2062/16687 [00:03<00:24, 603.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2123/16687 [00:03<00:24, 600.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2184/16687 [00:03<00:24, 597.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2244/16687 [00:03<00:24, 595.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2304/16687 [00:03<00:24, 594.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2364/16687 [00:04<00:24, 593.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2424/16687 [00:04<00:24, 593.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2484/16687 [00:04<00:23, 593.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2544/16687 [00:04<00:23, 592.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2604/16687 [00:04<00:23, 591.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2664/16687 [00:04<00:23, 591.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2724/16687 [00:04<00:23, 591.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2784/16687 [00:04<00:23, 591.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2844/16687 [00:04<00:23, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2904/16687 [00:04<00:23, 591.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2964/16687 [00:05<00:23, 591.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3024/16687 [00:05<00:23, 591.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3084/16687 [00:05<00:23, 591.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3144/16687 [00:05<00:22, 590.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3204/16687 [00:05<00:22, 590.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3264/16687 [00:05<00:22, 591.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3324/16687 [00:05<00:22, 591.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3384/16687 [00:05<00:22, 591.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3444/16687 [00:05<00:22, 592.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3504/16687 [00:05<00:22, 592.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3564/16687 [00:06<00:22, 591.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3624/16687 [00:06<00:22, 591.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3684/16687 [00:06<00:21, 591.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3744/16687 [00:06<00:21, 591.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3804/16687 [00:06<00:21, 591.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3864/16687 [00:06<00:21, 591.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3924/16687 [00:06<00:21, 591.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3984/16687 [00:06<00:21, 591.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4044/16687 [00:06<00:21, 591.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▌                       | 4104/16687 [00:07<00:21, 591.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4164/16687 [00:07<00:21, 591.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4224/16687 [00:07<00:21, 591.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4284/16687 [00:07<00:20, 591.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4344/16687 [00:07<00:20, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4404/16687 [00:07<00:20, 590.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4464/16687 [00:07<00:20, 590.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4524/16687 [00:07<00:20, 590.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4584/16687 [00:07<00:20, 590.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4644/16687 [00:07<00:20, 590.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4704/16687 [00:08<00:20, 590.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▊                      | 4764/16687 [00:08<00:20, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4824/16687 [00:08<00:20, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4884/16687 [00:08<00:20, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4944/16687 [00:08<00:19, 589.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5003/16687 [00:08<00:20, 581.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5062/16687 [00:08<00:19, 583.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5121/16687 [00:08<00:19, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5180/16687 [00:08<00:19, 584.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5239/16687 [00:08<00:19, 584.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5298/16687 [00:09<00:19, 584.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5357/16687 [00:09<00:19, 585.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5416/16687 [00:09<00:19, 585.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5475/16687 [00:09<00:19, 585.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5534/16687 [00:09<00:19, 585.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5593/16687 [00:09<00:18, 585.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5652/16687 [00:09<00:18, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5711/16687 [00:09<00:18, 582.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5770/16687 [00:09<00:18, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5829/16687 [00:09<00:18, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5888/16687 [00:10<00:18, 582.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5947/16687 [00:10<00:19, 559.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6004/16687 [00:10<00:19, 557.26batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  36%|███████████▎                   | 6060/16687 [00:10<00:19, 557.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6118/16687 [00:10<00:18, 561.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6175/16687 [00:10<00:18, 559.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6232/16687 [00:10<00:18, 560.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6290/16687 [00:10<00:18, 565.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6348/16687 [00:10<00:18, 567.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6406/16687 [00:10<00:17, 571.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6465/16687 [00:11<00:17, 574.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6524/16687 [00:11<00:17, 576.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6583/16687 [00:11<00:17, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6642/16687 [00:11<00:17, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6701/16687 [00:11<00:17, 579.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6760/16687 [00:11<00:17, 579.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6818/16687 [00:11<00:17, 574.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6876/16687 [00:11<00:17, 574.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6937/16687 [00:11<00:16, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6997/16687 [00:11<00:16, 588.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7056/16687 [00:12<00:16, 588.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7115/16687 [00:12<00:16, 588.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7174/16687 [00:12<00:16, 587.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7233/16687 [00:12<00:16, 588.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7292/16687 [00:12<00:15, 587.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7351/16687 [00:12<00:16, 578.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7410/16687 [00:12<00:15, 580.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7470/16687 [00:12<00:15, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7529/16687 [00:12<00:15, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7588/16687 [00:12<00:15, 585.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7647/16687 [00:13<00:15, 586.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7706/16687 [00:13<00:15, 587.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7765/16687 [00:13<00:15, 587.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7824/16687 [00:13<00:15, 587.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7883/16687 [00:13<00:14, 587.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7942/16687 [00:13<00:14, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8003/16687 [00:13<00:14, 590.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8064/16687 [00:13<00:14, 596.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8125/16687 [00:13<00:14, 600.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8186/16687 [00:14<00:14, 598.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8247/16687 [00:14<00:14, 600.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8308/16687 [00:14<00:14, 591.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8368/16687 [00:14<00:14, 590.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8428/16687 [00:14<00:14, 589.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8487/16687 [00:14<00:13, 588.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8546/16687 [00:14<00:13, 586.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8605/16687 [00:14<00:13, 581.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8664/16687 [00:14<00:13, 576.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8723/16687 [00:14<00:13, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8781/16687 [00:15<00:13, 577.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8841/16687 [00:15<00:13, 581.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8901/16687 [00:15<00:13, 584.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8960/16687 [00:15<00:13, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9019/16687 [00:15<00:13, 583.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9078/16687 [00:15<00:13, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9136/16687 [00:15<00:13, 571.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9194/16687 [00:15<00:13, 569.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9256/16687 [00:15<00:12, 581.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9318/16687 [00:15<00:12, 590.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9380/16687 [00:16<00:12, 597.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9440/16687 [00:16<00:12, 595.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9500/16687 [00:16<00:12, 585.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9559/16687 [00:16<00:12, 575.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9617/16687 [00:16<00:12, 565.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9676/16687 [00:16<00:12, 571.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9734/16687 [00:16<00:12, 567.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9792/16687 [00:16<00:12, 570.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9851/16687 [00:16<00:11, 574.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9910/16687 [00:16<00:11, 577.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9968/16687 [00:17<00:11, 577.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10027/16687 [00:17<00:11, 580.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10086/16687 [00:17<00:11, 583.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10145/16687 [00:17<00:11, 584.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10204/16687 [00:17<00:11, 581.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10263/16687 [00:17<00:11, 583.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10322/16687 [00:17<00:10, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10382/16687 [00:17<00:10, 585.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10441/16687 [00:17<00:10, 582.56batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  63%|██████████████████▉           | 10500/16687 [00:17<00:10, 580.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10561/16687 [00:18<00:10, 587.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10621/16687 [00:18<00:10, 588.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10681/16687 [00:18<00:10, 591.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10741/16687 [00:18<00:10, 575.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10799/16687 [00:18<00:10, 568.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10860/16687 [00:18<00:10, 578.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▋          | 10918/16687 [00:18<00:09, 577.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10976/16687 [00:18<00:09, 574.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11034/16687 [00:18<00:09, 574.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11092/16687 [00:19<00:09, 576.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11151/16687 [00:19<00:09, 577.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11210/16687 [00:19<00:09, 578.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11269/16687 [00:19<00:09, 579.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11327/16687 [00:19<00:09, 572.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11387/16687 [00:19<00:09, 579.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11446/16687 [00:19<00:09, 582.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11505/16687 [00:19<00:09, 575.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11563/16687 [00:19<00:08, 569.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11623/16687 [00:19<00:08, 577.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11682/16687 [00:20<00:08, 579.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11743/16687 [00:20<00:08, 585.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11803/16687 [00:20<00:08, 588.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11862/16687 [00:20<00:08, 586.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11921/16687 [00:20<00:08, 585.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11980/16687 [00:20<00:08, 584.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12039/16687 [00:20<00:07, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12098/16687 [00:20<00:07, 584.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12157/16687 [00:20<00:07, 581.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12217/16687 [00:20<00:07, 585.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12276/16687 [00:21<00:07, 586.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12335/16687 [00:21<00:07, 587.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12394/16687 [00:21<00:07, 588.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12453/16687 [00:21<00:07, 588.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12512/16687 [00:21<00:07, 581.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12571/16687 [00:21<00:07, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12629/16687 [00:21<00:07, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12687/16687 [00:21<00:06, 574.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12746/16687 [00:21<00:06, 578.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12807/16687 [00:21<00:06, 587.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12867/16687 [00:22<00:06, 590.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12927/16687 [00:22<00:06, 589.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12987/16687 [00:22<00:06, 589.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13046/16687 [00:22<00:06, 589.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13105/16687 [00:22<00:06, 589.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13164/16687 [00:22<00:05, 589.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13224/16687 [00:22<00:05, 589.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13283/16687 [00:22<00:05, 587.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13343/16687 [00:22<00:05, 589.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13402/16687 [00:22<00:05, 587.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13461/16687 [00:23<00:05, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13520/16687 [00:23<00:05, 582.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13579/16687 [00:23<00:05, 578.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13637/16687 [00:23<00:05, 575.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13696/16687 [00:23<00:05, 577.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13755/16687 [00:23<00:05, 580.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13816/16687 [00:23<00:04, 586.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13875/16687 [00:23<00:04, 584.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13934/16687 [00:23<00:04, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 13993/16687 [00:23<00:04, 579.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14052/16687 [00:24<00:04, 580.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▎    | 14111/16687 [00:24<00:04, 565.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14172/16687 [00:24<00:04, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14230/16687 [00:24<00:04, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14289/16687 [00:24<00:04, 577.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14348/16687 [00:24<00:04, 579.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14406/16687 [00:24<00:03, 578.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14464/16687 [00:24<00:03, 564.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14521/16687 [00:24<00:03, 565.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14581/16687 [00:25<00:03, 573.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14640/16687 [00:25<00:03, 577.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14698/16687 [00:25<00:03, 572.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▌   | 14756/16687 [00:25<00:03, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14814/16687 [00:25<00:03, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14876/16687 [00:25<00:03, 586.05batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  90%|██████████████████████████▊   | 14936/16687 [00:25<00:02, 588.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14995/16687 [00:25<00:02, 587.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15054/16687 [00:25<00:02, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15112/16687 [00:25<00:02, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15171/16687 [00:26<00:02, 568.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15233/16687 [00:26<00:02, 581.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▍  | 15294/16687 [00:26<00:02, 588.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15353/16687 [00:26<00:02, 587.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15412/16687 [00:26<00:02, 585.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15471/16687 [00:26<00:02, 584.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15530/16687 [00:26<00:01, 583.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|████████████████████████████  | 15589/16687 [00:26<00:01, 578.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15648/16687 [00:26<00:01, 579.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15707/16687 [00:26<00:01, 579.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15766/16687 [00:27<00:01, 582.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15825/16687 [00:27<00:01, 583.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15884/16687 [00:27<00:01, 583.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15943/16687 [00:27<00:01, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16002/16687 [00:27<00:01, 582.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16061/16687 [00:27<00:01, 582.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|████████████████████████████▉ | 16120/16687 [00:27<00:00, 578.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16179/16687 [00:27<00:00, 579.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16238/16687 [00:27<00:00, 579.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16297/16687 [00:27<00:00, 580.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16356/16687 [00:28<00:00, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16415/16687 [00:28<00:00, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16474/16687 [00:28<00:00, 581.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16533/16687 [00:28<00:00, 581.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16592/16687 [00:28<00:00, 582.06batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16651/16687 [00:28<00:00, 581.77batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  15%|██            | 3/20 [01:26<08:09, 28.81s/epoch, loss=0.7, prev_loss=0.7]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 19/16687 [00:00<01:28, 189.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 72/16687 [00:00<00:43, 385.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 131/16687 [00:00<00:34, 477.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 190/16687 [00:00<00:31, 519.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 249/16687 [00:00<00:30, 542.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 308/16687 [00:00<00:29, 555.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 367/16687 [00:00<00:28, 564.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 426/16687 [00:00<00:28, 570.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 485/16687 [00:00<00:28, 574.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 544/16687 [00:01<00:27, 576.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 603/16687 [00:01<00:27, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 662/16687 [00:01<00:27, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 720/16687 [00:01<00:28, 568.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 779/16687 [00:01<00:27, 573.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 837/16687 [00:01<00:27, 574.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 896/16687 [00:01<00:27, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 955/16687 [00:01<00:27, 579.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1014/16687 [00:01<00:26, 580.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1073/16687 [00:01<00:26, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1132/16687 [00:02<00:26, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1191/16687 [00:02<00:26, 582.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1250/16687 [00:02<00:26, 582.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1309/16687 [00:02<00:26, 584.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1368/16687 [00:02<00:26, 584.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1427/16687 [00:02<00:26, 584.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1486/16687 [00:02<00:26, 584.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1545/16687 [00:02<00:25, 584.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1604/16687 [00:02<00:26, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1663/16687 [00:02<00:25, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1722/16687 [00:03<00:25, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1781/16687 [00:03<00:25, 581.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1840/16687 [00:03<00:25, 581.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1899/16687 [00:03<00:25, 582.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1958/16687 [00:03<00:25, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2017/16687 [00:03<00:25, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2076/16687 [00:03<00:25, 581.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2135/16687 [00:03<00:24, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2194/16687 [00:03<00:24, 582.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2253/16687 [00:03<00:24, 582.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2312/16687 [00:04<00:24, 583.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2371/16687 [00:04<00:24, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2430/16687 [00:04<00:24, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2489/16687 [00:04<00:24, 582.37batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  15%|████▋                          | 2548/16687 [00:04<00:24, 582.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2607/16687 [00:04<00:24, 582.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2666/16687 [00:04<00:24, 582.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2725/16687 [00:04<00:24, 575.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2784/16687 [00:04<00:24, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2842/16687 [00:04<00:24, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2904/16687 [00:05<00:23, 586.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2966/16687 [00:05<00:23, 593.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3026/16687 [00:05<00:23, 592.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3086/16687 [00:05<00:22, 592.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3146/16687 [00:05<00:22, 592.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3206/16687 [00:05<00:22, 592.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3266/16687 [00:05<00:22, 587.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3325/16687 [00:05<00:22, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3384/16687 [00:05<00:23, 577.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3442/16687 [00:05<00:23, 574.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3500/16687 [00:06<00:23, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3558/16687 [00:06<00:23, 567.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3615/16687 [00:06<00:23, 567.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3672/16687 [00:06<00:22, 568.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3729/16687 [00:06<00:22, 568.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3786/16687 [00:06<00:22, 568.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3843/16687 [00:06<00:22, 568.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3900/16687 [00:06<00:22, 568.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3957/16687 [00:06<00:22, 568.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4014/16687 [00:07<00:22, 560.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4071/16687 [00:07<00:22, 557.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4129/16687 [00:07<00:22, 563.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4188/16687 [00:07<00:21, 569.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4247/16687 [00:07<00:21, 573.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4306/16687 [00:07<00:21, 577.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4365/16687 [00:07<00:21, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4424/16687 [00:07<00:21, 580.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4483/16687 [00:07<00:20, 581.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4542/16687 [00:07<00:20, 582.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4601/16687 [00:08<00:20, 582.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4660/16687 [00:08<00:20, 583.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4719/16687 [00:08<00:20, 582.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4778/16687 [00:08<00:20, 582.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4837/16687 [00:08<00:20, 574.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4896/16687 [00:08<00:20, 577.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4954/16687 [00:08<00:20, 578.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5012/16687 [00:08<00:20, 567.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5071/16687 [00:08<00:20, 573.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5130/16687 [00:08<00:20, 577.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5189/16687 [00:09<00:19, 579.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5248/16687 [00:09<00:19, 581.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5307/16687 [00:09<00:19, 582.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5366/16687 [00:09<00:19, 583.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5425/16687 [00:09<00:19, 584.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5484/16687 [00:09<00:19, 585.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5543/16687 [00:09<00:19, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5602/16687 [00:09<00:19, 570.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5661/16687 [00:09<00:19, 574.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5719/16687 [00:09<00:19, 571.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5777/16687 [00:10<00:19, 564.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5834/16687 [00:10<00:19, 562.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5891/16687 [00:10<00:19, 556.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5947/16687 [00:10<00:19, 549.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6007/16687 [00:10<00:18, 563.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6067/16687 [00:10<00:18, 573.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6126/16687 [00:10<00:18, 576.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6185/16687 [00:10<00:18, 577.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6243/16687 [00:10<00:18, 578.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6303/16687 [00:10<00:17, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6362/16687 [00:11<00:17, 580.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6422/16687 [00:11<00:17, 584.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6481/16687 [00:11<00:17, 577.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6541/16687 [00:11<00:17, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6602/16687 [00:11<00:17, 588.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6661/16687 [00:11<00:17, 587.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6720/16687 [00:11<00:17, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6780/16687 [00:11<00:16, 587.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6839/16687 [00:11<00:16, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6899/16687 [00:11<00:16, 586.69batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  42%|████████████▉                  | 6959/16687 [00:12<00:16, 588.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7019/16687 [00:12<00:16, 589.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7078/16687 [00:12<00:16, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7137/16687 [00:12<00:16, 583.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7197/16687 [00:12<00:16, 585.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7256/16687 [00:12<00:16, 585.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7315/16687 [00:12<00:16, 574.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7373/16687 [00:12<00:16, 568.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7432/16687 [00:12<00:16, 574.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7490/16687 [00:13<00:16, 570.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7548/16687 [00:13<00:15, 571.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7606/16687 [00:13<00:15, 572.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7664/16687 [00:13<00:16, 561.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7721/16687 [00:13<00:15, 561.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7779/16687 [00:13<00:15, 565.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7838/16687 [00:13<00:15, 572.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7896/16687 [00:13<00:15, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7954/16687 [00:13<00:15, 573.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8013/16687 [00:13<00:15, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8072/16687 [00:14<00:14, 580.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8131/16687 [00:14<00:14, 579.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8189/16687 [00:14<00:14, 579.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8247/16687 [00:14<00:14, 571.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8307/16687 [00:14<00:14, 578.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8367/16687 [00:14<00:14, 582.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8427/16687 [00:14<00:14, 586.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8486/16687 [00:14<00:14, 581.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8546/16687 [00:14<00:13, 586.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8606/16687 [00:14<00:13, 588.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8666/16687 [00:15<00:13, 590.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8726/16687 [00:15<00:13, 591.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8786/16687 [00:15<00:13, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8846/16687 [00:15<00:13, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8906/16687 [00:15<00:13, 586.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8966/16687 [00:15<00:13, 589.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9027/16687 [00:15<00:12, 593.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▉              | 9087/16687 [00:15<00:12, 592.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9147/16687 [00:15<00:12, 592.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9207/16687 [00:15<00:12, 588.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9267/16687 [00:16<00:12, 591.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9329/16687 [00:16<00:12, 597.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9391/16687 [00:16<00:12, 601.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9452/16687 [00:16<00:12, 595.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9512/16687 [00:16<00:12, 585.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9571/16687 [00:16<00:12, 585.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9630/16687 [00:16<00:12, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9690/16687 [00:16<00:11, 586.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9750/16687 [00:16<00:11, 588.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9810/16687 [00:16<00:11, 589.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9872/16687 [00:17<00:11, 595.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9932/16687 [00:17<00:11, 593.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9992/16687 [00:17<00:11, 591.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10052/16687 [00:17<00:11, 587.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10111/16687 [00:17<00:11, 582.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10172/16687 [00:17<00:11, 589.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10231/16687 [00:17<00:11, 586.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10291/16687 [00:17<00:10, 588.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10350/16687 [00:17<00:10, 586.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10409/16687 [00:18<00:11, 568.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10466/16687 [00:18<00:11, 557.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10525/16687 [00:18<00:10, 565.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10584/16687 [00:18<00:10, 571.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10643/16687 [00:18<00:10, 575.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10702/16687 [00:18<00:10, 576.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10761/16687 [00:18<00:10, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10820/16687 [00:18<00:10, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10879/16687 [00:18<00:09, 581.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10938/16687 [00:18<00:09, 582.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10997/16687 [00:19<00:09, 583.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11056/16687 [00:19<00:09, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11115/16687 [00:19<00:09, 580.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11174/16687 [00:19<00:09, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11233/16687 [00:19<00:09, 581.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11292/16687 [00:19<00:09, 561.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11349/16687 [00:19<00:09, 561.69batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  68%|████████████████████▌         | 11408/16687 [00:19<00:09, 568.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11467/16687 [00:19<00:09, 572.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11526/16687 [00:19<00:08, 575.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11585/16687 [00:20<00:08, 577.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11644/16687 [00:20<00:08, 579.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11703/16687 [00:20<00:08, 581.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11762/16687 [00:20<00:08, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11821/16687 [00:20<00:08, 583.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11880/16687 [00:20<00:08, 578.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11940/16687 [00:20<00:08, 583.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11999/16687 [00:20<00:08, 579.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12058/16687 [00:20<00:07, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12117/16687 [00:20<00:07, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12177/16687 [00:21<00:07, 584.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12237/16687 [00:21<00:07, 586.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12297/16687 [00:21<00:07, 588.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12359/16687 [00:21<00:07, 594.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12419/16687 [00:21<00:07, 593.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12479/16687 [00:21<00:07, 590.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12539/16687 [00:21<00:07, 588.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12598/16687 [00:21<00:07, 570.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12657/16687 [00:21<00:07, 574.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12716/16687 [00:22<00:06, 577.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12775/16687 [00:22<00:06, 579.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12834/16687 [00:22<00:06, 581.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12893/16687 [00:22<00:06, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12952/16687 [00:22<00:06, 582.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13011/16687 [00:22<00:06, 582.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13070/16687 [00:22<00:06, 573.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13129/16687 [00:22<00:06, 577.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13188/16687 [00:22<00:06, 580.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13247/16687 [00:22<00:05, 582.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13306/16687 [00:23<00:05, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13365/16687 [00:23<00:05, 582.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13424/16687 [00:23<00:05, 581.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13483/16687 [00:23<00:05, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13542/16687 [00:23<00:05, 584.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13601/16687 [00:23<00:05, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13660/16687 [00:23<00:05, 575.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13719/16687 [00:23<00:05, 579.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13778/16687 [00:23<00:04, 582.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13837/16687 [00:23<00:04, 584.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13896/16687 [00:24<00:04, 585.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13955/16687 [00:24<00:04, 586.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14014/16687 [00:24<00:04, 587.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14073/16687 [00:24<00:04, 587.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14132/16687 [00:24<00:04, 588.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14191/16687 [00:24<00:04, 584.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14250/16687 [00:24<00:04, 584.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14309/16687 [00:24<00:04, 556.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14366/16687 [00:24<00:04, 558.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14425/16687 [00:24<00:03, 567.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14484/16687 [00:25<00:03, 572.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14543/16687 [00:25<00:03, 576.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14602/16687 [00:25<00:03, 579.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14661/16687 [00:25<00:03, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14720/16687 [00:25<00:03, 582.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14779/16687 [00:25<00:03, 583.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14838/16687 [00:25<00:03, 584.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14897/16687 [00:25<00:03, 583.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14956/16687 [00:25<00:02, 583.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15015/16687 [00:25<00:02, 584.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15074/16687 [00:26<00:02, 581.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15134/16687 [00:26<00:02, 585.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15193/16687 [00:26<00:02, 576.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15251/16687 [00:26<00:02, 574.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15309/16687 [00:26<00:02, 572.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15368/16687 [00:26<00:02, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15428/16687 [00:26<00:02, 580.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15488/16687 [00:26<00:02, 584.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15548/16687 [00:26<00:01, 586.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15608/16687 [00:26<00:01, 588.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15667/16687 [00:27<00:01, 587.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15726/16687 [00:27<00:01, 586.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15785/16687 [00:27<00:01, 585.96batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15844/16687 [00:27<00:01, 585.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15903/16687 [00:27<00:01, 585.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15962/16687 [00:27<00:01, 586.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16021/16687 [00:27<00:01, 585.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16080/16687 [00:27<00:01, 580.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16139/16687 [00:27<00:00, 581.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16198/16687 [00:27<00:00, 581.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16257/16687 [00:28<00:00, 581.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16316/16687 [00:28<00:00, 581.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16375/16687 [00:28<00:00, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16434/16687 [00:28<00:00, 582.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16493/16687 [00:28<00:00, 582.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16552/16687 [00:28<00:00, 580.98batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16611/16687 [00:28<00:00, 576.80batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16669/16687 [00:28<00:00, 563.36batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██▊           | 4/20 [01:55<07:42, 28.89s/epoch, loss=0.7, prev_loss=0.7]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 15/16687 [00:00<01:52, 148.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 66/16687 [00:00<00:46, 358.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 126/16687 [00:00<00:35, 466.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 183/16687 [00:00<00:32, 506.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 243/16687 [00:00<00:30, 538.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 304/16687 [00:00<00:29, 560.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 365/16687 [00:00<00:28, 574.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 423/16687 [00:00<00:28, 573.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 482/16687 [00:00<00:28, 576.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 540/16687 [00:01<00:28, 567.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 597/16687 [00:01<00:28, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 656/16687 [00:01<00:28, 569.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 716/16687 [00:01<00:27, 578.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 774/16687 [00:01<00:27, 575.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 832/16687 [00:01<00:27, 572.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 890/16687 [00:01<00:27, 569.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 949/16687 [00:01<00:27, 574.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                             | 1007/16687 [00:01<00:27, 565.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1066/16687 [00:01<00:27, 570.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1125/16687 [00:02<00:27, 575.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1184/16687 [00:02<00:26, 578.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1243/16687 [00:02<00:26, 580.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1302/16687 [00:02<00:26, 582.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1361/16687 [00:02<00:26, 578.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1420/16687 [00:02<00:26, 580.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1479/16687 [00:02<00:26, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1538/16687 [00:02<00:25, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1597/16687 [00:02<00:26, 576.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1655/16687 [00:02<00:26, 572.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1715/16687 [00:03<00:25, 578.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1774/16687 [00:03<00:25, 580.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1833/16687 [00:03<00:25, 582.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1892/16687 [00:03<00:25, 582.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1951/16687 [00:03<00:25, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2010/16687 [00:03<00:25, 586.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2069/16687 [00:03<00:24, 587.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2128/16687 [00:03<00:24, 587.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2187/16687 [00:03<00:25, 577.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2245/16687 [00:03<00:25, 576.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2303/16687 [00:04<00:24, 576.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2361/16687 [00:04<00:25, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2418/16687 [00:04<00:25, 554.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2474/16687 [00:04<00:25, 548.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2533/16687 [00:04<00:25, 559.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2590/16687 [00:04<00:25, 553.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2649/16687 [00:04<00:24, 562.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2706/16687 [00:04<00:24, 563.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2763/16687 [00:04<00:24, 562.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2820/16687 [00:04<00:24, 561.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2880/16687 [00:05<00:24, 572.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2941/16687 [00:05<00:23, 583.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3000/16687 [00:05<00:23, 577.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3059/16687 [00:05<00:23, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3118/16687 [00:05<00:23, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3177/16687 [00:05<00:23, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3236/16687 [00:05<00:23, 579.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3294/16687 [00:05<00:23, 577.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3352/16687 [00:05<00:23, 572.05batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  20%|██████▎                        | 3410/16687 [00:06<00:23, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3469/16687 [00:06<00:22, 575.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3528/16687 [00:06<00:22, 577.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3587/16687 [00:06<00:22, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3646/16687 [00:06<00:22, 580.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3705/16687 [00:06<00:22, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3764/16687 [00:06<00:22, 581.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3823/16687 [00:06<00:22, 581.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3882/16687 [00:06<00:22, 581.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3941/16687 [00:06<00:22, 573.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3999/16687 [00:07<00:22, 570.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4057/16687 [00:07<00:22, 557.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4113/16687 [00:07<00:22, 556.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4169/16687 [00:07<00:22, 555.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4225/16687 [00:07<00:22, 555.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4283/16687 [00:07<00:22, 562.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4340/16687 [00:07<00:21, 562.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4397/16687 [00:07<00:22, 556.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4454/16687 [00:07<00:21, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4511/16687 [00:07<00:21, 562.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4568/16687 [00:08<00:21, 552.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4628/16687 [00:08<00:21, 565.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4689/16687 [00:08<00:20, 577.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4747/16687 [00:08<00:20, 573.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4805/16687 [00:08<00:20, 567.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4862/16687 [00:08<00:21, 558.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████▏                     | 4918/16687 [00:08<00:21, 551.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4974/16687 [00:08<00:21, 550.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5035/16687 [00:08<00:20, 566.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5093/16687 [00:08<00:20, 569.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5152/16687 [00:09<00:20, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5210/16687 [00:09<00:19, 573.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5268/16687 [00:09<00:19, 572.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5326/16687 [00:09<00:19, 572.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5385/16687 [00:09<00:19, 576.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5443/16687 [00:09<00:19, 572.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5504/16687 [00:09<00:19, 582.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5564/16687 [00:09<00:19, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5623/16687 [00:09<00:19, 577.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5681/16687 [00:10<00:19, 564.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5739/16687 [00:10<00:19, 567.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5800/16687 [00:10<00:18, 578.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5859/16687 [00:10<00:18, 581.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5918/16687 [00:10<00:18, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5977/16687 [00:10<00:18, 584.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6036/16687 [00:10<00:18, 583.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6095/16687 [00:10<00:18, 583.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6154/16687 [00:10<00:18, 585.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6213/16687 [00:10<00:17, 584.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6272/16687 [00:11<00:18, 576.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6330/16687 [00:11<00:17, 577.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6391/16687 [00:11<00:17, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6450/16687 [00:11<00:17, 586.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6511/16687 [00:11<00:17, 591.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6572/16687 [00:11<00:16, 595.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6632/16687 [00:11<00:16, 594.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6692/16687 [00:11<00:16, 592.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6752/16687 [00:11<00:16, 591.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6812/16687 [00:11<00:17, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6870/16687 [00:12<00:17, 557.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▊                  | 6926/16687 [00:12<00:17, 549.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6983/16687 [00:12<00:17, 554.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7042/16687 [00:12<00:17, 563.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7101/16687 [00:12<00:16, 568.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7161/16687 [00:12<00:16, 575.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7222/16687 [00:12<00:16, 584.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7283/16687 [00:12<00:15, 590.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7344/16687 [00:12<00:15, 595.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7404/16687 [00:12<00:15, 590.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7464/16687 [00:13<00:15, 588.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7523/16687 [00:13<00:16, 567.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7580/16687 [00:13<00:16, 565.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7641/16687 [00:13<00:15, 576.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7702/16687 [00:13<00:15, 585.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7763/16687 [00:13<00:15, 591.51batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  47%|██████████████▌                | 7824/16687 [00:13<00:14, 595.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7885/16687 [00:13<00:14, 599.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7945/16687 [00:13<00:14, 597.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8005/16687 [00:13<00:14, 578.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8064/16687 [00:14<00:14, 578.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8122/16687 [00:14<00:14, 577.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8180/16687 [00:14<00:15, 564.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8238/16687 [00:14<00:14, 566.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8296/16687 [00:14<00:14, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8355/16687 [00:14<00:14, 574.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▋               | 8413/16687 [00:14<00:14, 576.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8472/16687 [00:14<00:14, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8530/16687 [00:14<00:14, 558.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8588/16687 [00:15<00:14, 564.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8647/16687 [00:15<00:14, 569.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8705/16687 [00:15<00:14, 569.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8764/16687 [00:15<00:13, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8823/16687 [00:15<00:13, 576.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8882/16687 [00:15<00:13, 578.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8941/16687 [00:15<00:13, 579.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 9000/16687 [00:15<00:13, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9059/16687 [00:15<00:13, 580.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9118/16687 [00:15<00:13, 581.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9177/16687 [00:16<00:13, 573.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9236/16687 [00:16<00:12, 577.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9295/16687 [00:16<00:12, 578.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9354/16687 [00:16<00:12, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9413/16687 [00:16<00:12, 583.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9473/16687 [00:16<00:12, 586.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9532/16687 [00:16<00:12, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9591/16687 [00:16<00:12, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9650/16687 [00:16<00:12, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9709/16687 [00:16<00:11, 582.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9768/16687 [00:17<00:12, 572.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9829/16687 [00:17<00:11, 580.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9888/16687 [00:17<00:11, 581.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9947/16687 [00:17<00:11, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10006/16687 [00:17<00:11, 581.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10065/16687 [00:17<00:11, 576.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10123/16687 [00:17<00:11, 574.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10182/16687 [00:17<00:11, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10241/16687 [00:17<00:11, 579.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10300/16687 [00:17<00:10, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10359/16687 [00:18<00:11, 567.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10416/16687 [00:18<00:11, 557.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10475/16687 [00:18<00:10, 565.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10532/16687 [00:18<00:10, 561.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10589/16687 [00:18<00:11, 553.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10648/16687 [00:18<00:10, 562.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10707/16687 [00:18<00:10, 569.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▎          | 10766/16687 [00:18<00:10, 573.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10825/16687 [00:18<00:10, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10884/16687 [00:19<00:10, 578.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10942/16687 [00:19<00:10, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10999/16687 [00:19<00:10, 560.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11059/16687 [00:19<00:09, 569.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11116/16687 [00:19<00:09, 563.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11175/16687 [00:19<00:09, 570.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11234/16687 [00:19<00:09, 573.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11293/16687 [00:19<00:09, 575.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11352/16687 [00:19<00:09, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11411/16687 [00:19<00:09, 578.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11470/16687 [00:20<00:09, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11528/16687 [00:20<00:08, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11587/16687 [00:20<00:08, 579.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11646/16687 [00:20<00:08, 582.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11705/16687 [00:20<00:08, 584.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████▏        | 11764/16687 [00:20<00:08, 585.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11823/16687 [00:20<00:08, 586.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11882/16687 [00:20<00:08, 587.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11941/16687 [00:20<00:08, 587.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12000/16687 [00:20<00:08, 569.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12059/16687 [00:21<00:08, 573.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12118/16687 [00:21<00:07, 575.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12177/16687 [00:21<00:07, 578.39batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12236/16687 [00:21<00:07, 580.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12295/16687 [00:21<00:07, 582.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12354/16687 [00:21<00:07, 583.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12413/16687 [00:21<00:07, 584.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12472/16687 [00:21<00:07, 577.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12531/16687 [00:21<00:07, 579.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12590/16687 [00:21<00:07, 579.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12649/16687 [00:22<00:06, 581.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12708/16687 [00:22<00:06, 575.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12767/16687 [00:22<00:06, 578.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12826/16687 [00:22<00:06, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12885/16687 [00:22<00:06, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12944/16687 [00:22<00:06, 584.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13003/16687 [00:22<00:06, 585.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13064/16687 [00:22<00:06, 592.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13124/16687 [00:22<00:06, 584.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13183/16687 [00:22<00:06, 583.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13242/16687 [00:23<00:05, 579.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13300/16687 [00:23<00:05, 572.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13358/16687 [00:23<00:05, 574.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13417/16687 [00:23<00:05, 578.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13476/16687 [00:23<00:05, 580.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13535/16687 [00:23<00:05, 581.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13594/16687 [00:23<00:05, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13653/16687 [00:23<00:05, 583.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13712/16687 [00:23<00:05, 583.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13771/16687 [00:23<00:05, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13830/16687 [00:24<00:04, 583.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13889/16687 [00:24<00:04, 569.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13949/16687 [00:24<00:04, 576.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14009/16687 [00:24<00:04, 582.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14070/16687 [00:24<00:04, 590.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14130/16687 [00:24<00:04, 590.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14191/16687 [00:24<00:04, 595.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14251/16687 [00:24<00:04, 594.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14312/16687 [00:24<00:03, 597.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14372/16687 [00:25<00:03, 593.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14432/16687 [00:25<00:03, 585.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14491/16687 [00:25<00:03, 569.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14549/16687 [00:25<00:03, 571.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14607/16687 [00:25<00:03, 566.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14664/16687 [00:25<00:03, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14722/16687 [00:25<00:03, 565.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14779/16687 [00:25<00:03, 565.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14839/16687 [00:25<00:03, 574.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14898/16687 [00:25<00:03, 576.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14957/16687 [00:26<00:02, 579.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15017/16687 [00:26<00:02, 584.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15076/16687 [00:26<00:02, 581.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15135/16687 [00:26<00:02, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15194/16687 [00:26<00:02, 579.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15253/16687 [00:26<00:02, 581.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15312/16687 [00:26<00:02, 582.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15371/16687 [00:26<00:02, 584.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15432/16687 [00:26<00:02, 591.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15492/16687 [00:26<00:02, 590.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15552/16687 [00:27<00:01, 587.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15611/16687 [00:27<00:01, 586.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15670/16687 [00:27<00:01, 569.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15729/16687 [00:27<00:01, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15788/16687 [00:27<00:01, 575.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15847/16687 [00:27<00:01, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15906/16687 [00:27<00:01, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15964/16687 [00:27<00:01, 578.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16024/16687 [00:27<00:01, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16083/16687 [00:27<00:01, 583.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16142/16687 [00:28<00:00, 574.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16201/16687 [00:28<00:00, 576.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16260/16687 [00:28<00:00, 577.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16319/16687 [00:28<00:00, 578.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16378/16687 [00:28<00:00, 579.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16437/16687 [00:28<00:00, 580.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16496/16687 [00:28<00:00, 581.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16555/16687 [00:28<00:00, 581.81batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16614/16687 [00:28<00:00, 581.81batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16673/16687 [00:28<00:00, 581.90batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██▊           | 4/20 [02:24<07:42, 28.89s/epoch, loss=0.7, prev_loss=0.7]\u001b[AINFO:pykeen.evaluation.evaluator:Evaluation took 44.90s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 5: 0.00323996733813273. Saved model weights to /work/.data/pykeen/checkpoints/best-model-weights-9869f37a-379e-45f6-bc48-57d0b6cd18af.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 5.\n",
      "Training epochs on cuda:0:  25%|███▌          | 5/20 [03:09<11:18, 45.20s/epoch, loss=0.7, prev_loss=0.7]\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 13/16687 [00:00<02:10, 128.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 69/16687 [00:00<00:43, 380.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 125/16687 [00:00<00:35, 461.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 183/16687 [00:00<00:32, 504.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 237/16687 [00:00<00:31, 517.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 292/16687 [00:00<00:31, 527.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 348/16687 [00:00<00:30, 537.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 405/16687 [00:00<00:29, 547.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 460/16687 [00:00<00:29, 543.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 515/16687 [00:01<00:29, 545.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 572/16687 [00:01<00:29, 551.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 631/16687 [00:01<00:28, 560.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 688/16687 [00:01<00:28, 562.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▍                              | 747/16687 [00:01<00:28, 568.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 806/16687 [00:01<00:27, 571.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 865/16687 [00:01<00:27, 574.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 923/16687 [00:01<00:27, 564.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                              | 982/16687 [00:01<00:27, 569.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1039/16687 [00:01<00:27, 563.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1096/16687 [00:02<00:27, 564.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1153/16687 [00:02<00:27, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1210/16687 [00:02<00:27, 563.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▎                            | 1267/16687 [00:02<00:27, 560.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1326/16687 [00:02<00:27, 566.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1385/16687 [00:02<00:26, 572.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1443/16687 [00:02<00:26, 567.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1500/16687 [00:02<00:27, 558.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1556/16687 [00:02<00:27, 556.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1613/16687 [00:02<00:26, 558.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1669/16687 [00:03<00:26, 558.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1726/16687 [00:03<00:26, 558.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1782/16687 [00:03<00:26, 558.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1842/16687 [00:03<00:26, 568.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▌                           | 1900/16687 [00:03<00:25, 571.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1958/16687 [00:03<00:25, 573.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2019/16687 [00:03<00:25, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2080/16687 [00:03<00:24, 589.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2139/16687 [00:03<00:24, 586.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2198/16687 [00:03<00:24, 584.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2257/16687 [00:04<00:24, 582.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2316/16687 [00:04<00:24, 578.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2374/16687 [00:04<00:25, 559.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2431/16687 [00:04<00:25, 549.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2487/16687 [00:04<00:26, 543.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2543/16687 [00:04<00:25, 547.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2601/16687 [00:04<00:25, 556.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2660/16687 [00:04<00:24, 564.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2719/16687 [00:04<00:24, 570.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2778/16687 [00:04<00:24, 573.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2837/16687 [00:05<00:24, 576.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2896/16687 [00:05<00:23, 579.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2954/16687 [00:05<00:23, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3013/16687 [00:05<00:23, 581.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3072/16687 [00:05<00:23, 583.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3131/16687 [00:05<00:23, 585.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3192/16687 [00:05<00:22, 589.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3252/16687 [00:05<00:22, 590.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3313/16687 [00:05<00:22, 594.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3373/16687 [00:06<00:22, 584.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3432/16687 [00:06<00:22, 584.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3491/16687 [00:06<00:23, 572.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3549/16687 [00:06<00:22, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3609/16687 [00:06<00:22, 579.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3667/16687 [00:06<00:23, 563.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3724/16687 [00:06<00:23, 562.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3781/16687 [00:06<00:22, 563.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3839/16687 [00:06<00:22, 568.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3898/16687 [00:06<00:22, 572.49batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  24%|███████▎                       | 3956/16687 [00:07<00:22, 571.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4014/16687 [00:07<00:22, 570.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4073/16687 [00:07<00:21, 574.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4131/16687 [00:07<00:21, 575.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4191/16687 [00:07<00:21, 579.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▉                       | 4252/16687 [00:07<00:21, 587.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4311/16687 [00:07<00:21, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4370/16687 [00:07<00:20, 586.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4429/16687 [00:07<00:20, 585.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4488/16687 [00:07<00:20, 585.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4547/16687 [00:08<00:20, 581.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4607/16687 [00:08<00:20, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4666/16687 [00:08<00:20, 581.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4725/16687 [00:08<00:20, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4783/16687 [00:08<00:20, 567.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4843/16687 [00:08<00:20, 574.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4901/16687 [00:08<00:20, 571.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4959/16687 [00:08<00:20, 569.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5016/16687 [00:08<00:20, 565.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5074/16687 [00:08<00:20, 567.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5131/16687 [00:09<00:20, 568.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5188/16687 [00:09<00:20, 554.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5247/16687 [00:09<00:20, 564.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5307/16687 [00:09<00:19, 573.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5366/16687 [00:09<00:19, 577.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5425/16687 [00:09<00:19, 581.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5484/16687 [00:09<00:19, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5542/16687 [00:09<00:19, 573.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5600/16687 [00:09<00:19, 568.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5658/16687 [00:09<00:19, 572.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5716/16687 [00:10<00:19, 567.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5773/16687 [00:10<00:19, 553.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5833/16687 [00:10<00:19, 564.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5892/16687 [00:10<00:18, 571.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5953/16687 [00:10<00:18, 580.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6012/16687 [00:10<00:18, 581.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6071/16687 [00:10<00:18, 581.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6130/16687 [00:10<00:18, 582.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6189/16687 [00:10<00:18, 582.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6248/16687 [00:11<00:17, 582.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6307/16687 [00:11<00:18, 575.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6365/16687 [00:11<00:18, 571.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6423/16687 [00:11<00:18, 567.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6480/16687 [00:11<00:18, 559.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6537/16687 [00:11<00:18, 561.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6596/16687 [00:11<00:17, 569.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6655/16687 [00:11<00:17, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6714/16687 [00:11<00:17, 579.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6773/16687 [00:11<00:17, 582.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6832/16687 [00:12<00:16, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6891/16687 [00:12<00:16, 584.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6950/16687 [00:12<00:16, 576.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7009/16687 [00:12<00:16, 579.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7068/16687 [00:12<00:16, 581.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7127/16687 [00:12<00:16, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7186/16687 [00:12<00:16, 585.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7245/16687 [00:12<00:16, 586.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7304/16687 [00:12<00:15, 586.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7363/16687 [00:12<00:15, 587.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7422/16687 [00:13<00:15, 587.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7481/16687 [00:13<00:15, 587.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7540/16687 [00:13<00:15, 578.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7599/16687 [00:13<00:15, 581.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7658/16687 [00:13<00:15, 583.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7717/16687 [00:13<00:15, 585.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7776/16687 [00:13<00:15, 586.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7837/16687 [00:13<00:14, 593.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7897/16687 [00:13<00:15, 585.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7957/16687 [00:13<00:14, 589.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8016/16687 [00:14<00:14, 586.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|███████████████                | 8075/16687 [00:14<00:14, 585.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8134/16687 [00:14<00:14, 577.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8192/16687 [00:14<00:14, 576.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8250/16687 [00:14<00:14, 576.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8309/16687 [00:14<00:14, 580.61batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  50%|███████████████▌               | 8368/16687 [00:14<00:14, 583.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8427/16687 [00:14<00:14, 585.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8486/16687 [00:14<00:13, 586.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8545/16687 [00:14<00:13, 587.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|███████████████▉               | 8604/16687 [00:15<00:13, 587.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8663/16687 [00:15<00:14, 566.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8721/16687 [00:15<00:14, 568.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8778/16687 [00:15<00:13, 567.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8838/16687 [00:15<00:13, 575.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8899/16687 [00:15<00:13, 584.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8958/16687 [00:15<00:13, 584.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9017/16687 [00:15<00:13, 586.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9076/16687 [00:15<00:12, 586.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9135/16687 [00:15<00:12, 587.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9194/16687 [00:16<00:12, 580.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9253/16687 [00:16<00:12, 582.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9312/16687 [00:16<00:12, 584.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9371/16687 [00:16<00:12, 571.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9430/16687 [00:16<00:12, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9489/16687 [00:16<00:12, 577.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9547/16687 [00:16<00:12, 569.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9606/16687 [00:16<00:12, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9665/16687 [00:16<00:12, 576.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9724/16687 [00:17<00:12, 578.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9782/16687 [00:17<00:12, 572.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9840/16687 [00:17<00:11, 573.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9898/16687 [00:17<00:11, 573.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9956/16687 [00:17<00:11, 565.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10013/16687 [00:17<00:11, 565.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10072/16687 [00:17<00:11, 572.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10133/16687 [00:17<00:11, 583.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10194/16687 [00:17<00:10, 591.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10255/16687 [00:17<00:10, 596.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10315/16687 [00:18<00:10, 591.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10375/16687 [00:18<00:10, 583.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10434/16687 [00:18<00:10, 583.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10493/16687 [00:18<00:10, 583.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10552/16687 [00:18<00:10, 570.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10611/16687 [00:18<00:10, 573.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10670/16687 [00:18<00:10, 576.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10729/16687 [00:18<00:10, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10788/16687 [00:18<00:10, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10847/16687 [00:18<00:10, 580.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10906/16687 [00:19<00:09, 581.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10965/16687 [00:19<00:09, 581.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11024/16687 [00:19<00:09, 581.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11083/16687 [00:19<00:09, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11141/16687 [00:19<00:09, 571.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11199/16687 [00:19<00:09, 570.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11258/16687 [00:19<00:09, 574.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11317/16687 [00:19<00:09, 577.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11376/16687 [00:19<00:09, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11435/16687 [00:19<00:09, 580.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11494/16687 [00:20<00:08, 581.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11553/16687 [00:20<00:08, 581.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11612/16687 [00:20<00:08, 581.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11671/16687 [00:20<00:08, 583.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11730/16687 [00:20<00:08, 568.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11787/16687 [00:20<00:08, 556.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11843/16687 [00:20<00:08, 557.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11902/16687 [00:20<00:08, 565.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11961/16687 [00:20<00:08, 570.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12020/16687 [00:20<00:08, 574.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12079/16687 [00:21<00:07, 577.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12138/16687 [00:21<00:07, 578.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12196/16687 [00:21<00:07, 575.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12254/16687 [00:21<00:07, 570.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12312/16687 [00:21<00:07, 558.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12369/16687 [00:21<00:07, 559.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12426/16687 [00:21<00:07, 551.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12485/16687 [00:21<00:07, 561.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12542/16687 [00:21<00:07, 550.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▋       | 12598/16687 [00:22<00:07, 550.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12655/16687 [00:22<00:07, 554.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12714/16687 [00:22<00:07, 564.56batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12774/16687 [00:22<00:06, 572.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12832/16687 [00:22<00:06, 565.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12891/16687 [00:22<00:06, 572.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12950/16687 [00:22<00:06, 577.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13009/16687 [00:22<00:06, 580.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13068/16687 [00:22<00:06, 583.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▌      | 13127/16687 [00:22<00:06, 584.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13186/16687 [00:23<00:05, 586.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13245/16687 [00:23<00:05, 587.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13304/16687 [00:23<00:05, 580.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13363/16687 [00:23<00:05, 583.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13422/16687 [00:23<00:05, 573.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13481/16687 [00:23<00:05, 578.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13540/16687 [00:23<00:05, 581.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▍     | 13599/16687 [00:23<00:05, 583.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13658/16687 [00:23<00:05, 585.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13717/16687 [00:23<00:05, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13776/16687 [00:24<00:04, 587.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13835/16687 [00:24<00:04, 587.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13894/16687 [00:24<00:04, 582.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13953/16687 [00:24<00:04, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14012/16687 [00:24<00:04, 563.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14072/16687 [00:24<00:04, 572.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14133/16687 [00:24<00:04, 582.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14194/16687 [00:24<00:04, 589.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14255/16687 [00:24<00:04, 594.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14315/16687 [00:24<00:03, 595.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14375/16687 [00:25<00:03, 595.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14435/16687 [00:25<00:03, 587.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14494/16687 [00:25<00:03, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14552/16687 [00:25<00:03, 568.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14609/16687 [00:25<00:03, 565.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14669/16687 [00:25<00:03, 574.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14728/16687 [00:25<00:03, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14787/16687 [00:25<00:03, 578.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14846/16687 [00:25<00:03, 579.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14905/16687 [00:26<00:03, 580.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14964/16687 [00:26<00:02, 581.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15023/16687 [00:26<00:02, 581.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15082/16687 [00:26<00:02, 581.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15141/16687 [00:26<00:02, 581.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15200/16687 [00:26<00:02, 581.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15259/16687 [00:26<00:02, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15318/16687 [00:26<00:02, 582.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15377/16687 [00:26<00:02, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15436/16687 [00:26<00:02, 583.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15495/16687 [00:27<00:02, 583.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15554/16687 [00:27<00:01, 583.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15613/16687 [00:27<00:01, 583.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15672/16687 [00:27<00:01, 583.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15731/16687 [00:27<00:01, 579.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15790/16687 [00:27<00:01, 581.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15849/16687 [00:27<00:01, 583.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15908/16687 [00:27<00:01, 585.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15967/16687 [00:27<00:01, 586.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16026/16687 [00:27<00:01, 585.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16085/16687 [00:28<00:01, 586.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16144/16687 [00:28<00:00, 584.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16203/16687 [00:28<00:00, 573.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16262/16687 [00:28<00:00, 576.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16320/16687 [00:28<00:00, 573.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16378/16687 [00:28<00:00, 564.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▌| 16439/16687 [00:28<00:00, 575.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16500/16687 [00:28<00:00, 584.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16561/16687 [00:28<00:00, 590.78batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16622/16687 [00:28<00:00, 595.39batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16683/16687 [00:29<00:00, 598.28batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  30%|███▌        | 6/20 [03:38<09:16, 39.77s/epoch, loss=0.701, prev_loss=0.7]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:32, 179.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 72/16687 [00:00<00:42, 388.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 130/16687 [00:00<00:34, 474.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 187/16687 [00:00<00:32, 509.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 245/16687 [00:00<00:30, 532.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 304/16687 [00:00<00:29, 549.08batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   2%|▋                               | 363/16687 [00:00<00:29, 561.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▊                               | 421/16687 [00:00<00:28, 566.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 479/16687 [00:00<00:28, 570.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 537/16687 [00:01<00:28, 573.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 595/16687 [00:01<00:27, 574.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 653/16687 [00:01<00:27, 575.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 711/16687 [00:01<00:27, 574.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 769/16687 [00:01<00:27, 575.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 827/16687 [00:01<00:27, 576.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 885/16687 [00:01<00:27, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 943/16687 [00:01<00:27, 578.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                             | 1001/16687 [00:01<00:27, 578.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1060/16687 [00:01<00:26, 578.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1119/16687 [00:02<00:26, 579.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1178/16687 [00:02<00:26, 581.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1237/16687 [00:02<00:26, 580.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1296/16687 [00:02<00:26, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1354/16687 [00:02<00:26, 578.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1412/16687 [00:02<00:26, 578.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1470/16687 [00:02<00:26, 578.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1528/16687 [00:02<00:26, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1586/16687 [00:02<00:26, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1644/16687 [00:02<00:25, 579.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1702/16687 [00:03<00:25, 579.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1760/16687 [00:03<00:25, 579.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1818/16687 [00:03<00:26, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1876/16687 [00:03<00:26, 567.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1933/16687 [00:03<00:26, 561.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1990/16687 [00:03<00:26, 559.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2048/16687 [00:03<00:25, 564.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2106/16687 [00:03<00:25, 568.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2163/16687 [00:03<00:25, 563.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2220/16687 [00:03<00:25, 563.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2278/16687 [00:04<00:25, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2337/16687 [00:04<00:25, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2395/16687 [00:04<00:24, 574.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2454/16687 [00:04<00:24, 577.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2512/16687 [00:04<00:25, 560.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2570/16687 [00:04<00:25, 564.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2629/16687 [00:04<00:24, 570.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2687/16687 [00:04<00:24, 567.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2744/16687 [00:04<00:24, 558.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2801/16687 [00:04<00:24, 559.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2858/16687 [00:05<00:24, 559.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▍                         | 2914/16687 [00:05<00:24, 557.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2972/16687 [00:05<00:24, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3030/16687 [00:05<00:24, 565.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3087/16687 [00:05<00:24, 555.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3143/16687 [00:05<00:24, 554.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3202/16687 [00:05<00:23, 562.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3261/16687 [00:05<00:23, 567.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3320/16687 [00:05<00:23, 571.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3379/16687 [00:05<00:23, 574.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3438/16687 [00:06<00:22, 577.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3496/16687 [00:06<00:22, 577.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3555/16687 [00:06<00:22, 578.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3614/16687 [00:06<00:22, 581.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3673/16687 [00:06<00:22, 569.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3733/16687 [00:06<00:22, 575.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3794/16687 [00:06<00:22, 585.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3853/16687 [00:06<00:21, 585.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▎                       | 3912/16687 [00:06<00:21, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3971/16687 [00:07<00:21, 585.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 4030/16687 [00:07<00:21, 575.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4088/16687 [00:07<00:22, 557.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4147/16687 [00:07<00:22, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4204/16687 [00:07<00:22, 562.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4261/16687 [00:07<00:22, 559.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4319/16687 [00:07<00:21, 564.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4377/16687 [00:07<00:21, 567.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▏                      | 4435/16687 [00:07<00:21, 569.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4494/16687 [00:07<00:21, 573.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4553/16687 [00:08<00:21, 576.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4612/16687 [00:08<00:20, 578.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4671/16687 [00:08<00:20, 579.75batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  28%|████████▊                      | 4730/16687 [00:08<00:20, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4789/16687 [00:08<00:20, 581.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4848/16687 [00:08<00:20, 581.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4907/16687 [00:08<00:20, 566.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4964/16687 [00:08<00:21, 550.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5023/16687 [00:08<00:20, 559.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▍                     | 5081/16687 [00:08<00:20, 563.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5138/16687 [00:09<00:20, 558.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5196/16687 [00:09<00:20, 561.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▊                     | 5256/16687 [00:09<00:20, 570.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5314/16687 [00:09<00:19, 573.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5372/16687 [00:09<00:19, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████                     | 5430/16687 [00:09<00:19, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5488/16687 [00:09<00:19, 566.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5547/16687 [00:09<00:19, 571.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5606/16687 [00:09<00:19, 575.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5665/16687 [00:09<00:19, 577.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5723/16687 [00:10<00:18, 578.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▋                    | 5783/16687 [00:10<00:18, 582.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5842/16687 [00:10<00:18, 579.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5900/16687 [00:10<00:18, 570.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5959/16687 [00:10<00:18, 575.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6018/16687 [00:10<00:18, 577.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6076/16687 [00:10<00:18, 563.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6134/16687 [00:10<00:18, 566.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6194/16687 [00:10<00:18, 576.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6252/16687 [00:11<00:18, 576.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6311/16687 [00:11<00:17, 578.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6370/16687 [00:11<00:17, 579.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6428/16687 [00:11<00:17, 575.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6486/16687 [00:11<00:17, 572.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6545/16687 [00:11<00:17, 575.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6603/16687 [00:11<00:17, 574.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6661/16687 [00:11<00:17, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6718/16687 [00:11<00:17, 559.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6777/16687 [00:11<00:17, 566.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6836/16687 [00:12<00:17, 571.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6895/16687 [00:12<00:17, 574.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6954/16687 [00:12<00:16, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7012/16687 [00:12<00:16, 575.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7071/16687 [00:12<00:16, 579.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7130/16687 [00:12<00:16, 581.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7189/16687 [00:12<00:16, 564.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7246/16687 [00:12<00:16, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7303/16687 [00:12<00:16, 557.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7361/16687 [00:12<00:16, 563.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▊                 | 7420/16687 [00:13<00:16, 569.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7479/16687 [00:13<00:16, 573.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7538/16687 [00:13<00:15, 575.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████                 | 7596/16687 [00:13<00:15, 575.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7655/16687 [00:13<00:15, 577.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7714/16687 [00:13<00:15, 578.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7772/16687 [00:13<00:15, 576.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7830/16687 [00:13<00:15, 574.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7888/16687 [00:13<00:15, 575.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7947/16687 [00:13<00:15, 578.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 8006/16687 [00:14<00:14, 579.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8064/16687 [00:14<00:14, 579.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8122/16687 [00:14<00:15, 570.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8180/16687 [00:14<00:15, 563.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8237/16687 [00:14<00:15, 558.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8293/16687 [00:14<00:15, 556.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8349/16687 [00:14<00:15, 550.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8408/16687 [00:14<00:14, 558.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8467/16687 [00:14<00:14, 565.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8526/16687 [00:14<00:14, 571.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8585/16687 [00:15<00:14, 576.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8643/16687 [00:15<00:13, 577.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8701/16687 [00:15<00:13, 577.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▎              | 8759/16687 [00:15<00:13, 577.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8817/16687 [00:15<00:13, 577.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8875/16687 [00:15<00:13, 578.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▌              | 8933/16687 [00:15<00:13, 575.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8991/16687 [00:15<00:13, 562.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9048/16687 [00:15<00:13, 552.97batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  55%|████████████████▉              | 9104/16687 [00:16<00:13, 550.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9161/16687 [00:16<00:13, 554.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9222/16687 [00:16<00:13, 569.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9282/16687 [00:16<00:12, 577.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9340/16687 [00:16<00:12, 574.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9398/16687 [00:16<00:12, 562.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9456/16687 [00:16<00:12, 566.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9515/16687 [00:16<00:12, 571.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9574/16687 [00:16<00:12, 575.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9633/16687 [00:16<00:12, 578.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9692/16687 [00:17<00:12, 581.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9751/16687 [00:17<00:11, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9810/16687 [00:17<00:11, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9869/16687 [00:17<00:11, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9927/16687 [00:17<00:11, 564.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9984/16687 [00:17<00:12, 554.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10040/16687 [00:17<00:12, 551.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10101/16687 [00:17<00:11, 565.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10158/16687 [00:17<00:11, 557.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10214/16687 [00:17<00:11, 550.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▍           | 10271/16687 [00:18<00:11, 554.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10328/16687 [00:18<00:11, 558.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10386/16687 [00:18<00:11, 564.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10444/16687 [00:18<00:10, 567.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10502/16687 [00:18<00:10, 570.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10560/16687 [00:18<00:10, 573.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████           | 10618/16687 [00:18<00:10, 574.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10676/16687 [00:18<00:10, 575.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10734/16687 [00:18<00:10, 576.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10792/16687 [00:18<00:10, 577.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10850/16687 [00:19<00:10, 577.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10908/16687 [00:19<00:10, 577.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10966/16687 [00:19<00:09, 577.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11024/16687 [00:19<00:09, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11082/16687 [00:19<00:09, 576.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11140/16687 [00:19<00:09, 572.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11198/16687 [00:19<00:09, 573.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11257/16687 [00:19<00:09, 575.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11316/16687 [00:19<00:09, 578.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11375/16687 [00:19<00:09, 580.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11434/16687 [00:20<00:09, 582.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11493/16687 [00:20<00:08, 582.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11552/16687 [00:20<00:08, 583.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11611/16687 [00:20<00:08, 580.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11670/16687 [00:20<00:08, 571.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11728/16687 [00:20<00:08, 573.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11786/16687 [00:20<00:08, 575.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11844/16687 [00:20<00:08, 576.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11903/16687 [00:20<00:08, 577.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11961/16687 [00:20<00:08, 578.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12020/16687 [00:21<00:08, 578.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12078/16687 [00:21<00:08, 564.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12135/16687 [00:21<00:08, 561.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12193/16687 [00:21<00:07, 566.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12253/16687 [00:21<00:07, 576.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12314/16687 [00:21<00:07, 583.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12373/16687 [00:21<00:07, 579.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▎       | 12432/16687 [00:21<00:07, 581.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12493/16687 [00:21<00:07, 587.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12554/16687 [00:22<00:06, 591.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12614/16687 [00:22<00:06, 592.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12674/16687 [00:22<00:06, 590.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12734/16687 [00:22<00:06, 589.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12793/16687 [00:22<00:06, 578.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12852/16687 [00:22<00:06, 580.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12913/16687 [00:22<00:06, 586.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12973/16687 [00:22<00:06, 588.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13033/16687 [00:22<00:06, 589.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13093/16687 [00:22<00:06, 581.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13152/16687 [00:23<00:06, 581.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13211/16687 [00:23<00:06, 574.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13269/16687 [00:23<00:06, 566.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13327/16687 [00:23<00:05, 569.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13384/16687 [00:23<00:05, 567.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13441/16687 [00:23<00:05, 564.35batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13499/16687 [00:23<00:05, 568.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13557/16687 [00:23<00:05, 571.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13615/16687 [00:23<00:05, 573.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13673/16687 [00:23<00:05, 570.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13732/16687 [00:24<00:05, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13790/16687 [00:24<00:05, 561.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13851/16687 [00:24<00:04, 574.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|█████████████████████████     | 13909/16687 [00:24<00:04, 573.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13968/16687 [00:24<00:04, 576.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14026/16687 [00:24<00:04, 567.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14085/16687 [00:24<00:04, 571.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14143/16687 [00:24<00:04, 568.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14200/16687 [00:24<00:04, 564.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14257/16687 [00:24<00:04, 566.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14316/16687 [00:25<00:04, 571.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14375/16687 [00:25<00:04, 574.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▉    | 14434/16687 [00:25<00:03, 577.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14494/16687 [00:25<00:03, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14553/16687 [00:25<00:03, 577.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14612/16687 [00:25<00:03, 578.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14670/16687 [00:25<00:03, 577.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14728/16687 [00:25<00:03, 572.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14786/16687 [00:25<00:03, 560.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14843/16687 [00:26<00:03, 553.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14901/16687 [00:26<00:03, 560.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14960/16687 [00:26<00:03, 566.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 15018/16687 [00:26<00:02, 569.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15077/16687 [00:26<00:02, 573.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15136/16687 [00:26<00:02, 575.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15195/16687 [00:26<00:02, 578.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15254/16687 [00:26<00:02, 579.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15313/16687 [00:26<00:02, 580.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15372/16687 [00:26<00:02, 581.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15431/16687 [00:27<00:02, 582.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15490/16687 [00:27<00:02, 583.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15549/16687 [00:27<00:01, 582.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15608/16687 [00:27<00:01, 582.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15667/16687 [00:27<00:01, 584.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15726/16687 [00:27<00:01, 582.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15785/16687 [00:27<00:01, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15844/16687 [00:27<00:01, 581.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15903/16687 [00:27<00:01, 582.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15962/16687 [00:27<00:01, 583.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16021/16687 [00:28<00:01, 584.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16080/16687 [00:28<00:01, 585.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16139/16687 [00:28<00:00, 583.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16198/16687 [00:28<00:00, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16257/16687 [00:28<00:00, 580.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16316/16687 [00:28<00:00, 580.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16375/16687 [00:28<00:00, 581.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16434/16687 [00:28<00:00, 581.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16493/16687 [00:28<00:00, 582.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16552/16687 [00:28<00:00, 565.04batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16611/16687 [00:29<00:00, 571.04batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16670/16687 [00:29<00:00, 573.92batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  35%|███▌      | 7/20 [04:08<07:52, 36.37s/epoch, loss=0.701, prev_loss=0.701]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 17/16687 [00:00<01:39, 168.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 68/16687 [00:00<00:45, 367.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 123/16687 [00:00<00:37, 447.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 180/16687 [00:00<00:33, 493.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 237/16687 [00:00<00:31, 519.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 294/16687 [00:00<00:30, 535.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 354/16687 [00:00<00:29, 555.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 411/16687 [00:00<00:29, 557.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 471/16687 [00:00<00:28, 569.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 531/16687 [00:01<00:27, 577.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 592/16687 [00:01<00:27, 584.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 651/16687 [00:01<00:27, 585.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 710/16687 [00:01<00:27, 582.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 769/16687 [00:01<00:27, 574.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 827/16687 [00:01<00:27, 572.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 885/16687 [00:01<00:27, 571.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 943/16687 [00:01<00:27, 574.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                             | 1001/16687 [00:01<00:27, 575.66batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   6%|█▉                             | 1059/16687 [00:01<00:27, 576.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1117/16687 [00:02<00:27, 576.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1176/16687 [00:02<00:26, 578.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1234/16687 [00:02<00:26, 574.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1294/16687 [00:02<00:26, 581.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1353/16687 [00:02<00:26, 581.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1412/16687 [00:02<00:27, 561.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1469/16687 [00:02<00:27, 551.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1525/16687 [00:02<00:27, 545.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▉                            | 1583/16687 [00:02<00:27, 553.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1642/16687 [00:02<00:26, 562.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1701/16687 [00:03<00:26, 568.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1760/16687 [00:03<00:25, 574.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1818/16687 [00:03<00:25, 575.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1876/16687 [00:03<00:25, 576.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1934/16687 [00:03<00:25, 576.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 1992/16687 [00:03<00:25, 570.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2050/16687 [00:03<00:25, 567.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2108/16687 [00:03<00:25, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2166/16687 [00:03<00:25, 573.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2225/16687 [00:03<00:25, 577.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▏                          | 2284/16687 [00:04<00:24, 579.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2343/16687 [00:04<00:24, 580.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2403/16687 [00:04<00:24, 584.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2462/16687 [00:04<00:24, 570.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2521/16687 [00:04<00:24, 575.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▊                          | 2580/16687 [00:04<00:24, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2638/16687 [00:04<00:24, 571.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2696/16687 [00:04<00:24, 572.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████                          | 2755/16687 [00:04<00:24, 575.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2814/16687 [00:04<00:23, 578.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2873/16687 [00:05<00:23, 579.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2932/16687 [00:05<00:23, 581.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 2991/16687 [00:05<00:23, 576.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3049/16687 [00:05<00:24, 563.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3106/16687 [00:05<00:24, 563.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3163/16687 [00:05<00:24, 560.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3220/16687 [00:05<00:24, 551.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████                         | 3279/16687 [00:05<00:23, 561.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3340/16687 [00:05<00:23, 574.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3401/16687 [00:06<00:22, 583.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3461/16687 [00:06<00:22, 588.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3522/16687 [00:06<00:22, 592.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▋                        | 3582/16687 [00:06<00:22, 573.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3640/16687 [00:06<00:22, 571.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3698/16687 [00:06<00:23, 556.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3755/16687 [00:06<00:23, 559.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3814/16687 [00:06<00:22, 567.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3873/16687 [00:06<00:22, 572.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3932/16687 [00:06<00:22, 575.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3991/16687 [00:07<00:21, 577.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4049/16687 [00:07<00:21, 574.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4107/16687 [00:07<00:22, 567.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4166/16687 [00:07<00:21, 572.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4224/16687 [00:07<00:21, 569.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4282/16687 [00:07<00:21, 572.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4340/16687 [00:07<00:21, 574.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4398/16687 [00:07<00:21, 560.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4455/16687 [00:07<00:22, 550.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4511/16687 [00:07<00:22, 551.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4570/16687 [00:08<00:21, 559.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4629/16687 [00:08<00:21, 566.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4688/16687 [00:08<00:21, 570.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4747/16687 [00:08<00:20, 573.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4806/16687 [00:08<00:20, 576.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4865/16687 [00:08<00:20, 578.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4924/16687 [00:08<00:20, 579.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4982/16687 [00:08<00:20, 564.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5039/16687 [00:08<00:21, 552.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5095/16687 [00:09<00:20, 554.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5152/16687 [00:09<00:20, 557.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5209/16687 [00:09<00:20, 559.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5267/16687 [00:09<00:20, 565.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5325/16687 [00:09<00:19, 568.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5383/16687 [00:09<00:19, 570.57batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  33%|██████████                     | 5441/16687 [00:09<00:19, 572.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5499/16687 [00:09<00:19, 574.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5557/16687 [00:09<00:19, 562.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5615/16687 [00:09<00:19, 565.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5674/16687 [00:10<00:19, 569.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5732/16687 [00:10<00:19, 572.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5790/16687 [00:10<00:18, 574.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5848/16687 [00:10<00:18, 576.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5907/16687 [00:10<00:18, 580.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5966/16687 [00:10<00:18, 582.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6025/16687 [00:10<00:18, 584.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▎                   | 6084/16687 [00:10<00:18, 585.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6143/16687 [00:10<00:18, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▌                   | 6202/16687 [00:10<00:17, 582.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6261/16687 [00:11<00:17, 581.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6320/16687 [00:11<00:17, 581.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6379/16687 [00:11<00:17, 580.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|███████████▉                   | 6438/16687 [00:11<00:17, 580.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6497/16687 [00:11<00:17, 569.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6556/16687 [00:11<00:17, 573.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6615/16687 [00:11<00:17, 576.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6674/16687 [00:11<00:17, 577.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▌                  | 6732/16687 [00:11<00:17, 562.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6789/16687 [00:11<00:17, 555.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6850/16687 [00:12<00:17, 569.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6910/16687 [00:12<00:16, 575.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6970/16687 [00:12<00:16, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7029/16687 [00:12<00:16, 583.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████▏                 | 7088/16687 [00:12<00:16, 583.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7147/16687 [00:12<00:16, 583.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7206/16687 [00:12<00:16, 583.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▍                 | 7265/16687 [00:12<00:16, 583.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7324/16687 [00:12<00:16, 583.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7383/16687 [00:12<00:15, 582.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7442/16687 [00:13<00:15, 583.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7501/16687 [00:13<00:15, 583.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7560/16687 [00:13<00:15, 584.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7619/16687 [00:13<00:15, 583.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7678/16687 [00:13<00:15, 579.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7739/16687 [00:13<00:15, 586.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▍                | 7799/16687 [00:13<00:15, 588.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7859/16687 [00:13<00:14, 590.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▋                | 7919/16687 [00:13<00:14, 585.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7978/16687 [00:13<00:14, 582.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8037/16687 [00:14<00:14, 584.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8096/16687 [00:14<00:14, 584.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8155/16687 [00:14<00:14, 584.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8214/16687 [00:14<00:14, 577.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▎               | 8273/16687 [00:14<00:14, 580.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8332/16687 [00:14<00:14, 576.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8391/16687 [00:14<00:14, 579.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8450/16687 [00:14<00:14, 581.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8509/16687 [00:14<00:14, 581.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8568/16687 [00:15<00:13, 583.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8627/16687 [00:15<00:13, 585.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8686/16687 [00:15<00:13, 581.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8745/16687 [00:15<00:13, 581.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8804/16687 [00:15<00:13, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8864/16687 [00:15<00:13, 586.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8925/16687 [00:15<00:13, 591.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8986/16687 [00:15<00:12, 595.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9046/16687 [00:15<00:12, 592.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9107/16687 [00:15<00:12, 595.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9168/16687 [00:16<00:12, 597.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████▏             | 9229/16687 [00:16<00:12, 599.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9290/16687 [00:16<00:12, 600.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9351/16687 [00:16<00:12, 595.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9411/16687 [00:16<00:12, 593.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9471/16687 [00:16<00:12, 591.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9531/16687 [00:16<00:12, 590.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9591/16687 [00:16<00:12, 578.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9649/16687 [00:16<00:12, 559.09batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9709/16687 [00:16<00:12, 568.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9769/16687 [00:17<00:12, 576.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9827/16687 [00:17<00:11, 574.19batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  59%|██████████████████▎            | 9886/16687 [00:17<00:11, 578.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▍            | 9944/16687 [00:17<00:11, 578.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|█████████████████▉            | 10002/16687 [00:17<00:11, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10060/16687 [00:17<00:11, 578.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10119/16687 [00:17<00:11, 579.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10178/16687 [00:17<00:11, 579.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10236/16687 [00:17<00:11, 571.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10294/16687 [00:17<00:11, 561.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10353/16687 [00:18<00:11, 567.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10411/16687 [00:18<00:11, 570.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10469/16687 [00:18<00:10, 569.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10528/16687 [00:18<00:10, 572.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|███████████████████           | 10586/16687 [00:18<00:10, 574.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10645/16687 [00:18<00:10, 576.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10704/16687 [00:18<00:10, 577.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10763/16687 [00:18<00:10, 578.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10821/16687 [00:18<00:10, 571.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10880/16687 [00:18<00:10, 574.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10939/16687 [00:19<00:09, 576.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 10997/16687 [00:19<00:09, 577.04batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11055/16687 [00:19<00:09, 566.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|███████████████████▉          | 11114/16687 [00:19<00:09, 571.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11172/16687 [00:19<00:09, 572.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11231/16687 [00:19<00:09, 574.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11289/16687 [00:19<00:09, 575.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11348/16687 [00:19<00:09, 577.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11406/16687 [00:19<00:09, 570.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▌         | 11464/16687 [00:20<00:09, 558.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11520/16687 [00:20<00:09, 550.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11576/16687 [00:20<00:09, 551.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11633/16687 [00:20<00:09, 555.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11689/16687 [00:20<00:08, 556.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11746/16687 [00:20<00:08, 559.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11806/16687 [00:20<00:08, 569.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11865/16687 [00:20<00:08, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11924/16687 [00:20<00:08, 575.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 11982/16687 [00:20<00:08, 563.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12039/16687 [00:21<00:08, 563.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12098/16687 [00:21<00:08, 571.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12158/16687 [00:21<00:07, 576.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12217/16687 [00:21<00:07, 579.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12276/16687 [00:21<00:07, 580.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12335/16687 [00:21<00:07, 573.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12393/16687 [00:21<00:07, 570.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12451/16687 [00:21<00:07, 567.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12510/16687 [00:21<00:07, 571.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12568/16687 [00:21<00:07, 569.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12625/16687 [00:22<00:07, 564.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12684/16687 [00:22<00:07, 571.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▉       | 12742/16687 [00:22<00:07, 563.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12801/16687 [00:22<00:06, 568.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12859/16687 [00:22<00:06, 571.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12917/16687 [00:22<00:06, 573.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12976/16687 [00:22<00:06, 575.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13035/16687 [00:22<00:06, 577.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13093/16687 [00:22<00:06, 577.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13151/16687 [00:22<00:06, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13209/16687 [00:23<00:06, 555.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▊      | 13267/16687 [00:23<00:06, 560.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13325/16687 [00:23<00:05, 564.91batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13384/16687 [00:23<00:05, 569.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▏     | 13443/16687 [00:23<00:05, 572.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13501/16687 [00:23<00:05, 559.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13558/16687 [00:23<00:05, 549.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13617/16687 [00:23<00:05, 560.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13674/16687 [00:23<00:05, 560.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13732/16687 [00:24<00:05, 566.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13789/16687 [00:24<00:05, 559.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13846/16687 [00:24<00:05, 561.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13903/16687 [00:24<00:04, 558.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13959/16687 [00:24<00:04, 555.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14018/16687 [00:24<00:04, 563.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14078/16687 [00:24<00:04, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14139/16687 [00:24<00:04, 583.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14200/16687 [00:24<00:04, 591.40batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14260/16687 [00:24<00:04, 592.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▋    | 14320/16687 [00:25<00:04, 588.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14379/16687 [00:25<00:03, 585.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14438/16687 [00:25<00:03, 584.12batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14497/16687 [00:25<00:03, 582.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14556/16687 [00:25<00:03, 582.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14615/16687 [00:25<00:03, 581.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14674/16687 [00:25<00:03, 579.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14732/16687 [00:25<00:03, 578.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14790/16687 [00:25<00:03, 577.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▋   | 14848/16687 [00:25<00:03, 573.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▊   | 14906/16687 [00:26<00:03, 572.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|██████████████████████████▉   | 14965/16687 [00:26<00:02, 576.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15024/16687 [00:26<00:02, 579.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|███████████████████████████   | 15082/16687 [00:26<00:02, 566.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▏  | 15139/16687 [00:26<00:02, 565.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▎  | 15196/16687 [00:26<00:02, 559.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  91%|███████████████████████████▍  | 15255/16687 [00:26<00:02, 567.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▌  | 15316/16687 [00:26<00:02, 579.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|███████████████████████████▋  | 15377/16687 [00:26<00:02, 588.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15436/16687 [00:26<00:02, 584.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▊  | 15495/16687 [00:27<00:02, 585.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  93%|███████████████████████████▉  | 15554/16687 [00:27<00:01, 586.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████  | 15613/16687 [00:27<00:01, 587.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▏ | 15672/16687 [00:27<00:01, 585.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|████████████████████████████▎ | 15731/16687 [00:27<00:01, 584.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15790/16687 [00:27<00:01, 580.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▍ | 15849/16687 [00:27<00:01, 565.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  95%|████████████████████████████▌ | 15907/16687 [00:27<00:01, 566.98batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▋ | 15966/16687 [00:27<00:01, 572.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▊ | 16024/16687 [00:27<00:01, 559.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|████████████████████████████▉ | 16081/16687 [00:28<00:01, 559.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16140/16687 [00:28<00:00, 568.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████ | 16198/16687 [00:28<00:00, 570.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  97%|█████████████████████████████▏| 16257/16687 [00:28<00:00, 573.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▎| 16316/16687 [00:28<00:00, 575.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▍| 16374/16687 [00:28<00:00, 572.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|█████████████████████████████▌| 16433/16687 [00:28<00:00, 575.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▋| 16494/16687 [00:28<00:00, 584.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  99%|█████████████████████████████▊| 16553/16687 [00:28<00:00, 574.43batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▊| 16611/16687 [00:29<00:00, 561.01batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|█████████████████████████████▉| 16670/16687 [00:29<00:00, 567.83batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|████      | 8/20 [04:37<06:49, 34.13s/epoch, loss=0.701, prev_loss=0.701]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                           | 0/16687 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                 | 18/16687 [00:00<01:33, 178.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|▏                                | 71/16687 [00:00<00:43, 382.41batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▏                               | 130/16687 [00:00<00:34, 474.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▎                               | 185/16687 [00:00<00:32, 502.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|▍                               | 244/16687 [00:00<00:30, 532.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▌                               | 300/16687 [00:00<00:30, 541.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▋                               | 356/16687 [00:00<00:29, 546.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:   2%|▊                               | 416/16687 [00:00<00:29, 560.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|▉                               | 475/16687 [00:00<00:28, 568.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:   3%|█                               | 534/16687 [00:01<00:28, 572.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 593/16687 [00:01<00:27, 577.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▏                              | 651/16687 [00:01<00:28, 569.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:   4%|█▎                              | 708/16687 [00:01<00:28, 558.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▍                              | 768/16687 [00:01<00:28, 568.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▌                              | 828/16687 [00:01<00:27, 576.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   5%|█▋                              | 886/16687 [00:01<00:27, 571.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                              | 944/16687 [00:01<00:28, 557.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▊                             | 1000/16687 [00:01<00:28, 555.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:   6%|█▉                             | 1061/16687 [00:01<00:27, 570.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██                             | 1119/16687 [00:02<00:27, 573.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▏                            | 1177/16687 [00:02<00:26, 575.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   7%|██▎                            | 1236/16687 [00:02<00:26, 578.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▍                            | 1294/16687 [00:02<00:27, 562.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1353/16687 [00:02<00:26, 569.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   8%|██▌                            | 1412/16687 [00:02<00:26, 573.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▋                            | 1471/16687 [00:02<00:26, 575.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:   9%|██▊                            | 1529/16687 [00:02<00:26, 576.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|██▉                            | 1588/16687 [00:02<00:26, 577.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███                            | 1647/16687 [00:02<00:25, 578.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  10%|███▏                           | 1706/16687 [00:03<00:25, 579.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▎                           | 1765/16687 [00:03<00:25, 580.03batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  11%|███▍                           | 1824/16687 [00:03<00:25, 580.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  11%|███▍                           | 1883/16687 [00:03<00:25, 580.50batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▌                           | 1942/16687 [00:03<00:25, 580.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▋                           | 2001/16687 [00:03<00:25, 580.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  12%|███▊                           | 2060/16687 [00:03<00:25, 580.92batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|███▉                           | 2119/16687 [00:03<00:25, 580.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████                           | 2178/16687 [00:03<00:25, 580.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  13%|████▏                          | 2237/16687 [00:03<00:24, 580.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2296/16687 [00:04<00:24, 580.94batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▎                          | 2355/16687 [00:04<00:24, 580.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  14%|████▍                          | 2414/16687 [00:04<00:24, 581.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▌                          | 2473/16687 [00:04<00:24, 580.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  15%|████▋                          | 2532/16687 [00:04<00:24, 580.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▊                          | 2591/16687 [00:04<00:24, 580.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|████▉                          | 2650/16687 [00:04<00:24, 580.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  16%|█████                          | 2709/16687 [00:04<00:24, 580.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▏                         | 2768/16687 [00:04<00:23, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2827/16687 [00:04<00:23, 581.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  17%|█████▎                         | 2886/16687 [00:05<00:23, 583.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▍                         | 2945/16687 [00:05<00:23, 584.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▌                         | 3004/16687 [00:05<00:23, 585.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  18%|█████▋                         | 3064/16687 [00:05<00:23, 586.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▊                         | 3123/16687 [00:05<00:23, 580.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|█████▉                         | 3182/16687 [00:05<00:23, 571.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  19%|██████                         | 3240/16687 [00:05<00:23, 570.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3298/16687 [00:05<00:23, 570.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▏                        | 3357/16687 [00:05<00:23, 576.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  20%|██████▎                        | 3415/16687 [00:06<00:23, 576.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▍                        | 3473/16687 [00:06<00:22, 577.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  21%|██████▌                        | 3531/16687 [00:06<00:23, 562.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▋                        | 3588/16687 [00:06<00:23, 552.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▊                        | 3647/16687 [00:06<00:23, 561.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  22%|██████▉                        | 3706/16687 [00:06<00:22, 567.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|██████▉                        | 3765/16687 [00:06<00:22, 571.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████                        | 3824/16687 [00:06<00:22, 574.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  23%|███████▏                       | 3882/16687 [00:06<00:22, 569.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▎                       | 3939/16687 [00:06<00:22, 565.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▍                       | 3997/16687 [00:07<00:22, 569.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  24%|███████▌                       | 4057/16687 [00:07<00:21, 575.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▋                       | 4117/16687 [00:07<00:21, 581.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4176/16687 [00:07<00:21, 582.67batch/s]\u001b[A\n",
      "Training batches on cuda:0:  25%|███████▊                       | 4235/16687 [00:07<00:21, 571.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|███████▉                       | 4293/16687 [00:07<00:21, 567.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████                       | 4350/16687 [00:07<00:22, 559.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  26%|████████▏                      | 4409/16687 [00:07<00:21, 567.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▎                      | 4466/16687 [00:07<00:22, 554.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▍                      | 4522/16687 [00:07<00:22, 546.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  27%|████████▌                      | 4577/16687 [00:08<00:22, 540.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▌                      | 4636/16687 [00:08<00:21, 553.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▋                      | 4695/16687 [00:08<00:21, 561.93batch/s]\u001b[A\n",
      "Training batches on cuda:0:  28%|████████▊                      | 4754/16687 [00:08<00:20, 568.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|████████▉                      | 4813/16687 [00:08<00:20, 572.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  29%|█████████                      | 4871/16687 [00:08<00:21, 562.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▏                     | 4928/16687 [00:08<00:21, 553.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 4984/16687 [00:08<00:21, 544.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  30%|█████████▎                     | 5042/16687 [00:08<00:20, 554.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▍                     | 5101/16687 [00:09<00:20, 562.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▌                     | 5160/16687 [00:09<00:20, 568.23batch/s]\u001b[A\n",
      "Training batches on cuda:0:  31%|█████████▋                     | 5219/16687 [00:09<00:20, 572.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▊                     | 5278/16687 [00:09<00:19, 575.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|█████████▉                     | 5337/16687 [00:09<00:19, 577.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  32%|██████████                     | 5395/16687 [00:09<00:19, 577.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5454/16687 [00:09<00:19, 578.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▏                    | 5513/16687 [00:09<00:19, 579.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  33%|██████████▎                    | 5572/16687 [00:09<00:19, 580.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▍                    | 5631/16687 [00:09<00:19, 579.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▌                    | 5689/16687 [00:10<00:19, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  34%|██████████▋                    | 5750/16687 [00:10<00:18, 585.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▊                    | 5811/16687 [00:10<00:18, 590.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  35%|██████████▉                    | 5872/16687 [00:10<00:18, 594.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████                    | 5933/16687 [00:10<00:17, 598.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 5993/16687 [00:10<00:17, 594.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  36%|███████████▏                   | 6053/16687 [00:10<00:17, 592.62batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▎                   | 6113/16687 [00:10<00:17, 590.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  37%|███████████▍                   | 6173/16687 [00:10<00:17, 588.37batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  37%|███████████▌                   | 6232/16687 [00:10<00:17, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▋                   | 6291/16687 [00:11<00:17, 583.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▊                   | 6351/16687 [00:11<00:17, 587.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  38%|███████████▉                   | 6410/16687 [00:11<00:17, 583.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████                   | 6469/16687 [00:11<00:17, 579.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6528/16687 [00:11<00:17, 582.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  39%|████████████▏                  | 6587/16687 [00:11<00:17, 573.48batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▎                  | 6645/16687 [00:11<00:17, 563.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  40%|████████████▍                  | 6702/16687 [00:11<00:17, 561.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▌                  | 6759/16687 [00:11<00:17, 553.78batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▋                  | 6815/16687 [00:11<00:17, 554.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  41%|████████████▊                  | 6871/16687 [00:12<00:17, 547.58batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▊                  | 6926/16687 [00:12<00:18, 542.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|████████████▉                  | 6985/16687 [00:12<00:17, 554.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  42%|█████████████                  | 7044/16687 [00:12<00:17, 563.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▏                 | 7103/16687 [00:12<00:16, 569.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▎                 | 7162/16687 [00:12<00:16, 573.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  43%|█████████████▍                 | 7221/16687 [00:12<00:16, 576.60batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▌                 | 7280/16687 [00:12<00:16, 578.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7339/16687 [00:12<00:16, 580.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  44%|█████████████▋                 | 7398/16687 [00:12<00:16, 577.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▊                 | 7457/16687 [00:13<00:15, 579.02batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|█████████████▉                 | 7516/16687 [00:13<00:15, 580.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  45%|██████████████                 | 7575/16687 [00:13<00:15, 581.82batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▏                | 7634/16687 [00:13<00:15, 582.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▎                | 7693/16687 [00:13<00:15, 582.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  46%|██████████████▍                | 7752/16687 [00:13<00:15, 582.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7811/16687 [00:13<00:15, 579.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  47%|██████████████▌                | 7869/16687 [00:13<00:15, 577.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▋                | 7927/16687 [00:13<00:15, 574.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▊                | 7985/16687 [00:14<00:15, 568.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  48%|██████████████▉                | 8044/16687 [00:14<00:15, 572.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████                | 8102/16687 [00:14<00:15, 570.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▏               | 8160/16687 [00:14<00:15, 566.14batch/s]\u001b[A\n",
      "Training batches on cuda:0:  49%|███████████████▎               | 8220/16687 [00:14<00:14, 575.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8278/16687 [00:14<00:14, 566.54batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▍               | 8336/16687 [00:14<00:14, 568.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  50%|███████████████▌               | 8395/16687 [00:14<00:14, 572.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▋               | 8453/16687 [00:14<00:14, 574.07batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▊               | 8512/16687 [00:14<00:14, 576.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  51%|███████████████▉               | 8570/16687 [00:15<00:14, 576.89batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████               | 8629/16687 [00:15<00:13, 578.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▏              | 8688/16687 [00:15<00:13, 579.69batch/s]\u001b[A\n",
      "Training batches on cuda:0:  52%|████████████████▎              | 8748/16687 [00:15<00:13, 582.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▎              | 8807/16687 [00:15<00:13, 566.97batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▍              | 8864/16687 [00:15<00:14, 553.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:  53%|████████████████▌              | 8920/16687 [00:15<00:14, 551.96batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▋              | 8976/16687 [00:15<00:14, 546.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▊              | 9031/16687 [00:15<00:14, 541.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:  54%|████████████████▉              | 9086/16687 [00:15<00:14, 536.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|████████████████▉              | 9142/16687 [00:16<00:13, 543.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  55%|█████████████████              | 9202/16687 [00:16<00:13, 557.08batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▏             | 9262/16687 [00:16<00:13, 567.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▎             | 9322/16687 [00:16<00:12, 575.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  56%|█████████████████▍             | 9381/16687 [00:16<00:12, 576.59batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▌             | 9439/16687 [00:16<00:12, 567.88batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▋             | 9497/16687 [00:16<00:12, 569.45batch/s]\u001b[A\n",
      "Training batches on cuda:0:  57%|█████████████████▊             | 9556/16687 [00:16<00:12, 573.00batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▊             | 9615/16687 [00:16<00:12, 575.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|█████████████████▉             | 9674/16687 [00:16<00:12, 576.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  58%|██████████████████             | 9732/16687 [00:17<00:12, 571.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▏            | 9790/16687 [00:17<00:12, 567.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▎            | 9849/16687 [00:17<00:11, 572.16batch/s]\u001b[A\n",
      "Training batches on cuda:0:  59%|██████████████████▍            | 9908/16687 [00:17<00:11, 575.47batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▌            | 9967/16687 [00:17<00:11, 577.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████            | 10025/16687 [00:17<00:11, 573.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  60%|██████████████████▏           | 10084/16687 [00:17<00:11, 575.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▏           | 10143/16687 [00:17<00:11, 577.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▎           | 10202/16687 [00:17<00:11, 579.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  61%|██████████████████▍           | 10261/16687 [00:17<00:11, 578.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▌           | 10319/16687 [00:18<00:11, 574.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:  62%|██████████████████▋           | 10380/16687 [00:18<00:10, 583.74batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10439/16687 [00:18<00:10, 577.90batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▊           | 10498/16687 [00:18<00:10, 580.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  63%|██████████████████▉           | 10558/16687 [00:18<00:10, 583.47batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  64%|███████████████████           | 10617/16687 [00:18<00:10, 576.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▏          | 10675/16687 [00:18<00:10, 573.56batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████▎          | 10733/16687 [00:18<00:10, 557.19batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▍          | 10792/16687 [00:18<00:10, 565.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10849/16687 [00:19<00:10, 555.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:  65%|███████████████████▌          | 10907/16687 [00:19<00:10, 560.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▋          | 10964/16687 [00:19<00:10, 557.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▊          | 11023/16687 [00:19<00:10, 565.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████▉          | 11081/16687 [00:19<00:09, 570.06batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████          | 11140/16687 [00:19<00:09, 575.35batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11199/16687 [00:19<00:09, 578.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  67%|████████████████████▏         | 11257/16687 [00:19<00:09, 577.85batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▎         | 11315/16687 [00:19<00:09, 564.53batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▍         | 11372/16687 [00:19<00:09, 560.18batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████▌         | 11429/16687 [00:20<00:09, 562.76batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▋         | 11486/16687 [00:20<00:09, 561.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  69%|████████████████████▊         | 11544/16687 [00:20<00:09, 564.84batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▊         | 11603/16687 [00:20<00:08, 571.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|████████████████████▉         | 11662/16687 [00:20<00:08, 577.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████         | 11721/16687 [00:20<00:08, 580.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▏        | 11780/16687 [00:20<00:08, 579.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▎        | 11839/16687 [00:20<00:08, 580.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  71%|█████████████████████▍        | 11898/16687 [00:20<00:08, 580.70batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▍        | 11957/16687 [00:20<00:08, 581.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▌        | 12016/16687 [00:21<00:08, 573.64batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████▋        | 12074/16687 [00:21<00:08, 570.17batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▊        | 12132/16687 [00:21<00:08, 563.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|█████████████████████▉        | 12189/16687 [00:21<00:08, 556.20batch/s]\u001b[A\n",
      "Training batches on cuda:0:  73%|██████████████████████        | 12245/16687 [00:21<00:08, 549.65batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████        | 12302/16687 [00:21<00:07, 555.27batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▏       | 12361/16687 [00:21<00:07, 563.05batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████▎       | 12418/16687 [00:21<00:07, 561.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▍       | 12479/16687 [00:21<00:07, 573.40batch/s]\u001b[A\n",
      "Training batches on cuda:0:  75%|██████████████████████▌       | 12540/16687 [00:21<00:07, 582.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▋       | 12601/16687 [00:22<00:06, 589.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12662/16687 [00:22<00:06, 593.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|██████████████████████▊       | 12723/16687 [00:22<00:06, 597.28batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|██████████████████████▉       | 12784/16687 [00:22<00:06, 599.86batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████       | 12845/16687 [00:22<00:06, 601.71batch/s]\u001b[A\n",
      "Training batches on cuda:0:  77%|███████████████████████▏      | 12906/16687 [00:22<00:06, 602.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▎      | 12967/16687 [00:22<00:06, 592.24batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▍      | 13027/16687 [00:22<00:06, 591.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|███████████████████████▌      | 13087/16687 [00:22<00:06, 581.77batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13146/16687 [00:23<00:06, 572.49batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▋      | 13204/16687 [00:23<00:06, 572.87batch/s]\u001b[A\n",
      "Training batches on cuda:0:  79%|███████████████████████▊      | 13262/16687 [00:23<00:06, 566.26batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|███████████████████████▉      | 13319/16687 [00:23<00:05, 562.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████      | 13376/16687 [00:23<00:05, 557.29batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████▏     | 13433/16687 [00:23<00:05, 558.95batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13489/16687 [00:23<00:05, 556.75batch/s]\u001b[A\n",
      "Training batches on cuda:0:  81%|████████████████████████▎     | 13545/16687 [00:23<00:05, 556.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▍     | 13604/16687 [00:23<00:05, 565.61batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▌     | 13661/16687 [00:23<00:05, 560.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|████████████████████████▋     | 13721/16687 [00:24<00:05, 571.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▊     | 13782/16687 [00:24<00:04, 581.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13843/16687 [00:24<00:04, 588.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:  83%|████████████████████████▉     | 13904/16687 [00:24<00:04, 593.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████     | 13965/16687 [00:24<00:04, 597.10batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▏    | 14026/16687 [00:24<00:04, 599.80batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|█████████████████████████▎    | 14086/16687 [00:24<00:04, 599.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▍    | 14146/16687 [00:24<00:04, 593.15batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▌    | 14206/16687 [00:24<00:04, 590.22batch/s]\u001b[A\n",
      "Training batches on cuda:0:  85%|█████████████████████████▋    | 14266/16687 [00:24<00:04, 585.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14325/16687 [00:25<00:04, 578.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|█████████████████████████▊    | 14383/16687 [00:25<00:03, 577.57batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|█████████████████████████▉    | 14441/16687 [00:25<00:03, 571.73batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████    | 14501/16687 [00:25<00:03, 579.63batch/s]\u001b[A\n",
      "Training batches on cuda:0:  87%|██████████████████████████▏   | 14561/16687 [00:25<00:03, 582.79batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▎   | 14620/16687 [00:25<00:03, 584.72batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14679/16687 [00:25<00:03, 582.99batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|██████████████████████████▍   | 14738/16687 [00:25<00:03, 581.13batch/s]\u001b[A\n",
      "Training batches on cuda:0:  89%|██████████████████████████▌   | 14797/16687 [00:25<00:03, 569.00batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|████      | 8/20 [05:03<07:35, 37.94s/epoch, loss=0.701, prev_loss=0.701]\u001b[A\n",
      "\u001b[33m[W 2023-01-30 09:02:25,021]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py\", line 259, in __call__\n",
      "    result = pipeline(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py\", line 1291, in pipeline\n",
      "    losses = training_loop_instance.train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 378, in train\n",
      "    result = self._train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 659, in _train\n",
      "    self.optimizer.step()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 23, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 234, in step\n",
      "    adam(params_with_grad,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 300, in adam\n",
      "    func(params,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 363, in _single_tensor_adam\n",
      "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hpo_pipeline_result \u001b[38;5;241m=\u001b[39m \u001b[43mhpo_pipeline_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:486\u001b[0m, in \u001b[0;36mhpo_pipeline_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhpo_pipeline_from_config\u001b[39m(config: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HpoPipelineResult:\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the HPO pipeline using a properly formatted configuration dictionary.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhpo_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:857\u001b[0m, in \u001b[0;36mhpo_pipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, model_kwargs_ranges, loss, loss_kwargs, loss_kwargs_ranges, regularizer, regularizer_kwargs, regularizer_kwargs_ranges, optimizer, optimizer_kwargs, optimizer_kwargs_ranges, lr_scheduler, lr_scheduler_kwargs, lr_scheduler_kwargs_ranges, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, negative_sampler_kwargs_ranges, epochs, training_kwargs, training_kwargs_ranges, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, metric, filter_validation_when_testing, result_tracker, result_tracker_kwargs, device, storage, sampler, sampler_kwargs, pruner, pruner_kwargs, study_name, direction, load_if_exists, n_trials, timeout, n_jobs, save_model_directory)\u001b[0m\n\u001b[1;32m    801\u001b[0m objective \u001b[38;5;241m=\u001b[39m Objective(\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# 1. Dataset\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    854\u001b[0m )\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# Invoke optimization of the objective function.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrial\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mMemoryError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HpoPipelineResult(\n\u001b[1;32m    866\u001b[0m     study\u001b[38;5;241m=\u001b[39mstudy,\n\u001b[1;32m    867\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    868\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:259\u001b[0m, in \u001b[0;36mObjective.__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_stopper_callbacks(_stopper_kwargs, trial, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric, result_tracker\u001b[38;5;241m=\u001b[39mresult_tracker)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 1. Dataset\u001b[39;49;00m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 2. Model\u001b[39;49;00m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 3. Loss\u001b[39;49;00m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_loss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 4. Regularizer\u001b[39;49;00m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_regularizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5. Optimizer\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_optimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5.1 Learning Rate Scheduler\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lr_scheduler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 6. Training Loop\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_negative_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 7. Training\u001b[39;49;00m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_training_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 8. Evaluation\u001b[39;49;00m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 9. Tracker\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Misc.\u001b[39;49;00m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use validation set during HPO!\u001b[39;49;00m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# close run in result tracker\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     result_tracker\u001b[38;5;241m.\u001b[39mend_run(success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:659\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    656\u001b[0m     callback\u001b[38;5;241m.\u001b[39mpre_step()\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;66;03m# update parameters according to optimizer\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# After changing applying the gradients to the embeddings, the model is notified that the forward\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# constraints are no longer applied\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpost_parameter_update()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from OGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, predictor, x, adj_t, split_edge, optimizer, batch_size):\n",
    "\n",
    "    row, col, _ = adj_t.coo()\n",
    "    edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(x, adj_t)\n",
    "#         print('h:', h)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "#         print('Train: edge:', edge)\n",
    "#         print()\n",
    "#         print('h[edge[0]]:', h[edge[0]])\n",
    "#         print()\n",
    "#         print('h[edge[1]]:', h[edge[1]])\n",
    "#         print()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "#         print('pos out:', pos_out)\n",
    "\n",
    "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
    "                                 num_neg_samples=perm.size(0), method='dense')\n",
    "\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, predictor, x, adj_t, split_edge, evaluator, batch_size):\n",
    "#     print('test')\n",
    "    \n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(x, adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['eval_train']['edge'].to(x.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "    \n",
    "#     print('pos_train_pred:', pos_train_pred)\n",
    "#     print('neg_train_pred:', neg_valid_pred)\n",
    "#     print()\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 20, 30]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: Embedding(4267, 256)\n",
      "\n",
      "Hits@10\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 0.03%, Valid: 0.02%, Test: 0.01%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 3.96%, Valid: 3.64%, Test: 2.58%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 01, Loss: 1.2921, Train: 4.55%, Valid: 4.17%, Test: 3.92%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 3.10%, Valid: 2.87%, Test: 5.68%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 4.74%, Valid: 4.37%, Test: 6.92%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 02, Loss: 0.9923, Train: 5.45%, Valid: 5.01%, Test: 7.74%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.26%, Valid: 0.24%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.56%, Valid: 0.51%, Test: 0.08%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 03, Loss: 0.8506, Train: 0.75%, Valid: 0.70%, Test: 0.15%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 2.34%, Valid: 2.15%, Test: 3.71%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 3.19%, Valid: 2.99%, Test: 4.94%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 04, Loss: 0.7528, Train: 4.13%, Valid: 3.85%, Test: 5.89%\n",
      "---\n",
      "Hits@10\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 11.42%, Valid: 10.23%, Test: 5.50%\n",
      "Hits@20\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 14.15%, Valid: 12.74%, Test: 8.07%\n",
      "Hits@30\n",
      "Run: 01, Epoch: 05, Loss: 0.6931, Train: 15.53%, Valid: 14.05%, Test: 10.79%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 1.85%, Valid: 1.68%, Test: 1.89%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 2.54%, Valid: 2.31%, Test: 3.93%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 01, Loss: 1.2701, Train: 3.27%, Valid: 2.98%, Test: 5.27%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 2.24%, Valid: 2.03%, Test: 5.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 2.96%, Valid: 2.76%, Test: 6.26%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 02, Loss: 0.9578, Train: 3.51%, Valid: 3.28%, Test: 7.50%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 0.01%, Valid: 0.01%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 3.82%, Valid: 3.54%, Test: 0.68%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 03, Loss: 0.7824, Train: 4.12%, Valid: 3.85%, Test: 0.81%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 0.08%, Valid: 0.07%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 0.94%, Valid: 0.82%, Test: 0.46%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 04, Loss: 0.7227, Train: 2.58%, Valid: 2.38%, Test: 1.64%\n",
      "---\n",
      "Hits@10\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 0.08%, Valid: 0.07%, Test: 0.02%\n",
      "Hits@20\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 3.21%, Valid: 2.77%, Test: 0.12%\n",
      "Hits@30\n",
      "Run: 02, Epoch: 05, Loss: 0.6739, Train: 9.13%, Valid: 8.10%, Test: 4.56%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 2.52%, Valid: 2.35%, Test: 4.53%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 3.55%, Valid: 3.30%, Test: 5.95%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 01, Loss: 1.2287, Train: 4.32%, Valid: 3.98%, Test: 6.75%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 1.82%, Valid: 1.60%, Test: 3.81%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 2.47%, Valid: 2.18%, Test: 5.72%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 02, Loss: 0.9087, Train: 2.75%, Valid: 2.47%, Test: 6.41%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 0.87%, Valid: 0.66%, Test: 0.04%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 4.18%, Valid: 3.79%, Test: 0.64%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 03, Loss: 0.7954, Train: 5.75%, Valid: 5.28%, Test: 4.03%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 2.11%, Valid: 1.86%, Test: 1.60%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 3.90%, Valid: 3.40%, Test: 3.19%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 04, Loss: 0.7186, Train: 6.68%, Valid: 5.87%, Test: 5.10%\n",
      "---\n",
      "Hits@10\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 12.81%, Valid: 11.61%, Test: 6.73%\n",
      "Hits@20\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 13.97%, Valid: 12.68%, Test: 11.25%\n",
      "Hits@30\n",
      "Run: 03, Epoch: 05, Loss: 0.6663, Train: 14.80%, Valid: 13.53%, Test: 13.48%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 2.25%, Valid: 2.07%, Test: 4.32%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 3.23%, Valid: 3.00%, Test: 5.84%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 01, Loss: 1.2368, Train: 4.14%, Valid: 3.81%, Test: 6.71%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 1.79%, Valid: 1.57%, Test: 2.65%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 2.30%, Valid: 2.04%, Test: 3.99%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 02, Loss: 0.9149, Train: 2.76%, Valid: 2.54%, Test: 4.57%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 5.26%, Valid: 4.80%, Test: 1.83%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 6.05%, Valid: 5.59%, Test: 3.85%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 03, Loss: 0.7997, Train: 6.63%, Valid: 6.13%, Test: 4.86%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 0.08%, Valid: 0.08%, Test: 0.03%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 0.70%, Valid: 0.62%, Test: 0.05%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 04, Loss: 0.7205, Train: 2.30%, Valid: 2.09%, Test: 0.49%\n",
      "---\n",
      "Hits@10\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 3.59%, Valid: 3.06%, Test: 0.07%\n",
      "Hits@20\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 8.51%, Valid: 7.52%, Test: 0.77%\n",
      "Hits@30\n",
      "Run: 04, Epoch: 05, Loss: 0.6588, Train: 12.65%, Valid: 11.30%, Test: 2.98%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hidden_channels = 256\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "runs = 4\n",
    "lr = 0.005\n",
    "batch_size = 64 * 1024\n",
    "epochs = 5\n",
    "log_steps = 1\n",
    "eval_steps = 1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "adj_t = data.adj_t.to(device)\n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "\n",
    "# We randomly pick some training samples that we want to evaluate on:\n",
    "torch.manual_seed(12345)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "\n",
    "model = GCN(hidden_channels, hidden_channels,\n",
    "                hidden_channels, num_layers,\n",
    "                dropout).to(device)\n",
    "\n",
    "emb = torch.nn.Embedding(data.adj_t.size(0),\n",
    "                         hidden_channels).to(device)\n",
    "\n",
    "print('Embedding:', emb)\n",
    "print()\n",
    "predictor = LinkPredictor(hidden_channels, hidden_channels, 1,\n",
    "                          num_layers, dropout).to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "# loggers = {\n",
    "#     'Hits@10': Logger(args.runs, args),\n",
    "#     'Hits@20': Logger(args.runs, args),\n",
    "#     'Hits@30': Logger(args.runs, args),\n",
    "# }\n",
    "\n",
    "for run in range(runs):\n",
    "    torch.nn.init.xavier_uniform_(emb.weight)\n",
    "#     print('Weights:', emb.weight)\n",
    "#     print()\n",
    "    model.reset_parameters()\n",
    "    predictor.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.parameters()) + list(emb.parameters()) +\n",
    "        list(predictor.parameters()), lr=lr)\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        loss = train(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                     optimizer, batch_size)\n",
    "\n",
    "        if epoch % eval_steps == 0:\n",
    "#             print('Eval')\n",
    "            results = test(model, predictor, emb.weight, adj_t, split_edge,\n",
    "                           evaluator, batch_size)\n",
    "#             for key, result in results.items():\n",
    "#                 loggers[key].add_result(run, result)\n",
    "\n",
    "            if epoch % log_steps == 0:\n",
    "                for key, result in results.items():\n",
    "                    train_hits, valid_hits, test_hits = result\n",
    "                    print(key)\n",
    "                    print(f'Run: {run + 1:02d}, '\n",
    "                          f'Epoch: {epoch:02d}, '\n",
    "                          f'Loss: {loss:.4f}, '\n",
    "                          f'Train: {100 * train_hits:.2f}%, '\n",
    "                          f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                          f'Test: {100 * test_hits:.2f}%')\n",
    "                print('---')\n",
    "\n",
    "#     for key in loggers.keys():\n",
    "#         print(key)\n",
    "#         loggers[key].print_statistics(run)\n",
    "\n",
    "# for key in loggers.keys():\n",
    "#     print(key)\n",
    "#     loggers[key].print_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
