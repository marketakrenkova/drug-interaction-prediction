{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph\n",
    "#### Drug-Food or Drug-Supplements interaction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pykeen.models import predict\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.models import TransE\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/triplets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>interaction</th>\n",
       "      <th>drug2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apixaban</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dabigatran etexilate</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>increase_bleeding</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>increase_hemorrhage</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deferasirox</td>\n",
       "      <td>increase_gastrointestinal_bleeding</td>\n",
       "      <td>Lepirudin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  drug1                         interaction      drug2\n",
       "0              Apixaban   increase_anticoagulant_activities  Lepirudin\n",
       "1  Dabigatran etexilate   increase_anticoagulant_activities  Lepirudin\n",
       "2             Dasatinib                   increase_bleeding  Lepirudin\n",
       "3             Dasatinib                 increase_hemorrhage  Lepirudin\n",
       "4           Deferasirox  increase_gastrointestinal_bleeding  Lepirudin"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi_df = pd.read_csv(data_dir + 'ddi.tsv', sep='\\t', index_col=[0])\n",
    "ddi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total interactions: 3123450\n",
      "unique interactions: 205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interaction\n",
       "decrease_absorption                             576\n",
       "decrease_adverse_effects                        384\n",
       "decrease_anticholinergic_activities              26\n",
       "decrease_anticoagulant_activities              5174\n",
       "decrease_antihypertensive_activities          63420\n",
       "                                              ...  \n",
       "increase_visual_accommodation_disturbances        2\n",
       "increase_vomiting                                54\n",
       "increase_water_intoxication                     256\n",
       "increase_weakness                              1710\n",
       "increase_weight_gain                             16\n",
       "Length: 205, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('total interactions:', ddi_df.shape[0])\n",
    "print('unique interactions:', len(set(ddi_df.interaction)))\n",
    "\n",
    "interaction_counts = ddi_df.groupby(by=['interaction']).size()\n",
    "interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decrease_absorption',\n",
       " 'decrease_adverse_effects',\n",
       " 'decrease_anticholinergic_activities',\n",
       " 'decrease_anticoagulant_activities',\n",
       " 'decrease_antihypertensive_activities',\n",
       " 'decrease_antiplatelet_activities',\n",
       " 'decrease_arrhythmogenic_activities',\n",
       " 'decrease_bioavailability',\n",
       " 'decrease_bronchodilatory_activities',\n",
       " 'decrease_cardiotoxicity',\n",
       " 'decrease_cytotoxicity',\n",
       " 'decrease_diuretic_activities',\n",
       " 'decrease_effectiveness',\n",
       " 'decrease_excretion_rate',\n",
       " 'decrease_fluid_retaining_activities',\n",
       " 'decrease_hypertension',\n",
       " 'decrease_hypoglycemia',\n",
       " 'decrease_hypotension',\n",
       " 'decrease_metabolism',\n",
       " 'decrease_myopathy',\n",
       " 'decrease_nephrotoxicity',\n",
       " 'decrease_neuromuscular_blockade',\n",
       " 'decrease_protein_binding',\n",
       " 'decrease_qtc_prolongation',\n",
       " 'decrease_rhabdomyolysis',\n",
       " 'decrease_sedation',\n",
       " 'decrease_seizure',\n",
       " 'decrease_serum_concentration',\n",
       " 'decrease_skeletal_muscle_relaxing_activities',\n",
       " 'decrease_stimulatory_activities',\n",
       " 'decrease_therapeutic_efficacy',\n",
       " 'decrease_vasoconstricting_activities',\n",
       " 'decrease_vasopressor_activities',\n",
       " 'increase_adverse_effects',\n",
       " 'increase_alpha-adrenergic_activities',\n",
       " 'increase_analgesic_activities',\n",
       " 'increase_anemia',\n",
       " 'increase_angioedema',\n",
       " 'increase_anti-angiogenesis',\n",
       " 'increase_anticholinergic_activities',\n",
       " 'increase_anticoagulant_activities',\n",
       " 'increase_anticonvulsant_toxicity',\n",
       " 'increase_antihypertensive_activities',\n",
       " 'increase_antiplatelet_activities',\n",
       " 'increase_antipsychotic_activities',\n",
       " 'increase_arrhythmogenic_activities',\n",
       " 'increase_atrioventricular_blocking_(av_block)_activities',\n",
       " 'increase_bioavailability',\n",
       " 'increase_bleeding',\n",
       " 'increase_bradycardia',\n",
       " 'increase_bronchoconstrictory_activities',\n",
       " 'increase_bronchospasm',\n",
       " 'increase_bruising',\n",
       " 'increase_cardiac_arrest',\n",
       " 'increase_cardiac_arrhythmia',\n",
       " 'increase_cardiodepressant_activities',\n",
       " 'increase_cardiotoxicity',\n",
       " 'increase_cardiovascular_complications',\n",
       " 'increase_cardiovascular_impairment',\n",
       " 'increase_change_in_thyroid_function_activities',\n",
       " 'increase_cns_depression_activities',\n",
       " 'increase_cns_stimulation',\n",
       " 'increase_confusion',\n",
       " 'increase_congestive_heart_failure',\n",
       " 'increase_constipation',\n",
       " 'increase_convulsion',\n",
       " 'increase_cutaneous_drug_reaction',\n",
       " 'increase_cytopenia',\n",
       " 'increase_death',\n",
       " 'increase_decreased_alertness_activities',\n",
       " 'increase_dermatologic_adverse_activities',\n",
       " 'increase_diuretic_activities',\n",
       " 'increase_dizziness',\n",
       " 'increase_drowsiness',\n",
       " 'increase_dyspnea',\n",
       " 'increase_edema_formation',\n",
       " 'increase_electrolyte_disturbance_activities',\n",
       " 'increase_electrolyte_imbalance',\n",
       " 'increase_elevated_creatine_kinase_(cpk)',\n",
       " 'increase_encephalopathy',\n",
       " 'increase_excretion_rate',\n",
       " 'increase_extrapyramidal_symptoms',\n",
       " 'increase_facial_flushing',\n",
       " 'increase_fluid_retaining_activities',\n",
       " 'increase_fluid_retention',\n",
       " 'increase_gastrointestinal_bleeding',\n",
       " 'increase_gastrointestinal_irritation',\n",
       " 'increase_gastrointestinal_motility_reducing_activities',\n",
       " 'increase_gastrointestinal_ulceration',\n",
       " 'increase_generalized_seizure',\n",
       " 'increase_gouty_arthritis',\n",
       " 'increase_granulocytopenia',\n",
       " 'increase_hemorrhage',\n",
       " 'increase_hemorrhagic_cystitis',\n",
       " 'increase_hepatotoxic_activities',\n",
       " 'increase_hyperbilirubinemia',\n",
       " 'increase_hypercalcemia',\n",
       " 'increase_hypercoagulability',\n",
       " 'increase_hyperglycemia',\n",
       " 'increase_hyperkalemia',\n",
       " 'increase_hyperkinetic_symptoms',\n",
       " 'increase_hypersensitivity_reaction',\n",
       " 'increase_hypertension',\n",
       " 'increase_hyperthermia',\n",
       " 'increase_hypertrichosis',\n",
       " 'increase_hyperuricemia',\n",
       " 'increase_hypocalcemia',\n",
       " 'increase_hypoglycemia',\n",
       " 'increase_hypokalemia',\n",
       " 'increase_hypolipidaemic_activities',\n",
       " 'increase_hypomagnesemia',\n",
       " 'increase_hypomania',\n",
       " 'increase_hyponatremia',\n",
       " 'increase_hypotension',\n",
       " 'increase_hypothyroid_activities',\n",
       " 'increase_hypotonia',\n",
       " 'increase_immunosuppressive_activities',\n",
       " 'increase_increased_glucose',\n",
       " 'increase_increased_serum_creatinine',\n",
       " 'increase_increased_transaminases',\n",
       " 'increase_infection',\n",
       " 'increase_intraocular_pressure',\n",
       " 'increase_irritability',\n",
       " 'increase_ischemic_colitis',\n",
       " 'increase_jaw_osteonecrosis',\n",
       " 'increase_lactic_acidosis',\n",
       " 'increase_leukopenia',\n",
       " 'increase_liver_damage',\n",
       " 'increase_liver_enzyme_elevations',\n",
       " 'increase_metabolic_acidosis',\n",
       " 'increase_metabolism',\n",
       " 'increase_methemoglobinemia',\n",
       " 'increase_mucosal_ulceration',\n",
       " 'increase_myelosuppression',\n",
       " 'increase_myocardial_depression',\n",
       " 'increase_myoglobinuria',\n",
       " 'increase_myopathic_rhabdomyolysis_activities',\n",
       " 'increase_myopathy',\n",
       " 'increase_nausea',\n",
       " 'increase_nephrotoxicity',\n",
       " 'increase_neuroexcitatory_activities',\n",
       " 'increase_neuroleptic_malignant_syndrome',\n",
       " 'increase_neuromuscular_blockade',\n",
       " 'increase_neurotoxic_activities',\n",
       " 'increase_neutropenia',\n",
       " 'increase_nitritoid_reactions',\n",
       " 'increase_oligohydrosis',\n",
       " 'increase_opioid_antagonism_activities',\n",
       " 'increase_opioid_toxicity',\n",
       " 'increase_orthostatic_hypotension',\n",
       " 'increase_osteomalacia',\n",
       " 'increase_ototoxicity',\n",
       " 'increase_pancreatitis_activities',\n",
       " 'increase_peptic_ulcer',\n",
       " 'increase_peripheral_neuropathy',\n",
       " 'increase_photosensitizing_activities',\n",
       " 'increase_priapism',\n",
       " 'increase_pseudotumor_cerebri',\n",
       " 'increase_psychotic_reaction',\n",
       " 'increase_pulmonary_toxicity',\n",
       " 'increase_qtc_prolongation',\n",
       " 'increase_rash',\n",
       " 'increase_reduced_gastrointestinal_motility',\n",
       " 'increase_reduced_intravascular_volume',\n",
       " 'increase_renal_failure',\n",
       " 'increase_respiratory_depression',\n",
       " 'increase_rhabdomyolysis',\n",
       " 'increase_sedation',\n",
       " 'increase_seizure',\n",
       " 'increase_serotonergic_activities',\n",
       " 'increase_serotonin_syndrome',\n",
       " 'increase_serum_concentration',\n",
       " 'increase_severe_leukopenia',\n",
       " 'increase_shortness_of_breath',\n",
       " 'increase_sinus_node_depression',\n",
       " 'increase_skeletal_muscle_relaxing_activities',\n",
       " 'increase_sleep_disorders',\n",
       " 'increase_smooth_muscle_relaxing_activities',\n",
       " 'increase_somnolence',\n",
       " 'increase_stevens-johnson_syndrome',\n",
       " 'increase_sympathomimetic_activities',\n",
       " 'increase_syncope',\n",
       " 'increase_tachycardia',\n",
       " 'increase_tardive_dyskinesia',\n",
       " 'increase_tendinopathy',\n",
       " 'increase_teratogenic_activities',\n",
       " 'increase_therapeutic_efficacy',\n",
       " 'increase_thrombocytopenia',\n",
       " 'increase_thromboembolism',\n",
       " 'increase_thrombogenic_activities',\n",
       " 'increase_thrombosis',\n",
       " 'increase_torsade_de_pointes',\n",
       " 'increase_ulceration',\n",
       " 'increase_urinary_retention',\n",
       " 'increase_uterotonic_activities',\n",
       " 'increase_vasoconstricting_activities',\n",
       " 'increase_vasodilatory_activities',\n",
       " 'increase_vasopressor_activities',\n",
       " 'increase_vasospastic_reactions',\n",
       " 'increase_ventricular_arrhythmias',\n",
       " 'increase_visual_accommodation_disturbances',\n",
       " 'increase_vomiting',\n",
       " 'increase_water_intoxication',\n",
       " 'increase_weakness',\n",
       " 'increase_weight_gain'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ddi_df.interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI1</th>\n",
       "      <th>REL</th>\n",
       "      <th>CUI2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689301</th>\n",
       "      <td>1-Androsten-3beta-ol-17-one</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Testosterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689302</th>\n",
       "      <td>4-DHEA</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Testosterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689319</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Cytochrome P450 2D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689320</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>TOPICAL DRUGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689322</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Cytochrome P450 3A4 substrates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CUI1             REL  \\\n",
       "689301  1-Androsten-3beta-ol-17-one  interacts_with   \n",
       "689302                       4-DHEA  interacts_with   \n",
       "689319                    Blackbush  interacts_with   \n",
       "689320                    Blackbush  interacts_with   \n",
       "689322                    Blackbush  interacts_with   \n",
       "\n",
       "                                  CUI2  \n",
       "689301                    Testosterone  \n",
       "689302                    Testosterone  \n",
       "689319             Cytochrome P450 2D6  \n",
       "689320                   TOPICAL DRUGS  \n",
       "689322  Cytochrome P450 3A4 substrates  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_supplement_df = pd.read_csv(data_dir + 'ds_relations.tsv', sep='\\t', index_col=[0])\n",
    "# drug_supplement_df = drug_supplement_df[drug_supplement_df['REL'] != 'has_ingredient']\n",
    "drug_supplement_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total interactions: 3057\n",
      "unique interactions: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "REL\n",
       "interacts_with    3057\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('total interactions:', drug_supplement_df.shape[0])\n",
    "print('unique interactions:', len(set(drug_supplement_df.REL)))\n",
    "\n",
    "ds_interaction_counts = drug_supplement_df.groupby(by=['REL']).size()\n",
    "ds_interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_count = pd.concat([interaction_counts, ds_interaction_counts])\n",
    "interactions_count.to_csv('interaction_counts.csv', header=['interaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size(n):\n",
    "    if n == 2:\n",
    "        return 1, 1\n",
    "    if n == 3:\n",
    "        return 1, 2\n",
    "    if n == 4:\n",
    "        return 2, 3\n",
    "    if n == 5:\n",
    "        return 3, 4\n",
    "    if n == 6:\n",
    "        return 4, 5\n",
    "    # n == 7\n",
    "    return 4, 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : valid : test = 80 : 10 : 10\n",
    "def split_data_relation(df_relation):\n",
    "    \n",
    "    # too few triplets with the realtion\n",
    "    if df_relation.shape[0] <= 7:\n",
    "        train_size, valid_size = compute_size(df_relation.shape[0])\n",
    "        \n",
    "        # shuffle df_relation\n",
    "        df_relation = df_relation.sample(frac=1, random_state=42)\n",
    "        \n",
    "        X_train = df_relation.iloc[:train_size]\n",
    "        X_valid = df_relation.iloc[train_size:valid_size]\n",
    "        X_test = df_relation.iloc[valid_size:]\n",
    "\n",
    "    else:\n",
    "        X_train, X_rem = train_test_split(df_relation, train_size=0.8, random_state=42)\n",
    "        X_valid, X_test = train_test_split(X_rem, test_size=0.5, random_state=42)\n",
    "        \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-supplements relation dataset\n",
    "def split_drug_supplements_dataset(drug_supplement_df):\n",
    "    relations = set(drug_supplement_df.REL)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    test_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "\n",
    "    for rel in relations:\n",
    "        train, valid, test = split_data_relation(drug_supplement_df[drug_supplement_df['REL'] == rel])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "\n",
    "    train_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-drug interaction dataset (from DrugBank)\n",
    "def split_ddi_dataset(ddi_df):\n",
    "    interactions = set(ddi_df.interaction)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    test_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    \n",
    "    for inter in interactions:\n",
    "        train, valid, test = split_data_relation(ddi_df[ddi_df['interaction'] == inter])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "        \n",
    "    train_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrugBank drug-drug interactions\n",
      "train dataset size: 2498661\n",
      "validation dataset size: 312349\n",
      "test dataset size: 312440\n",
      "\n",
      "Drug Supplement database - drug-suplement interactions\n",
      "train dataset size: 2445\n",
      "validation dataset size: 306\n",
      "test dataset size: 306\n"
     ]
    }
   ],
   "source": [
    "# DrugBank drug-drug interactions\n",
    "print('DrugBank drug-drug interactions')\n",
    "train_triplets_ddi, valid_triplets_ddi, test_triplets_ddi = split_ddi_dataset(ddi_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# Drug Supplement database - drug-suplement interactions\n",
    "print('Drug Supplement database - drug-suplement interactions')\n",
    "train_triplets_ds, valid_triplets_ds, test_triplets_ds = split_drug_supplements_dataset(drug_supplement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All interactions:\n",
      "train dataset size: 2501106\n",
      "validation dataset size: 312655\n",
      "test dataset size: 312746\n"
     ]
    }
   ],
   "source": [
    "# all interactions\n",
    "train_triplets = pd.concat([train_triplets_ddi, train_triplets_ds])\n",
    "valid_triplets = pd.concat([valid_triplets_ddi, valid_triplets_ds])\n",
    "test_triplets = pd.concat([test_triplets_ddi, test_triplets_ds])\n",
    "\n",
    "print('All interactions:')\n",
    "print('train dataset size:', train_triplets.shape[0])\n",
    "print('validation dataset size:',valid_triplets.shape[0])\n",
    "print('test dataset size:',test_triplets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique interactions: 206\n",
      "['increase_sedation', 'decrease_anticholinergic_activities', 'increase_anemia', 'increase_tardive_dyskinesia', 'decrease_serum_concentration', 'increase_nausea', 'increase_hypercoagulability', 'increase_death', 'increase_metabolism', 'increase_bronchoconstrictory_activities']\n"
     ]
    }
   ],
   "source": [
    "all_relations = set(train_triplets.relation)\n",
    "print('Number of unique interactions:', len(all_relations))\n",
    "print(list(all_relations)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add rest of the data into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final size of train dataset (with other relations): 3799697\n"
     ]
    }
   ],
   "source": [
    "files = listdir(data_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file == 'ddi.tsv' or file == '.ipynb_checkpoints' or file == 'ds_relations.tsv':\n",
    "        continue\n",
    "    if 'train' in file or 'valid' in file or 'test' in file:\n",
    "        continue\n",
    "           \n",
    "    df = pd.read_csv(data_dir + file, sep='\\t', index_col=[0])\n",
    "    \n",
    "    # if file == 'ds_relations.tsv':\n",
    "    #     df = df[df['REL'] == 'has_ingredient']\n",
    "    \n",
    "    df.set_axis(['head', 'relation', 'tail'], axis=1, inplace=True) \n",
    "    train_triplets = pd.concat([train_triplets, df])\n",
    "    \n",
    "print('Final size of train dataset (with other relations):', train_triplets.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = train_triplets.astype(str)\n",
    "valid_triplets = valid_triplets.astype(str)\n",
    "test_triplets = test_triplets.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train, valid and test datasets\n",
    "\n",
    "train_triplets.to_csv(data_dir + 'train.tsv', sep='\\t')\n",
    "valid_triplets.to_csv(data_dir + 'valid.tsv', sep='\\t')\n",
    "test_triplets.to_csv(data_dir + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datasets into Triples Factory format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "      data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "      create_inverse_triples=False,\n",
    "      entity_to_id=None,\n",
    "      relation_to_id=None,\n",
    "      compact_id=False \n",
    "    )\n",
    "    print(tf_data)  # kam mizeji nejake trojice? - jiny pocet zde a po vytvoreni datasetu\n",
    "    return tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriplesFactory(num_entities=597163, num_relations=215, create_inverse_triples=False, num_triples=3650539)\n",
      "TriplesFactory(num_entities=4565, num_relations=183, create_inverse_triples=False, num_triples=312528)\n",
      "TriplesFactory(num_entities=4529, num_relations=206, create_inverse_triples=False, num_triples=312641)\n"
     ]
    }
   ],
   "source": [
    "tf_train = convert_to_triples_factory(train_triplets)\n",
    "tf_valid = convert_to_triples_factory(valid_triplets)\n",
    "tf_test = convert_to_triples_factory(test_triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=970934743\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a coverage of all entities and relation with only 547580 triples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# take just subset of data for testing\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_sub, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m valid_sub, _ \u001b[38;5;241m=\u001b[39m tf_valid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m0.15\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_sub, _ \u001b[38;5;241m=\u001b[39m tf_test\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m0.15\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/triples_factory.py:673\u001b[0m, in \u001b[0;36mCoreTriplesFactory.split\u001b[0;34m(self, ratios, random_state, randomize_cleanup, method)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Split a triples factory into a train/test.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m:param ratios:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    training_factory, testing_factory, validation_factory = factory.split(ratios)\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# Make new triples factories for each group\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone_and_exchange_triples(\n\u001b[1;32m    668\u001b[0m         mapped_triples\u001b[38;5;241m=\u001b[39mtriples,\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;66;03m# do not explicitly create inverse triples for testing; this is handled by the evaluation code\u001b[39;00m\n\u001b[1;32m    670\u001b[0m         create_inverse_triples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    671\u001b[0m     )\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, triples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m--> 673\u001b[0m         \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m            \u001b[49m\u001b[43mratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandomize_cleanup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomize_cleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/splitting.py:511\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(mapped_triples, ratios, random_state, randomize_cleanup, method)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m splitter_cls \u001b[38;5;129;01mis\u001b[39;00m CleanupSplitter \u001b[38;5;129;01mand\u001b[39;00m randomize_cleanup:\n\u001b[1;32m    510\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaner\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cleaner_resolver\u001b[38;5;241m.\u001b[39mnormalize_cls(RandomizedCleaner)\n\u001b[0;32m--> 511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msplitter_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplitter_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/splitting.py:383\u001b[0m, in \u001b[0;36mSplitter.split\u001b[0;34m(self, mapped_triples, ratios, random_state)\u001b[0m\n\u001b[1;32m    381\u001b[0m ratios \u001b[38;5;241m=\u001b[39m normalize_ratios(ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[1;32m    382\u001b[0m sizes \u001b[38;5;241m=\u001b[39m get_absolute_split_sizes(n_total\u001b[38;5;241m=\u001b[39mmapped_triples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], ratios\u001b[38;5;241m=\u001b[39mratios)\n\u001b[0;32m--> 383\u001b[0m triples_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_absolute_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (triples, exp_size, exp_ratio) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(triples_groups, sizes, ratios)):\n\u001b[1;32m    389\u001b[0m     actual_size \u001b[38;5;241m=\u001b[39m triples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/triples/splitting.py:451\u001b[0m, in \u001b[0;36mCoverageSplitter.split_absolute_size\u001b[0;34m(self, mapped_triples, sizes, random_state)\u001b[0m\n\u001b[1;32m    449\u001b[0m remaining_triples \u001b[38;5;241m=\u001b[39m mapped_triples[\u001b[38;5;241m~\u001b[39mseed_mask]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_seed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m sizes[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a coverage of all entities and relation with only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m triples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m remaining_sizes \u001b[38;5;241m=\u001b[39m (sizes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m train_seed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(sizes[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    453\u001b[0m train, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m _split_triples(\n\u001b[1;32m    454\u001b[0m     mapped_triples\u001b[38;5;241m=\u001b[39mremaining_triples,\n\u001b[1;32m    455\u001b[0m     sizes\u001b[38;5;241m=\u001b[39mremaining_sizes,\n\u001b[1;32m    456\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m    457\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find a coverage of all entities and relation with only 547580 triples."
     ]
    }
   ],
   "source": [
    "# take just subset of data for testing\n",
    "\n",
    "train_sub, _ = tf_train.split(0.15)\n",
    "valid_sub, _ = tf_valid.split(0.15)\n",
    "test_sub, _ = tf_test.split(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TriplesFactory(num_entities=647147, num_relations=219, create_inverse_triples=False, num_triples=601202)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_relation_whitelist = all_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "result = pipeline(\n",
    "    training=train_sub,\n",
    "    testing=test_sub,\n",
    "    validation=valid_sub,\n",
    "    model='TransE',\n",
    "    epochs=1,\n",
    "    evaluator=RankBasedEvaluator,\n",
    "#     model_kwargs=dict(embedding_dim=128),\n",
    "    device='gpu',\n",
    "    optimizer='Adam',\n",
    "#     evaluation_relation_whitelist=evaluation_relation_whitelist,\n",
    "#     training_kwargs=dict(\n",
    "#         num_epochs=2,\n",
    "#         checkpoint_name='transE_checkpoint.pt',\n",
    "#         checkpoint_directory='kg_ckeckpoints',\n",
    "#         checkpoint_frequency=0\n",
    "#     ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_10 = result.get_metric('hits@10')\n",
    "hits_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "# model = result.model\n",
    "\n",
    "# predictions_df = predict.get_prediction_df(\n",
    "#     model, \n",
    "#     triples_factory=result.training, \n",
    "#     tail_label='Kiwi', \n",
    "#     relation_label='increase_sleep_disorders')\n",
    "\n",
    "# predictions_df.head(15)\n",
    "\n",
    "predicted_tails_df = predict.get_tail_prediction_df(\n",
    "        model = result.model, \n",
    "        head_label = \"Ibuprofen\", \n",
    "        relation_label = \"decrease_adverse_effects\", \n",
    "        triples_factory = result.training,\n",
    "    )\n",
    "\n",
    "predicted_tails_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "# # ????\n",
    "# evaluator = RankBasedEvaluator()\n",
    "\n",
    "# triples = tf_test.mapped_triples\n",
    "\n",
    "# eval_results = evaluator.evaluate(\n",
    "#     model=model,\n",
    "#     mapped_triples=triples,\n",
    "#     batch_size=1024,\n",
    "#     additional_filter_triples=[\n",
    "#        train_sub.mapped_triples,\n",
    "#        valid_sub.mapped_triples,\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_to_directory(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 921595332.\n",
      "INFO:pykeen.pipeline.api:Using device: gpu\n",
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "Training epochs on cuda:0:   0%|                                               | 0/50 [00:00<?, ?epoch/s]\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   2%|▎             | 1/50 [00:00<00:05,  9.14epoch/s, loss=1.7, prev_loss=nan]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   4%|▌            | 2/50 [00:00<00:05,  9.07epoch/s, loss=1.48, prev_loss=1.7]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   6%|▋           | 3/50 [00:00<00:05,  9.05epoch/s, loss=1.38, prev_loss=1.48]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   8%|█            | 4/50 [00:00<00:05,  9.10epoch/s, loss=1.3, prev_loss=1.38]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  10%|█▎           | 5/50 [00:00<00:04,  9.13epoch/s, loss=1.22, prev_loss=1.3]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  12%|█▍          | 6/50 [00:00<00:04,  9.23epoch/s, loss=1.23, prev_loss=1.22]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  14%|█▋          | 7/50 [00:00<00:04,  9.25epoch/s, loss=1.15, prev_loss=1.23]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  16%|██           | 8/50 [00:00<00:04,  9.31epoch/s, loss=1.2, prev_loss=1.15]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  18%|██▎          | 9/50 [00:00<00:04,  9.34epoch/s, loss=1.11, prev_loss=1.2]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██▏        | 10/50 [00:01<00:04,  9.32epoch/s, loss=1.09, prev_loss=1.11]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  22%|██▍        | 11/50 [00:01<00:04,  9.34epoch/s, loss=1.06, prev_loss=1.09]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  24%|██▋        | 12/50 [00:01<00:04,  9.24epoch/s, loss=1.17, prev_loss=1.06]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  26%|██▊        | 13/50 [00:01<00:03,  9.26epoch/s, loss=1.12, prev_loss=1.17]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  28%|███        | 14/50 [00:01<00:03,  9.23epoch/s, loss=1.09, prev_loss=1.12]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  30%|███▎       | 15/50 [00:01<00:03,  9.10epoch/s, loss=1.07, prev_loss=1.09]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  32%|███▌       | 16/50 [00:01<00:03,  9.11epoch/s, loss=1.06, prev_loss=1.07]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  34%|███▍      | 17/50 [00:01<00:03,  9.21epoch/s, loss=0.972, prev_loss=1.06]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  36%|███▉       | 18/50 [00:01<00:03,  9.29epoch/s, loss=1.1, prev_loss=0.972]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  38%|████▌       | 19/50 [00:02<00:03,  9.39epoch/s, loss=1.05, prev_loss=1.1]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|████▍      | 20/50 [00:02<00:03,  9.39epoch/s, loss=1.01, prev_loss=1.05]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  42%|█████▉        | 21/50 [00:02<00:03,  9.44epoch/s, loss=1, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  44%|██████▏       | 22/50 [00:02<00:02,  9.46epoch/s, loss=1.01, prev_loss=1]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  46%|████▌     | 23/50 [00:02<00:02,  9.37epoch/s, loss=0.962, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  48%|████▊     | 24/50 [00:02<00:02,  9.41epoch/s, loss=1.02, prev_loss=0.962]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  50%|█████▌     | 25/50 [00:02<00:02,  9.29epoch/s, loss=1.01, prev_loss=1.02]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  52%|█████▏    | 26/50 [00:02<00:02,  9.23epoch/s, loss=0.981, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  54%|████▊    | 27/50 [00:02<00:02,  9.32epoch/s, loss=0.925, prev_loss=0.981]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  56%|███████▎     | 28/50 [00:03<00:02,  9.37epoch/s, loss=1, prev_loss=0.925]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  58%|███████▌     | 29/50 [00:03<00:02,  9.42epoch/s, loss=0.963, prev_loss=1]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  60%|█████▍   | 30/50 [00:03<00:02,  9.37epoch/s, loss=0.996, prev_loss=0.963]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  62%|█████▌   | 31/50 [00:03<00:02,  9.44epoch/s, loss=0.933, prev_loss=0.996]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  64%|█████▊   | 32/50 [00:03<00:01,  9.50epoch/s, loss=0.953, prev_loss=0.933]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  66%|█████▉   | 33/50 [00:03<00:01,  9.52epoch/s, loss=0.952, prev_loss=0.953]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  68%|██████   | 34/50 [00:03<00:01,  9.51epoch/s, loss=0.934, prev_loss=0.952]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  70%|██████▎  | 35/50 [00:03<00:01,  9.53epoch/s, loss=0.959, prev_loss=0.934]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  72%|██████▍  | 36/50 [00:03<00:01,  9.50epoch/s, loss=0.857, prev_loss=0.959]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  74%|██████▋  | 37/50 [00:03<00:01,  9.54epoch/s, loss=0.879, prev_loss=0.857]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  76%|██████▊  | 38/50 [00:04<00:01,  9.56epoch/s, loss=0.899, prev_loss=0.879]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  78%|███████  | 39/50 [00:04<00:01,  9.52epoch/s, loss=0.956, prev_loss=0.899]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  80%|███████▏ | 40/50 [00:04<00:01,  9.54epoch/s, loss=0.885, prev_loss=0.956]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  82%|████████▏ | 41/50 [00:04<00:00,  9.58epoch/s, loss=0.92, prev_loss=0.885]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  84%|████████▍ | 42/50 [00:04<00:00,  9.50epoch/s, loss=0.834, prev_loss=0.92]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  86%|███████▋ | 43/50 [00:04<00:00,  9.52epoch/s, loss=0.862, prev_loss=0.834]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  88%|███████▉ | 44/50 [00:04<00:00,  9.55epoch/s, loss=0.879, prev_loss=0.862]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  90%|████████ | 45/50 [00:04<00:00,  9.57epoch/s, loss=0.873, prev_loss=0.879]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  92%|████████▎| 46/50 [00:04<00:00,  9.60epoch/s, loss=0.916, prev_loss=0.873]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  94%|████████▍| 47/50 [00:05<00:00,  9.60epoch/s, loss=0.869, prev_loss=0.916]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  96%|█████████▌| 48/50 [00:05<00:00,  9.58epoch/s, loss=0.88, prev_loss=0.869]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  98%|█████████▊| 49/50 [00:05<00:00,  9.59epoch/s, loss=0.861, prev_loss=0.88]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                               | 0/7 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0: 100%|█████████| 50/50 [00:05<00:00,  9.40epoch/s, loss=0.819, prev_loss=0.861]\u001b[A\n",
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=201.\n",
      "Evaluating on cuda:0: 100%|████████████████████████████████████████| 201/201 [00:00<00:00, 8.99ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.03s seconds\n"
     ]
    }
   ],
   "source": [
    "result = pipeline(\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    "    epochs=50,\n",
    "    evaluator=RankBasedEvaluator,\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 150\n",
    "    },\n",
    "    regularizer = \"Lp\",\n",
    "    regularizer_kwargs = {\n",
    "      \"apply_only_once\": False,\n",
    "      \"weight\": 0.01,\n",
    "      \"p\": 2.0,\n",
    "      \"normalize\": False\n",
    "    },\n",
    "    \n",
    "    device='gpu',\n",
    "    optimizer = \"AdaGrad\",\n",
    "    optimizer_kwargs = {\n",
    "      \"lr\": 0.01\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransE(\n",
       "  (loss): MarginRankingLoss(\n",
       "    (margin_activation): ReLU()\n",
       "  )\n",
       "  (interaction): TransEInteraction()\n",
       "  (entity_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (regularizer): LpRegularizer()\n",
       "      (_embeddings): Embedding(14, 100)\n",
       "    )\n",
       "  )\n",
       "  (relation_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (regularizer): LpRegularizer()\n",
       "      (_embeddings): Embedding(55, 100)\n",
       "    )\n",
       "  )\n",
       "  (weight_regularizers): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = result.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Side</th>\n",
       "      <th>Type</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>0.460870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>2.644154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>2.246284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>0.460874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>2.644154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.441398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.484395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.527993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.441398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.484395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Side         Type                 Metric     Value\n",
       "0    head   optimistic  z_geometric_mean_rank  0.460870\n",
       "1    tail   optimistic  z_geometric_mean_rank  2.644154\n",
       "2    both   optimistic  z_geometric_mean_rank  2.246284\n",
       "3    head    realistic  z_geometric_mean_rank  0.460874\n",
       "4    tail    realistic  z_geometric_mean_rank  2.644154\n",
       "..    ...          ...                    ...       ...\n",
       "220  tail    realistic     adjusted_hits_at_k  0.441398\n",
       "221  both    realistic     adjusted_hits_at_k  0.484395\n",
       "222  head  pessimistic     adjusted_hits_at_k  0.527993\n",
       "223  tail  pessimistic     adjusted_hits_at_k  0.441398\n",
       "224  both  pessimistic     adjusted_hits_at_k  0.484395\n",
       "\n",
       "[225 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        training = tf_train,\n",
    "        validation = tf_valid,\n",
    "        testing = tf_test,\n",
    "        model='TransR',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=20, high=160, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-02 11:48:50,403]\u001b[0m A new study created in memory with name: no-name-ce86071b-113e-43a3-adea-27f872da1cf2\u001b[0m\n",
      "No random seed is specified. Setting to 1425790650.\n",
      "Training epochs on cuda:0:   0%|                     | 0/100 [00:00<?, ?epoch/s]\n",
      "Training batches on cuda:0:   0%|                  | 0/28520 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 1/28520 [00:00<1:14:23,  6.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|          | 7/28520 [00:00<16:00, 29.68batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 13/28520 [00:00<12:10, 39.01batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 19/28520 [00:00<10:52, 43.66batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 25/28520 [00:00<10:12, 46.52batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 30/28520 [00:00<10:28, 45.36batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 36/28520 [00:00<09:59, 47.55batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 42/28520 [00:00<09:40, 49.03batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 48/28520 [00:01<09:28, 50.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 54/28520 [00:01<09:19, 50.83batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 60/28520 [00:01<09:14, 51.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 66/28520 [00:01<09:09, 51.81batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 72/28520 [00:01<09:03, 52.30batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 78/28520 [00:01<09:03, 52.38batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 84/28520 [00:01<09:03, 52.37batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 90/28520 [00:01<09:03, 52.32batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|         | 96/28520 [00:01<09:02, 52.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 102/28520 [00:02<09:02, 52.43batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 108/28520 [00:02<09:01, 52.51batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 114/28520 [00:02<09:01, 52.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 120/28520 [00:02<09:01, 52.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 126/28520 [00:02<09:01, 52.42batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 132/28520 [00:02<09:01, 52.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   0%|        | 138/28520 [00:02<09:02, 52.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 144/28520 [00:02<09:02, 52.34batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 150/28520 [00:03<09:02, 52.31batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 156/28520 [00:03<09:02, 52.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 162/28520 [00:03<09:04, 52.11batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 168/28520 [00:03<09:03, 52.21batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 174/28520 [00:03<09:02, 52.25batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 180/28520 [00:03<09:01, 52.33batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 186/28520 [00:03<09:00, 52.39batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 192/28520 [00:03<09:00, 52.44batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 198/28520 [00:03<08:59, 52.46batch/s]\u001b[A\n",
      "Training batches on cuda:0:   1%|        | 204/28520 [00:04<09:00, 52.41batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   0%|                     | 0/100 [00:04<?, ?epoch/s]\u001b[A\n",
      "\u001b[33m[W 2023-02-02 11:48:57,322]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py\", line 259, in __call__\n",
      "    result = pipeline(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py\", line 1291, in pipeline\n",
      "    losses = training_loop_instance.train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 378, in train\n",
      "    result = self._train(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 642, in _train\n",
      "    batch_loss = self._forward_pass(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py\", line 817, in _forward_pass\n",
      "    loss = self._process_batch(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py\", line 139, in _process_batch\n",
      "    return self._process_batch_static(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py\", line 101, in _process_batch_static\n",
      "    positive_batch = positive_batch[start:stop].to(device=model.device)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hpo_pipeline_result \u001b[38;5;241m=\u001b[39m \u001b[43mhpo_pipeline_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:486\u001b[0m, in \u001b[0;36mhpo_pipeline_from_config\u001b[0;34m(config, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhpo_pipeline_from_config\u001b[39m(config: Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HpoPipelineResult:\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the HPO pipeline using a properly formatted configuration dictionary.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhpo_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:857\u001b[0m, in \u001b[0;36mhpo_pipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, model_kwargs_ranges, loss, loss_kwargs, loss_kwargs_ranges, regularizer, regularizer_kwargs, regularizer_kwargs_ranges, optimizer, optimizer_kwargs, optimizer_kwargs_ranges, lr_scheduler, lr_scheduler_kwargs, lr_scheduler_kwargs_ranges, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, negative_sampler_kwargs_ranges, epochs, training_kwargs, training_kwargs_ranges, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, metric, filter_validation_when_testing, result_tracker, result_tracker_kwargs, device, storage, sampler, sampler_kwargs, pruner, pruner_kwargs, study_name, direction, load_if_exists, n_trials, timeout, n_jobs, save_model_directory)\u001b[0m\n\u001b[1;32m    801\u001b[0m objective \u001b[38;5;241m=\u001b[39m Objective(\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# 1. Dataset\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    854\u001b[0m )\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# Invoke optimization of the objective function.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrial\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mMemoryError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HpoPipelineResult(\n\u001b[1;32m    866\u001b[0m     study\u001b[38;5;241m=\u001b[39mstudy,\n\u001b[1;32m    867\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    868\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/hpo/hpo.py:259\u001b[0m, in \u001b[0;36mObjective.__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_stopper_callbacks(_stopper_kwargs, trial, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric, result_tracker\u001b[38;5;241m=\u001b[39mresult_tracker)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 1. Dataset\u001b[39;49;00m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 2. Model\u001b[39;49;00m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 3. Loss\u001b[39;49;00m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_loss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 4. Regularizer\u001b[39;49;00m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_regularizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5. Optimizer\u001b[39;49;00m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_optimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5.1 Learning Rate Scheduler\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lr_scheduler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 6. Training Loop\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_negative_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 7. Training\u001b[39;49;00m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_training_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 8. Evaluation\u001b[39;49;00m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 9. Tracker\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_tracker_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Misc.\u001b[39;49;00m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use validation set during HPO!\u001b[39;49;00m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# close run in result tracker\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     result_tracker\u001b[38;5;241m.\u001b[39mend_run(success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:642\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    639\u001b[0m stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m _sub_batch_size, current_batch_size)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# forward pass call\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m current_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m    651\u001b[0m num_training_instances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:817\u001b[0m, in \u001b[0;36mTrainingLoop._forward_pass\u001b[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_pass\u001b[39m(\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    809\u001b[0m     batch: BatchType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;66;03m# raise error when non-finite loss occurs (NaN, +/-inf)\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misfinite(loss):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py:139\u001b[0m, in \u001b[0;36mSLCWATrainingLoop._process_batch\u001b[0;34m(self, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_batch\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     batch: SLCWABatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     slice_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch_static\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py:101\u001b[0m, in \u001b[0;36mSLCWATrainingLoop._process_batch_static\u001b[0;34m(model, loss, mode, batch, start, stop, label_smoothing, slice_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m positive_batch, negative_batch, positive_filter \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# send to device\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m positive_batch \u001b[38;5;241m=\u001b[39m \u001b[43mpositive_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m negative_batch \u001b[38;5;241m=\u001b[39m negative_batch[start:stop]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m positive_filter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Running: nations - try\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 466234060.\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "Training epochs on cuda:0:   0%|                                              | 0/100 [00:00<?, ?epoch/s]\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████████████████████████████████████| 50/50 [00:00<00:00, 495.79batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   1%|            | 1/100 [00:00<00:19,  4.98epoch/s, loss=1.49, prev_loss=nan]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 468.44batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   2%|▏          | 2/100 [00:00<00:20,  4.83epoch/s, loss=1.37, prev_loss=1.49]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 449.36batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   3%|▎          | 3/100 [00:00<00:20,  4.69epoch/s, loss=1.33, prev_loss=1.37]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 412.71batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   4%|▍          | 4/100 [00:00<00:20,  4.58epoch/s, loss=1.34, prev_loss=1.33]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|███████████████████████████████████▎| 49/50 [00:00<00:00, 481.66batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   5%|▌           | 5/100 [00:01<00:20,  4.63epoch/s, loss=1.3, prev_loss=1.34]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  66%|███████████████████████▊            | 33/50 [00:00<00:00, 327.92batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   6%|▊            | 6/100 [00:01<00:21,  4.44epoch/s, loss=1.3, prev_loss=1.3]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 423.74batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   7%|▊           | 7/100 [00:01<00:21,  4.42epoch/s, loss=1.27, prev_loss=1.3]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|████████████████████████████        | 39/50 [00:00<00:00, 389.04batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   8%|▉          | 8/100 [00:01<00:20,  4.41epoch/s, loss=1.22, prev_loss=1.27]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████████▏          | 35/50 [00:00<00:00, 343.29batch/s]\u001b[A\n",
      "Training epochs on cuda:0:   9%|▉          | 9/100 [00:02<00:20,  4.37epoch/s, loss=1.22, prev_loss=1.22]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 425.67batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  10%|█         | 10/100 [00:02<00:20,  4.45epoch/s, loss=1.18, prev_loss=1.22]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 455.02batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  11%|█         | 11/100 [00:02<00:19,  4.53epoch/s, loss=1.19, prev_loss=1.18]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 447.84batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  12%|█▏        | 12/100 [00:02<00:19,  4.59epoch/s, loss=1.19, prev_loss=1.19]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████████             | 32/50 [00:00<00:00, 313.16batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  13%|█▎        | 13/100 [00:02<00:19,  4.42epoch/s, loss=1.11, prev_loss=1.19]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 459.24batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  14%|█▍        | 14/100 [00:03<00:18,  4.53epoch/s, loss=1.12, prev_loss=1.11]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 456.98batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  15%|█▌        | 15/100 [00:03<00:18,  4.52epoch/s, loss=1.13, prev_loss=1.12]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 398.46batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  16%|█▌        | 16/100 [00:03<00:18,  4.49epoch/s, loss=1.13, prev_loss=1.13]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  17%|█▋        | 17/100 [00:03<00:17,  4.69epoch/s, loss=1.11, prev_loss=1.13]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  18%|█▊        | 18/100 [00:03<00:17,  4.75epoch/s, loss=1.13, prev_loss=1.11]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 469.24batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  19%|█▉        | 19/100 [00:04<00:17,  4.69epoch/s, loss=1.09, prev_loss=1.13]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 397.87batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  20%|██        | 20/100 [00:04<00:17,  4.56epoch/s, loss=1.06, prev_loss=1.09]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████████████████████████████▌      | 41/50 [00:00<00:00, 406.69batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  21%|██        | 21/100 [00:04<00:17,  4.49epoch/s, loss=1.05, prev_loss=1.06]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|███████████████████████████████████▎| 49/50 [00:00<00:00, 481.44batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  22%|██▏       | 22/100 [00:04<00:17,  4.54epoch/s, loss=1.07, prev_loss=1.05]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████████             | 32/50 [00:00<00:00, 313.94batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  23%|██▎       | 23/100 [00:05<00:17,  4.35epoch/s, loss=1.03, prev_loss=1.07]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 442.26batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  24%|██▍       | 24/100 [00:05<00:17,  4.43epoch/s, loss=1.04, prev_loss=1.03]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 457.45batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  25%|██▌       | 25/100 [00:05<00:16,  4.51epoch/s, loss=1.06, prev_loss=1.04]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 445.64batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  26%|███▍         | 26/100 [00:05<00:16,  4.53epoch/s, loss=1, prev_loss=1.06]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 453.35batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  27%|███▌         | 27/100 [00:05<00:15,  4.62epoch/s, loss=1.01, prev_loss=1]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 414.85batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  28%|██▊       | 28/100 [00:06<00:15,  4.60epoch/s, loss=1.01, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 414.47batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  29%|██▉       | 29/100 [00:06<00:15,  4.61epoch/s, loss=0.99, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 447.90batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  30%|███       | 30/100 [00:06<00:15,  4.66epoch/s, loss=1.02, prev_loss=0.99]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████████▋         | 37/50 [00:00<00:00, 366.67batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  31%|██▊      | 31/100 [00:06<00:15,  4.60epoch/s, loss=0.994, prev_loss=1.02]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 413.47batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  32%|██▌     | 32/100 [00:07<00:15,  4.49epoch/s, loss=0.997, prev_loss=0.994]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████████████████████████████████▌ | 48/50 [00:00<00:00, 473.74batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  33%|██▉      | 33/100 [00:07<00:14,  4.53epoch/s, loss=1.01, prev_loss=0.997]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|███████████████████████████████████▎| 49/50 [00:00<00:00, 482.97batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  34%|███      | 34/100 [00:07<00:14,  4.55epoch/s, loss=0.972, prev_loss=1.01]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 413.33batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  35%|██▊     | 35/100 [00:07<00:14,  4.55epoch/s, loss=0.977, prev_loss=0.972]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 453.44batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  36%|██▉     | 36/100 [00:07<00:14,  4.53epoch/s, loss=0.926, prev_loss=0.977]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 427.93batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  37%|███▎     | 37/100 [00:08<00:14,  4.48epoch/s, loss=0.97, prev_loss=0.926]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  64%|███████████████████████             | 32/50 [00:00<00:00, 316.10batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  38%|███▍     | 38/100 [00:08<00:14,  4.23epoch/s, loss=0.953, prev_loss=0.97]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████████▉          | 36/50 [00:00<00:00, 352.65batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  39%|███     | 39/100 [00:08<00:14,  4.17epoch/s, loss=0.982, prev_loss=0.953]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███████████████████████████▎        | 38/50 [00:00<00:00, 379.74batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  40%|███▌     | 40/100 [00:08<00:14,  4.22epoch/s, loss=0.92, prev_loss=0.982]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████████████████████████████▌      | 41/50 [00:00<00:00, 402.18batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  41%|███▋     | 41/100 [00:09<00:13,  4.29epoch/s, loss=0.997, prev_loss=0.92]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 458.27batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  42%|███▎    | 42/100 [00:09<00:13,  4.36epoch/s, loss=0.912, prev_loss=0.997]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████████████████████████████████████| 50/50 [00:00<00:00, 496.33batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  43%|███▍    | 43/100 [00:09<00:12,  4.50epoch/s, loss=0.942, prev_loss=0.912]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 455.45batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  44%|███▌    | 44/100 [00:09<00:12,  4.58epoch/s, loss=0.907, prev_loss=0.942]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████████████████████████████▌      | 41/50 [00:00<00:00, 406.29batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  45%|███▌    | 45/100 [00:09<00:12,  4.55epoch/s, loss=0.899, prev_loss=0.907]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 457.60batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  46%|███▋    | 46/100 [00:10<00:11,  4.53epoch/s, loss=0.941, prev_loss=0.899]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███████████████████████████▎        | 38/50 [00:00<00:00, 376.53batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  47%|███▊    | 47/100 [00:10<00:12,  4.42epoch/s, loss=0.901, prev_loss=0.941]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 426.82batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  48%|███▊    | 48/100 [00:10<00:11,  4.43epoch/s, loss=0.891, prev_loss=0.901]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████████▋         | 37/50 [00:00<00:00, 369.23batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  49%|███▉    | 49/100 [00:10<00:11,  4.34epoch/s, loss=0.908, prev_loss=0.891]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████████▏          | 35/50 [00:00<00:00, 349.02batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  50%|████    | 50/100 [00:11<00:11,  4.31epoch/s, loss=0.891, prev_loss=0.908]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 457.20batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  51%|████    | 51/100 [00:11<00:11,  4.40epoch/s, loss=0.853, prev_loss=0.891]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  82%|█████████████████████████████▌      | 41/50 [00:00<00:00, 404.88batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  52%|████▏   | 52/100 [00:11<00:10,  4.37epoch/s, loss=0.912, prev_loss=0.853]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|███████████████████████████████████▎| 49/50 [00:00<00:00, 489.17batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  53%|████▏   | 53/100 [00:11<00:10,  4.47epoch/s, loss=0.869, prev_loss=0.912]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  98%|███████████████████████████████████▎| 49/50 [00:00<00:00, 484.39batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  54%|████▎   | 54/100 [00:12<00:10,  4.53epoch/s, loss=0.865, prev_loss=0.869]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 444.82batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  55%|████▉    | 55/100 [00:12<00:09,  4.52epoch/s, loss=0.89, prev_loss=0.865]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 396.50batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  56%|█████    | 56/100 [00:12<00:09,  4.50epoch/s, loss=0.881, prev_loss=0.89]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|████████████████████████████        | 39/50 [00:00<00:00, 388.31batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  57%|████▌   | 57/100 [00:12<00:09,  4.50epoch/s, loss=0.859, prev_loss=0.881]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  58%|████▋   | 58/100 [00:12<00:09,  4.65epoch/s, loss=0.862, prev_loss=0.859]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|███████████████████████████████▋    | 44/50 [00:00<00:00, 433.22batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  59%|████▋   | 59/100 [00:13<00:08,  4.65epoch/s, loss=0.878, prev_loss=0.862]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 455.78batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  60%|████▊   | 60/100 [00:13<00:08,  4.65epoch/s, loss=0.869, prev_loss=0.878]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 441.91batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  61%|████▉   | 61/100 [00:13<00:08,  4.65epoch/s, loss=0.876, prev_loss=0.869]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████████▋         | 37/50 [00:00<00:00, 368.96batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  62%|████▉   | 62/100 [00:13<00:08,  4.50epoch/s, loss=0.826, prev_loss=0.876]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 457.79batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  63%|█████   | 63/100 [00:13<00:08,  4.51epoch/s, loss=0.864, prev_loss=0.826]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████████████████████████████████▌ | 48/50 [00:00<00:00, 477.63batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  64%|█████   | 64/100 [00:14<00:07,  4.54epoch/s, loss=0.879, prev_loss=0.864]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 463.00batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  65%|█████▏  | 65/100 [00:14<00:07,  4.64epoch/s, loss=0.845, prev_loss=0.879]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 423.29batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  66%|█████▎  | 66/100 [00:14<00:07,  4.63epoch/s, loss=0.859, prev_loss=0.845]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 453.25batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  67%|█████▎  | 67/100 [00:14<00:07,  4.66epoch/s, loss=0.846, prev_loss=0.859]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████████▋         | 37/50 [00:00<00:00, 368.06batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  68%|█████▍  | 68/100 [00:15<00:07,  4.50epoch/s, loss=0.868, prev_loss=0.846]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 464.17batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  69%|██████▏  | 69/100 [00:15<00:06,  4.58epoch/s, loss=0.82, prev_loss=0.868]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 418.10batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  70%|██████▎  | 70/100 [00:15<00:06,  4.60epoch/s, loss=0.857, prev_loss=0.82]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 426.72batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  71%|█████▋  | 71/100 [00:15<00:06,  4.54epoch/s, loss=0.821, prev_loss=0.857]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  72%|█████████████████████████▉          | 36/50 [00:00<00:00, 352.51batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  72%|█████▊  | 72/100 [00:15<00:06,  4.40epoch/s, loss=0.799, prev_loss=0.821]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|████████████████████████████        | 39/50 [00:00<00:00, 386.09batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  73%|█████▊  | 73/100 [00:16<00:06,  4.36epoch/s, loss=0.813, prev_loss=0.799]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███████████████████████████▎        | 38/50 [00:00<00:00, 373.67batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  74%|█████▉  | 74/100 [00:16<00:06,  4.28epoch/s, loss=0.829, prev_loss=0.813]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 448.17batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  75%|██████  | 75/100 [00:16<00:05,  4.35epoch/s, loss=0.812, prev_loss=0.829]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|███████████████████████████████▋    | 44/50 [00:00<00:00, 438.82batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  76%|██████  | 76/100 [00:16<00:05,  4.46epoch/s, loss=0.832, prev_loss=0.812]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  70%|█████████████████████████▏          | 35/50 [00:00<00:00, 343.96batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  77%|██████▏ | 77/100 [00:17<00:05,  4.31epoch/s, loss=0.822, prev_loss=0.832]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  76%|███████████████████████████▎        | 38/50 [00:00<00:00, 379.10batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  78%|██████▏ | 78/100 [00:17<00:05,  4.29epoch/s, loss=0.812, prev_loss=0.822]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 394.63batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  79%|██████▎ | 79/100 [00:17<00:04,  4.33epoch/s, loss=0.806, prev_loss=0.812]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 413.69batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  80%|██████▍ | 80/100 [00:17<00:04,  4.39epoch/s, loss=0.773, prev_loss=0.806]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████████████████████████████████▌ | 48/50 [00:00<00:00, 472.30batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  81%|██████▍ | 81/100 [00:18<00:04,  4.53epoch/s, loss=0.809, prev_loss=0.773]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 423.17batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  82%|██████▌ | 82/100 [00:18<00:03,  4.54epoch/s, loss=0.798, prev_loss=0.809]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  88%|███████████████████████████████▋    | 44/50 [00:00<00:00, 431.44batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  83%|██████▋ | 83/100 [00:18<00:03,  4.50epoch/s, loss=0.822, prev_loss=0.798]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 416.62batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  84%|██████▋ | 84/100 [00:18<00:03,  4.53epoch/s, loss=0.778, prev_loss=0.822]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 462.63batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  85%|██████▊ | 85/100 [00:18<00:03,  4.60epoch/s, loss=0.798, prev_loss=0.778]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  74%|██████████████████████████▋         | 37/50 [00:00<00:00, 366.79batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  86%|███████▋ | 86/100 [00:19<00:03,  4.46epoch/s, loss=0.79, prev_loss=0.798]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  96%|██████████████████████████████████▌ | 48/50 [00:00<00:00, 479.79batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  87%|███████▊ | 87/100 [00:19<00:02,  4.53epoch/s, loss=0.798, prev_loss=0.79]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0: 100%|████████████████████████████████████| 50/50 [00:00<00:00, 492.91batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  88%|███████ | 88/100 [00:19<00:02,  4.62epoch/s, loss=0.778, prev_loss=0.798]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 461.24batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  89%|███████ | 89/100 [00:19<00:02,  4.67epoch/s, loss=0.769, prev_loss=0.778]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  78%|████████████████████████████        | 39/50 [00:00<00:00, 385.92batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  90%|███████▏| 90/100 [00:19<00:02,  4.55epoch/s, loss=0.787, prev_loss=0.769]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  86%|██████████████████████████████▉     | 43/50 [00:00<00:00, 425.41batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  91%|███████▎| 91/100 [00:20<00:02,  4.44epoch/s, loss=0.789, prev_loss=0.787]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 418.73batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  92%|███████▎| 92/100 [00:20<00:01,  4.41epoch/s, loss=0.784, prev_loss=0.789]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  84%|██████████████████████████████▏     | 42/50 [00:00<00:00, 417.23batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  93%|███████▍| 93/100 [00:20<00:01,  4.40epoch/s, loss=0.778, prev_loss=0.784]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  94%|█████████████████████████████████▊  | 47/50 [00:00<00:00, 460.82batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  94%|███████▌| 94/100 [00:20<00:01,  4.53epoch/s, loss=0.766, prev_loss=0.778]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  90%|████████████████████████████████▍   | 45/50 [00:00<00:00, 449.81batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  95%|████████▌| 95/100 [00:21<00:01,  4.59epoch/s, loss=0.78, prev_loss=0.766]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 394.53batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  96%|████████▋| 96/100 [00:21<00:00,  4.56epoch/s, loss=0.801, prev_loss=0.78]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  68%|████████████████████████▍           | 34/50 [00:00<00:00, 338.18batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  97%|███████▊| 97/100 [00:21<00:00,  4.47epoch/s, loss=0.779, prev_loss=0.801]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  92%|█████████████████████████████████   | 46/50 [00:00<00:00, 457.00batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  98%|███████▊| 98/100 [00:21<00:00,  4.58epoch/s, loss=0.785, prev_loss=0.779]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  96%|██████████████████████████████████▌ | 48/50 [00:00<00:00, 453.74batch/s]\u001b[A\n",
      "Training epochs on cuda:0:  99%|███████▉| 99/100 [00:21<00:00,  4.62epoch/s, loss=0.775, prev_loss=0.785]\u001b[A\n",
      "Training batches on cuda:0:   0%|                                              | 0/50 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cuda:0:  80%|████████████████████████████▊       | 40/50 [00:00<00:00, 399.30batch/s]\u001b[A\n",
      "Training epochs on cuda:0: 100%|███████| 100/100 [00:22<00:00,  4.50epoch/s, loss=0.794, prev_loss=0.775]\u001b[A\n",
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=201.\n",
      "Evaluating on cuda:0: 100%|████████████████████████████████████████| 201/201 [00:00<00:00, 8.27ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.03s seconds\n"
     ]
    }
   ],
   "source": [
    "config2 = {\n",
    "    \"metadata\": {\n",
    "    \"title\": \"nations - try\",\n",
    "    \"comments\": \"comment\"\n",
    "  },\n",
    "  \"pipeline\": {\n",
    "    \"dataset\": \"nations\",\n",
    "    \"model\": \"TransE\",\n",
    "    \"model_kwargs\": {\n",
    "      \"embedding_dim\": 50,\n",
    "      \"scoring_fct_norm\": 1\n",
    "    },\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\n",
    "      \"lr\": 0.01\n",
    "    },\n",
    "    \"loss\": \"MarginRankingLoss\",\n",
    "    \"loss_kwargs\": {\n",
    "      \"reduction\": \"mean\",\n",
    "      \"margin\": 1\n",
    "    },\n",
    "    \"training_loop\": \"slcwa\",\n",
    "    \"negative_sampler\": \"basic\",\n",
    "    \"negative_sampler_kwargs\": {\n",
    "      \"num_negs_per_pos\": 1\n",
    "    },\n",
    "    \"training_kwargs\": {\n",
    "      \"num_epochs\": 100,\n",
    "      \"batch_size\": 32\n",
    "    },\n",
    "    \"evaluator_kwargs\": {\n",
    "      \"filtered\": True\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "pipeline_result = pipeline_from_config(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Side</th>\n",
       "      <th>Type</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>0.630263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>3.690055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>3.158749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>0.630264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>z_geometric_mean_rank</td>\n",
       "      <td>3.690055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.627598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.578141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.527993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.627598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.578141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Side         Type                 Metric     Value\n",
       "0    head   optimistic  z_geometric_mean_rank  0.630263\n",
       "1    tail   optimistic  z_geometric_mean_rank  3.690055\n",
       "2    both   optimistic  z_geometric_mean_rank  3.158749\n",
       "3    head    realistic  z_geometric_mean_rank  0.630264\n",
       "4    tail    realistic  z_geometric_mean_rank  3.690055\n",
       "..    ...          ...                    ...       ...\n",
       "220  tail    realistic     adjusted_hits_at_k  0.627598\n",
       "221  both    realistic     adjusted_hits_at_k  0.578141\n",
       "222  head  pessimistic     adjusted_hits_at_k  0.527993\n",
       "223  tail  pessimistic     adjusted_hits_at_k  0.627598\n",
       "224  both  pessimistic     adjusted_hits_at_k  0.578141\n",
       "\n",
       "[225 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 3941871803.\n",
      "INFO:pykeen.pipeline.api:Using device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: dataset = nations\n",
      "Parameter: dataset_kwargs = None\n",
      "Parameter: model = MuRE\n",
      "Parameter: model_kwargs.random_seed = 3941871803\n",
      "Parameter: model_kwargs.loss = MarginRankingLoss(\n",
      "  (margin_activation): ReLU()\n",
      ")\n",
      "Parameter: loss_kwargs = None\n",
      "Parameter: regularizer_kwargs = None\n",
      "Parameter: optimizer = Adam\n",
      "Parameter: optimizer_kwargs.lr = 0.001\n",
      "Parameter: optimizer_kwargs.betas = (0.9, 0.999)\n",
      "Parameter: optimizer_kwargs.eps = 1e-08\n",
      "Parameter: optimizer_kwargs.weight_decay = 0\n",
      "Parameter: optimizer_kwargs.amsgrad = False\n",
      "Parameter: optimizer_kwargs.maximize = False\n",
      "Parameter: optimizer_kwargs.foreach = None\n",
      "Parameter: optimizer_kwargs.capturable = False\n",
      "Parameter: optimizer_kwargs.differentiable = False\n",
      "Parameter: optimizer_kwargs.fused = False\n",
      "Parameter: training_loop = SLCWATrainingLoop\n",
      "Parameter: evaluator = RankBasedEvaluator\n",
      "Parameter: callbacks = validation-loss\n",
      "Parameter: callback_kwargs.triples_factory = TriplesFactory(num_entities=14, num_relations=55, create_inverse_triples=False, num_triples=199, path=\"/usr/local/lib/python3.8/dist-packages/pykeen/datasets/nations/valid.txt\")\n",
      "Parameter: num_epochs = 5\n",
      "Parameter: batch_size = 256\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Invalid TrainingCallback name: validation-loss. Valid choices are: ['evaluation', 'evaluationloop', 'gradientabsclipping', 'gradientnormclipping', 'stopper', 'tracker']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m get_dataset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# pipeline_result = pipeline(\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     model='RotatE',\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     dataset=dataset,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     )    \u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation-loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:470\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    464\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing RGCN without graph-based sampling! Please select sampler=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschlichtkrull\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    466\u001b[0m         sampler,\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Prepare all of the callbacks\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m callback \u001b[38;5;241m=\u001b[39m \u001b[43mMultiTrainingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# Register a callback for the result tracker, if given\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_tracker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/callbacks.py:406\u001b[0m, in \u001b[0;36mMultiTrainingCallback.__init__\u001b[0;34m(self, callbacks, callback_kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03mInitialize the callback.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    additional keyword-based parameters for instantiating the callbacks\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[43mcallback_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/class_resolver/api.py:345\u001b[0m, in \u001b[0;36mClassResolver.make_many\u001b[0;34m(self, queries, kwargs, **common_kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_kwargs_list) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_query_list):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in number number of queries and kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake(query\u001b[38;5;241m=\u001b[39m_result_tracker, pos_kwargs\u001b[38;5;241m=\u001b[39m_result_tracker_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_kwargs)\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _result_tracker, _result_tracker_kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_query_list, _kwargs_list)\n\u001b[1;32m    348\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/class_resolver/api.py:346\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_kwargs_list) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_query_list):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in number number of queries and kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_result_tracker_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _result_tracker, _result_tracker_kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_query_list, _kwargs_list)\n\u001b[1;32m    348\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/class_resolver/api.py:202\u001b[0m, in \u001b[0;36mClassResolver.make\u001b[0;34m(self, query, pos_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiate a class with optional kwargs.\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m)):\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[X] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(pos_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/class_resolver/api.py:176\u001b[0m, in \u001b[0;36mClassResolver.lookup\u001b[0;34m(self, query, default)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlookup\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: HintOrType[X], default: Optional[Type[X]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type[X]:\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lookup a class.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookup_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookup_dict_synonyms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynonyms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/class_resolver/api.py:378\u001b[0m, in \u001b[0;36mget_cls\u001b[0;34m(query, base, lookup_dict, lookup_dict_synonyms, default, suffix)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m         valid_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(lookup_dict\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;241m.\u001b[39munion(lookup_dict_synonyms \u001b[38;5;129;01mor\u001b[39;00m []))\n\u001b[0;32m--> 378\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Valid choices are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_choices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, base):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Invalid TrainingCallback name: validation-loss. Valid choices are: ['evaluation', 'evaluationloop', 'gradientabsclipping', 'gradientnormclipping', 'stopper', 'tracker']\""
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.trackers import ResultTracker\n",
    "\n",
    "\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "\n",
    "pipeline_result = pipeline(\n",
    "    model='RotatE',\n",
    "    dataset=dataset,\n",
    "    result_tracker=\"console\",\n",
    "    result_tracker_kwargs = dict(metric_filter='.*head.realistic.hits_at_10.*'),\n",
    "    training_kwargs = dict(\n",
    "        num_epochs = 5,\n",
    "        callbacks=\"validation-loss\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "        ),\n",
    "    )    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
