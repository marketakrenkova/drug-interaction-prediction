{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph\n",
    "#### Drug-Food or Drug-Supplements interaction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory, CoreTriplesFactory\n",
    "from pykeen.models import TransE\n",
    "from pykeen.evaluation import RankBasedEvaluator, OGBEvaluator\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from kg_model import KG_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/triplets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_df = pd.read_csv(data_dir + 'ddi.tsv', sep='\\t', index_col=[0])\n",
    "ddi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total interactions:', ddi_df.shape[0])\n",
    "print('unique interactions:', len(set(ddi_df.interaction)))\n",
    "\n",
    "interaction_counts = ddi_df.groupby(by=['interaction']).size()\n",
    "interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ddi_df.interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_supplement_df = pd.read_csv(data_dir + 'ds_relations.tsv', sep='\\t', index_col=[0])\n",
    "# drug_supplement_df = drug_supplement_df[drug_supplement_df['REL'] != 'has_ingredient']\n",
    "drug_supplement_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total interactions:', drug_supplement_df.shape[0])\n",
    "print('unique interactions:', len(set(drug_supplement_df.REL)))\n",
    "\n",
    "ds_interaction_counts = drug_supplement_df.groupby(by=['REL']).size()\n",
    "ds_interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_count = pd.concat([interaction_counts, ds_interaction_counts])\n",
    "interactions_count.to_csv('interaction_counts.csv', header=['interaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size(n):\n",
    "    if n == 2:\n",
    "        return 1, 1\n",
    "    if n == 3:\n",
    "        return 1, 2\n",
    "    if n == 4:\n",
    "        return 2, 3\n",
    "    if n == 5:\n",
    "        return 3, 4\n",
    "    if n == 6:\n",
    "        return 4, 5\n",
    "    # n == 7\n",
    "    return 4, 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : valid : test = 80 : 10 : 10\n",
    "def split_data_relation(df_relation):\n",
    "    \n",
    "    # too few triplets with the realtion\n",
    "    if df_relation.shape[0] <= 7:\n",
    "        train_size, valid_size = compute_size(df_relation.shape[0])\n",
    "        \n",
    "        # shuffle df_relation\n",
    "        df_relation = df_relation.sample(frac=1, random_state=42)\n",
    "        \n",
    "        X_train = df_relation.iloc[:train_size]\n",
    "        X_valid = df_relation.iloc[train_size:valid_size]\n",
    "        X_test = df_relation.iloc[valid_size:]\n",
    "\n",
    "    else:\n",
    "        X_train, X_rem = train_test_split(df_relation, train_size=0.8, random_state=42)\n",
    "        X_valid, X_test = train_test_split(X_rem, test_size=0.5, random_state=42)\n",
    "        \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-supplements relation dataset\n",
    "def split_drug_supplements_dataset(drug_supplement_df):\n",
    "    relations = set(drug_supplement_df.REL)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    test_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "\n",
    "    for rel in relations:\n",
    "        train, valid, test = split_data_relation(drug_supplement_df[drug_supplement_df['REL'] == rel])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "\n",
    "    train_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-drug interaction dataset (from DrugBank)\n",
    "def split_ddi_dataset(ddi_df):\n",
    "    interactions = set(ddi_df.interaction)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    test_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    \n",
    "    for inter in interactions:\n",
    "        train, valid, test = split_data_relation(ddi_df[ddi_df['interaction'] == inter])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "        \n",
    "    train_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugBank drug-drug interactions\n",
    "print('DrugBank drug-drug interactions')\n",
    "train_triplets_ddi, valid_triplets_ddi, test_triplets_ddi = split_ddi_dataset(ddi_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# Drug Supplement database - drug-suplement interactions\n",
    "print('Drug Supplement database - drug-suplement interactions')\n",
    "train_triplets_ds, valid_triplets_ds, test_triplets_ds = split_drug_supplements_dataset(drug_supplement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all interactions\n",
    "train_triplets = pd.concat([train_triplets_ddi, train_triplets_ds])\n",
    "valid_triplets = pd.concat([valid_triplets_ddi, valid_triplets_ds])\n",
    "test_triplets = pd.concat([test_triplets_ddi, test_triplets_ds])\n",
    "\n",
    "print('All interactions:')\n",
    "print('train dataset size:', train_triplets.shape[0])\n",
    "print('validation dataset size:',valid_triplets.shape[0])\n",
    "print('test dataset size:',test_triplets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = set(train_triplets.relation)\n",
    "print('Number of unique interactions:', len(all_relations))\n",
    "print(list(all_relations)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add rest of the data into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(data_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file == 'ddi.tsv' or file == '.ipynb_checkpoints' or file == 'ds_relations.tsv':\n",
    "        continue\n",
    "    if 'train' in file or 'valid' in file or 'test' in file:\n",
    "        continue\n",
    "           \n",
    "    df = pd.read_csv(data_dir + file, sep='\\t', index_col=[0])\n",
    "    \n",
    "    # if file == 'ds_relations.tsv':\n",
    "    #     df = df[df['REL'] == 'has_ingredient']\n",
    "    \n",
    "    df.set_axis(['head', 'relation', 'tail'], axis=1, inplace=True) \n",
    "    train_triplets = pd.concat([train_triplets, df])\n",
    "    \n",
    "print('Final size of train dataset (with other relations):', train_triplets.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = train_triplets.astype(str)\n",
    "valid_triplets = valid_triplets.astype(str)\n",
    "test_triplets = test_triplets.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train, valid and test datasets\n",
    "\n",
    "train_triplets.to_csv(data_dir + 'train.tsv', sep='\\t')\n",
    "valid_triplets.to_csv(data_dir + 'valid.tsv', sep='\\t')\n",
    "test_triplets.to_csv(data_dir + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "specification = '_biokg'\n",
    "\n",
    "train_triplets = pd.read_csv(data_dir + 'train' + specification + '.tsv', sep='\\t')\n",
    "valid_triplets = pd.read_csv(data_dir + 'valid' + specification + '.tsv', sep='\\t')\n",
    "test_triplets = pd.read_csv(data_dir + 'test' + specification + '.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB00091</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB00680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB11730</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00674</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB09083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01189</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB08936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00656</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286388</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P35367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286389</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P50148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286390</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>Q14643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286391</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P05771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286392</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P19838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286393 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head             relation     tail\n",
       "0           DB00091            interacts  DB00680\n",
       "1           DB11730            interacts  DB01229\n",
       "2           DB00674            interacts  DB09083\n",
       "3           DB01189            interacts  DB08936\n",
       "4           DB00656            interacts  DB01193\n",
       "...             ...                  ...      ...\n",
       "2286388  SMP0062895  involved_in_pathway   P35367\n",
       "2286389  SMP0062895  involved_in_pathway   P50148\n",
       "2286390  SMP0062895  involved_in_pathway   Q14643\n",
       "2286391  SMP0062895  involved_in_pathway   P05771\n",
       "2286392  SMP0062895  involved_in_pathway   P19838\n",
       "\n",
       "[2286393 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_drugs = pd.read_csv('../data/common_drugs.csv', sep=';')\n",
    "common_drugs = common_drugs['DrugBank_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB13180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB06595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB00967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710881</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713314</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713397</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714848</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716650</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_6834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            head      relation           tail\n",
       "1422     DB00343     interacts        DB13180\n",
       "1879     DB00343     interacts        DB01294\n",
       "2124     DB00343     interacts        DB01104\n",
       "5535     DB00343     interacts        DB06595\n",
       "5587     DB00343     interacts        DB00967\n",
       "...          ...           ...            ...\n",
       "1710881  DB00343  drug-protein  protein_12429\n",
       "1713314  DB00343  drug-protein  protein_14135\n",
       "1713397  DB00343  drug-protein  protein_12433\n",
       "1714848  DB00343  drug-protein  protein_14123\n",
       "1716650  DB00343  drug-protein   protein_6834\n",
       "\n",
       "[1063 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets[train_triplets['head'] == common_drugs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datasets into Triples Factory format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "      data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "      create_inverse_triples=False,\n",
    "      entity_to_id=None,\n",
    "      relation_to_id=None,\n",
    "      compact_id=False \n",
    "    )\n",
    "    print(tf_data)  \n",
    "    return tf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriplesFactory(num_entities=33046, num_relations=55, create_inverse_triples=False, num_triples=2070392)\n",
      "TriplesFactory(num_entities=2410, num_relations=1, create_inverse_triples=False, num_triples=164779)\n",
      "TriplesFactory(num_entities=2424, num_relations=1, create_inverse_triples=False, num_triples=164800)\n"
     ]
    }
   ],
   "source": [
    "tf_train = convert_to_triples_factory(train_triplets.astype(str))\n",
    "tf_valid = convert_to_triples_factory(valid_triplets.astype(str))\n",
    "tf_test = convert_to_triples_factory(test_triplets.astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=911018226\n",
      "using automatically assigned random_state=3478811012\n",
      "using automatically assigned random_state=2178546174\n"
     ]
    }
   ],
   "source": [
    "# take just subset of data for testing\n",
    "\n",
    "train_sub, _ = tf_train.split(0.15)\n",
    "valid_sub, _ = tf_valid.split(0.15)\n",
    "test_sub, _ = tf_test.split(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'epochs': 2, \n",
    "          'optimizer': 'adam', \n",
    "          'learning_rate': 0.005,\n",
    "          'loss': 'MarginRankingLoss',\n",
    "          'batch': 512,\n",
    "          'embedding_dim': 300,\n",
    "          'margin': 0.64,\n",
    "          'evaluator': 'rankedbased'\n",
    "         }\n",
    "params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 3395914155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.training.training_loop:=> no checkpoint found at 'kg_checkpoints/complex-jupyter_test_checkpoint.pt'. Creating a new file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e172232ffcf4915b6094c90cc53af28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/4044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/4044 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e302cde44f48e5a59ce95691631e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/165k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 210.32s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    }
   ],
   "source": [
    "model_kg = KG_model('complex', tf_train, tf_valid, tf_test, 'jupyter_test')\n",
    "model_kg.set_params2(params)\n",
    "\n",
    "print('Training...')\n",
    "model_kg.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetPredictions(df=       tail_id     score       tail_label\n",
       "3773      3773  4.956060          DB08918\n",
       "2789      2789  4.889006          DB00871\n",
       "4389      4389  4.857689          DB11827\n",
       "2609      2609  4.852685          DB00681\n",
       "2849      2849  4.843045          DB00934\n",
       "...        ...       ...              ...\n",
       "28589    28589 -5.563348  sideeffect_5358\n",
       "10956    10956 -5.580075      disease_880\n",
       "29970    29970 -5.617806   sideeffect_680\n",
       "24460    24460 -5.680283  sideeffect_1186\n",
       "25881    25881 -5.863306  sideeffect_2614\n",
       "\n",
       "[33046 rows x 3 columns], factory=TriplesFactory(num_entities=33046, num_relations=55, create_inverse_triples=False, num_triples=2070392), target='tail', other_columns_fixed_ids=(3272, 45))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_kg.trained_model.metric_results.to_df()\n",
    "\n",
    "head = common_drugs[0]\n",
    "relation = 'interacts'\n",
    "\n",
    "pred = predict_target(\n",
    "            model = model_kg.trained_model.model, \n",
    "            head = head, \n",
    "            relation = relation, \n",
    "            triples_factory = model_kg.trained_model.training,\n",
    "        )\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031339778797701"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kg.trained_model.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hits@10       mrr\n",
       "0  0.000322  0.000313"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrices = dict()\n",
    "metrices['hits@10'] = [model_kg.trained_model.get_metric('hits@10')]\n",
    "metrices['mrr'] = [model_kg.trained_model.get_metric('mrr')]\n",
    "\n",
    "df_result = pd.DataFrame(metrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 3760700609.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a87232afd74c438b90870ccf7b9906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1216 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=512.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4baa2b7e624235a28f470c39294706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/24.7k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 6.40s seconds\n"
     ]
    }
   ],
   "source": [
    "# creating a model\n",
    "result = pipeline(\n",
    "    training=train_sub,\n",
    "    testing=test_sub,\n",
    "    validation=valid_sub,\n",
    "    model='transe',\n",
    "    epochs=1,\n",
    "    evaluator=None,\n",
    "#     device='gpu',\n",
    "#     optimizer='Adam',\n",
    "#     training_kwargs=dict(\n",
    "#         batch_size=32,\n",
    "#         use_tqdm=True\n",
    "# #         num_epochs=2,\n",
    "# #         checkpoint_name='transE_checkpoint.pt',\n",
    "# #         checkpoint_directory='kg_ckeckpoints',\n",
    "# #         checkpoint_frequency=0\n",
    "#     ),\n",
    "#     use_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_10 = result.get_metric('hits@10')\n",
    "hits_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_to_directory(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.datasets import Hetionet, BioKG\n",
    "dataset = Hetionet()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.training.entity_id_to_label.values()\n",
    "for l in labels:\n",
    "    if 'Compound' in l:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline(\n",
    "#     dataset=BioKG,\n",
    "    training=tf_train,\n",
    "    vlidation=tf_valid,\n",
    "    model='ComplEx',\n",
    "    epochs=5,\n",
    "    evaluator=OGBEvaluator(tf_test),\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 1000\n",
    "    },\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs = dict(\n",
    "                lr = 0.001\n",
    "    ),\n",
    "    loss = 'MarginRankingLoss',\n",
    "    device='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        training = tf_train,\n",
    "        validation = tf_valid,\n",
    "        testing = tf_test,\n",
    "        model='TransR',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=20, high=160, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    \"metadata\": {\n",
    "    \"title\": \"nations - try\",\n",
    "    \"comments\": \"comment\"\n",
    "  },\n",
    "  \"pipeline\": {\n",
    "    \"dataset\": \"nations\",\n",
    "    \"model\": \"TransE\",\n",
    "    \"model_kwargs\": {\n",
    "      \"embedding_dim\": 50,\n",
    "      \"scoring_fct_norm\": 1\n",
    "    },\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\n",
    "      \"lr\": 0.01\n",
    "    },\n",
    "    \"loss\": \"MarginRankingLoss\",\n",
    "    \"loss_kwargs\": {\n",
    "      \"reduction\": \"mean\",\n",
    "      \"margin\": 1\n",
    "    },\n",
    "    \"training_loop\": \"slcwa\",\n",
    "    \"negative_sampler\": \"basic\",\n",
    "    \"negative_sampler_kwargs\": {\n",
    "      \"num_negs_per_pos\": 1\n",
    "    },\n",
    "    \"training_kwargs\": {\n",
    "      \"num_epochs\": 100,\n",
    "      \"batch_size\": 32\n",
    "    },\n",
    "    \"evaluator_kwargs\": {\n",
    "      \"filtered\": True\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "pipeline_result = pipeline_from_config(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.trackers import ResultTracker\n",
    "\n",
    "\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "\n",
    "pipeline_result = pipeline(\n",
    "    model='RotatE',\n",
    "    dataset=dataset,\n",
    "    result_tracker=\"console\",\n",
    "    result_tracker_kwargs = dict(metric_filter='.*head.realistic.hits_at_10.*'),\n",
    "    training_kwargs = dict(\n",
    "        num_epochs = 5,\n",
    "        callbacks=\"validation-loss\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "        ),\n",
    "    )    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.models import TransE\n",
    "from torch.optim import Adam\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "\n",
    "model_name_dict = {'transe': TransE}\n",
    "\n",
    "model = model_name_dict['transe'](triples_factory=train_sub)\n",
    "optimizer = Adam(params=model.get_grad_params())\n",
    "\n",
    "training_loop = SLCWATrainingLoop(\n",
    "    model=model,\n",
    "    triples_factory=train_sub,\n",
    "    optimizer=optimizer,\n",
    " \n",
    ")\n",
    "\n",
    "_ = training_loop.train(\n",
    "    triples_factory=train_sub,\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop.device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "evaluator = RankBasedEvaluator()\n",
    "\n",
    "# Get triples to test\n",
    "mapped_triples = test_sub.mapped_triples\n",
    "\n",
    "# Evaluate\n",
    "results = evaluator.evaluate(\n",
    "    model=model,\n",
    "    mapped_triples=mapped_triples,\n",
    "    batch_size=1024,\n",
    "    additional_filter_triples=[\n",
    "        train_sub.mapped_triples,\n",
    "        valid_sub.mapped_triples,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
