{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph\n",
    "#### Drug-Food or Drug-Supplements interaction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory, CoreTriplesFactory\n",
    "from pykeen.models import TransE\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from kg_model import KG_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/triplets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>interaction</th>\n",
       "      <th>drug2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB06605</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>DB00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB06695</td>\n",
       "      <td>increase_anticoagulant_activities</td>\n",
       "      <td>DB00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB01254</td>\n",
       "      <td>increase_bleeding</td>\n",
       "      <td>DB00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01254</td>\n",
       "      <td>increase_hemorrhage</td>\n",
       "      <td>DB00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB01609</td>\n",
       "      <td>increase_gastrointestinal_bleeding</td>\n",
       "      <td>DB00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     drug1                         interaction    drug2\n",
       "0  DB06605   increase_anticoagulant_activities  DB00001\n",
       "1  DB06695   increase_anticoagulant_activities  DB00001\n",
       "2  DB01254                   increase_bleeding  DB00001\n",
       "3  DB01254                 increase_hemorrhage  DB00001\n",
       "4  DB01609  increase_gastrointestinal_bleeding  DB00001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddi_df = pd.read_csv(data_dir + 'ddi.tsv', sep='\\t', index_col=[0])\n",
    "ddi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total interactions: 1681172\n",
      "unique interactions: 202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interaction\n",
       "decrease_absorption                       425\n",
       "decrease_adverse_effects                  252\n",
       "decrease_anticoagulant_activities        1450\n",
       "decrease_antihypertensive_activities    27395\n",
       "decrease_antiplatelet_activities           10\n",
       "                                        ...  \n",
       "increase_ventricular_arrhythmias          104\n",
       "increase_vomiting                          30\n",
       "increase_water_intoxication               150\n",
       "increase_weakness                         984\n",
       "increase_weight_gain                        6\n",
       "Length: 202, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('total interactions:', ddi_df.shape[0])\n",
    "print('unique interactions:', len(set(ddi_df.interaction)))\n",
    "\n",
    "interaction_counts = ddi_df.groupby(by=['interaction']).size()\n",
    "interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decrease_absorption',\n",
       " 'decrease_adverse_effects',\n",
       " 'decrease_anticoagulant_activities',\n",
       " 'decrease_antihypertensive_activities',\n",
       " 'decrease_antiplatelet_activities',\n",
       " 'decrease_arrhythmogenic_activities',\n",
       " 'decrease_bioavailability',\n",
       " 'decrease_bronchodilatory_activities',\n",
       " 'decrease_cardiotoxicity',\n",
       " 'decrease_cytotoxicity',\n",
       " 'decrease_diuretic_activities',\n",
       " 'decrease_effectiveness',\n",
       " 'decrease_excretion_rate',\n",
       " 'decrease_fluid_retaining_activities',\n",
       " 'decrease_hypertension',\n",
       " 'decrease_hypoglycemia',\n",
       " 'decrease_hypotension',\n",
       " 'decrease_metabolism',\n",
       " 'decrease_myopathy',\n",
       " 'decrease_nephrotoxicity',\n",
       " 'decrease_neuromuscular_blockade',\n",
       " 'decrease_protein_binding',\n",
       " 'decrease_qtc_prolongation',\n",
       " 'decrease_rhabdomyolysis',\n",
       " 'decrease_sedation',\n",
       " 'decrease_seizure',\n",
       " 'decrease_serum_concentration',\n",
       " 'decrease_skeletal_muscle_relaxing_activities',\n",
       " 'decrease_stimulatory_activities',\n",
       " 'decrease_therapeutic_efficacy',\n",
       " 'decrease_vasoconstricting_activities',\n",
       " 'decrease_vasopressor_activities',\n",
       " 'increase_adverse_effects',\n",
       " 'increase_alpha-adrenergic_activities',\n",
       " 'increase_analgesic_activities',\n",
       " 'increase_anemia',\n",
       " 'increase_angioedema',\n",
       " 'increase_anti-angiogenesis',\n",
       " 'increase_anticholinergic_activities',\n",
       " 'increase_anticoagulant_activities',\n",
       " 'increase_anticonvulsant_toxicity',\n",
       " 'increase_antihypertensive_activities',\n",
       " 'increase_antiplatelet_activities',\n",
       " 'increase_antipsychotic_activities',\n",
       " 'increase_arrhythmogenic_activities',\n",
       " 'increase_atrioventricular_blocking_(av_block)_activities',\n",
       " 'increase_bioavailability',\n",
       " 'increase_bleeding',\n",
       " 'increase_bradycardia',\n",
       " 'increase_bronchoconstrictory_activities',\n",
       " 'increase_bronchospasm',\n",
       " 'increase_bruising',\n",
       " 'increase_cardiac_arrest',\n",
       " 'increase_cardiac_arrhythmia',\n",
       " 'increase_cardiodepressant_activities',\n",
       " 'increase_cardiotoxicity',\n",
       " 'increase_cardiovascular_complications',\n",
       " 'increase_cardiovascular_impairment',\n",
       " 'increase_change_in_thyroid_function_activities',\n",
       " 'increase_cns_depression_activities',\n",
       " 'increase_cns_stimulation',\n",
       " 'increase_confusion',\n",
       " 'increase_congestive_heart_failure',\n",
       " 'increase_constipation',\n",
       " 'increase_convulsion',\n",
       " 'increase_cutaneous_drug_reaction',\n",
       " 'increase_cytopenia',\n",
       " 'increase_death',\n",
       " 'increase_decreased_alertness_activities',\n",
       " 'increase_dermatologic_adverse_activities',\n",
       " 'increase_diuretic_activities',\n",
       " 'increase_dizziness',\n",
       " 'increase_drowsiness',\n",
       " 'increase_dyspnea',\n",
       " 'increase_edema_formation',\n",
       " 'increase_electrolyte_imbalance',\n",
       " 'increase_elevated_creatine_kinase_(cpk)',\n",
       " 'increase_encephalopathy',\n",
       " 'increase_excretion_rate',\n",
       " 'increase_extrapyramidal_symptoms',\n",
       " 'increase_facial_flushing',\n",
       " 'increase_fluid_retaining_activities',\n",
       " 'increase_fluid_retention',\n",
       " 'increase_gastrointestinal_bleeding',\n",
       " 'increase_gastrointestinal_irritation',\n",
       " 'increase_gastrointestinal_motility_reducing_activities',\n",
       " 'increase_gastrointestinal_ulceration',\n",
       " 'increase_generalized_seizure',\n",
       " 'increase_gouty_arthritis',\n",
       " 'increase_granulocytopenia',\n",
       " 'increase_hemorrhage',\n",
       " 'increase_hemorrhagic_cystitis',\n",
       " 'increase_hepatotoxic_activities',\n",
       " 'increase_hyperbilirubinemia',\n",
       " 'increase_hypercalcemia',\n",
       " 'increase_hypercoagulability',\n",
       " 'increase_hyperglycemia',\n",
       " 'increase_hyperkalemia',\n",
       " 'increase_hyperkinetic_symptoms',\n",
       " 'increase_hypersensitivity_reaction',\n",
       " 'increase_hypertension',\n",
       " 'increase_hyperthermia',\n",
       " 'increase_hypertrichosis',\n",
       " 'increase_hyperuricemia',\n",
       " 'increase_hypocalcemia',\n",
       " 'increase_hypoglycemia',\n",
       " 'increase_hypokalemia',\n",
       " 'increase_hypolipidaemic_activities',\n",
       " 'increase_hypomagnesemia',\n",
       " 'increase_hypomania',\n",
       " 'increase_hyponatremia',\n",
       " 'increase_hypotension',\n",
       " 'increase_hypothyroid_activities',\n",
       " 'increase_hypotonia',\n",
       " 'increase_immunosuppressive_activities',\n",
       " 'increase_increased_glucose',\n",
       " 'increase_increased_serum_creatinine',\n",
       " 'increase_increased_transaminases',\n",
       " 'increase_infection',\n",
       " 'increase_intraocular_pressure',\n",
       " 'increase_irritability',\n",
       " 'increase_ischemic_colitis',\n",
       " 'increase_jaw_osteonecrosis',\n",
       " 'increase_lactic_acidosis',\n",
       " 'increase_leukopenia',\n",
       " 'increase_liver_damage',\n",
       " 'increase_liver_enzyme_elevations',\n",
       " 'increase_metabolic_acidosis',\n",
       " 'increase_metabolism',\n",
       " 'increase_methemoglobinemia',\n",
       " 'increase_mucosal_ulceration',\n",
       " 'increase_myelosuppression',\n",
       " 'increase_myocardial_depression',\n",
       " 'increase_myoglobinuria',\n",
       " 'increase_myopathic_rhabdomyolysis_activities',\n",
       " 'increase_myopathy',\n",
       " 'increase_nausea',\n",
       " 'increase_nephrotoxicity',\n",
       " 'increase_neuroexcitatory_activities',\n",
       " 'increase_neuroleptic_malignant_syndrome',\n",
       " 'increase_neuromuscular_blockade',\n",
       " 'increase_neurotoxic_activities',\n",
       " 'increase_neutropenia',\n",
       " 'increase_nitritoid_reactions',\n",
       " 'increase_oligohydrosis',\n",
       " 'increase_opioid_antagonism_activities',\n",
       " 'increase_opioid_toxicity',\n",
       " 'increase_orthostatic_hypotension',\n",
       " 'increase_osteomalacia',\n",
       " 'increase_ototoxicity',\n",
       " 'increase_pancreatitis_activities',\n",
       " 'increase_peptic_ulcer',\n",
       " 'increase_peripheral_neuropathy',\n",
       " 'increase_photosensitizing_activities',\n",
       " 'increase_priapism',\n",
       " 'increase_pseudotumor_cerebri',\n",
       " 'increase_psychotic_reaction',\n",
       " 'increase_pulmonary_toxicity',\n",
       " 'increase_qtc_prolongation',\n",
       " 'increase_rash',\n",
       " 'increase_reduced_gastrointestinal_motility',\n",
       " 'increase_reduced_intravascular_volume',\n",
       " 'increase_renal_failure',\n",
       " 'increase_respiratory_depression',\n",
       " 'increase_rhabdomyolysis',\n",
       " 'increase_sedation',\n",
       " 'increase_seizure',\n",
       " 'increase_serotonergic_activities',\n",
       " 'increase_serotonin_syndrome',\n",
       " 'increase_serum_concentration',\n",
       " 'increase_severe_leukopenia',\n",
       " 'increase_shortness_of_breath',\n",
       " 'increase_sinus_node_depression',\n",
       " 'increase_skeletal_muscle_relaxing_activities',\n",
       " 'increase_sleep_disorders',\n",
       " 'increase_smooth_muscle_relaxing_activities',\n",
       " 'increase_somnolence',\n",
       " 'increase_stevens-johnson_syndrome',\n",
       " 'increase_sympathomimetic_activities',\n",
       " 'increase_syncope',\n",
       " 'increase_tachycardia',\n",
       " 'increase_tardive_dyskinesia',\n",
       " 'increase_tendinopathy',\n",
       " 'increase_teratogenic_activities',\n",
       " 'increase_therapeutic_efficacy',\n",
       " 'increase_thrombocytopenia',\n",
       " 'increase_thromboembolism',\n",
       " 'increase_thrombogenic_activities',\n",
       " 'increase_thrombosis',\n",
       " 'increase_torsade_de_pointes',\n",
       " 'increase_ulceration',\n",
       " 'increase_urinary_retention',\n",
       " 'increase_uterotonic_activities',\n",
       " 'increase_vasoconstricting_activities',\n",
       " 'increase_vasodilatory_activities',\n",
       " 'increase_vasopressor_activities',\n",
       " 'increase_vasospastic_reactions',\n",
       " 'increase_ventricular_arrhythmias',\n",
       " 'increase_vomiting',\n",
       " 'increase_water_intoxication',\n",
       " 'increase_weakness',\n",
       " 'increase_weight_gain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ddi_df.interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI1</th>\n",
       "      <th>REL</th>\n",
       "      <th>CUI2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>689301</th>\n",
       "      <td>1-Androsten-3beta-ol-17-one</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Testosterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689302</th>\n",
       "      <td>4-DHEA</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Testosterone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689319</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Cytochrome P450 2D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689320</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>TOPICAL DRUGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689322</th>\n",
       "      <td>Blackbush</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>Cytochrome P450 3A4 substrates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               CUI1             REL   \n",
       "689301  1-Androsten-3beta-ol-17-one  interacts_with  \\\n",
       "689302                       4-DHEA  interacts_with   \n",
       "689319                    Blackbush  interacts_with   \n",
       "689320                    Blackbush  interacts_with   \n",
       "689322                    Blackbush  interacts_with   \n",
       "\n",
       "                                  CUI2  \n",
       "689301                    Testosterone  \n",
       "689302                    Testosterone  \n",
       "689319             Cytochrome P450 2D6  \n",
       "689320                   TOPICAL DRUGS  \n",
       "689322  Cytochrome P450 3A4 substrates  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_supplement_df = pd.read_csv(data_dir + 'ds_relations.tsv', sep='\\t', index_col=[0])\n",
    "# drug_supplement_df = drug_supplement_df[drug_supplement_df['REL'] != 'has_ingredient']\n",
    "drug_supplement_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total interactions: 3057\n",
      "unique interactions: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "REL\n",
       "interacts_with    3057\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('total interactions:', drug_supplement_df.shape[0])\n",
    "print('unique interactions:', len(set(drug_supplement_df.REL)))\n",
    "\n",
    "ds_interaction_counts = drug_supplement_df.groupby(by=['REL']).size()\n",
    "ds_interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_count = pd.concat([interaction_counts, ds_interaction_counts])\n",
    "interactions_count.to_csv('interaction_counts.csv', header=['interaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size(n):\n",
    "    if n == 2:\n",
    "        return 1, 1\n",
    "    if n == 3:\n",
    "        return 1, 2\n",
    "    if n == 4:\n",
    "        return 2, 3\n",
    "    if n == 5:\n",
    "        return 3, 4\n",
    "    if n == 6:\n",
    "        return 4, 5\n",
    "    # n == 7\n",
    "    return 4, 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : valid : test = 80 : 10 : 10\n",
    "def split_data_relation(df_relation):\n",
    "    \n",
    "    # too few triplets with the realtion\n",
    "    if df_relation.shape[0] <= 7:\n",
    "        train_size, valid_size = compute_size(df_relation.shape[0])\n",
    "        \n",
    "        # shuffle df_relation\n",
    "        df_relation = df_relation.sample(frac=1, random_state=42)\n",
    "        \n",
    "        X_train = df_relation.iloc[:train_size]\n",
    "        X_valid = df_relation.iloc[train_size:valid_size]\n",
    "        X_test = df_relation.iloc[valid_size:]\n",
    "\n",
    "    else:\n",
    "        X_train, X_rem = train_test_split(df_relation, train_size=0.8, random_state=42)\n",
    "        X_valid, X_test = train_test_split(X_rem, test_size=0.5, random_state=42)\n",
    "        \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-supplements relation dataset\n",
    "def split_drug_supplements_dataset(drug_supplement_df):\n",
    "    relations = set(drug_supplement_df.REL)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    test_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "\n",
    "    for rel in relations:\n",
    "        train, valid, test = split_data_relation(drug_supplement_df[drug_supplement_df['REL'] == rel])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "\n",
    "    train_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-drug interaction dataset (from DrugBank)\n",
    "def split_ddi_dataset(ddi_df):\n",
    "    interactions = set(ddi_df.interaction)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    test_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    \n",
    "    for inter in interactions:\n",
    "        train, valid, test = split_data_relation(ddi_df[ddi_df['interaction'] == inter])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "        \n",
    "    train_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugBank drug-drug interactions\n",
    "print('DrugBank drug-drug interactions')\n",
    "train_triplets_ddi, valid_triplets_ddi, test_triplets_ddi = split_ddi_dataset(ddi_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# Drug Supplement database - drug-suplement interactions\n",
    "print('Drug Supplement database - drug-suplement interactions')\n",
    "train_triplets_ds, valid_triplets_ds, test_triplets_ds = split_drug_supplements_dataset(drug_supplement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all interactions\n",
    "train_triplets = pd.concat([train_triplets_ddi, train_triplets_ds])\n",
    "valid_triplets = pd.concat([valid_triplets_ddi, valid_triplets_ds])\n",
    "test_triplets = pd.concat([test_triplets_ddi, test_triplets_ds])\n",
    "\n",
    "print('All interactions:')\n",
    "print('train dataset size:', train_triplets.shape[0])\n",
    "print('validation dataset size:',valid_triplets.shape[0])\n",
    "print('test dataset size:',test_triplets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = set(train_triplets.relation)\n",
    "print('Number of unique interactions:', len(all_relations))\n",
    "print(list(all_relations)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add rest of the data into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(data_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file == 'ddi.tsv' or file == '.ipynb_checkpoints' or file == 'ds_relations.tsv':\n",
    "        continue\n",
    "    if 'train' in file or 'valid' in file or 'test' in file:\n",
    "        continue\n",
    "           \n",
    "    df = pd.read_csv(data_dir + file, sep='\\t', index_col=[0])\n",
    "    \n",
    "    # if file == 'ds_relations.tsv':\n",
    "    #     df = df[df['REL'] == 'has_ingredient']\n",
    "    \n",
    "    df.set_axis(['head', 'relation', 'tail'], axis=1, inplace=True) \n",
    "    train_triplets = pd.concat([train_triplets, df])\n",
    "    \n",
    "print('Final size of train dataset (with other relations):', train_triplets.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = train_triplets.astype(str)\n",
    "valid_triplets = valid_triplets.astype(str)\n",
    "test_triplets = test_triplets.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train, valid and test datasets\n",
    "\n",
    "train_triplets.to_csv(data_dir + 'train.tsv', sep='\\t')\n",
    "valid_triplets.to_csv(data_dir + 'valid.tsv', sep='\\t')\n",
    "test_triplets.to_csv(data_dir + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "train_triplets = pd.read_csv(data_dir + 'train.tsv', sep='\\t')\n",
    "valid_triplets = pd.read_csv(data_dir + 'valid.tsv', sep='\\t')\n",
    "test_triplets = pd.read_csv(data_dir + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB09329</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB00355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB00957</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB00531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00570</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB00197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB04930</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB00412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00231</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB09301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286387</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P35367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286388</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P50148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286389</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>Q14643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286390</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P05771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286391</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P19838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head                 relation     tail\n",
       "0           DB09329  both (depends on drugs)  DB00355\n",
       "1           DB00957  both (depends on drugs)  DB00531\n",
       "2           DB00570  both (depends on drugs)  DB00197\n",
       "3           DB04930  both (depends on drugs)  DB00412\n",
       "4           DB00231  both (depends on drugs)  DB09301\n",
       "...             ...                      ...      ...\n",
       "2286387  SMP0062895      involved_in_pathway   P35367\n",
       "2286388  SMP0062895      involved_in_pathway   P50148\n",
       "2286389  SMP0062895      involved_in_pathway   Q14643\n",
       "2286390  SMP0062895      involved_in_pathway   P05771\n",
       "2286391  SMP0062895      involved_in_pathway   P19838\n",
       "\n",
       "[2286392 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_drugs = pd.read_csv('../data/common_drugs.csv', sep=';')\n",
    "common_drugs = common_drugs['DrugBank_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB01041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8482</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB06119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB09046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB09237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19144</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>both (depends on drugs)</td>\n",
       "      <td>DB00834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710880</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713313</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713396</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714847</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716649</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_6834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            head                 relation           tail\n",
       "3620     DB00343  both (depends on drugs)        DB01041\n",
       "8482     DB00343  both (depends on drugs)        DB06119\n",
       "12306    DB00343  both (depends on drugs)        DB09046\n",
       "12803    DB00343  both (depends on drugs)        DB09237\n",
       "19144    DB00343  both (depends on drugs)        DB00834\n",
       "...          ...                      ...            ...\n",
       "1710880  DB00343             drug-protein  protein_12429\n",
       "1713313  DB00343             drug-protein  protein_14135\n",
       "1713396  DB00343             drug-protein  protein_12433\n",
       "1714847  DB00343             drug-protein  protein_14123\n",
       "1716649  DB00343             drug-protein   protein_6834\n",
       "\n",
       "[1059 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets[train_triplets['head'] == common_drugs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datasets into Triples Factory format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "      data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "      create_inverse_triples=False,\n",
    "      entity_to_id=None,\n",
    "      relation_to_id=None,\n",
    "      compact_id=False \n",
    "    )\n",
    "    print(tf_data)  \n",
    "    return tf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriplesFactory(num_entities=33046, num_relations=58, create_inverse_triples=False, num_triples=2074440)\n",
      "TriplesFactory(num_entities=2402, num_relations=4, create_inverse_triples=False, num_triples=164903)\n",
      "TriplesFactory(num_entities=2415, num_relations=4, create_inverse_triples=False, num_triples=164926)\n"
     ]
    }
   ],
   "source": [
    "tf_train = convert_to_triples_factory(train_triplets.astype(str))\n",
    "tf_valid = convert_to_triples_factory(valid_triplets.astype(str))\n",
    "tf_test = convert_to_triples_factory(test_triplets.astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:using automatically assigned random_state=1718957934\n",
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [312593, 1942284]\n",
      "WARNING:pykeen.utils:using automatically assigned random_state=2149889400\n",
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [22900, 143024]\n",
      "WARNING:pykeen.utils:using automatically assigned random_state=1566622866\n",
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [22928, 143105]\n"
     ]
    }
   ],
   "source": [
    "# take just subset of data for testing\n",
    "\n",
    "train_sub, _ = tf_train.split(0.15)\n",
    "valid_sub, _ = tf_valid.split(0.15)\n",
    "test_sub, _ = tf_test.split(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'epochs': 20, \n",
    "          'optimizer': 'adam', \n",
    "          'learning_rate': 0.005,\n",
    "          'loss': 'MarginRankingLoss',\n",
    "          'batch': 512,\n",
    "          'embedding_dim': 300,\n",
    "          'margin': 0.64\n",
    "         }\n",
    "params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:loaded random seed 2357393914 from checkpoint.\n",
      "INFO:pykeen.pipeline.api:Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.training.training_loop:=> loading checkpoint 'kg_checkpoints/complex-pos_neg_checkpoint.pt'\n",
      "INFO:pykeen.training.training_loop:=> loaded checkpoint 'kg_checkpoints/complex-pos_neg_checkpoint.pt' stopped after having finished epoch 20\n",
      "INFO:pykeen.stoppers.stopper:=> loading stopper summary dict from training loop checkpoint in 'kg_checkpoints/complex-pos_neg_checkpoint.pt'\n",
      "INFO:pykeen.stoppers.stopper:=> loaded stopper summary dictionary from checkpoint in 'kg_checkpoints/complex-pos_neg_checkpoint.pt'\n",
      "WARNING:pykeen.training.training_loop:the training loop was configured with a stopper but no stopper configuration was saved in the checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165818a845b4fdfa4ea3bff12e17395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0: 100%|##########| 20/20 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5753d9165036485f96ab6d8327b9693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/165k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 210.90s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    }
   ],
   "source": [
    "model_kg = KG_model('complex', tf_train, tf_valid, tf_test, 'pos_neg')\n",
    "model_kg.set_params2(params)\n",
    "print('Training...')\n",
    "model_kg.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetPredictions(df=       tail_id     score       tail_label\n",
       "2864      2864  8.414460          DB00949\n",
       "3537      3537  8.359592          DB06218\n",
       "4743      4743  8.183308          DB14185\n",
       "4436      4436  8.159472          DB12141\n",
       "2947      2947  8.087454          DB01035\n",
       "...        ...       ...              ...\n",
       "28571    28571 -6.994305  sideeffect_5341\n",
       "25494    25494 -7.299763  sideeffect_2226\n",
       "10730    10730 -7.357508       disease_52\n",
       "26331    26331 -7.434183   sideeffect_306\n",
       "24450    24450 -7.434982  sideeffect_1177\n",
       "\n",
       "[33046 rows x 3 columns], factory=TriplesFactory(num_entities=33046, num_relations=58, create_inverse_triples=False, num_triples=2074440), target='tail', other_columns_fixed_ids=(3272, 49))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_kg.trained_model.metric_results.to_df()\n",
    "\n",
    "head = common_drugs[0]\n",
    "relation = 'negative'\n",
    "\n",
    "pred = predict_target(\n",
    "            model = model_kg.trained_model.model, \n",
    "            head = head, \n",
    "            relation = relation, \n",
    "            triples_factory = model_kg.trained_model.training,\n",
    "        )\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002082085848087445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kg.trained_model.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 542217978.\n",
      "Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "INFO:pykeen.training.training_loop:Starting sub_batch_size search for training now...\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (bases): Embedding(\n",
      "        (_embeddings): Embedding(17, 400)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "INFO:pykeen.training.training_loop:Even sub_batch_size=1 does not fit in memory with these parameters\n",
      "WARNING:pykeen.training.slcwa:This model supports sub-batching, but it also requires slicing, which is not possible for sLCWA\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "The current model can't be trained on this hardware with these parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# creating a model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_sub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_sub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGCN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;43;03m#     evaluator=RankBasedEvaluator,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdistmult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;43;03m#     device='gpu',\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;43;03m#     optimizer='Adam',\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;43;03m#     training_kwargs=dict(\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;43;03m#         batch_size=32,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;43;03m#         use_tqdm=True\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;43;03m# #         num_epochs=2,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;43;03m# #         checkpoint_name='transE_checkpoint.pt',\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;43;03m# #         checkpoint_directory='kg_ckeckpoints',\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;43;03m# #         checkpoint_frequency=0\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;43;03m#     ),\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;43;03m#     use_tqdm=True,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/pipeline/api.py:1291\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 1291\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m training_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:378\u001b[0m, in \u001b[0;36mTrainingLoop.train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# send model to device before going into the internal training loop\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(get_preferred_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, allow_ambiguity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[1;32m    409\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:523\u001b[0m, in \u001b[0;36mTrainingLoop._train\u001b[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# This will find necessary parameters to optimize the use of the hardware at hand\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m only_size_probing\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_memory_optimization\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m ):\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m# return the relevant parameters slice_size and batch_size\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m     sub_batch_size, slice_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_batch_and_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sub_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m sub_batch_size \u001b[38;5;241m==\u001b[39m batch_size:  \u001b[38;5;66;03m# by default do not split batches in sub-batches\u001b[39;00m\n\u001b[1;32m    528\u001b[0m     sub_batch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/training_loop.py:950\u001b[0m, in \u001b[0;36mTrainingLoop.sub_batch_and_slice\u001b[0;34m(self, batch_size, sampler, triples_factory)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finished_search:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sub_batch_size, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 950\u001b[0m slice_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_size_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupports_sub_batching\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupports_sub_batching\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sub_batch_size, slice_size\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/training/slcwa.py:165\u001b[0m, in \u001b[0;36mSLCWATrainingLoop._slice_size_search\u001b[0;34m(self, triples_factory, batch_size, sub_batch_size, supports_sub_batching)\u001b[0m\n\u001b[1;32m    163\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support sub-batching and slicing is not possible for sLCWA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(report)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current model can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be trained on this hardware with these parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMemoryError\u001b[0m: The current model can't be trained on this hardware with these parameters."
     ]
    }
   ],
   "source": [
    "# creating a model\n",
    "result = pipeline(\n",
    "    training=train_sub,\n",
    "    testing=test_sub,\n",
    "    validation=valid_sub,\n",
    "    model='RGCN',\n",
    "    epochs=1,\n",
    "#     evaluator=RankBasedEvaluator,\n",
    "    model_kwargs=dict(embedding_dim=20, num_layers=1, interaction='distmult'),\n",
    "#     device='gpu',\n",
    "#     optimizer='Adam',\n",
    "#     training_kwargs=dict(\n",
    "#         batch_size=32,\n",
    "#         use_tqdm=True\n",
    "# #         num_epochs=2,\n",
    "# #         checkpoint_name='transE_checkpoint.pt',\n",
    "# #         checkpoint_directory='kg_ckeckpoints',\n",
    "# #         checkpoint_frequency=0\n",
    "#     ),\n",
    "#     use_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_10 = result.get_metric('hits@10')\n",
    "hits_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_to_directory(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2372029315.\n",
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.pipeline.api:Using device: gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d98b897bd547229ac838c9a9cc11ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/7 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=201.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784a998ae50244069f08ab9504d8bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.03s seconds\n"
     ]
    }
   ],
   "source": [
    "result = pipeline(\n",
    "    dataset='Nations',\n",
    "    model='TransE',\n",
    "    epochs=5,\n",
    "    evaluator=RankBasedEvaluator,\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 150\n",
    "    },\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs = dict(\n",
    "                lr = 0.1\n",
    "    ),\n",
    "    loss = 'MarginRankingLoss',\n",
    "    device='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransE(\n",
       "  (loss): MarginRankingLoss(\n",
       "    (margin_activation): ReLU()\n",
       "  )\n",
       "  (interaction): TransEInteraction()\n",
       "  (entity_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (_embeddings): Embedding(14, 150)\n",
       "    )\n",
       "  )\n",
       "  (relation_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (_embeddings): Embedding(55, 150)\n",
       "    )\n",
       "  )\n",
       "  (weight_regularizers): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = result.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Side</th>\n",
       "      <th>Type</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>variance</td>\n",
       "      <td>7.486349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tail</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>variance</td>\n",
       "      <td>7.560159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>both</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>variance</td>\n",
       "      <td>7.528458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head</td>\n",
       "      <td>realistic</td>\n",
       "      <td>variance</td>\n",
       "      <td>7.486350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>variance</td>\n",
       "      <td>7.560159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tail</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.534498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>both</td>\n",
       "      <td>realistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.390649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>head</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.244790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tail</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.534498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>both</td>\n",
       "      <td>pessimistic</td>\n",
       "      <td>adjusted_hits_at_k</td>\n",
       "      <td>0.390649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Side         Type              Metric     Value\n",
       "0    head   optimistic            variance  7.486349\n",
       "1    tail   optimistic            variance  7.560159\n",
       "2    both   optimistic            variance  7.528458\n",
       "3    head    realistic            variance  7.486350\n",
       "4    tail    realistic            variance  7.560159\n",
       "..    ...          ...                 ...       ...\n",
       "220  tail    realistic  adjusted_hits_at_k  0.534498\n",
       "221  both    realistic  adjusted_hits_at_k  0.390649\n",
       "222  head  pessimistic  adjusted_hits_at_k  0.244790\n",
       "223  tail  pessimistic  adjusted_hits_at_k  0.534498\n",
       "224  both  pessimistic  adjusted_hits_at_k  0.390649\n",
       "\n",
       "[225 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41630384325981146"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        training = tf_train,\n",
    "        validation = tf_valid,\n",
    "        testing = tf_test,\n",
    "        model='TransR',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=20, high=160, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    \"metadata\": {\n",
    "    \"title\": \"nations - try\",\n",
    "    \"comments\": \"comment\"\n",
    "  },\n",
    "  \"pipeline\": {\n",
    "    \"dataset\": \"nations\",\n",
    "    \"model\": \"TransE\",\n",
    "    \"model_kwargs\": {\n",
    "      \"embedding_dim\": 50,\n",
    "      \"scoring_fct_norm\": 1\n",
    "    },\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\n",
    "      \"lr\": 0.01\n",
    "    },\n",
    "    \"loss\": \"MarginRankingLoss\",\n",
    "    \"loss_kwargs\": {\n",
    "      \"reduction\": \"mean\",\n",
    "      \"margin\": 1\n",
    "    },\n",
    "    \"training_loop\": \"slcwa\",\n",
    "    \"negative_sampler\": \"basic\",\n",
    "    \"negative_sampler_kwargs\": {\n",
    "      \"num_negs_per_pos\": 1\n",
    "    },\n",
    "    \"training_kwargs\": {\n",
    "      \"num_epochs\": 100,\n",
    "      \"batch_size\": 32\n",
    "    },\n",
    "    \"evaluator_kwargs\": {\n",
    "      \"filtered\": True\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "pipeline_result = pipeline_from_config(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///work/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.trackers import ResultTracker\n",
    "\n",
    "\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "\n",
    "pipeline_result = pipeline(\n",
    "    model='RotatE',\n",
    "    dataset=dataset,\n",
    "    result_tracker=\"console\",\n",
    "    result_tracker_kwargs = dict(metric_filter='.*head.realistic.hits_at_10.*'),\n",
    "    training_kwargs = dict(\n",
    "        num_epochs = 5,\n",
    "        callbacks=\"validation-loss\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "        ),\n",
    "    )    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EagerDataset(num_entities=14, num_relations=55, create_inverse_triples=False, metadata={'name': 'nations'})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
