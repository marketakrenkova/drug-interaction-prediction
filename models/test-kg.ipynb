{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph\n",
    "#### Drug-Food or Drug-Supplements interaction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory, CoreTriplesFactory\n",
    "from pykeen.models import TransE\n",
    "from pykeen.evaluation import RankBasedEvaluator, OGBEvaluator\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from kg_model import KG_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/triplets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_df = pd.read_csv(data_dir + 'ddi.tsv', sep='\\t', index_col=[0])\n",
    "ddi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total interactions:', ddi_df.shape[0])\n",
    "print('unique interactions:', len(set(ddi_df.interaction)))\n",
    "\n",
    "interaction_counts = ddi_df.groupby(by=['interaction']).size()\n",
    "interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ddi_df.interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_supplement_df = pd.read_csv(data_dir + 'ds_relations.tsv', sep='\\t', index_col=[0])\n",
    "# drug_supplement_df = drug_supplement_df[drug_supplement_df['REL'] != 'has_ingredient']\n",
    "drug_supplement_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total interactions:', drug_supplement_df.shape[0])\n",
    "print('unique interactions:', len(set(drug_supplement_df.REL)))\n",
    "\n",
    "ds_interaction_counts = drug_supplement_df.groupby(by=['REL']).size()\n",
    "ds_interaction_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_count = pd.concat([interaction_counts, ds_interaction_counts])\n",
    "interactions_count.to_csv('interaction_counts.csv', header=['interaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size(n):\n",
    "    if n == 2:\n",
    "        return 1, 1\n",
    "    if n == 3:\n",
    "        return 1, 2\n",
    "    if n == 4:\n",
    "        return 2, 3\n",
    "    if n == 5:\n",
    "        return 3, 4\n",
    "    if n == 6:\n",
    "        return 4, 5\n",
    "    # n == 7\n",
    "    return 4, 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : valid : test = 80 : 10 : 10\n",
    "def split_data_relation(df_relation):\n",
    "    \n",
    "    # too few triplets with the realtion\n",
    "    if df_relation.shape[0] <= 7:\n",
    "        train_size, valid_size = compute_size(df_relation.shape[0])\n",
    "        \n",
    "        # shuffle df_relation\n",
    "        df_relation = df_relation.sample(frac=1, random_state=42)\n",
    "        \n",
    "        X_train = df_relation.iloc[:train_size]\n",
    "        X_valid = df_relation.iloc[train_size:valid_size]\n",
    "        X_test = df_relation.iloc[valid_size:]\n",
    "\n",
    "    else:\n",
    "        X_train, X_rem = train_test_split(df_relation, train_size=0.8, random_state=42)\n",
    "        X_valid, X_test = train_test_split(X_rem, test_size=0.5, random_state=42)\n",
    "        \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-supplements relation dataset\n",
    "def split_drug_supplements_dataset(drug_supplement_df):\n",
    "    relations = set(drug_supplement_df.REL)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "    test_triplets = pd.DataFrame(columns=['CUI1', 'REL', 'CUI2'])\n",
    "\n",
    "    for rel in relations:\n",
    "        train, valid, test = split_data_relation(drug_supplement_df[drug_supplement_df['REL'] == rel])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "\n",
    "    train_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'CUI1': 'head', 'REL': 'relation', 'CUI2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drug-drug interaction dataset (from DrugBank)\n",
    "def split_ddi_dataset(ddi_df):\n",
    "    interactions = set(ddi_df.interaction)\n",
    "    \n",
    "    train_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    valid_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    test_triplets = pd.DataFrame(columns=['drug1', 'interaction', 'drug2'])\n",
    "    \n",
    "    for inter in interactions:\n",
    "        train, valid, test = split_data_relation(ddi_df[ddi_df['interaction'] == inter])\n",
    "        train_triplets = pd.concat([train_triplets, train])\n",
    "        valid_triplets = pd.concat([valid_triplets, valid])\n",
    "        test_triplets = pd.concat([test_triplets, test])\n",
    "        \n",
    "    train_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    valid_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)\n",
    "    test_triplets.rename(columns={'drug1': 'head', 'interaction': 'relation', 'drug2': 'tail'}, inplace=True)    \n",
    "\n",
    "\n",
    "    print('train dataset size:', train_triplets.shape[0])\n",
    "    print('validation dataset size:',valid_triplets.shape[0])\n",
    "    print('test dataset size:',test_triplets.shape[0])\n",
    "    \n",
    "    return train_triplets, valid_triplets, test_triplets    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DrugBank drug-drug interactions\n",
    "print('DrugBank drug-drug interactions')\n",
    "train_triplets_ddi, valid_triplets_ddi, test_triplets_ddi = split_ddi_dataset(ddi_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# Drug Supplement database - drug-suplement interactions\n",
    "print('Drug Supplement database - drug-suplement interactions')\n",
    "train_triplets_ds, valid_triplets_ds, test_triplets_ds = split_drug_supplements_dataset(drug_supplement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all interactions\n",
    "train_triplets = pd.concat([train_triplets_ddi, train_triplets_ds])\n",
    "valid_triplets = pd.concat([valid_triplets_ddi, valid_triplets_ds])\n",
    "test_triplets = pd.concat([test_triplets_ddi, test_triplets_ds])\n",
    "\n",
    "print('All interactions:')\n",
    "print('train dataset size:', train_triplets.shape[0])\n",
    "print('validation dataset size:',valid_triplets.shape[0])\n",
    "print('test dataset size:',test_triplets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = set(train_triplets.relation)\n",
    "print('Number of unique interactions:', len(all_relations))\n",
    "print(list(all_relations)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add rest of the data into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(data_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file == 'ddi.tsv' or file == '.ipynb_checkpoints' or file == 'ds_relations.tsv':\n",
    "        continue\n",
    "    if 'train' in file or 'valid' in file or 'test' in file:\n",
    "        continue\n",
    "           \n",
    "    df = pd.read_csv(data_dir + file, sep='\\t', index_col=[0])\n",
    "    \n",
    "    # if file == 'ds_relations.tsv':\n",
    "    #     df = df[df['REL'] == 'has_ingredient']\n",
    "    \n",
    "    df.set_axis(['head', 'relation', 'tail'], axis=1, inplace=True) \n",
    "    train_triplets = pd.concat([train_triplets, df])\n",
    "    \n",
    "print('Final size of train dataset (with other relations):', train_triplets.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = train_triplets.astype(str)\n",
    "valid_triplets = valid_triplets.astype(str)\n",
    "test_triplets = test_triplets.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train, valid and test datasets\n",
    "\n",
    "train_triplets.to_csv(data_dir + 'train.tsv', sep='\\t')\n",
    "valid_triplets.to_csv(data_dir + 'valid.tsv', sep='\\t')\n",
    "test_triplets.to_csv(data_dir + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "specification = '_drugbank'\n",
    "\n",
    "train_triplets = pd.read_csv(data_dir + 'train' + specification + '.tsv', sep='\\t')\n",
    "valid_triplets = pd.read_csv(data_dir + 'valid' + specification + '.tsv', sep='\\t')\n",
    "test_triplets = pd.read_csv(data_dir + 'test' + specification + '.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB00091</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB00680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB11730</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB00674</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB09083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB01189</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB08936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB00656</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383597</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P35367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383598</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P50148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383599</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>Q14643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383600</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P05771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383601</th>\n",
       "      <td>SMP0062895</td>\n",
       "      <td>involved_in_pathway</td>\n",
       "      <td>P19838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1383602 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head             relation     tail\n",
       "0           DB00091            interacts  DB00680\n",
       "1           DB11730            interacts  DB01229\n",
       "2           DB00674            interacts  DB09083\n",
       "3           DB01189            interacts  DB08936\n",
       "4           DB00656            interacts  DB01193\n",
       "...             ...                  ...      ...\n",
       "1383597  SMP0062895  involved_in_pathway   P35367\n",
       "1383598  SMP0062895  involved_in_pathway   P50148\n",
       "1383599  SMP0062895  involved_in_pathway   Q14643\n",
       "1383600  SMP0062895  involved_in_pathway   P05771\n",
       "1383601  SMP0062895  involved_in_pathway   P19838\n",
       "\n",
       "[1383602 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_drugs = pd.read_csv('../data/common_drugs.csv', sep=';')\n",
    "common_drugs = common_drugs['DrugBank_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB13180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB01104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB06595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>interacts</td>\n",
       "      <td>DB00967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710881</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713314</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713397</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_12433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714848</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_14123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716650</th>\n",
       "      <td>DB00343</td>\n",
       "      <td>drug-protein</td>\n",
       "      <td>protein_6834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            head      relation           tail\n",
       "1422     DB00343     interacts        DB13180\n",
       "1879     DB00343     interacts        DB01294\n",
       "2124     DB00343     interacts        DB01104\n",
       "5535     DB00343     interacts        DB06595\n",
       "5587     DB00343     interacts        DB00967\n",
       "...          ...           ...            ...\n",
       "1710881  DB00343  drug-protein  protein_12429\n",
       "1713314  DB00343  drug-protein  protein_14135\n",
       "1713397  DB00343  drug-protein  protein_12433\n",
       "1714848  DB00343  drug-protein  protein_14123\n",
       "1716650  DB00343  drug-protein   protein_6834\n",
       "\n",
       "[1063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets[train_triplets['head'] == common_drugs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datasets into Triples Factory format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_triples_factory(data):\n",
    "    tf_data = TriplesFactory.from_labeled_triples(\n",
    "      data[[\"head\", \"relation\", \"tail\"]].values,\n",
    "      create_inverse_triples=False,\n",
    "      entity_to_id=None,\n",
    "      relation_to_id=None,\n",
    "      compact_id=False \n",
    "    )\n",
    "    print(tf_data)  \n",
    "    return tf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriplesFactory(num_entities=9981, num_relations=6, create_inverse_triples=False, num_triples=1167601)\n",
      "TriplesFactory(num_entities=2410, num_relations=1, create_inverse_triples=False, num_triples=164779)\n",
      "TriplesFactory(num_entities=2424, num_relations=1, create_inverse_triples=False, num_triples=164800)\n"
     ]
    }
   ],
   "source": [
    "tf_train = convert_to_triples_factory(train_triplets.astype(str))\n",
    "tf_valid = convert_to_triples_factory(valid_triplets.astype(str))\n",
    "tf_test = convert_to_triples_factory(test_triplets.astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=3914162399\n",
      "using automatically assigned random_state=1770133623\n",
      "using automatically assigned random_state=2042898104\n"
     ]
    }
   ],
   "source": [
    "# take just subset of data for testing\n",
    "\n",
    "train_sub, _ = tf_train.split(0.15)\n",
    "valid_sub, _ = tf_valid.split(0.15)\n",
    "test_sub, _ = tf_test.split(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'epochs': 2, \n",
    "          'optimizer': 'adam', \n",
    "          'learning_rate': 0.005,\n",
    "          'loss': 'MarginRankingLoss',\n",
    "          'batch': 512,\n",
    "          'embedding_dim': 300,\n",
    "          'margin': 0.64,\n",
    "          'evaluator': 'rankedbased'\n",
    "         }\n",
    "params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.training.training_loop:=> loading checkpoint 'kg_checkpoints/complex-jupyter_test_checkpoint.pt'\n",
      "INFO:pykeen.training.training_loop:=> loaded checkpoint 'kg_checkpoints/complex-jupyter_test_checkpoint.pt' stopped after having finished epoch 2\n",
      "INFO:pykeen.stoppers.stopper:=> loading stopper summary dict from training loop checkpoint in 'kg_checkpoints/complex-jupyter_test_checkpoint.pt'\n",
      "INFO:pykeen.stoppers.stopper:=> loaded stopper summary dictionary from checkpoint in 'kg_checkpoints/complex-jupyter_test_checkpoint.pt'\n",
      "WARNING:pykeen.training.training_loop:the training loop was configured with a stopper but no stopper configuration was saved in the checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974215bd20e242a89fd5ea89ac76e5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0: 100%|##########| 2/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519e2d49af6a494cbacca49d088c93a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/165k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 210.22s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    }
   ],
   "source": [
    "model_kg = KG_model('complex', tf_train, tf_valid, tf_test, 'jupyter_test')\n",
    "model_kg.set_params2(params)\n",
    "\n",
    "print('Training...')\n",
    "model_kg.train()\n",
    "print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetPredictions(df=       tail_id     score       tail_label\n",
       "3773      3773  4.956060          DB08918\n",
       "2789      2789  4.889006          DB00871\n",
       "4389      4389  4.857689          DB11827\n",
       "2609      2609  4.852685          DB00681\n",
       "2849      2849  4.843045          DB00934\n",
       "...        ...       ...              ...\n",
       "28589    28589 -5.563348  sideeffect_5358\n",
       "10956    10956 -5.580075      disease_880\n",
       "29970    29970 -5.617806   sideeffect_680\n",
       "24460    24460 -5.680283  sideeffect_1186\n",
       "25881    25881 -5.863306  sideeffect_2614\n",
       "\n",
       "[33046 rows x 3 columns], factory=TriplesFactory(num_entities=33046, num_relations=55, create_inverse_triples=False, num_triples=2070392), target='tail', other_columns_fixed_ids=(3272, 45))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_kg.trained_model.metric_results.to_df()\n",
    "\n",
    "head = common_drugs[0]\n",
    "relation = 'interacts'\n",
    "\n",
    "pred = predict_target(\n",
    "            model = model_kg.trained_model.model, \n",
    "            head = head, \n",
    "            relation = relation, \n",
    "            triples_factory = model_kg.trained_model.training,\n",
    "        )\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031339778797701"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kg.trained_model.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@10</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hits@10       mrr\n",
       "0  0.000322  0.000313"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrices = dict()\n",
    "metrices['hits@10'] = [model_kg.trained_model.get_metric('hits@10')]\n",
    "metrices['mrr'] = [model_kg.trained_model.get_metric('mrr')]\n",
    "\n",
    "df_result = pd.DataFrame(metrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 3760700609.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a87232afd74c438b90870ccf7b9906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1216 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=512.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4baa2b7e624235a28f470c39294706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/24.7k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 6.40s seconds\n"
     ]
    }
   ],
   "source": [
    "# creating a model\n",
    "result = pipeline(\n",
    "    training=train_sub,\n",
    "    testing=test_sub,\n",
    "    validation=valid_sub,\n",
    "    model='transe',\n",
    "    epochs=1,\n",
    "    evaluator=None,\n",
    "#     device='gpu',\n",
    "#     optimizer='Adam',\n",
    "#     training_kwargs=dict(\n",
    "#         batch_size=32,\n",
    "#         use_tqdm=True\n",
    "# #         num_epochs=2,\n",
    "# #         checkpoint_name='transE_checkpoint.pt',\n",
    "# #         checkpoint_directory='kg_ckeckpoints',\n",
    "# #         checkpoint_frequency=0\n",
    "#     ),\n",
    "#     use_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_10 = result.get_metric('hits@10')\n",
    "hits_at_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save_to_directory(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.datasets import Hetionet, BioKG\n",
    "dataset = Hetionet()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.training.entity_id_to_label.values()\n",
    "for l in labels:\n",
    "    if 'Compound' in l:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline(\n",
    "#     dataset=BioKG,\n",
    "    training=tf_train,\n",
    "    vlidation=tf_valid,\n",
    "    model='ComplEx',\n",
    "    epochs=5,\n",
    "    evaluator=OGBEvaluator(tf_test),\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 1000\n",
    "    },\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs = dict(\n",
    "                lr = 0.001\n",
    "    ),\n",
    "    loss = 'MarginRankingLoss',\n",
    "    device='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.hpo import hpo_pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'optuna': dict(\n",
    "        n_trials=5,\n",
    "    ),\n",
    "    'pipeline': dict(\n",
    "        training = tf_train,\n",
    "        validation = tf_valid,\n",
    "        testing = tf_test,\n",
    "        model='TransR',\n",
    "        model_kwargs_ranges=dict(\n",
    "               embedding_dim=dict(type=int, low=20, high=160, q=20),\n",
    "        ),\n",
    "        optimizer='Adam',\n",
    "        optimizer_kwargs=dict(lr=0.01),\n",
    "        loss='marginranking',\n",
    "        loss_kwargs=dict(margin=1),\n",
    "        training_loop='slcwa',\n",
    "        training_kwargs=dict(num_epochs=100, batch_size=128),\n",
    "        negative_sampler='basic',\n",
    "        negative_sampler_kwargs=dict(num_negs_per_pos=1),\n",
    "        evaluator_kwargs=dict(filtered=True),\n",
    "        evaluation_kwargs=dict(batch_size=128),\n",
    "        stopper='early',\n",
    "        stopper_kwargs=dict(frequency=5, patience=2, relative_delta=0.002),\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result = hpo_pipeline_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_pipeline_result.save_to_directory('hpo_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    \"metadata\": {\n",
    "    \"title\": \"nations - try\",\n",
    "    \"comments\": \"comment\"\n",
    "  },\n",
    "  \"pipeline\": {\n",
    "    \"dataset\": \"nations\",\n",
    "    \"model\": \"TransE\",\n",
    "    \"model_kwargs\": {\n",
    "      \"embedding_dim\": 50,\n",
    "      \"scoring_fct_norm\": 1\n",
    "    },\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"optimizer_kwargs\": {\n",
    "      \"lr\": 0.01\n",
    "    },\n",
    "    \"loss\": \"MarginRankingLoss\",\n",
    "    \"loss_kwargs\": {\n",
    "      \"reduction\": \"mean\",\n",
    "      \"margin\": 1\n",
    "    },\n",
    "    \"training_loop\": \"slcwa\",\n",
    "    \"negative_sampler\": \"basic\",\n",
    "    \"negative_sampler_kwargs\": {\n",
    "      \"num_negs_per_pos\": 1\n",
    "    },\n",
    "    \"training_kwargs\": {\n",
    "      \"num_epochs\": 100,\n",
    "      \"batch_size\": 32\n",
    "    },\n",
    "    \"evaluator_kwargs\": {\n",
    "      \"filtered\": True\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "pipeline_result = pipeline_from_config(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result.metric_results.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset\n",
    "from pykeen.trackers import ResultTracker\n",
    "\n",
    "\n",
    "dataset = get_dataset(dataset=\"nations\")\n",
    "\n",
    "pipeline_result = pipeline(\n",
    "    model='RotatE',\n",
    "    dataset=dataset,\n",
    "    result_tracker=\"console\",\n",
    "    result_tracker_kwargs = dict(metric_filter='.*head.realistic.hits_at_10.*'),\n",
    "    training_kwargs = dict(\n",
    "        num_epochs = 5,\n",
    "        callbacks=\"validation-loss\",\n",
    "        callback_kwargs=dict(\n",
    "            evaluation_triples=dataset.validation.mapped_triples,\n",
    "            prefix=\"validation\",\n",
    "        ),\n",
    "    )    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. This may lead to non-reproducible results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad18a2c4a3464d52b5e1890bfbcbd76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/1214 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/1214 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/1214 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/1214 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/1214 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pykeen.models import TransE\n",
    "from torch.optim import Adam\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "\n",
    "model_name_dict = {'transe': TransE}\n",
    "\n",
    "model = model_name_dict['transe'](triples_factory=train_sub)\n",
    "optimizer = Adam(params=model.get_grad_params())\n",
    "\n",
    "training_loop = SLCWATrainingLoop(\n",
    "    model=model,\n",
    "    triples_factory=train_sub,\n",
    "    optimizer=optimizer,\n",
    " \n",
    ")\n",
    "\n",
    "_ = training_loop.train(\n",
    "    triples_factory=train_sub,\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop.device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f4d63b14a5467e8981e4e18c84d892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/24.7k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m mapped_triples \u001b[38;5;241m=\u001b[39m test_sub\u001b[38;5;241m.\u001b[39mmapped_triples\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_filter_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_sub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_sub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/evaluation/evaluator.py:213\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, model, mapped_triples, batch_size, slice_size, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m# Clear the ranks from the current evaluator\u001b[39;00m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m--> 213\u001b[0m rv \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Since squeeze is true, we can expect that evaluate returns a MetricResult, but we need to tell MyPy that\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(MetricResults, rv)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/evaluation/evaluator.py:687\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, mapped_triples, evaluator, only_size_probing, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets, mode)\u001b[0m\n\u001b[1;32m    685\u001b[0m relation_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[0;32m--> 687\u001b[0m     relation_filter \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# If we only probe sizes we do not need more than one batch\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing \u001b[38;5;129;01mand\u001b[39;00m evaluated_once:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/evaluation/evaluator.py:760\u001b[0m, in \u001b[0;36m_evaluate_batch\u001b[0;34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_batch\u001b[39m(\n\u001b[1;32m    721\u001b[0m     batch: MappedTriples,\n\u001b[1;32m    722\u001b[0m     model: Model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m     mode: Optional[InductiveMode],\n\u001b[1;32m    731\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mBoolTensor:\n\u001b[1;32m    732\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m    Evaluate ranking for batch.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m        The relation filter, which can be re-used for the same batch.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 760\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mfiltered \u001b[38;5;129;01mor\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mrequires_positive_mask:\n\u001b[1;32m    763\u001b[0m         column \u001b[38;5;241m=\u001b[39m TARGET_TO_INDEX[target]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/models/base.py:471\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, hrt_batch, target, full_batch, ids, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_batch:\n\u001b[1;32m    470\u001b[0m         hrt_batch \u001b[38;5;241m=\u001b[39m hrt_batch[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;241m==\u001b[39m LABEL_RELATION:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_batch:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/models/base.py:409\u001b[0m, in \u001b[0;36mModel.predict_t\u001b[0;34m(self, hr_batch, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Enforce evaluation mode\u001b[39;00m\n\u001b[1;32m    408\u001b[0m hr_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_batch(batch\u001b[38;5;241m=\u001b[39mhr_batch, index_relation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 409\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_with_sigmoid:\n\u001b[1;32m    411\u001b[0m     scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(scores)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/models/nbase.py:505\u001b[0m, in \u001b[0;36mERModel.score_t\u001b[0;34m(self, hr_batch, slice_size, mode, tails)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tails \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tails\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    503\u001b[0m     t \u001b[38;5;241m=\u001b[39m parallel_unsqueeze(t, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repeat_if_necessary(\n\u001b[0;32m--> 505\u001b[0m     scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    506\u001b[0m     representations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentity_representations,\n\u001b[1;32m    507\u001b[0m     num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_entity_len(mode\u001b[38;5;241m=\u001b[39mmode) \u001b[38;5;28;01mif\u001b[39;00m tails \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tails\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    508\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py:265\u001b[0m, in \u001b[0;36mInteraction.score\u001b[0;34m(self, h, r, t, slice_size, slice_dim)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores with optional slicing.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m.. note ::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    The scores.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m slice_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    268\u001b[0m     [\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28mself\u001b[39m(h\u001b[38;5;241m=\u001b[39mh_batch, r\u001b[38;5;241m=\u001b[39mr_batch, t\u001b[38;5;241m=\u001b[39mt_batch)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     dim\u001b[38;5;241m=\u001b[39mslice_dim,\n\u001b[1;32m    273\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/modules.py:412\u001b[0m, in \u001b[0;36mFunctionalInteraction.forward\u001b[0;34m(self, h, r, t)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    396\u001b[0m     h: HeadRepresentation,\n\u001b[1;32m    397\u001b[0m     r: RelationRepresentation,\n\u001b[1;32m    398\u001b[0m     t: TailRepresentation,\n\u001b[1;32m    399\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    400\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute broadcasted triple scores given broadcasted representations for head, relation and tails.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, `*dims`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/nn/functional.py:754\u001b[0m, in \u001b[0;36mtranse_interaction\u001b[0;34m(h, r, t, p, power_norm)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranse_interaction\u001b[39m(\n\u001b[1;32m    732\u001b[0m     h: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m    733\u001b[0m     r: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the TransE interaction function.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    :param h: shape: (`*batch_dims`, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnegative_norm_of_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/utils.py:652\u001b[0m, in \u001b[0;36mnegative_norm_of_sum\u001b[0;34m(p, power_norm, *x)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnegative_norm_of_sum\u001b[39m(\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;241m*\u001b[39mx: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m    637\u001b[0m     p: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    638\u001b[0m     power_norm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    639\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    640\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate negative norm of a sum of vectors on already broadcasted representations.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    :param x: shape: (batch_size, num_heads, num_relations, num_tails, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m        The scores.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnegative_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pykeen/utils.py:676\u001b[0m, in \u001b[0;36mnegative_norm\u001b[0;34m(x, p, power_norm)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m(x\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m p)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    645\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py:1517\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1515\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "evaluator = RankBasedEvaluator()\n",
    "\n",
    "# Get triples to test\n",
    "mapped_triples = test_sub.mapped_triples\n",
    "\n",
    "# Evaluate\n",
    "results = evaluator.evaluate(\n",
    "    model=model,\n",
    "    mapped_triples=mapped_triples,\n",
    "    batch_size=1024,\n",
    "    additional_filter_triples=[\n",
    "        train_sub.mapped_triples,\n",
    "        valid_sub.mapped_triples,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.models import TransE\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "from pykeen.triples import TriplesFactory\n",
    "from torch.optim import Adam\n",
    "from pykeen.datasets import Nations\n",
    "\n",
    "def train2():\n",
    "        resolve_device(\"gpu\")\n",
    "        triples_factory = train_sub\n",
    "        model = TransE(\n",
    "            triples_factory=triples_factory,\n",
    "            random_seed=123,\n",
    "        )\n",
    "\n",
    "        optimizer = Adam(params=model.get_grad_params())\n",
    "        training_loop = SLCWATrainingLoop(model=model, triples_factory=triples_factory, optimizer=optimizer)\n",
    "\n",
    "        losses = training_loop.train(\n",
    "            triples_factory=triples_factory,\n",
    "            num_epochs=2,\n",
    "            batch_size=512,\n",
    "#             checkpoint_name=self.model_name + '-' + self.specification + '_checkpoint.pt',     \n",
    "#             checkpoint_frequency=10,\n",
    "#             checkpoint_directory='kg_checkpoints'\n",
    "        )\n",
    "\n",
    "        return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dc4967dad944c891e2eec2671eaa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/607 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/607 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0312737463137267, 0.6153485694964596]\n"
     ]
    }
   ],
   "source": [
    "model, losses = train2()\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filtered setting was enabled, but there were no `additional_filter_triples`\n",
      "given. This means you probably forgot to pass (at least) the training triples. Try:\n",
      "\n",
      "    additional_filter_triples=[dataset.training.mapped_triples]\n",
      "\n",
      "Or if you want to use the Bordes et al. (2013) approach to filtering, do:\n",
      "\n",
      "    additional_filter_triples=[\n",
      "        dataset.training.mapped_triples,\n",
      "        dataset.validation.mapped_triples,\n",
      "    ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba1fc80ec1c44159e7634519c7ab55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/24.7k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = RankBasedEvaluator()\n",
    "results = evaluator.evaluate(model, test_sub.mapped_triples, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002942772989626974"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"results/results-complex_best_pipeline2.2/trained_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"kg_checkpoints/complex-best_pipeline2.2_checkpoint.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ids = torch.as_tensor(tf_train.entities_to_ids([\"DB01558\"]))\n",
    "relation_ids = torch.as_tensor(tf_train.relations_to_ids([\"interacts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB08813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TargetPredictions(df=      tail_id      score  tail_label\n",
       "3693     3693  15.568054     DB06822\n",
       "4805     4805  14.277541     DB14562\n",
       "2614     2614  13.750781     DB00686\n",
       "4196     4196  13.639177     DB11126\n",
       "3958     3958  13.620421     DB09258\n",
       "...       ...        ...         ...\n",
       "7010     7010  -7.504188   FDB013567\n",
       "8985     8985  -7.841544  SMP0000113\n",
       "6839     6839  -7.995562   FDB001014\n",
       "8586     8586  -8.243190      Q14643\n",
       "6840     6840  -9.058373   FDB001131\n",
       "\n",
       "[9981 rows x 3 columns], factory=TriplesFactory(num_entities=9981, num_relations=6, create_inverse_triples=False, num_triples=1167601), target='tail', other_columns_fixed_ids=(3709, 3))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "head = common_drugs[1]\n",
    "print(head)\n",
    "relation = 'interacts'\n",
    "\n",
    "pred = predict_target(\n",
    "            model = model, \n",
    "            head = head, \n",
    "            relation = relation, \n",
    "            triples_factory = tf_train,\n",
    "        )\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8343f1c295490ad08729f17064e1ab8ac071c711efe2732632787d24e0261b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
