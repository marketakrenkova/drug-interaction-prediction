{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c65a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fdb1d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dir = '../predictions/'\n",
    "triplets_dir = '../data/triplets/'\n",
    "drugbank_dir = '../data/drugbank/'\n",
    "specification = 'best_pipeline4-run2'\n",
    "data_dir = '/drugbank/'\n",
    "food_compounds_names_path = '../data/triplets/compounds_names.tsv'\n",
    "model_name = 'rotate_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06a3a9",
   "metadata": {},
   "source": [
    "### Create id - name mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "61395743",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_name_map = pd.read_csv(drugbank_dir + 'drug_id_name_map.csv', sep=',', index_col=[0])\n",
    "food_name_map = pd.read_csv(triplets_dir + 'food_name.tsv', sep='\\t', index_col=[0])\n",
    "food_compound_map = pd.read_csv(triplets_dir + 'compounds_names.tsv', sep='\\t', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8a368210",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_ids = drug_name_map.id\n",
    "drug_names = drug_name_map.drug_name\n",
    "drug_id_map_dict = dict(zip(drug_ids, drug_names))\n",
    "\n",
    "food_ids = food_name_map.public_id\n",
    "food_names = food_name_map.name\n",
    "food_id_map_dict = dict(zip(food_ids, food_names))\n",
    "\n",
    "compound_ids = food_compound_map.compound_id\n",
    "compound_names = food_compound_map.name\n",
    "compound_id_map_dict = dict(zip(compound_ids, compound_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca606e",
   "metadata": {},
   "source": [
    "### Load drugs and foods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aa174626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DB01006  ',\n",
       " 'DB00642',\n",
       " 'DB00544',\n",
       " 'DB00661',\n",
       " 'DB00441',\n",
       " 'DB01101',\n",
       " 'DB00563',\n",
       " 'DB00958',\n",
       " 'DB01217',\n",
       " 'DB00531']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common_drugs = pd.read_csv('../data/common_drugs_num_interactions.csv', sep=';')\n",
    "common_drugs = pd.read_csv('../data/drugs4prediction.csv', sep=';')\n",
    "common_drugs = common_drugs.dropna()\n",
    "common_drugs_ids = common_drugs.db_id.values\n",
    "\n",
    "common_drugs_ids = list(set(common_drugs_ids))\n",
    "common_drugs_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d022f37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FOOD00055',\n",
       " 'FOOD00255',\n",
       " 'FOOD00256',\n",
       " \"St. John's Wort\",\n",
       " 'FOOD00181',\n",
       " 'Dandelion',\n",
       " \"Cat's claw\",\n",
       " 'Nettle',\n",
       " 'Cordyceps',\n",
       " 'Reishi Mushroom']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/foods4predictions-2.txt', 'r') as f:\n",
    "    foods = f.readlines()\n",
    "\n",
    "foods = [food.strip() for food in foods]\n",
    "foods[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e674c377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dandelion'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_id_map_dict[foods[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ffa5f",
   "metadata": {},
   "source": [
    "### Load predictions for specific drug/food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7633811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(prediction_file):\n",
    "    try:\n",
    "        predictions = pd.read_csv(prediction_file, sep=',', index_col=[0])\n",
    "    except:\n",
    "        return None\n",
    "    # keep just drug/food/food compound predictions\n",
    "    predictions['node_type'] = list(itertools.repeat('xxx', predictions.shape[0]))\n",
    "    predictions.loc[predictions['tail_label'].str.contains(\"DB\\d+\", regex=True), 'node_type'] = \"drug\"\n",
    "    predictions.loc[predictions['tail_label'].str.contains(\"FDB\"), 'node_type'] = \"food_compound\"\n",
    "    predictions.loc[predictions['tail_label'].str.contains(\"FOOD\"), 'node_type'] = \"food\"\n",
    "    predictions = predictions.loc[predictions['node_type'] != 'xxx']\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# assign entity names to ids\n",
    "def assign_names(predictions, show=False):\n",
    "    tail_names = []\n",
    "    for row in predictions.iterrows():\n",
    "        tail = row[1].tail_label\n",
    "        node_type = row[1].node_type\n",
    "\n",
    "        if node_type == 'drug':\n",
    "            tail_name = drug_id_map_dict.get(tail, tail)\n",
    "        elif node_type == 'food':\n",
    "            tail_name = food_id_map_dict.get(tail, tail)\n",
    "        else:\n",
    "            tail_name = compound_id_map_dict.get(tail, tail)\n",
    "\n",
    "        if show:\n",
    "            print(tail, tail_name)    \n",
    "        tail_names.append(tail_name)\n",
    "    return tail_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c0e67f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions with Cyclophosphamide\n",
      "       tail_id       score tail_label  in_validation  in_testing node_type\n",
      "5675      5675 -105.695244    DB04836          False       False      drug\n",
      "3235      3235 -105.768951    DB00054          False       False      drug\n",
      "3529      3529 -105.810745    DB00357          False       False      drug\n",
      "3571      3571 -105.848656    DB00400          False       False      drug\n",
      "4182      4182 -105.881790    DB01015          False       False      drug\n",
      "3589      3589 -105.918869    DB00418          False       False      drug\n",
      "3562      3562 -105.930542    DB00391          False       False      drug\n",
      "3598      3598 -106.036926    DB00427          False       False      drug\n",
      "10868    10868 -106.067764    DB14568          False       False      drug\n",
      "4198      4198 -106.214905    DB01032          False       False      drug\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drug predictions\n",
    "drug_id = common_drugs_ids[9]\n",
    "prediction_file = prediction_dir + specification + data_dir + model_name + drug_id + '_interacts_' + specification + '.csv'\n",
    "\n",
    "print('Interactions with', drug_id_map_dict[drug_id])\n",
    "\n",
    "predictions = get_predictions(prediction_file)\n",
    "print(predictions.head(10))\n",
    "print()\n",
    "_ = assign_names(predictions, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "db1f61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tails = predictions.tail_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bb88138b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions with Grapefruit\n",
      "       tail_id       score tail_label  in_validation  in_testing node_type\n",
      "3739      3739 -107.699249    DB00570          False       False      drug\n",
      "4292      4292 -107.819351    DB01128          False       False      drug\n",
      "3439      3439 -108.764252    DB00266          False       False      drug\n",
      "10463    10463 -108.867500    DB13884          False       False      drug\n",
      "3773      3773 -108.982513    DB00604          False       False      drug\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Vinblastine',\n",
       " 'Bicalutamide',\n",
       " 'Dicoumarol',\n",
       " 'Albutrepenonacog alfa',\n",
       " 'Cisapride',\n",
       " 'Heparin',\n",
       " 'Teniposide',\n",
       " 'Cephalexin',\n",
       " 'Phenprocoumon',\n",
       " 'Doxorubicin',\n",
       " 'Theophylline',\n",
       " 'Doxazosin',\n",
       " 'Erlotinib',\n",
       " 'Pretomanid',\n",
       " 'Tamoxifen',\n",
       " 'Eucalyptus oil',\n",
       " 'Bortezomib',\n",
       " 'Drotrecogin alfa',\n",
       " 'Prednisone',\n",
       " 'Primaquine',\n",
       " 'Cabergoline',\n",
       " 'Atorvastatin',\n",
       " 'Cerivastatin',\n",
       " 'Reteplase',\n",
       " 'Nateglinide',\n",
       " 'Sildenafil',\n",
       " 'Tolbutamide',\n",
       " 'Irinotecan',\n",
       " 'Argatroban',\n",
       " 'Aminophenazone',\n",
       " 'Perhexiline',\n",
       " 'Methotrexate',\n",
       " 'Docetaxel',\n",
       " 'Carboplatin',\n",
       " 'Esomeprazole',\n",
       " 'Lovastatin',\n",
       " 'Fentanyl',\n",
       " 'Methysergide',\n",
       " 'Digitoxin',\n",
       " 'Pentoxifylline',\n",
       " 'Dabrafenib',\n",
       " 'Cefpirome',\n",
       " 'Lumiracoxib',\n",
       " 'Capecitabine',\n",
       " 'Vindesine',\n",
       " 'Zidovudine',\n",
       " 'Cefoxitin',\n",
       " 'Synthetic Conjugated Estrogens, B',\n",
       " 'Pantoprazole',\n",
       " 'Anakinra',\n",
       " 'Urokinase',\n",
       " 'Selenium',\n",
       " 'Carbamazepine',\n",
       " 'Saquinavir',\n",
       " 'Cefamandole',\n",
       " 'Epoprostenol',\n",
       " 'Vorapaxar',\n",
       " 'Desogestrel',\n",
       " 'Rolapitant',\n",
       " 'Propranolol',\n",
       " 'Voriconazole',\n",
       " 'Levacetylmethadol',\n",
       " 'Alprazolam',\n",
       " 'Paclitaxel',\n",
       " 'Dronabinol',\n",
       " 'Sorafenib',\n",
       " 'Etodolac',\n",
       " 'Ibuprofen',\n",
       " 'Repaglinide',\n",
       " 'Ipecac',\n",
       " 'Imatinib',\n",
       " 'Clobazam',\n",
       " 'Clonazepam',\n",
       " 'Alteplase',\n",
       " 'Telmisartan',\n",
       " 'Celiprolol',\n",
       " 'Hydroxyurea',\n",
       " 'Inositol',\n",
       " 'Amoxicillin',\n",
       " 'Itraconazole',\n",
       " 'Montelukast',\n",
       " 'Fenofibrate',\n",
       " 'Ketoprofen',\n",
       " 'Dipyridamole',\n",
       " 'Dexlansoprazole',\n",
       " 'Oxyphenbutazone',\n",
       " 'Nitrendipine',\n",
       " 'Olaparib',\n",
       " 'Oxycodone',\n",
       " 'Ceftolozane',\n",
       " 'Nefazodone',\n",
       " 'Anistreplase',\n",
       " 'Everolimus',\n",
       " 'Brivaracetam',\n",
       " 'Progesterone',\n",
       " 'Midazolam',\n",
       " 'Methimazole']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# food predicitons\n",
    "idx=2\n",
    "food_id = foods[idx]\n",
    "prediction_file = prediction_dir + specification + data_dir + model_name + food_id + '_interacts_' + specification + '.csv'\n",
    "\n",
    "food_name = food_id\n",
    "if \"FOOD\" in food_id:\n",
    "    food_name = food_id_map_dict[food_id]\n",
    "print('Interactions with', food_name)\n",
    "\n",
    "predictions = get_predictions(prediction_file)\n",
    "print(predictions.head())\n",
    "print()\n",
    "assign_names(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a17d2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if the predicted drug/food is in different interaction with the same drug in the training data\n",
    "def check_known_triplets(idx, snd_idx, data):\n",
    "    \n",
    "    run = 'run2/'\n",
    "    \n",
    "    train_triplets = pd.read_csv(triplets_dir + run + 'train_' + data + '.tsv', sep='\\t', index_col=[0])\n",
    "    valid_triplets = pd.read_csv(triplets_dir + run + 'valid_' + data + '.tsv', sep='\\t', index_col=[0])\n",
    "    test_triplets = pd.read_csv(triplets_dir + run + 'test_' + data + '.tsv', sep='\\t', index_col=[0])\n",
    "\n",
    "    filtered_triplets = train_triplets.loc[train_triplets.index == idx]\n",
    "    in_train = filtered_triplets.loc[filtered_triplets['tail'] == snd_idx].any().sum()\n",
    "\n",
    "    filtered_triplets = valid_triplets.loc[valid_triplets.index == idx]\n",
    "    in_valid = filtered_triplets.loc[filtered_triplets['tail'] == snd_idx].any().sum()\n",
    "\n",
    "    filtered_triplets = test_triplets.loc[test_triplets.index == idx]\n",
    "    in_test = filtered_triplets.loc[filtered_triplets['tail'] == snd_idx].any().sum()\n",
    "\n",
    "#     print(f'Relation in triplets:')\n",
    "#     print(f'- train:', 'yes' if in_train else 'no')\n",
    "#     print(f'- valid:', 'yes' if in_valid else 'no')\n",
    "#     print(f'- test:', 'yes' if in_test else 'no')\n",
    "\n",
    "    in_triplets = in_train or in_valid or in_test\n",
    "\n",
    "    # find also symetric relations\n",
    "    filtered_triplets = train_triplets.loc[train_triplets.index == snd_idx]\n",
    "    in_train = filtered_triplets.loc[filtered_triplets['tail'] == idx].any().sum()\n",
    "\n",
    "    filtered_triplets = valid_triplets.loc[valid_triplets.index == snd_idx]\n",
    "    in_valid = filtered_triplets.loc[filtered_triplets['tail'] == idx].any().sum()\n",
    "\n",
    "    filtered_triplets = test_triplets.loc[test_triplets.index == snd_idx]\n",
    "    in_test = filtered_triplets.loc[filtered_triplets['tail'] == idx].any().sum()\n",
    "\n",
    "#     print(f'Symetric relation in triplets:')\n",
    "#     print(f'- train:', 'yes' if in_train else 'no')\n",
    "#     print(f'- valid:', 'yes' if in_valid else 'no')\n",
    "#     print(f'- test:', 'yes' if in_test else 'no')\n",
    "    \n",
    "    if in_triplets or in_train or in_valid or in_test:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b2c5e83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: DB01217 interacts with DB01062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'drugbank'\n",
    "idx = 'DB01217'\n",
    "snd_idx = 'DB01062'\n",
    "print('Prediction:', idx, 'interacts with', snd_idx)\n",
    "check_known_triplets(idx, snd_idx, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a5389",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1cd2481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_predictions_k(common_drugs_ids, prediction_dir, specification, model_name, data_dir, run, triplets_dir, k=10):\n",
    "    relevant = []\n",
    "    \n",
    "\n",
    "    data = data_dir.replace('/', '')\n",
    "\n",
    "    valid_triplets = pd.read_csv(triplets_dir + run + 'valid_' + data + '.tsv', sep='\\t', index_col=[0])\n",
    "    test_triplets = pd.read_csv(triplets_dir + run + 'test_' + data + '.tsv', sep='\\t', index_col=[0])\n",
    "    \n",
    "    valid_triplets2 = valid_triplets.reset_index().set_index('tail')\n",
    "    test_triplets2 = test_triplets.reset_index().set_index('tail')\n",
    "\n",
    "    for drug in common_drugs_ids:\n",
    "        prediction_file = prediction_dir + specification + data_dir + model_name + drug + '_interacts_' + specification + '.csv'\n",
    "        preds = get_predictions(prediction_file)\n",
    "        \n",
    "        if preds is None:\n",
    "            continue\n",
    "        \n",
    "        # we are intersested only in first k predictions\n",
    "        preds = preds.head(k)\n",
    "\n",
    "        in_valid_count = 0\n",
    "        in_test_count = 0\n",
    "        \n",
    "        tails = preds.tail_label.values\n",
    "\n",
    "        filtered_triplets_valid = valid_triplets.loc[valid_triplets.index == drug]\n",
    "        filtered_triplets_test = test_triplets.loc[test_triplets.index == drug]\n",
    "        \n",
    "\n",
    "        # count triplets (drug, interacts, tail_id) that are in validation/testing dataset\n",
    "        for tail_id in tails:\n",
    "            if filtered_triplets_valid.loc[filtered_triplets_valid['tail'] == tail_id].any().sum() > 0:\n",
    "                in_valid_count += 1\n",
    "            if filtered_triplets_test.loc[filtered_triplets_test['tail'] == tail_id].any().sum() > 0:\n",
    "                in_test_count += 1\n",
    "        \n",
    "        # check also symmetric triplets\n",
    "        filtered_triplets_valid2 = valid_triplets2.loc[valid_triplets2.index == drug]\n",
    "        filtered_triplets_test2 = test_triplets2.loc[test_triplets2.index == drug]\n",
    "\n",
    "        # count triplets (drug, interacts, tail_id) that are in validation/testing dataset\n",
    "        for tail_id in tails:\n",
    "            if filtered_triplets_valid2.loc[filtered_triplets_valid2['head'] == tail_id].any().sum() > 0:\n",
    "                in_valid_count += 1\n",
    "            if filtered_triplets_test2.loc[filtered_triplets_test2['head'] == tail_id].any().sum() > 0:\n",
    "                in_test_count += 1\n",
    "\n",
    "        relevant.append((in_valid_count + in_test_count)/k)\n",
    "\n",
    "#     print(f'Avg. percentage of relevant triplets for first {k} predictions: {np.mean(relevant)}')\n",
    "#     print(f'Max. percentage of relevant triplets for first {k} predictions: {np.max(relevant)}')\n",
    "#     print(f'Min. percentage of relevant triplets for first {k} predictions: {np.min(relevant)}')\n",
    "    \n",
    "    return np.mean(relevant)\n",
    "\n",
    "\n",
    "# relevant_predictions_k(common_drugs_ids, prediction_dir, specification + 'run2', model_name, data_dir, 'run2/', triplets_dir, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "52e4531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotate_ /interactions/: 0.8666666666666667\n",
      "rotate_ /drugbank/: 0.8222222222222223\n",
      "rotate_ /hetionet/: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotate_ /biokg/: nan\n",
      "complex_ /interactions/: 0.6499999999999999\n",
      "complex_ /drugbank/: 0.5166666666666667\n",
      "complex_ /hetionet/: 0.8527777777777779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex_ /biokg/: nan\n"
     ]
    }
   ],
   "source": [
    "runs = ['run1', 'run2', 'run3']\n",
    "specification = 'best_pipeline4-'\n",
    "data_dirs = ['/interactions/', '/drugbank/', '/hetionet/', '/biokg/']\n",
    "model_names = ['rotate_', 'complex_']\n",
    "\n",
    "for model_name in model_names:\n",
    "    for data_dir in data_dirs:\n",
    "        rel_10_list = []\n",
    "        for run in runs:\n",
    "            \n",
    "#             rel1 = relevant_predictions_k(common_drugs_ids, prediction_dir, specification + run, model_name, data_dir, run + '/', triplets_dir, 1)\n",
    "            rel10 = relevant_predictions_k(common_drugs_ids, prediction_dir, specification + run, model_name, data_dir, run + '/', triplets_dir, 10)\n",
    "#             rel20 = relevant_predictions_k(common_drugs_ids, prediction_dir, specification + run, model_name, data_dir, run + '/', triplets_dir, 20)\n",
    "#             rel100 = relevant_predictions_k(common_drugs_ids, prediction_dir, specification + run, model_name, data_dir, run + '/', triplets_dir, 100)\n",
    "\n",
    "            rel_10_list.append(rel10)\n",
    "                \n",
    "        print(f\"{model_name} {data_dir}: {np.mean(rel_10_list)}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63eccce",
   "metadata": {},
   "source": [
    "### Human evaluation\n",
    "Transform the predictions into a human readable form (id -> name), so a human can decide if the predictions make sense (based on some medical knowledge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfc1fb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(116, tail_id                116\n",
      "score           -33.843025\n",
      "tail_label         DB00122\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 116, dtype: object), (194, tail_id                194\n",
      "score           -33.889561\n",
      "tail_label         DB00233\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 194, dtype: object), (145, tail_id                145\n",
      "score           -33.965977\n",
      "tail_label         DB00180\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 145, dtype: object), (243, tail_id                243\n",
      "score           -33.966263\n",
      "tail_label         DB00287\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 243, dtype: object), (185, tail_id                185\n",
      "score           -34.103146\n",
      "tail_label         DB00223\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 185, dtype: object), (1645, tail_id               1645\n",
      "score           -34.206009\n",
      "tail_label         DB08889\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             drug\n",
      "Name: 1645, dtype: object), (2584, tail_id               2584\n",
      "score           -34.206139\n",
      "tail_label       FOOD00256\n",
      "in_validation        False\n",
      "in_testing           False\n",
      "node_type             food\n",
      "Name: 2584, dtype: object), (115, tail_id               115\n",
      "score           -34.25753\n",
      "tail_label        DB00120\n",
      "in_validation       False\n",
      "in_testing          False\n",
      "node_type            drug\n",
      "Name: 115, dtype: object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_human_all = pd.DataFrame()\n",
    "\n",
    "for drug_id in common_drugs_ids:\n",
    "    prediction_file = prediction_dir + specification + data_dir + model_name + drug_id + '_interacts_' + specification + '.csv'\n",
    "#     prediction_file = prediction_dir + specification + data_dir + 'common_preds/common_preds_' + drug_id + '.csv'\n",
    "    predictions = get_predictions(prediction_file)\n",
    "    \n",
    "    if predictions is None:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    # filter out known triplets \n",
    "    for row in predictions.iterrows():\n",
    "        snd_idx = row[1].tail_label\n",
    "        known_triplet = check_known_triplets(drug_id, snd_idx, 'interactions')\n",
    "        \n",
    "        # TODO: opravit\n",
    "        if known_triplet:\n",
    "            predictions.drop(row[0])\n",
    "  \n",
    "        \n",
    "    predictions_human = pd.DataFrame()\n",
    "    k = 10\n",
    "    \n",
    "    predictions = predictions.head(k)\n",
    "    drug_name = drug_id_map_dict[drug_id]\n",
    "    tail_names = assign_names(predictions)\n",
    "    \n",
    "    predictions_human['drug1'] = list(itertools.repeat(drug_name, k))\n",
    "    predictions_human['drug1_id'] = list(itertools.repeat(drug_id, k))\n",
    "    predictions_human['relation'] = list(itertools.repeat('interacts', k))\n",
    "    predictions_human['drug2'] = tail_names\n",
    "    predictions_human['drug2_id'] = predictions.tail_label.values\n",
    "    \n",
    "    predictions_human_all = pd.concat([predictions_human_all, predictions_human])\n",
    "\n",
    "predictions_human_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0fb2891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_human_all_food = pd.DataFrame()\n",
    "\n",
    "for food_id in foods:\n",
    "    prediction_file = prediction_dir + specification + data_dir + model_name + food_id + '_interacts_' + specification + '.csv'\n",
    "#     prediction_file = prediction_dir + specification + data_dir + 'common_preds/common_preds_' + food_id + '.csv'\n",
    "\n",
    "    predictions = get_predictions(prediction_file)\n",
    "    \n",
    "    if predictions is None or predictions.shape[0] == 0:\n",
    "        continue\n",
    "    \n",
    "    # filter out known triplets \n",
    "    for row in predictions.iterrows():\n",
    "        snd_idx = row[1].tail_label\n",
    "        known_triplet = check_known_triplets(drug, snd_idx, 'interactions')\n",
    "        \n",
    "        if known_triplet:\n",
    "            predictions.drop(row[0])\n",
    "            \n",
    "    \n",
    "    predictions_human = pd.DataFrame()\n",
    "    k = predictions.shape[0]\n",
    "    \n",
    "    predictions = predictions.drop(predictions[predictions.node_type != 'drug'].index)\n",
    "    \n",
    "    if k > 10:\n",
    "        k = 10\n",
    "        predictions = predictions.head(k)\n",
    "\n",
    "    \n",
    "    if 'FDB' in food_id:\n",
    "        food_name = compound_id_map_dict[food_id]\n",
    "    elif 'FOOD' in food_id:\n",
    "        food_name = food_id_map_dict[food_id]\n",
    "    else:\n",
    "        food_name = food_id\n",
    "    tail_names = assign_names(predictions)\n",
    "    \n",
    "    predictions_human['food'] = list(itertools.repeat(food_name, k))\n",
    "    predictions_human['food_id'] = list(itertools.repeat(food_id, k))\n",
    "    predictions_human['relation'] = list(itertools.repeat('interacts', k))\n",
    "    predictions_human['drug2'] = tail_names\n",
    "    predictions_human['drug2_id'] = predictions.tail_label.values\n",
    "    \n",
    "    predictions_human_all_food = pd.concat([predictions_human_all_food, predictions_human])\n",
    "\n",
    "predictions_human_all_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ecf817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_human_all.to_csv(prediction_dir + \"predictions_human_all_interactions_drugs.csv\")\n",
    "predictions_human_all_food.to_csv(prediction_dir + \"predictions_human_all_interactions_foods.csv\")\n",
    "\n",
    "# predictions_human_all.to_csv(prediction_dir + \"predictions_human_all_drugbank_drugs.csv\")\n",
    "# predictions_human_all_food.to_csv(prediction_dir + \"predictions_human_all_drugbank_foods.csv\")\n",
    "\n",
    "# predictions_human_all.to_csv(prediction_dir + \"predictions_human_all_drugs_common_interactions.csv\")\n",
    "# predictions_human_all_food.to_csv(prediction_dir + \"predictions_human_all_foods_common_interactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64053b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find foods for each food compound in predictions_human_all_food\n",
    "food_compound_map = pd.read_csv(triplets_dir + 'food_compound.tsv', sep='\\t', index_col=[0])\n",
    "\n",
    "compound_to_food = {}\n",
    "\n",
    "for index, row in food_compound_map.iterrows():\n",
    "    compound_id = row['compound_id']\n",
    "    food_id = row['food_id']\n",
    "    \n",
    "    if compound_id not in compound_to_food:\n",
    "        compound_to_food[compound_id] = [food_id_map_dict[food_id]]\n",
    "    else:\n",
    "        compound_to_food[compound_id].append(food_id_map_dict[food_id])\n",
    "        \n",
    "compound_to_food\n",
    "\n",
    "# TODO: sort by an amount of a comound in a food (take first x) ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prediction_dir + 'compound_to_food.json', 'w') as f:\n",
    "    json.dump(compound_to_food, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e9f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(triplets_dir + 'train_' + 'drugbank' + '.tsv', sep='\\t')\n",
    "valid = pd.read_csv(triplets_dir + 'valid_' + 'drugbank' + '.tsv', sep='\\t')\n",
    "test = pd.read_csv(triplets_dir + 'test_' + 'drugbank' + '.tsv', sep='\\t')\n",
    "\n",
    "# find leaked triplets in test data\n",
    "num_leaked_triplets = 0\n",
    "for row in train.iterrows():\n",
    "    h = row[1].values[0]\n",
    "    t = row[1].values[2]\n",
    "    tmp = test.loc[test['head'] == h]\n",
    "    leaked = tmp.loc[test['tail'] == t].any().sum()\n",
    "    num_leaked_triplets += leaked\n",
    "    if leaked:\n",
    "        print('Same:',row[1].values)\n",
    "    \n",
    "    tmp = test.loc[test['tail'] == h]\n",
    "    leaked = tmp.loc[test['head'] == t].any().sum()\n",
    "    num_leaked_triplets += leaked\n",
    "    if leaked:\n",
    "        print('Inversed:', row[1].values)\n",
    "\n",
    "num_leaked_triplets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1990469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciton analysis - search them in test/valid data\n",
    "\n",
    "list_of_predictions = [\n",
    "    [('DB00563', 'DB00330'), ('DB00563', 'DB00515'), ('DB00563', 'DB00530'), ('DB00563', 'DB00007'), ('DB00563', 'DB00279'), ('DB00563', 'DB00063'),\n",
    "('DB00563', 'DB00436'), ('DB00563', 'DB00201'), ('DB00563', 'DB00479'), ('DB00563', 'DB00065')],\n",
    "    [('DB00642', 'DB00365'), ('DB00642', 'DB00289'), ('DB00642', 'DB00461'), ('DB00642', 'DB00059'), ('DB00642', 'DB00573'), ('DB00642', 'DB00330'), ('DB00642', 'DB00095'), ('DB00642', 'DB00245'), ('DB00642', 'DB00074'), ('DB00642', 'DB00537')],\n",
    "    [('DB00441', 'DB00225'), ('DB00441', 'DB00193'), ('DB00441', 'DB00017'), ('DB00441', 'DB00327'), ('DB00441', 'DB00322'), ('DB00441', 'DB00262'), ('DB00441', 'DB00007'), ('DB00441', 'DB00227'), ('DB00441', 'DB00198'), ('DB00441', 'DB00276')],\n",
    "    [('DB01101', 'DB00853'), ('DB01101', 'DB00576'), ('DB01101', 'DB00675'), ('DB01101', 'DB00812'), ('DB01101', 'DB00888'), ('DB01101', 'DB00731'), ('DB01101', 'DB00700'), ('DB01101', 'DB00829'), ('DB01101', 'DB00936'), ('DB01101', 'DB00498')],\n",
    "    [('DB00958', 'DB00547'), ('DB00958', 'DB00006'), ('DB00958', 'DB00583'), ('DB00958', 'DB00428'), ('DB00958', 'DB00499'), ('DB00958', 'DB00789'), ('DB00958', 'DB00229'), ('DB00958', 'DB00477'), ('DB00958', 'DB00661'), ('DB00958', 'DB00035')],\n",
    "    [('DB01229', 'DB00227'), ('DB01229', 'DB00999'), ('DB01229', 'DB00714'), ('DB01229', 'DB00734'), ('DB01229', 'DB00857'), ('DB01229', 'DB00875'), ('DB01229', 'DB01261'), ('DB01229', 'DB00717'), ('DB01229', 'DB00722'), ('DB01229', 'DB00968')],\n",
    "    [('DB00531', 'DB00224'), ('DB00531', 'DB00054'), ('DB00531', 'DB00391'), ('DB00531', 'DB00514'), ('DB00531', 'DB00286'), ('DB00531', 'DB00087'), ('DB00531', 'DB00490'), ('DB00531', 'DB00357'), ('DB00531', 'DB00361'), ('DB00531', 'DB00071')],\n",
    "    [('DB00544', 'DB00075'), ('DB00544', 'DB00307'), ('DB00544', 'DB00526'), ('DB00544', 'DB00495'), ('DB00544', 'DB00354'), ('DB00544', 'DB00382'), ('DB00544', 'DB00206'), ('DB00544', 'DB00363'), ('DB00544', 'DB00218'), ('DB00544', 'DB00433')],\n",
    "    [('DB01217', 'DB01073'), ('DB01217', 'DB01167'), ('DB01217', 'DB00613'), ('DB01217', 'DB00338'), ('DB01217', 'DB01047'), ('DB01217', 'DB00374'), ('DB01217', 'DB00762'), ('DB01217', 'DB00394'), ('DB01217', 'DB00056'), ('DB01217', 'DB00862')],\n",
    "\n",
    "    [('DB00682', 'DB00445'), ('DB00682', 'DB00479'), ('DB00682', 'DB00455'), ('DB00682', 'DB00307'), ('DB00682', 'DB00258'), ('DB00682', 'DB00391'), ('DB00682', 'DB00487'), ('DB00682', 'DB00006'), ('DB00682', 'DB00197'), ('DB00682', 'DB00620')],\n",
    "    [('DB00661', 'DB00345'), ('DB00661', 'DB00208'), ('DB00661', 'DB00041'), ('DB00661', 'DB00299'), ('DB00661', 'DB00470'), ('DB00661', 'DB00444'), ('DB00661', 'DB00624'), ('DB00661', 'DB00648'), ('DB00661', 'DB00344'), ('DB00661', 'DB00297')],\n",
    "\n",
    "]\n",
    "\n",
    "for l in list_of_predictions:\n",
    "    count = 0\n",
    "    for pred in l:\n",
    "        count += check_known_triplets(pred[0], pred[1], 'drugbank')\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00207b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
